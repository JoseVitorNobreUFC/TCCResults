CODE
"export function tokenize(input: string): Tok[] {\nconst toks: Tok[] = [];\nlet i = 0;\nconst n = input.length;\nconst peek = () => input[i] ?? '';\nconst advance = () => input[i++];\nconst readWord = () => {\nlet s = '';\nwhile (i < n && isIdent(peek())) s += advance();\nreturn s;\n};\nconst readPhrase = () => {\nadvance();\nlet s = '';\nwhile (i < n) {\nconst c = advance();\nif (c === ```) break;\nif (c === '\\' && i < n) {\nconst next = advance();\ns += next;\n} else {\ns += c;\n}\n}\nreturn s;\n};\nwhile (i < n) {\nconst c = peek();\nif (isSpace(c)) {\ni++;\ncontinue;\n}\nif (c === '(') {\ntoks.push({ kind: 'LPAREN' });\ni++;\ncontinue;\n}\nif (c === ')') {\ntoks.push({ kind: 'RPAREN' });\ni++;\ncontinue;\n}\nif (c === ':') {\ntoks.push({ kind: 'COLON' });\ni++;\ncontinue;\n}\nif (c === ```) {\nconst text = readPhrase();\ntoks.push({ kind: 'PHRASE', text });\ncontinue;\n}\nif (c === '-') {\ntoks.push({ kind: 'MINUS' });\ni++;\ncontinue;\n}\nif (isIdent(c)) {\nconst w = readWord();\nconst upper = w.toUpperCase();\nif (upper === 'AND') toks.push({ kind: 'AND' });\nelse if (upper === 'OR') toks.push({ kind: 'OR' });\nelse if (upper === 'NOT') toks.push({ kind: 'NOT' });\nelse toks.push({ kind: 'WORD', text: w });\ncontinue;\n}\ni++;\n}\ntoks.push({ kind: 'EOF' });\nreturn toks;\n}"
"export function tokenize(input: string): Tok[] {\nconst toks: Tok[] = [];\nlet i = 0;\nconst n = input.length;\nconst peek = () => input[i] ?? '';\nconst advance = () => input[i++];\nconst readWord = () => {\nlet s = '';\nwhile (i < n && isIdent(peek())) s += advance();\nreturn s;\n};\nconst readPhrase = () => {\nadvance();\nlet s = '';\nwhile (i < n) {\nconst c = advance();\nif (c === ```) break;\nif (c === '\\' && i < n) {\nconst next = advance();\ns += next;\n} else {\ns += c;\n}\n}\nreturn s;\n};\nwhile (i < n) {\nconst c = peek();\nif (isSpace(c)) {\ni++;\ncontinue;\n}\nif (c === '(') {\ntoks.push({ kind: 'LPAREN' });\ni++;\ncontinue;\n}\nif (c === ')') {\ntoks.push({ kind: 'RPAREN' });\ni++;\ncontinue;\n}\nif (c === ':') {\ntoks.push({ kind: 'COLON' });\ni++;\ncontinue;\n}\nif (c === ```) {\nconst text = readPhrase();\ntoks.push({ kind: 'PHRASE', text });\ncontinue;\n}\nif (c === '-') {\ntoks.push({ kind: 'MINUS' });\ni++;\ncontinue;\n}\nif (isIdent(c)) {\nconst w = readWord();\nconst upper = w.toUpperCase();\nif (upper === 'AND') toks.push({ kind: 'AND' });\nelse if (upper === 'OR') toks.push({ kind: 'OR' });\nelse if (upper === 'NOT') toks.push({ kind: 'NOT' });\nelse toks.push({ kind: 'WORD', text: w });\ncontinue;\n}\ni++;\n}\ntoks.push({ kind: 'EOF' });\nreturn toks;\n}"
"private parsePrimaryOrField(): Ast {\nif (this.at('LPAREN')) {\nthis.advance();\nconst inside = this.parseOr();\nthis.advance();\nreturn inside;\n}\nif (this.at('PHRASE')) {\nconst t = this.advance() as Extract<Tok, { kind: 'PHRASE' }>;\nreturn { type: 'Phrase', value: t.text };\n}\nif (this.at('WORD')) {\nconst wordTok = this.advance() as Extract<Tok, { kind: 'WORD' }>;\nif (this.at('COLON')) {\nthis.advance();\nlet value: string;\nif (this.at('PHRASE')) {\nconst p = this.advance() as Extract<Tok, { kind: 'PHRASE' }>;\nvalue = p.text;\n} else if (this.at('WORD')) {\nconst w = this.advance() as Extract<Tok, { kind: 'WORD' }>;\nvalue = w.text;\n} else {\nconst t = this.advance();\nvalue = tokText(t);\n}\nreturn { type: 'Field', field: wordTok.text, value };\n}\nreturn { type: 'Term', value: wordTok.text };\n}\nconst w = this.advance() as Extract<Tok, { kind: 'WORD' }>;\nreturn { type: 'Phrase', value: 'text' in w ? w.text : '' };\n}"
"export function twig({\nbase,\nenvironmentVariables,\ncompletionOptions,\nautocomplete,\nonClickVariable,\nonClickMissingVariable,\nextraExtensions,\n}: {\nbase: LanguageSupport;\nenvironmentVariables: WrappedEnvironmentVariable[];\ncompletionOptions: TwigCompletionOption[];\nautocomplete?: GenericCompletionConfig;\nonClickVariable: (option: WrappedEnvironmentVariable, tagValue: string, startPos: number) => void;\nonClickMissingVariable: (name: string, tagValue: string, startPos: number) => void;\nonClickPathParameter: (name: string) => void;\nextraExtensions: Extension[];\n}) {\nconst language = mixLanguage(base);\nconst variableOptions: TwigCompletionOption[] =\nenvironmentVariables.map((v) => ({\nname: v.variable.name,\nvalue: v.variable.value,\ntype: 'variable',\nlabel: v.variable.name,\ndescription: `Inherited from ${v.source}`,\nonClick: (rawTag: string, startPos: number) => onClickVariable(v, rawTag, startPos),\n})) ?? [];\nconst options = [...variableOptions, ...completionOptions];\nconst completions = twigCompletion({ options });\nreturn [\nlanguage,\nbase.support,\nlanguage.data.of({ autocomplete: completions }),\nbase.language.data.of({ autocomplete: completions }),\nlanguage.data.of({ autocomplete: genericCompletion(autocomplete) }),\nbase.language.data.of({ autocomplete: genericCompletion(autocomplete) }),\ntemplateTagsPlugin(options, onClickMissingVariable),\n...extraExtensions,\n];\n}"
"function pathParameters(\nview: EditorView,\nonClickPathParameter: (name: string) => void,\n): DecorationSet {\nconst widgets: Range<Decoration>[] = [];\nconst tree = syntaxTree(view.state);\nfor (const { from, to } of view.visibleRanges) {\ntree.iterate({\nfrom,\nto,\nenter(node) {\nif (node.name === 'Text') {\nfor (let i = node.from; i < node.to; i++) {\nconst innerTree = syntaxTree(view.state).resolveInner(i);\nif (innerTree.node.name === 'url') {\ninnerTree.toTree().iterate({\nenter(node) {\nif (node.name !== 'Placeholder') return;\nconst globalFrom = innerTree.node.from + node.from;\nconst globalTo = innerTree.node.from + node.to;\nconst rawText = view.state.doc.sliceString(globalFrom, globalTo);\nconst onClick = () => onClickPathParameter(rawText);\nconst widget = new PathPlaceholderWidget(rawText, globalFrom, onClick);\nconst deco = Decoration.replace({ widget, inclusive: false });\nwidgets.push(deco.range(globalFrom, globalTo));\n},\n});\nbreak;\n}\n}\n}\n},\n});\n}\nwidgets.sort((a, b) => a.from - b.from);\nreturn Decoration.set(widgets);\n}"
"function templateTags(\nview: EditorView,\noptions: TwigCompletionOption[],\nonClickMissingVariable: (name: string, rawTag: string, startPos: number) => void,\n): DecorationSet {\nconst widgets: Range<Decoration>[] = [];\nconst tree = syntaxTree(view.state);\nfor (const { from, to } of view.visibleRanges) {\ntree.iterate({\nfrom,\nto,\nenter(node) {\nif (node.name === 'Tag') {\nif (isSelectionInsideNode(view, node)) return;\nconst rawTag = view.state.doc.sliceString(node.from, node.to);\nconst inner = rawTag.replace(/^\$\{\[\s*/, '').replace(/\s*]}$/, '');\nlet name = inner.match(/([\w.]+)[(]/)?.[1] ?? inner;\nif (inner.includes('\n')) {\nreturn;\n}\nif (name === 'Response') {\nname = 'response';\n}\nlet option = options.find(\n(o) => o.name === name || (o.type === 'function' && o.aliases?.includes(name)),\n);\nif (option == null) {\nconst from = node.from;\noption = {\ninvalid: true,\ntype: 'variable',\nname: inner,\nvalue: null,\nlabel: inner,\nonClick: () => {\nonClickMissingVariable(name, rawTag, from);\n},\n};\n}\nlet invalid = false;\nif (option.type === 'function') {\nconst tokens = parseTemplate(rawTag);\nconst values = collectArgumentValues(tokens, option);\nfor (const arg of option.args) {\nif (!('optional' in arg)) continue;\nif (!arg.optional && values[arg.name] == null) {\ninvalid = true;\nbreak;\n}\n}\n}\nconst widget = new TemplateTagWidget({ ...option, invalid }, rawTag, node.from);\nconst deco = Decoration.replace({ widget, inclusive: true });\nwidgets.push(deco.range(node.from, node.to));\n}\n},\n});\n}\nwidgets.sort((a, b) => a.from - b.from);\nreturn Decoration.set(widgets);\n}"
"function templateTags(\nview: EditorView,\noptions: TwigCompletionOption[],\nonClickMissingVariable: (name: string, rawTag: string, startPos: number) => void,\n): DecorationSet {\nconst widgets: Range<Decoration>[] = [];\nconst tree = syntaxTree(view.state);\nfor (const { from, to } of view.visibleRanges) {\ntree.iterate({\nfrom,\nto,\nenter(node) {\nif (node.name === 'Tag') {\nif (isSelectionInsideNode(view, node)) return;\nconst rawTag = view.state.doc.sliceString(node.from, node.to);\nconst inner = rawTag.replace(/^\$\{\[\s*/, '').replace(/\s*]}$/, '');\nlet name = inner.match(/([\w.]+)[(]/)?.[1] ?? inner;\nif (inner.includes('\n')) {\nreturn;\n}\nif (name === 'Response') {\nname = 'response';\n}\nlet option = options.find(\n(o) => o.name === name || (o.type === 'function' && o.aliases?.includes(name)),\n);\nif (option == null) {\nconst from = node.from;\noption = {\ninvalid: true,\ntype: 'variable',\nname: inner,\nvalue: null,\nlabel: inner,\nonClick: () => {\nonClickMissingVariable(name, rawTag, from);\n},\n};\n}\nlet invalid = false;\nif (option.type === 'function') {\nconst tokens = parseTemplate(rawTag);\nconst values = collectArgumentValues(tokens, option);\nfor (const arg of option.args) {\nif (!('optional' in arg)) continue;\nif (!arg.optional && values[arg.name] == null) {\ninvalid = true;\nbreak;\n}\n}\n}\nconst widget = new TemplateTagWidget({ ...option, invalid }, rawTag, node.from);\nconst deco = Decoration.replace({ widget, inclusive: true });\nwidgets.push(deco.range(node.from, node.to));\n}\n},\n});\n}\nwidgets.sort((a, b) => a.from - b.from);\nreturn Decoration.set(widgets);\n}"
"public runRequest(req: AxiosRequestConfig): RequestRunResult<InterceptorError> {\nconst processedReq = preProcessRequest(req)\nconst relevantCookies = this.cookieJarService.getCookiesForURL(\nnew URL(processedReq.url!)\n)\nif (relevantCookies.length > 0) {\nprocessedReq.headers[`Cookie`] = relevantCookies\n.map((cookie) => `${cookie.name!}=${cookie.value!}`)\n.join(`;`)\n}\nconst reqID = this.reqIDTicker++;\nreturn {\ncancel: () => {\ninvoke(`plugin:hopp_native_interceptor|cancel_request`, { reqId: reqID });\n},\nresponse: (async () => {\nconst requestDef = await convertToRequestDef(\nprocessedReq,\nreqID,\nthis.caCertificates.value,\nthis.clientCertificates.value,\nthis.validateCerts.value,\nthis.proxyInfo.value\n)\ntry {\nconst response: RunRequestResponse = await invoke(\n`plugin:hopp_native_interceptor|run_request`,\n{ req: requestDef }\n)\nreturn E.right({\nheaders: Object.fromEntries(\nresponse.headers.map(({ key, value }) => [key, value])\n),\nstatus: response.status,\nstatusText: response.status_text,\ndata: new Uint8Array(response.data).buffer,\nconfig: {\ntimeData: {\nstartTime: response.time_start_ms,\nendTime: response.time_end_ms\n}\n},\nadditional: {\nmultiHeaders: response.headers\n}\n})\n} catch (e) {\nif (typeof e === `object` && (e as any)[`RequestCancelled`]) {\nreturn E.left(`cancellation` as const)\n}\nreturn E.left(<InterceptorError>{\nhumanMessage: {\nheading: (t) => t(`error.network_fail`),\ndescription: (t) => t(`helpers.network_fail`),\n}\n})\n}\n})()\n}\n}"
"async function runRequest(\nreq: AxiosRequestConfig,\ncancelToken: CancelToken\n): RequestRunResult[`response`] {\nconst defaultProxyURL = await getDefaultProxyUrl()\nconst multipartKey =\nreq.data instanceof FormData ? `proxyRequestData-${v4()}` : null\nconst headers =\nreq.data instanceof FormData\n? <ProxyHeaders>{\n`multipart-part-key`: multipartKey,\n}\n: <ProxyHeaders>{}\nconst payload = getProxyPayload(req, multipartKey)\ntry {\nconst { data } = await axios.post(\nsettingsStore.value.PROXY_URL ?? defaultProxyURL,\npayload,\n{\nheaders,\ncancelToken,\n}\n)\nif (!data.success) {\nreturn E.left({\nhumanMessage: {\nheading: (t) => t(`error.network_fail`),\ndescription: (t) => data.data?.message ?? t(`error.proxy_error`),\n},\n})\n}\nif (data.isBinary) {\ndata.data = decodeB64StringToArrayBuffer(data.data)\n}\nreturn E.right(data)\n} catch (e) {\nif (axios.isCancel(e)) {\nreturn E.left(`cancellation`)\n}\nreturn E.left({\nhumanMessage: {\nheading: (t) => t(`error.network_fail`),\ndescription: (t) => t(`helpers.network_fail`),\n},\nerror: e,\n})\n}\n}"
"function removeDuplicateCollectionsFromPath(\nidToRemove: string,\ncollectionPath: string | null,\ncollections: HoppCollection[],\ntype: `collection` | `request`\n): HoppCollection[] {\nconst indexes = collectionPath?.split(`/`).map((x) => parseInt(x))\nindexes && indexes.pop()\nconst parentPath = indexes?.join(`/`)\nconst parentCollection = parentPath\n? navigateToFolderWithIndexPath(\ncollections,\nparentPath.split(`/`).map((x) => parseInt(x)) || []\n)\n: undefined\nif (collectionPath && parentCollection) {\nif (type === `collection`) {\nparentCollection.folders = removeDuplicatesFromAnArrayById(\nidToRemove,\nparentCollection.folders\n)\n} else {\nparentCollection.requests = removeDuplicatesFromAnArrayById(\nidToRemove,\nparentCollection.requests\n)\n}\n} else {\nreturn removeDuplicatesFromAnArrayById(idToRemove, collections)\n}\nreturn collections\nfunction removeDuplicatesFromAnArrayById<T extends { id?: string }>(\nidToRemove: string,\narrayWithID: T[]\n) {\nconst duplicateEntries = arrayWithID.filter(\n(entry) => entry.id === idToRemove\n)\nif (duplicateEntries.length === 2) {\nconst duplicateEntryIndex = arrayWithID.findIndex(\n(entry) => entry.id === idToRemove\n)\narrayWithID.splice(duplicateEntryIndex, 1)\n}\nreturn arrayWithID\n}\n}"
"moveFolder(\n{ state }: RESTCollectionStoreType,\n{ path, destinationPath }: { path: string; destinationPath: string | null }\n) {\nconst newState = state\nif (destinationPath === null) {\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst folderIndex = indexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(\nnewState,\nindexPaths\n)\nif (containingFolder === null) {\nconsole.error(\n`The folder to move is already in the root. Skipping request to move folder.`\n)\nreturn {}\n}\nconst theFolder = containingFolder.folders.splice(folderIndex, 1)\nnewState.push(theFolder[0] as HoppCollection)\nreturn {\nstate: newState,\n}\n}\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst destinationIndexPaths = destinationPath\n.split(`/`)\n.map((x) => parseInt(x))\nif (indexPaths.length === 0 || destinationIndexPaths.length === 0) {\nconsole.error(\n`Given path is too short. Skipping request to move folder '${path}' to destination '${destinationPath}'.`\n)\nreturn {}\n}\nconst target = navigateToFolderWithIndexPath(\nnewState,\ndestinationIndexPaths\n)\nif (target === null) {\nconsole.error(\n`Could not resolve destination path '${destinationPath}'. Skipping moveFolder dispatch.`\n)\nreturn {}\n}\nconst folderIndex = indexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(newState, indexPaths)\nif (containingFolder === null) {\nconst theFolder = newState.splice(folderIndex, 1)\ntarget.folders.push(theFolder[0])\n} else {\nconst theFolder = containingFolder.folders.splice(folderIndex, 1)\ntarget.folders.push(theFolder[0])\n}\nreturn { state: newState }\n},"
"duplicateCollection(\n{ state }: RESTCollectionStoreType,\n{ path, collectionSyncID }: { path: string; collectionSyncID?: string }\n) {\nconst t = getI18n()\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst isRootCollection = indexPaths.length === 1\nconst collection = navigateToFolderWithIndexPath(state, [...indexPaths])\nif (collection) {\nconst name = `${collection.name} - ${t(`action.duplicate`)}`\nfunction recursiveChangeRefIdToAvoidConflicts(\ncollection: HoppCollection\n): HoppCollection {\nconst newCollection = {\n...collection,\n_ref_id: generateUniqueRefId(`coll`),\n}\nnewCollection.folders = newCollection.folders.map((folder) =>\nrecursiveChangeRefIdToAvoidConflicts(folder)\n)\nreturn newCollection\n}\nconst duplicatedCollection = {\n...cloneDeep(collection),\nname,\n...(collection.id\n? { id: `${collection.id}-duplicate-collection` }\n: {}),\n}\nconst duplicatedCollectionWithNewRefId =\nrecursiveChangeRefIdToAvoidConflicts(duplicatedCollection)\nif (isRootCollection) {\nnewState.push(duplicatedCollectionWithNewRefId)\n} else {\nconst parentCollectionIndexPath = indexPaths.slice(0, -1)\nconst parentCollection = navigateToFolderWithIndexPath(state, [\n...parentCollectionIndexPath,\n])\nparentCollection?.folders.push(duplicatedCollectionWithNewRefId)\n}\n}\nreturn {\nstate: newState,\n}\n},"
"updateRequestOrder(\n{ state }: RESTCollectionStoreType,\n{\nrequestIndex,\ndestinationRequestIndex,\ndestinationCollectionPath,\n}: {\nrequestIndex: number\ndestinationRequestIndex: number | null\ndestinationCollectionPath: string\n}\n) {\nconst newState = state\nconst indexPaths = destinationCollectionPath\n.split(`/`)\n.map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve path '${destinationCollectionPath}'. Ignoring reorderRequest dispatch.`\n)\nreturn {}\n}\nif (destinationRequestIndex === null) {\ntargetLocation.requests.push(\ntargetLocation.requests.splice(requestIndex, 1)[0]\n)\nresolveSaveContextOnRequestReorder({\nlastIndex: requestIndex,\nnewIndex: targetLocation.requests.length,\nfolderPath: destinationCollectionPath,\n})\nreturn {\nstate: newState,\n}\n}\nreorderItems(targetLocation.requests, requestIndex, destinationRequestIndex)\nresolveSaveContextOnRequestReorder({\nlastIndex: requestIndex,\nnewIndex: destinationRequestIndex,\nfolderPath: destinationCollectionPath,\n})\nreturn {\nstate: newState,\n}\n},"
"duplicateCollection(\n{ state }: GraphqlCollectionStoreType,\n{ path, collectionSyncID }: { path: string; collectionSyncID?: string }\n) {\nconst t = getI18n()\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst isRootCollection = indexPaths.length === 1\nconst collection = navigateToFolderWithIndexPath(state, [...indexPaths])\nif (collection) {\nconst name = `${collection.name} - ${t(`action.duplicate`)}`\nconst duplicatedCollection = {\n...cloneDeep(collection),\nname,\n...(collection.id\n? { id: `${collection.id}-duplicate-collection` }\n: {}),\n}\nif (isRootCollection) {\nnewState.push(duplicatedCollection)\n} else {\nconst parentCollectionIndexPath = indexPaths.slice(0, -1)\nconst parentCollection = navigateToFolderWithIndexPath(state, [\n...parentCollectionIndexPath,\n])\nparentCollection?.folders.push(duplicatedCollection)\n}\n}\nreturn {\nstate: newState,\n}\n},"
"moveRequest(\n{ state }: GraphqlCollectionStoreType,\n{\npath,\nrequestIndex,\ndestinationPath,\n}: { path: string; requestIndex: number; destinationPath: string }\n) {\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve source path '${path}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\nconst req = targetLocation.requests[requestIndex]\nconst destIndexPaths = destinationPath.split(`/`).map((x) => parseInt(x))\nconst destLocation = navigateToFolderWithIndexPath(newState, destIndexPaths)\nif (destLocation === null) {\nconsole.log(\n`Could not resolve destination path '${destinationPath}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\ndestLocation.requests.push(req)\ntargetLocation.requests.splice(requestIndex, 1)\nreturn {\nstate: newState,\n}\n},"
"private constructProxyRequest(\nrequest: RelayRequest,\naccessToken: string\n): ProxyRequest {\nconst wantsBinary = true\nlet requestData: any = null\nif (request.content) {\nswitch (request.content.kind) {\ncase `json`:\nrequestData =\ntypeof request.content.content === `string`\n? request.content.content\n: JSON.stringify(request.content.content)\nbreak\ncase `binary`:\nif (\nrequest.content.content instanceof Blob ||\nrequest.content.content instanceof File\n) {\nrequestData = request.content.content\n} else if (typeof request.content.content === `string`) {\ntry {\nconst base64 =\nrequest.content.content.split(`,`)[1] || request.content.content\nconst binaryString = window.atob(base64)\nconst bytes = new Uint8Array(binaryString.length)\nfor (let i = 0; i < binaryString.length; i++) {\nbytes[i] = binaryString.charCodeAt(i)\n}\nrequestData = new Blob([bytes.buffer])\n} catch (e) {\nconsole.error(`Error converting binary data:`, e)\nrequestData = request.content.content\n}\n} else {\nrequestData = request.content.content\n}\nbreak\ncase `multipart`:\nrequestData = ``\nbreak\ndefault:\nrequestData = request.content.content\n}\n}\nreturn {\naccessToken,\nwantsBinary,\nurl: request.url,\nmethod: request.method,\nheaders: request.headers,\nparams: request.params,\ndata: requestData,\nauth:\nrequest.auth?.kind === `basic`\n? {\nusername: request.auth.username,\npassword: request.auth.password,\n}\n: undefined,\n}\n}"
"async onBeforeRouteChange(to, _from, next) {\nconst onboardingStatus = await auth.getOnboardingStatus();\nif (\n!onboardingStatus?.onboardingCompleted &&\nto.name !== 'onboarding' &&\nto.name === 'index'\n) {\nreturn next({ name: 'onboarding' });\n}\nconst res = await auth.getUserDetails();\nif (res.errors?.[0].message === UNAUTHORIZED) {\nreturn next();\n}\nif (\n!onboardingStatus?.onboardingCompleted &&\n!onboardingStatus?.canReRunOnboarding &&\nto.name !== 'index' &&\nto.name === 'onboarding'\n) {\nreturn next();\n}\nif (\nonboardingStatus?.onboardingCompleted &&\n!onboardingStatus.canReRunOnboarding &&\nto.name === 'onboarding'\n) {\nreturn next({ name: 'index' });\n}\nconst isAdmin = res.data?.me.isAdmin;\nif (!isGuestRoute(to.name) && !isAdmin) {\nreturn next({ name: 'index' });\n}\nif (isAdmin && onboardingStatus?.onboardingCompleted) {\nconst isInfraNotSetup = await getFirstTimeInfraSetupStatus();\nif (isGuestRoute(to.name)) {\nconst name = isInfraNotSetup ? 'setup' : 'dashboard';\nreturn next({ name });\n}\nif (isSetupRoute(to.name) && !isInfraNotSetup) {\nreturn next({ name: 'dashboard' });\n}\nif (isInfraNotSetup && !isSetupRoute(to.name)) {\nreturn next({ name: 'setup' });\n}\n}\nnext();\n},"
"async signInMagicLink(email: string, origin: string) {\nif (!validateEmail(email))\nreturn E.left({\nmessage: INVALID_EMAIL,\nstatusCode: HttpStatus.BAD_REQUEST,\n});\nlet user: AuthUser;\nconst queriedUser = await this.usersService.findUserByEmail(email);\nif (O.isNone(queriedUser)) {\nuser = await this.usersService.createUserViaMagicLink(email);\n} else {\nuser = queriedUser.value;\n}\nconst generatedTokens = await this.generateMagicLinkTokens(user);\nlet url: string;\nswitch (origin) {\ncase Origin.ADMIN:\nurl = this.configService.get('VITE_ADMIN_URL');\nbreak;\ncase Origin.APP:\nurl = this.configService.get('VITE_BASE_URL');\nbreak;\ndefault:\nurl = this.configService.get('VITE_BASE_URL');\n}\nawait this.mailerService.sendEmail(email, {\ntemplate: 'user-invitation',\nvariables: {\ninviteeEmail: email,\nmagicLink: `${url}/enter?token=${generatedTokens.token}`,\n},\n});\nreturn E.right(<DeviceIdentifierToken>{\ndeviceIdentifier: generatedTokens.deviceIdentifier,\n});\n}"
"async verifyMagicLinkTokens(\nmagicLinkIDTokens: VerifyMagicDto,\n): Promise<E.Right<AuthTokens> | E.Left<RESTError>> {\nconst passwordlessTokens =\nawait this.validatePasswordlessTokens(magicLinkIDTokens);\nif (O.isNone(passwordlessTokens))\nreturn E.left({\nmessage: INVALID_MAGIC_LINK_DATA,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nconst user = await this.usersService.findUserById(\npasswordlessTokens.value.userUid,\n);\nif (O.isNone(user))\nreturn E.left({\nmessage: USER_NOT_FOUND,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nconst profile = {\nprovider: 'magic',\nid: user.value.email,\n};\nconst providerAccountExists = await this.checkIfProviderAccountExists(\nuser.value,\nprofile,\n);\nif (O.isNone(providerAccountExists)) {\nawait this.usersService.createProviderAccount(\nuser.value,\nnull,\nnull,\nprofile,\n);\n}\nconst currentTime = new Date();\nif (currentTime > passwordlessTokens.value.expiresOn)\nreturn E.left({\nmessage: MAGIC_LINK_EXPIRED,\nstatusCode: HttpStatus.UNAUTHORIZED,\n});\nconst tokens = await this.generateAuthTokens(\npasswordlessTokens.value.userUid,\n);\nif (E.isLeft(tokens))\nreturn E.left({\nmessage: tokens.left.message,\nstatusCode: tokens.left.statusCode,\n});\nconst deletedPasswordlessToken =\nawait this.deleteMagicLinkVerificationTokens(passwordlessTokens.value);\nif (E.isLeft(deletedPasswordlessToken))\nreturn E.left({\nmessage: deletedPasswordlessToken.left,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nthis.usersService.updateUserLastLoggedOn(passwordlessTokens.value.userUid);\nreturn E.right(tokens.right);\n}"
"export async function buildDerivedEnv() {\nconst envConfigMap = await loadInfraConfiguration();\nconst derivedEnv: Record<string, string> = {};\nconst baseUrl = process.env.VITE_BASE_URL || '';\nconst backendUrl = process.env.VITE_BACKEND_API_URL || '';\nconst normalizedBackendUrl = backendUrl?.replace(/\/+$/, '');\nconst expectedSecure = determineAllowSecureCookies(baseUrl).toString();\nconst currentSecure = envConfigMap.INFRA.ALLOW_SECURE_COOKIES;\nif (currentSecure !== expectedSecure) {\nderivedEnv.ALLOW_SECURE_COOKIES = expectedSecure;\n}\nconst callbackConfigs = [\n{ key: InfraConfigEnum.GOOGLE_CALLBACK_URL, path: '/auth/google/callback' },\n{\nkey: InfraConfigEnum.MICROSOFT_CALLBACK_URL,\npath: '/auth/microsoft/callback',\n},\n{ key: InfraConfigEnum.GITHUB_CALLBACK_URL, path: '/auth/github/callback' },\n];\nfor (const { key, path } of callbackConfigs) {\nconst currentCallback = envConfigMap.INFRA[key];\nconst expectedCallback = `${normalizedBackendUrl}${path}`;\nif (\nbackendUrl.length > 0 &&\ncurrentCallback &&\ncurrentCallback !== expectedCallback\n) {\nderivedEnv[key] = expectedCallback;\n}\n}\nreturn derivedEnv;\n}"
"async initializeInfraConfigTable() {\ntry {\nconst defaultInfraConfigs = await getDefaultInfraConfigs();\nconst propsToInsert =\nawait getMissingInfraConfigEntries(defaultInfraConfigs);\nif (propsToInsert.length > 0) {\nawait this.prisma.infraConfig.createMany({ data: propsToInsert });\n}\nconst encryptionRequiredEntries =\nawait getEncryptionRequiredInfraConfigEntries(defaultInfraConfigs);\nif (encryptionRequiredEntries.length > 0) {\nconst dbOperations = encryptionRequiredEntries.map((dbConfig) => {\nreturn this.prisma.infraConfig.update({\nwhere: { name: dbConfig.name },\ndata: { value: encrypt(dbConfig.value), isEncrypted: true },\n});\n});\nawait Promise.allSettled(dbOperations);\n}\nconst derivedEnv = await buildDerivedEnv();\nif (Object.keys(derivedEnv).length > 0) {\nconst dbOperations = Object.entries(derivedEnv).map(([name, value]) => {\nreturn this.prisma.infraConfig.update({\nwhere: { name: name as InfraConfigEnum },\ndata: { value },\n});\n});\nawait Promise.allSettled(dbOperations);\n}\nif (\npropsToInsert.length > 0 ||\nencryptionRequiredEntries.length > 0 ||\nObject.keys(derivedEnv).length > 0\n) {\nstopApp();\n}\n} catch (error) {\nif (error.code === 'P1001') {\n} else if (error.code === 'P2021') {\nthrowErr(DATABASE_TABLE_NOT_EXIST);\n} else {\nconsole.log(error);\nthrowErr(error);\n}\n}\n}"
"async updateMany(\ninfraConfigs: InfraConfigArgs[],\ncheckDisallowedKeys: boolean = true,\n) {\nif (checkDisallowedKeys) {\nfor (let i = 0; i < infraConfigs.length; i++) {\nif (this.EXCLUDE_FROM_UPDATE_CONFIGS.includes(infraConfigs[i].name))\nreturn E.left(INFRA_CONFIG_OPERATION_NOT_ALLOWED);\n}\n}\nconst isValidate = this.validateEnvValues(infraConfigs);\nif (E.isLeft(isValidate)) return E.left(isValidate.left);\ntry {\nconst dbInfraConfig = await this.prisma.infraConfig.findMany({\nselect: { name: true, isEncrypted: true },\n});\nawait this.prisma.$transaction(async (tx) => {\nfor (let i = 0; i < infraConfigs.length; i++) {\nconst isEncrypted = dbInfraConfig.find(\n(p) => p.name === infraConfigs[i].name,\n)?.isEncrypted;\nawait tx.infraConfig.update({\nwhere: { name: infraConfigs[i].name },\ndata: {\nvalue: isEncrypted\n? encrypt(infraConfigs[i].value)\n: infraConfigs[i].value,\n},\n});\n}\n});\nstopApp();\nreturn E.right(infraConfigs);\n} catch (e) {\nreturn E.left(INFRA_CONFIG_UPDATE_FAILED);\n}\n}"
"isServiceConfigured(\nservice: AuthProvider,\nconfigMap: Record<string, string>,\n) {\nswitch (service) {\ncase AuthProvider.GOOGLE:\nreturn (\nconfigMap.GOOGLE_CLIENT_ID &&\nconfigMap.GOOGLE_CLIENT_SECRET &&\nconfigMap.GOOGLE_CALLBACK_URL &&\nconfigMap.GOOGLE_SCOPE\n);\ncase AuthProvider.GITHUB:\nreturn (\nconfigMap.GITHUB_CLIENT_ID &&\nconfigMap.GITHUB_CLIENT_SECRET &&\nconfigMap.GITHUB_CALLBACK_URL &&\nconfigMap.GITHUB_SCOPE\n);\ncase AuthProvider.MICROSOFT:\nreturn (\nconfigMap.MICROSOFT_CLIENT_ID &&\nconfigMap.MICROSOFT_CLIENT_SECRET &&\nconfigMap.MICROSOFT_CALLBACK_URL &&\nconfigMap.MICROSOFT_SCOPE &&\nconfigMap.MICROSOFT_TENANT\n);\ncase AuthProvider.EMAIL:\nif (configMap.MAILER_SMTP_ENABLE !== 'true') return false;\nif (configMap.MAILER_USE_CUSTOM_CONFIGS === 'true') {\nreturn (\nconfigMap.MAILER_SMTP_HOST &&\nconfigMap.MAILER_SMTP_PORT &&\nconfigMap.MAILER_SMTP_SECURE &&\nconfigMap.MAILER_SMTP_USER &&\nconfigMap.MAILER_SMTP_PASSWORD &&\nconfigMap.MAILER_TLS_REJECT_UNAUTHORIZED &&\nconfigMap.MAILER_ADDRESS_FROM\n);\n} else {\nreturn configMap.MAILER_SMTP_URL && configMap.MAILER_ADDRESS_FROM;\n}\ndefault:\nreturn false;\n}\n}"
"async updateOnboardingConfig(dto: SaveOnboardingConfigRequest) {\nconst onboardingRecoveryToken = crypto.randomUUID();\nconst configEntries: InfraConfigArgs[] = [\n...Object.entries(dto).map(([key, value]) => ({\nname: key as InfraConfigEnum,\nvalue,\n})),\n{\nname: InfraConfigEnum.ONBOARDING_COMPLETED,\nvalue: 'true',\n},\n{\nname: InfraConfigEnum.ONBOARDING_RECOVERY_TOKEN,\nvalue: onboardingRecoveryToken,\n},\n];\nconst isValidated = this.validateEnvValues(configEntries);\nif (E.isLeft(isValidated)) return E.left(isValidated.left);\nif (\ndto[InfraConfigEnum.MAILER_SMTP_ENABLE] === 'true' &&\n!this.isServiceConfigured(\nAuthProvider.EMAIL,\ndto as unknown as Record<string, string>,\n)\n) {\nreturn E.left(INFRA_CONFIG_SERVICE_NOT_CONFIGURED);\n}\nconst allowedAuthProviders =\ndto[InfraConfigEnum.VITE_ALLOWED_AUTH_PROVIDERS].split(',');\nif (allowedAuthProviders.length === 0) {\nreturn E.left(AUTH_PROVIDER_NOT_SPECIFIED);\n}\nfor (const provider of allowedAuthProviders) {\nif (\n!Object.values(AuthProvider).includes(provider as AuthProvider) ||\n!this.isServiceConfigured(\nprovider as AuthProvider,\ndto as unknown as Record<string, string>,\n)\n) {\nreturn E.left(INFRA_CONFIG_SERVICE_NOT_CONFIGURED);\n}\n}\nconst isUpdated = await this.updateMany(configEntries, false);\nif (E.isLeft(isUpdated)) return E.left(isUpdated.left);\nreturn E.right({\ntoken: onboardingRecoveryToken,\n} as SaveOnboardingConfigResponse);\n}"
"async updateTeamAccessRole(\nteamID: string,\nuserUid: string,\nnewRole: TeamAccessRole,\n): Promise<E.Left<string> | E.Right<TeamMember>> {\nconst ownerCount = await this.prisma.teamMember.count({\nwhere: {\nteamID,\nrole: TeamAccessRole.OWNER,\n},\n});\nconst member = await this.prisma.teamMember.findUnique({\nwhere: {\nteamID_userUid: {\nteamID,\nuserUid,\n},\n},\n});\nif (!member) return E.left(TEAM_MEMBER_NOT_FOUND);\nif (\nmember.role === TeamAccessRole.OWNER &&\nnewRole != TeamAccessRole.OWNER &&\nownerCount === 1\n) {\nreturn E.left(TEAM_ONLY_ONE_OWNER);\n}\nconst result = await this.prisma.teamMember.update({\nwhere: {\nteamID_userUid: {\nteamID,\nuserUid,\n},\n},\ndata: {\nrole: newRole,\n},\n});\nconst updatedMember: TeamMember = {\nmembershipID: result.id,\nuserUid: result.userUid,\nrole: TeamAccessRole[result.role],\n};\nthis.pubsub.publish(`team/${teamID}/member_updated`, updatedMember);\nreturn E.right(updatedMember);\n}"
"async exportCollectionToJSONObject(\nteamID: string,\ncollectionID: string,\n): Promise<E.Right<CollectionFolder> | E.Left<string>> {\nconst collection = await this.getCollection(collectionID);\nif (E.isLeft(collection)) return E.left(TEAM_INVALID_COLL_ID);\nconst childrenCollection = await this.prisma.teamCollection.findMany({\nwhere: {\nteamID,\nparentID: collectionID,\n},\norderBy: {\norderIndex: 'asc',\n},\n});\nconst childrenCollectionObjects = [];\nfor (const coll of childrenCollection) {\nconst result = await this.exportCollectionToJSONObject(teamID, coll.id);\nif (E.isLeft(result)) return E.left(result.left);\nchildrenCollectionObjects.push(result.right);\n}\nconst requests = await this.prisma.teamRequest.findMany({\nwhere: {\nteamID,\ncollectionID,\n},\norderBy: {\norderIndex: 'asc',\n},\n});\nconst data = transformCollectionData(collection.right.data);\nconst result: CollectionFolder = {\nname: collection.right.title,\nfolders: childrenCollectionObjects,\nrequests: requests.map((x) => x.request),\ndata,\n};\nreturn E.right(result);\n}"
"async importCollectionsFromJSON(\njsonString: string,\ndestTeamID: string,\ndestCollectionID: string | null,\n) {\nconst collectionsList = stringToJson<CollectionFolder[]>(jsonString);\nif (E.isLeft(collectionsList)) return E.left(TEAM_COLL_INVALID_JSON);\nif (!Array.isArray(collectionsList.right))\nreturn E.left(TEAM_COLL_INVALID_JSON);\nconst count = !destCollectionID\n? await this.getRootCollectionsCount(destTeamID)\n: await this.getChildCollectionsCount(destCollectionID);\nconst queryList = collectionsList.right.map((x) =>\nthis.generatePrismaQueryObjForFBCollFolder(x, destTeamID, count + 1),\n);\nconst parent = destCollectionID\n? {\nconnect: {\nid: destCollectionID,\n},\n}\n: undefined;\nconst teamCollections = await this.prisma.$transaction(\nqueryList.map((x) =>\nthis.prisma.teamCollection.create({\ndata: {\n...x,\nparent,\n},\n}),\n),\n);\nteamCollections.forEach((collection) =>\nthis.pubsub.publish(\n`team_coll/${destTeamID}/coll_added`,\nthis.cast(collection),\n),\n);\nreturn E.right(true);\n}"
"async createCollection(\nteamID: string,\ntitle: string,\ndata: string | null = null,\nparentTeamCollectionID: string | null,\n) {\nconst isTitleValid = isValidLength(title, this.TITLE_LENGTH);\nif (!isTitleValid) return E.left(TEAM_COLL_SHORT_TITLE);\nif (parentTeamCollectionID !== null) {\nconst isOwner = await this.isOwnerCheck(parentTeamCollectionID, teamID);\nif (O.isNone(isOwner)) return E.left(TEAM_NOT_OWNER);\n}\nif (data === '') return E.left(TEAM_COLL_DATA_INVALID);\nif (data) {\nconst jsonReq = stringToJson(data);\nif (E.isLeft(jsonReq)) return E.left(TEAM_COLL_DATA_INVALID);\ndata = jsonReq.right;\n}\nconst isParent = parentTeamCollectionID\n? {\nconnect: {\nid: parentTeamCollectionID,\n},\n}\n: undefined;\nconst teamCollection = await this.prisma.teamCollection.create({\ndata: {\ntitle: title,\nteam: {\nconnect: {\nid: teamID,\n},\n},\nparent: isParent,\ndata: data ?? undefined,\norderIndex: !parentTeamCollectionID\n? (await this.getRootCollectionsCount(teamID)) + 1\n: (await this.getChildCollectionsCount(parentTeamCollectionID)) + 1,\n},\n});\nthis.pubsub.publish(\n`team_coll/${teamID}/coll_added`,\nthis.cast(teamCollection),\n);\nreturn E.right(this.cast(teamCollection));\n}"
"async moveCollection(collectionID: string, destCollectionID: string | null) {\nconst collection = await this.getCollection(collectionID);\nif (E.isLeft(collection)) return E.left(collection.left);\nif (!destCollectionID) {\nif (!collection.right.parentID) {\nreturn E.left(TEAM_COL_ALREADY_ROOT);\n}\nawait this.updateOrderIndex(\ncollection.right.parentID,\n{ gt: collection.right.orderIndex },\n{ decrement: 1 },\n);\nconst updatedCollection = await this.changeParent(collection.right, null);\nif (E.isLeft(updatedCollection)) return E.left(updatedCollection.left);\nthis.pubsub.publish(\n`team_coll/${collection.right.teamID}/coll_moved`,\nupdatedCollection.right,\n);\nreturn E.right(updatedCollection.right);\n}\nif (collectionID === destCollectionID) {\nreturn E.left(TEAM_COLL_DEST_SAME);\n}\nconst destCollection = await this.getCollection(destCollectionID);\nif (E.isLeft(destCollection)) return E.left(TEAM_COLL_NOT_FOUND);\nif (collection.right.teamID !== destCollection.right.teamID) {\nreturn E.left(TEAM_COLL_NOT_SAME_TEAM);\n}\nconst checkIfParent = await this.isParent(\ncollection.right,\ndestCollection.right,\n);\nif (O.isNone(checkIfParent)) {\nreturn E.left(TEAM_COLL_IS_PARENT_COLL);\n}\nawait this.updateOrderIndex(\ncollection.right.parentID,\n{ gt: collection.right.orderIndex },\n{ decrement: 1 },\n);\nconst updatedCollection = await this.changeParent(\ncollection.right,\ndestCollection.right.id,\n);\nif (E.isLeft(updatedCollection)) return E.left(updatedCollection.left);\nthis.pubsub.publish(\n`team_coll/${collection.right.teamID}/coll_moved`,\nupdatedCollection.right,\n);\nreturn E.right(updatedCollection.right);\n}"
"async searchByTitle(\nsearchQuery: string,\nteamID: string,\ntake = 10,\nskip = 0,\n) {\nconst searchResults: SearchQueryReturnType[] = [];\nconst matchedCollections = await this.searchCollections(\nsearchQuery,\nteamID,\ntake,\nskip,\n);\nif (E.isLeft(matchedCollections))\nreturn E.left(<RESTError>{\nmessage: matchedCollections.left,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nsearchResults.push(...matchedCollections.right);\nconst matchedRequests = await this.searchRequests(\nsearchQuery,\nteamID,\ntake,\nskip,\n);\nif (E.isLeft(matchedRequests))\nreturn E.left(<RESTError>{\nmessage: matchedRequests.left,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nsearchResults.push(...matchedRequests.right);\nconst searchResultsWithTree: CollectionSearchNode[] = [];\nfor (let i = 0; i < searchResults.length; i++) {\nconst fetchedParentTree = await this.fetchParentTree(searchResults[i]);\nif (E.isLeft(fetchedParentTree))\nreturn E.left(<RESTError>{\nmessage: fetchedParentTree.left,\nstatusCode: HttpStatus.NOT_FOUND,\n});\nsearchResultsWithTree.push({\ntype: searchResults[i].type,\ntitle: searchResults[i].title,\nmethod: searchResults[i].method,\nid: searchResults[i].id,\npath: !fetchedParentTree\n? []\n: (fetchedParentTree.right as CollectionSearchNode[]),\n});\n}\nreturn E.right({ data: searchResultsWithTree });\n}"
"private generateParentTree(parentCollections: ParentTreeQueryReturnType[]) {\nfunction findChildren(id: string): CollectionSearchNode[] {\nconst collection = parentCollections.filter((item) => item.id === id)[0];\nif (collection.parentID == null) {\nreturn <CollectionSearchNode[]>[\n{\nid: collection.id,\ntitle: collection.title,\ntype: 'collection' as const,\npath: [],\n},\n];\n}\nconst res = <CollectionSearchNode[]>[\n{\nid: collection.id,\ntitle: collection.title,\ntype: 'collection' as const,\npath: findChildren(collection.parentID),\n},\n];\nreturn res;\n}\nif (parentCollections.length > 0) {\nif (parentCollections[0].parentID == null) {\nreturn <CollectionSearchNode[]>[\n{\nid: parentCollections[0].id,\ntitle: parentCollections[0].title,\ntype: 'collection',\npath: [],\n},\n];\n}\nreturn <CollectionSearchNode[]>[\n{\nid: parentCollections[0].id,\ntitle: parentCollections[0].title,\ntype: 'collection',\npath: findChildren(parentCollections[0].parentID),\n},\n];\n}\nreturn <CollectionSearchNode[]>[];\n}"
"async createInvitation(\ncreator: AuthUser,\nteamID: string,\ninviteeEmail: string,\ninviteeRole: TeamAccessRole,\n) {\nconst isEmailValid = validateEmail(inviteeEmail);\nif (!isEmailValid) return E.left(INVALID_EMAIL);\nconst team = await this.teamService.getTeamWithID(teamID);\nif (!team) return E.left(TEAM_INVALID_ID);\nconst isTeamMember = await this.teamService.getTeamMember(\nteam.id,\ncreator.uid,\n);\nif (!isTeamMember) return E.left(TEAM_MEMBER_NOT_FOUND);\nconst inviteeUser = await this.userService.findUserByEmail(inviteeEmail);\nif (O.isSome(inviteeUser)) {\nconst isTeamMember = await this.teamService.getTeamMember(\nteam.id,\ninviteeUser.value.uid,\n);\nif (isTeamMember) return E.left(TEAM_INVITE_ALREADY_MEMBER);\n}\nconst teamInvitation = await this.getTeamInviteByEmailAndTeamID(\ninviteeEmail,\nteam.id,\n);\nif (E.isRight(teamInvitation)) return E.left(TEAM_INVITE_MEMBER_HAS_INVITE);\nconst dbInvitation = await this.prisma.teamInvitation.create({\ndata: {\nteamID: team.id,\ninviteeEmail,\ninviteeRole,\ncreatorUid: creator.uid,\n},\n});\nawait this.mailerService.sendEmail(inviteeEmail, {\ntemplate: 'team-invitation',\nvariables: {\ninvitee: creator.displayName ?? 'A Hoppscotch User',\naction_url: `${this.configService.get('VITE_BASE_URL')}/join-team?id=${\ndbInvitation.id\n}`,\ninvite_team_name: team.name,\n},\n});\nconst invitation = this.cast(dbInvitation);\nthis.pubsub.publish(`team/${invitation.teamID}/invite_added`, invitation);\nreturn E.right(invitation);\n}"
"async createUserCollection(\nuser: AuthUser,\ntitle: string,\ndata: string | null = null,\nparentUserCollectionID: string | null,\ntype: ReqType,\n) {\nconst isTitleValid = isValidLength(title, this.TITLE_LENGTH);\nif (!isTitleValid) return E.left(USER_COLL_SHORT_TITLE);\nif (data === '') return E.left(USER_COLL_DATA_INVALID);\nif (data) {\nconst jsonReq = stringToJson(data);\nif (E.isLeft(jsonReq)) return E.left(USER_COLL_DATA_INVALID);\ndata = jsonReq.right;\n}\nif (parentUserCollectionID !== null) {\nconst parentCollection = await this.getUserCollection(\nparentUserCollectionID,\n);\nif (E.isLeft(parentCollection)) return E.left(parentCollection.left);\nif (parentCollection.right.userUid !== user.uid)\nreturn E.left(USER_NOT_OWNER);\nif (parentCollection.right.type !== type)\nreturn E.left(USER_COLL_NOT_SAME_TYPE);\n}\nconst isParent = parentUserCollectionID\n? {\nconnect: {\nid: parentUserCollectionID,\n},\n}\n: undefined;\nconst userCollection = await this.prisma.userCollection.create({\ndata: {\ntitle: title,\ntype: type,\nuser: {\nconnect: {\nuid: user.uid,\n},\n},\nparent: isParent,\ndata: data ?? undefined,\norderIndex: !parentUserCollectionID\n? (await this.getRootCollectionsCount(user.uid)) + 1\n: (await this.getChildCollectionsCount(parentUserCollectionID)) + 1,\n},\n});\nawait this.pubsub.publish(\n`user_coll/${user.uid}/created`,\nthis.cast(userCollection),\n);\nreturn E.right(this.cast(userCollection));\n}"
"async moveUserCollection(\nuserCollectionID: string,\ndestCollectionID: string | null,\nuserID: string,\n) {\nconst collection = await this.getUserCollection(userCollectionID);\nif (E.isLeft(collection)) return E.left(USER_COLL_NOT_FOUND);\nif (collection.right.userUid !== userID) return E.left(USER_NOT_OWNER);\nif (!destCollectionID) {\nif (!collection.right.parentID) {\nreturn E.left(USER_COLL_ALREADY_ROOT);\n}\nawait this.updateOrderIndex(\ncollection.right.parentID,\n{ gt: collection.right.orderIndex },\n{ decrement: 1 },\n);\nconst updatedCollection = await this.changeParent(collection.right, null);\nif (E.isLeft(updatedCollection)) return E.left(updatedCollection.left);\nthis.pubsub.publish(\n`user_coll/${collection.right.userUid}/moved`,\nthis.cast(updatedCollection.right),\n);\nreturn E.right(this.cast(updatedCollection.right));\n}\nif (userCollectionID === destCollectionID) {\nreturn E.left(USER_COLL_DEST_SAME);\n}\nconst destCollection = await this.getUserCollection(destCollectionID);\nif (E.isLeft(destCollection)) return E.left(USER_COLL_NOT_FOUND);\nif (collection.right.type !== destCollection.right.type) {\nreturn E.left(USER_COLL_NOT_SAME_TYPE);\n}\nif (collection.right.userUid !== destCollection.right.userUid) {\nreturn E.left(USER_COLL_NOT_SAME_USER);\n}\nconst checkIfParent = await this.isParent(\ncollection.right,\ndestCollection.right,\n);\nif (O.isNone(checkIfParent)) {\nreturn E.left(USER_COLL_IS_PARENT_COLL);\n}\nawait this.updateOrderIndex(\ncollection.right.parentID,\n{ gt: collection.right.orderIndex },\n{ decrement: 1 },\n);\nconst updatedCollection = await this.changeParent(\ncollection.right,\ndestCollection.right.id,\n);\nif (E.isLeft(updatedCollection)) return E.left(updatedCollection.left);\nthis.pubsub.publish(\n`user_coll/${collection.right.userUid}/moved`,\nthis.cast(updatedCollection.right),\n);\nreturn E.right(this.cast(updatedCollection.right));\n}"
"async updateUserCollection(\nnewTitle: string = null,\ncollectionData: string | null = null,\nuserCollectionID: string,\nuserID: string,\n) {\nif (collectionData === '') return E.left(USER_COLL_DATA_INVALID);\nif (collectionData) {\nconst jsonReq = stringToJson(collectionData);\nif (E.isLeft(jsonReq)) return E.left(USER_COLL_DATA_INVALID);\ncollectionData = jsonReq.right;\n}\nif (newTitle != null) {\nconst isTitleValid = isValidLength(newTitle, this.TITLE_LENGTH);\nif (!isTitleValid) return E.left(USER_COLL_SHORT_TITLE);\n}\nconst isOwner = await this.isOwnerCheck(userCollectionID, userID);\nif (O.isNone(isOwner)) return E.left(USER_NOT_OWNER);\ntry {\nconst updatedUserCollection = await this.prisma.userCollection.update({\nwhere: {\nid: userCollectionID,\n},\ndata: {\ndata: collectionData ?? undefined,\ntitle: newTitle ?? undefined,\n},\n});\nthis.pubsub.publish(\n`user_coll/${updatedUserCollection.userUid}/updated`,\nthis.cast(updatedUserCollection),\n);\nreturn E.right(this.cast(updatedUserCollection));\n} catch (error) {\nreturn E.left(USER_COLL_NOT_FOUND);\n}\n}"
"async createRequest(\ncollectionID: string,\ntitle: string,\nrequest: string,\ntype: ReqType,\nuser: AuthUser,\n): Promise<E.Left<string> | E.Right<UserRequest>> {\nconst jsonRequest = stringToJson(request);\nif (E.isLeft(jsonRequest)) return E.left(jsonRequest.left);\nconst collection =\nawait this.userCollectionService.getUserCollection(collectionID);\nif (E.isLeft(collection)) return E.left(collection.left);\nif (collection.right.userUid !== user.uid)\nreturn E.left(USER_COLLECTION_NOT_FOUND);\nif (collection.right.type !== ReqType[type])\nreturn E.left(USER_REQUEST_INVALID_TYPE);\ntry {\nconst requestCount =\nawait this.getRequestsCountInCollection(collectionID);\nconst request = await this.prisma.userRequest.create({\ndata: {\ncollectionID,\ntitle,\nrequest: jsonRequest.right,\ntype: ReqType[type],\norderIndex: requestCount + 1,\nuserUid: user.uid,\n},\n});\nconst userRequest = this.cast(request);\nawait this.pubsub.publish(\n`user_request/${user.uid}/created`,\nuserRequest,\n);\nreturn E.right(userRequest);\n} catch (err) {\nreturn E.left(USER_REQUEST_CREATION_FAILED);\n}\n}"
"async moveRequest(\nsrcCollID: string,\ndestCollID: string,\nrequestID: string,\nnextRequestID: string,\nuser: AuthUser,\n): Promise<E.Left<string> | E.Right<UserRequest>> {\nconst twoRequests = await this.findRequestAndNextRequest(\nsrcCollID,\ndestCollID,\nrequestID,\nnextRequestID,\nuser,\n);\nif (E.isLeft(twoRequests)) return twoRequests;\nconst { request: dbRequest, nextRequest: dbNextRequest } =\ntwoRequests.right;\nconst isTypeValidate = await this.validateTypeEqualityForMoveRequest(\nsrcCollID,\ndestCollID,\ndbRequest,\ndbNextRequest,\n);\nif (E.isLeft(isTypeValidate)) return E.left(isTypeValidate.left);\nconst updatedRequest = await this.reorderRequests(\nsrcCollID,\ndbRequest,\ndestCollID,\ndbNextRequest,\n);\nif (E.isLeft(updatedRequest)) return updatedRequest;\nconst userRequest: UserRequest = this.cast(updatedRequest.right);\nawait this.pubsub.publish(`user_request/${user.uid}/moved`, {\nrequest: userRequest,\nnextRequest: dbNextRequest ? this.cast(dbNextRequest) : null,\n});\nreturn E.right(userRequest);\n}"
"async validate(\naccessToken: string,\nrefreshToken: string,\nprofile: Profile,\ndone,\n) {\nconst email = profile.emails?.[0].value;\nif (!validateEmail(email))\nthrow new UnauthorizedException(AUTH_EMAIL_NOT_PROVIDED_BY_OAUTH);\nconst user = await this.usersService.findUserByEmail(email);\nif (O.isNone(user)) {\nconst createdUser = await this.usersService.createUserSSO(\naccessToken,\nrefreshToken,\nprofile,\n);\nreturn createdUser;\n}\nif (!user.value.displayName || !user.value.photoURL) {\nconst updatedUser = await this.usersService.updateUserDetails(\nuser.value,\nprofile,\n);\nif (E.isLeft(updatedUser)) {\nthrow new UnauthorizedException(updatedUser.left);\n}\n}\nconst providerAccountExists =\nawait this.authService.checkIfProviderAccountExists(user.value, profile);\nif (O.isNone(providerAccountExists))\nawait this.usersService.createProviderAccount(\nuser.value,\naccessToken,\nrefreshToken,\nprofile,\n);\nreturn user.value;\n}"
"export async function createHoppApp(\nel: string | Element,\nplatformDef: PlatformDef\n) {\ninitKernel(getKernelMode())\nsetPlatformDef(platformDef)\nconst app = createApp(App)\nconst initService = getService(InitializationService)\nawait initService.initPre()\ntry {\nawait initService.initAuthAndSync()\n} catch {\nconsole.error(\n`Failed connecting to the backend, make sure the service is running and accessible on the network`\n)\n}\nself.MonacoEnvironment = {\ngetWorker(_, label) {\nif (label === `typescript`) {\nreturn new tsWorker()\n}\nreturn new editorWorker()\n},\n}\nloader.config({ monaco })\nHOPP_MODULES.forEach((mod) => mod.onVueAppInit?.(app))\nplatformDef.addedHoppModules?.forEach((mod) => mod.onVueAppInit?.(app))\napp.mount(el)\nawait initService.initPost()\nconsole.info(\n`%cWE ♥️ OPEN SOURCE`,\n`margin:8px 0;font-family:sans-serif;font-weight:600;font-size:60px;color:violet;`\n)\nconsole.info(\n`%cContribute: https:\n`margin:8px 0;font-family:sans-serif;font-weight:500;font-size:24px;color:violet;`\n)\n}"
"export function usePreview(\npreviewEnabled: Ref<boolean>,\nresponseBodyText: Ref<string>\n): {\npreviewFrame: Ref<HTMLIFrameElement | null>\npreviewEnabled: Ref<boolean>\ntogglePreview: () => void\n} {\nconst previewFrame: Ref<HTMLIFrameElement | null> = ref(null)\nconst url = ref(``)\nconst updatePreviewFrame = () => {\nif (\npreviewEnabled.value &&\npreviewFrame.value &&\nshouldUpdatePreviewFrame.value\n) {\nconst previewDocument = new DOMParser().parseFromString(\nresponseBodyText.value,\n`text/html`\n)\npreviewDocument.head.innerHTML =\n`<base href=`${url.value}`>` + previewDocument.head.innerHTML\npreviewFrame.value.srcdoc = previewDocument.documentElement.outerHTML\npreviewFrame.value.setAttribute(`data-previewing-url`, url.value)\n}\n}\nwatch(\npreviewEnabled,\n() => {\nupdatePreviewFrame()\n},\n{\nimmediate: true,\n}\n)\nconst shouldUpdatePreviewFrame = computed(\n() => previewFrame.value?.getAttribute(`data-previewing-url`) !== url.value\n)\nconst togglePreview = () => {\npreviewEnabled.value = !previewEnabled.value\nupdatePreviewFrame()\n}\nreturn {\npreviewFrame,\npreviewEnabled,\ntogglePreview,\n}\n}"
"export function useSteps() {\ntype Step = ReturnType<typeof defineStep>\nconst steps: Step[] = []\nconst currentStepIndex = ref(0)\nconst currentStep = computed(() => {\nreturn steps[currentStepIndex.value]\n})\nconst backHistoryIndexes = ref([0])\nconst hasPreviousStep = computed(() => {\nreturn currentStepIndex.value > 0\n})\nconst addStep = (step: Step) => {\nsteps.push(step)\n}\nconst goToNextStep = () => {\ncurrentStepIndex.value++\nbackHistoryIndexes.value.push(currentStepIndex.value)\n}\nconst goToStep = (stepId: string) => {\ncurrentStepIndex.value = steps.findIndex((step) => step.id === stepId)\nbackHistoryIndexes.value.push(currentStepIndex.value)\n}\nconst goToPreviousStep = () => {\nif (backHistoryIndexes.value.length !== 1) {\nbackHistoryIndexes.value.pop()\ncurrentStepIndex.value =\nbackHistoryIndexes.value[backHistoryIndexes.value.length - 1]\n}\n}\nreturn {\nsteps,\ncurrentStep,\naddStep,\ngoToPreviousStep,\ngoToNextStep,\ngoToStep,\nhasPreviousStep,\n}\n}"
"export function useReadonlyStream<T>(\nstream$: Observable<T>,\ninitialValue?: T,\ncloneMode: CloneMode = `shallow`\n): Ref<T> {\nlet sub: Subscription | null = null\nonBeforeUnmount(() => {\nif (sub) {\nsub.unsubscribe()\n}\n})\nconst r = customRef((track, trigger) => {\nlet val = initialValue\nsub = stream$.subscribe((value) => {\nif (cloneMode === `noclone`) {\nval = value\n} else if (cloneMode === `shallow`) {\nval = clone(value)\n} else if (cloneMode === `deep`) {\nval = cloneDeep(value)\n}\ntrigger()\n})\nreturn {\nget() {\ntrack()\nreturn val\n},\nset() {\ntrigger()\nthrow new Error(`Cannot write to a ref from useReadonlyStream`)\n},\n}\n})\nreturn readonly(r) as Ref<T>\n}"
"export function useScrollerRef(\nlabel: string = `Lens`,\nclassSelector: string = `.cm-scroller`,\ninitialScrollTop?: number,\nscrollKey?: string\n) {\nconst containerRef = ref<HTMLElement | null>(null)\nconst scrollerRef = ref<HTMLElement | null>(null)\nconst scrollService = useService(ScrollService)\nlet isUnmounted = false\nfunction waitUntilScrollable(\nmaxTries = 60,\ndelay = 16\n): Promise<HTMLElement> {\nreturn new Promise((resolve, reject) => {\nlet tries = 0\nconst tryFind = () => {\nif (isUnmounted) {\nreject(new Error(`[${label}] Aborted: component unmounted`))\nreturn\n}\nconst scroller = containerRef.value?.querySelector(\nclassSelector\n) as HTMLElement | null\nif (scroller && scroller.scrollHeight > scroller.clientHeight) {\nresolve(scroller)\nreturn\n}\ntries++\nif (tries >= maxTries) {\nreject(\nnew Error(`[${label}] Timeout: ${classSelector} never scrollable`)\n)\n} else {\nsetTimeout(tryFind, delay)\n}\n}\ntryFind()\n})\n}\nlet onScroll: (() => void) | null = null\nonMounted(async () => {\ntry {\nconst scroller = await waitUntilScrollable()\nscrollerRef.value = scroller\nrequestAnimationFrame(() => {\nif (\nscrollKey &&\nscrollService.getScrollForKey(scrollKey) !== undefined\n) {\nscroller.scrollTop = scrollService.getScrollForKey(scrollKey)!\n} else if (initialScrollTop !== undefined) {\nscroller.scrollTop = initialScrollTop\n}\n})\nonScroll = () => {\nif (scrollKey) {\nscrollService.setScrollForKey(scrollKey, scroller.scrollTop)\n}\n}\nscroller.addEventListener(`scroll`, onScroll)\n} catch (error: any) {\nconsole.error(`[${label}] Failed to initialize scroller:`, error.message)\n}\n})\nonBeforeUnmount(() => {\nisUnmounted = true\nif (scrollerRef.value && onScroll) {\nscrollerRef.value.removeEventListener(`scroll`, onScroll)\n}\n})\nreturn { containerRef, scrollerRef }\n}"
"export async function useWhatsNewDialog() {\nconst persistenceService = getService(PersistenceService)\nconst versionFromLocalStorage =\nawait persistenceService.getLocalConfig(`hopp_v`)\nif (!versionFromLocalStorage) {\nawait persistenceService.setLocalConfig(\n`hopp_v`,\nhoppscotchCommonPkgVersion\n)\nreturn\n}\nif (versionFromLocalStorage === hoppscotchCommonPkgVersion) {\nreturn\n}\nconst getMajorVersion = (v: string) => v.split(`.`).slice(0, 2).join(`.`)\nconst majorVersionFromLocalStorage = getMajorVersion(versionFromLocalStorage)\nconst hoppscotchCommonPkgMajorVersion = getMajorVersion(\nhoppscotchCommonPkgVersion\n)\nif (majorVersionFromLocalStorage !== hoppscotchCommonPkgMajorVersion) {\nsetTimeout(async () => {\nconst notesUrl = await getReleaseNotes(hoppscotchCommonPkgMajorVersion)\nif (notesUrl) {\nsonner.custom(markRaw(WhatsNewDialog), {\ncomponentProps: {\nnotesUrl,\nversion: hoppscotchCommonPkgVersion,\n},\nposition: `bottom-left`,\nstyle: {\nbottom: `15px`,\nleft: `30px`,\n},\nduration: Infinity,\n})\n}\n}, 10000)\n}\nawait persistenceService.setLocalConfig(`hopp_v`, hoppscotchCommonPkgVersion)\n}"
"export function defineActionHandler<A extends HoppAction>(\naction: A,\nhandler: ActionFunc<A>,\nisActive: Ref<boolean> | undefined = undefined\n) {\nlet mounted = false\nlet bound = false\nonMounted(() => {\nmounted = true\nif (isActive === undefined || isActive.value === true) {\nbound = true\nbindAction(action, handler)\n}\n})\nonBeforeUnmount(() => {\nmounted = false\nbound = false\nunbindAction(action, handler)\n})\nif (isActive) {\nwatch(\nisActive,\n(active) => {\nif (mounted) {\nif (active) {\nif (!bound) {\nbound = true\nbindAction(action, handler)\n}\n} else if (bound) {\nbound = false\nunbindAction(action, handler)\n}\n}\n},\n{ immediate: true }\n)\n}\n}"
"function parseObj(): JSONObjectValue {\nconst nodeStart = start\nconst members: JSONObjectMember[] = []\nconst comments = [...pendingComments]\npendingComments = []\nexpect(`{`)\nlet first = true\nwhile (!skip(`}`)) {\nif (!first) {\nexpect(`,`)\nif (skip(`}`)) {\nbreak\n}\n}\nfirst = false\nconst memberComments = [...pendingComments]\npendingComments = []\nconst member = parseMember()\nif (memberComments.length > 0) {\nmember.comments = memberComments\n}\nmembers.push(member)\n}\nconst trailingComments = [...pendingComments]\npendingComments = []\nreturn {\nkind: `Object`,\nstart: nodeStart,\nend: lastEnd,\nmembers,\ncomments:\ncomments.length > 0 || trailingComments.length > 0\n? [...comments, ...trailingComments]\n: undefined,\n}\n}"
"function parseArr(): JSONArrayValue {\nconst nodeStart = start\nconst values: JSONValue[] = []\nconst comments = [...pendingComments]\npendingComments = []\nexpect(`[`)\nlet first = true\nwhile (!skip(`]`)) {\nif (!first) {\nexpect(`,`)\nif (skip(`]`)) {\nbreak\n}\n}\nfirst = false\nconst value = parseVal()\nif (pendingComments.length > 0 && typeof value === `object`) {\n;(value as JSONObjectValue).comments = [\n...((value as JSONObjectValue).comments || []),\n...pendingComments,\n]\npendingComments = []\n}\nvalues.push(value)\n}\nconst trailingComments = [...pendingComments]\npendingComments = []\nreturn {\nkind: `Array`,\nstart: nodeStart,\nend: lastEnd,\nvalues,\ncomments:\ncomments.length > 0 || trailingComments.length > 0\n? [...comments, ...trailingComments]\n: undefined,\n}\n}"
function readString() {\nch()\nwhile (code !== 34 && code > 31) {\nif (code === (92 as any)) {\nch()\nswitch (code) {\ncase 34:\ncase 47:\ncase 92:\ncase 98:\ncase 102:\ncase 110:\ncase 114:\ncase 116:\nch()\nbreak\ncase 117:\nch()\nreadHex()\nreadHex()\nreadHex()\nreadHex()\nbreak\ndefault:\nthrow syntaxError(`Bad character escape sequence.`)\n}\n} else if (end === strLen) {\nthrow syntaxError(`Unterminated string.`)\n} else {\nch()\n}\n}\nif (code === 34) {\nch()\nreturn\n}\nthrow syntaxError(`Unterminated string.`)\n}
"function lex() {\nlastEnd = end\nwhile (code === 9 || code === 10 || code === 13 || code === 32) {\nch()\n}\nif (code === 0) {\nkind = `EOF`\nreturn\n}\nstart = end\nswitch (code) {\ncase 34:\nkind = `String`\nreturn readString()\ncase 45:\ncase 48:\ncase 49:\ncase 50:\ncase 51:\ncase 52:\ncase 53:\ncase 54:\ncase 55:\ncase 56:\ncase 57:\nkind = `Number`\nreturn readNumber()\ncase 102:\nif (string.slice(start, start + 5) !== `false`) {\nbreak\n}\nend += 4\nch()\nkind = `Boolean`\nreturn\ncase 110:\nif (string.slice(start, start + 4) !== `null`) {\nbreak\n}\nend += 3\nch()\nkind = `Null`\nreturn\ncase 116:\nif (string.slice(start, start + 4) !== `true`) {\nbreak\n}\nend += 3\nch()\nkind = `Boolean`\nreturn\n}\nkind = string[start]\nch()\n}"
function readString() {\nch()\nwhile (code !== 34 && code > 31) {\nif (code === (92 as any)) {\nch()\nswitch (code) {\ncase 34:\ncase 47:\ncase 92:\ncase 98:\ncase 102:\ncase 110:\ncase 114:\ncase 116:\nch()\nbreak\ncase 117:\nch()\nreadHex()\nreadHex()\nreadHex()\nreadHex()\nbreak\ndefault:\nthrow syntaxError(`Bad character escape sequence.`)\n}\n} else if (end === strLen) {\nthrow syntaxError(`Unterminated string.`)\n} else {\nch()\n}\n}\nif (code === 34) {\nch()\nreturn\n}\nthrow syntaxError(`Unterminated string.`)\n}
"export function createRESTNetworkRequestStream(\nrequest: EffectiveHoppRESTRequest\n): [Observable<HoppRESTResponse>, () => void] {\nconst response = new BehaviorSubject<HoppRESTResponse>({\ntype: `loading`,\nreq: request,\n})\nconst req = cloneDeep(request)\nconst execResult = RESTRequest.toRequest(req).then((kernelRequest) => {\nif (!kernelRequest) {\nresponse.next({\ntype: `network_fail`,\nreq,\nerror: new Error(`Failed to create kernel request`),\n})\nresponse.complete()\nreturn\n}\nreturn service.execute(kernelRequest)\n})\nconst service = getService(KernelInterceptorService)\nexecResult.then((result) => {\nif (!result) return\nresult.response.then(async (res) => {\nif (res._tag === `Right`) {\nconst processedRes = await RESTResponse.toResponse(res.right, req)\nif (processedRes.type === `success`) {\nresponse.next(processedRes)\n} else {\nresponse.next({\ntype: `network_fail`,\nreq,\nerror: processedRes.error,\n})\n}\n} else {\nresponse.next({\ntype: `interceptor_error`,\nreq,\nerror: res.left,\n})\n}\nresponse.complete()\n})\n})\nreturn [\nresponse,\nasync () => {\nconst result = await execResult\nif (result) await result.cancel()\n},\n]\n}"
"export function getJSONOutlineAtPos(\njsonRootAst: JSONObjectValue | JSONArrayValue,\nposIndex: number\n): PathEntry[] | null {\ntry {\nconst rootObj = jsonRootAst\nif (posIndex > rootObj.end || posIndex < rootObj.start)\nthrow new Error(`Invalid position`)\nlet current: JSONValue = rootObj\nconst path: PathEntry[] = []\nif (rootObj.kind === `Object`) {\npath.push({\nkind: `RootObject`,\nastValue: rootObj,\n})\n} else {\npath.push({\nkind: `RootArray`,\nastValue: rootObj,\n})\n}\nwhile (current.kind === `Object` || current.kind === `Array`) {\nif (current.kind === `Object`) {\nconst next: JSONObjectMember | undefined = current.members.find(\n(member) => member.start <= posIndex && member.end >= posIndex\n)\nif (!next) throw new Error(`Couldn't find child`)\npath.push({\nkind: `ObjectMember`,\nname: next.key.value,\nastValue: next,\nastParent: current,\n})\ncurrent = next.value\n} else {\nconst nextIndex = current.values.findIndex(\n(value) => value.start <= posIndex && value.end >= posIndex\n)\nif (nextIndex < 0) throw new Error(`Couldn't find child`)\nconst next: JSONValue = current.values[nextIndex]\npath.push({\nkind: `ArrayMember`,\nindex: nextIndex,\nastValue: next,\nastParent: current,\n})\ncurrent = next\n}\n}\nreturn path\n} catch (e: any) {\nreturn null\n}\n}"
"function updateEnvsAfterTestScript(runResult: E.Right<SandboxTestResult>) {\nconst globalEnvVariables = updateEnvironments(\nrunResult.right.envs.global,\n`global`\n)\nsetGlobalEnvVariables({\nv: 2,\nvariables: globalEnvVariables,\n})\nconst selectedEnvVariables = updateEnvironments(\ncloneDeep(runResult.right.envs.selected),\n`selected`\n)\nif (environmentsStore.value.selectedEnvironmentIndex.type === `MY_ENV`) {\nconst env = getEnvironment({\ntype: `MY_ENV`,\nindex: environmentsStore.value.selectedEnvironmentIndex.index,\n})\nupdateEnvironment(environmentsStore.value.selectedEnvironmentIndex.index, {\nname: env.name,\nv: 2,\nid: `id` in env ? env.id : ``,\nvariables: selectedEnvVariables,\n})\n} else if (\nenvironmentsStore.value.selectedEnvironmentIndex.type === `TEAM_ENV`\n) {\nconst env = getEnvironment({\ntype: `TEAM_ENV`,\n})\npipe(\nupdateTeamEnvironment(\nJSON.stringify(selectedEnvVariables),\nenvironmentsStore.value.selectedEnvironmentIndex.teamEnvID,\nenv.name\n)\n)()\n}\n}"
"function translateToSandboxTestResults(\ntestDesc: SandboxTestResult\n): HoppTestResult {\nconst translateChildTests = (child: TestDescriptor): HoppTestData => {\nreturn {\ndescription: child.descriptor,\nexpectResults: child.expectResults,\ntests: child.children.map(translateChildTests),\n}\n}\nconst globals = cloneDeep(getGlobalVariables()).map((g, index) => ({\n...g,\ncurrentValue: getEnvironmentVariableValue(`Global`, index, g.secret) ?? ``,\n}))\nconst envVars = getCurrentEnvironment().variables.map((e, index) => ({\n...e,\ncurrentValue:\ngetEnvironmentVariableValue(\ngetCurrentEnvironment().id,\nindex,\ne.secret\n) ?? ``,\n}))\nreturn {\ndescription: ``,\nexpectResults: testDesc.tests.expectResults,\ntests: testDesc.tests.children.map(translateChildTests),\nscriptError: false,\nenvDiff: {\nglobal: {\nadditions: getAddedEnvVariables(globals, testDesc.envs.global),\ndeletions: getRemovedEnvVariables(globals, testDesc.envs.global),\nupdations: getUpdatedEnvVariables(globals, testDesc.envs.global),\n},\nselected: {\nadditions: getAddedEnvVariables(envVars, testDesc.envs.selected),\ndeletions: getRemovedEnvVariables(envVars, testDesc.envs.selected),\nupdations: getUpdatedEnvVariables(envVars, testDesc.envs.selected),\n},\n},\nconsoleEntries: testDesc.consoleEntries,\n}\n}"
"function parseV0ExtURL(\nurlParams: Record<string, any>,\ninitialReq?: HoppRESTRequest\n): HoppRESTRequest {\nconst resolvedReq = initialReq ?? getDefaultRESTRequest()\nif (urlParams.method && typeof urlParams.method === `string`) {\nresolvedReq.method = urlParams.method\n}\nif (urlParams.url && typeof urlParams.url === `string`) {\nif (urlParams.path && typeof urlParams.path === `string`) {\nresolvedReq.endpoint = `${urlParams.url}/${urlParams.path}`\n} else {\nresolvedReq.endpoint = urlParams.url\n}\n}\nif (urlParams.headers && typeof urlParams.headers === `string`) {\nresolvedReq.headers = JSON.parse(urlParams.headers)\n}\nif (urlParams.params && typeof urlParams.params === `string`) {\nresolvedReq.params = JSON.parse(urlParams.params)\n}\nif (urlParams.httpUser && typeof urlParams.httpUser === `string`) {\nresolvedReq.auth = {\nauthType: `basic`,\nauthActive: true,\nusername: urlParams.httpUser,\npassword: urlParams.httpPassword ?? ``,\n}\n}\nif (urlParams.bearerToken && typeof urlParams.bearerToken === `string`) {\nresolvedReq.auth = {\nauthType: `bearer`,\nauthActive: true,\ntoken: urlParams.bearerToken,\n}\n}\nif (urlParams.contentType) {\nif (urlParams.contentType === `multipart/form-data`) {\nresolvedReq.body = {\ncontentType: `multipart/form-data`,\nbody: JSON.parse(urlParams.bodyParams || `[]`).map(\n(x: any) =>\n<FormDataKeyValue>{\nactive: x.active,\nkey: x.key,\nvalue: x.value,\nisFile: false,\n}\n),\n}\n} else if (isJSONContentType(urlParams.contentType)) {\nif (urlParams.rawParams) {\nresolvedReq.body = {\ncontentType: urlParams.contentType,\nbody: urlParams.rawParams,\n}\n} else {\nresolvedReq.body = {\ncontentType: urlParams.contentType,\nbody: urlParams.bodyParams,\n}\n}\n} else {\nresolvedReq.body = {\ncontentType: urlParams.contentType,\nbody: urlParams.rawParams,\n}\n}\n}\nreturn resolvedReq\n}"
"onVueAppInit(app) {\nconst router = createRouter({\nhistory: createWebHistory(),\nroutes,\n})\nrouter.beforeEach(async (to, from) => {\n_isLoadingInitialRoute.value = isInitialRoute(from)\nconst onBeforeRouteChangePromises: Promise<any>[] = []\nHOPP_MODULES.forEach((mod) => {\nconst res = mod.onBeforeRouteChange?.(to, from, router)\nif (res) onBeforeRouteChangePromises.push(res)\n})\nplatform.addedHoppModules?.forEach((mod) => {\nconst res = mod.onBeforeRouteChange?.(to, from, router)\nif (res) onBeforeRouteChangePromises.push(res)\n})\nawait Promise.all(onBeforeRouteChangePromises)\n})\nrouter.afterEach((to) => {\nplatform.analytics?.logPageView(to.fullPath)\n_isLoadingInitialRoute.value = false\nHOPP_MODULES.forEach((mod) => {\nmod.onAfterRouteChange?.(to, router)\n})\nplatform.addedHoppModules?.forEach((mod) => {\nmod.onAfterRouteChange?.(to, router)\n})\n})\napp.use(router)\nHOPP_MODULES.forEach((mod) => mod.onRouterInit?.(app, router))\nplatform.addedHoppModules?.forEach((mod) => mod.onRouterInit?.(app, router))\n},"
"function computeCollectionInheritedProps(\ncollection: HoppCollection,\nref_id: string,\ntype: `my-collections` | `team-collections` = `my-collections`,\nparentAuth: HoppRESTAuth | null = null,\nparentHeaders: HoppRESTHeaders | null = null\n): { auth: HoppRESTAuth; headers: HoppRESTHeaders } | null {\nconst inheritedAuth =\ncollection.auth?.authType === `inherit` && collection.auth.authActive\n? (parentAuth ?? { authType: `none`, authActive: false })\n: (collection.auth ?? { authType: `none`, authActive: false })\nconst inheritedHeaders: HoppRESTHeaders = [\n...(parentHeaders ?? []),\n...collection.headers,\n]\nconst isTargetCollection =\ntype === `my-collections`\n? collection._ref_id === ref_id\n: collection.id === ref_id\nif (isTargetCollection) {\nreturn {\nauth: inheritedAuth,\nheaders: inheritedHeaders,\n}\n}\nfor (const folder of collection.folders) {\nconst result = computeCollectionInheritedProps(\nfolder,\nref_id,\ntype,\ninheritedAuth,\ninheritedHeaders\n)\nif (result) return result\n}\nreturn null\n}"
"function removeDuplicateCollectionsFromPath(\nidToRemove: string,\ncollectionPath: string | null,\ncollections: HoppCollection[],\ntype: `collection` | `request`\n): HoppCollection[] {\nconst indexes = collectionPath?.split(`/`).map((x) => parseInt(x))\nindexes && indexes.pop()\nconst parentPath = indexes?.join(`/`)\nconst parentCollection = parentPath\n? navigateToFolderWithIndexPath(\ncollections,\nparentPath.split(`/`).map((x) => parseInt(x)) || []\n)\n: undefined\nif (collectionPath && parentCollection) {\nif (type === `collection`) {\nparentCollection.folders = removeDuplicatesFromAnArrayById(\nidToRemove,\nparentCollection.folders\n)\n} else {\nparentCollection.requests = removeDuplicatesFromAnArrayById(\nidToRemove,\nparentCollection.requests\n)\n}\n} else {\nreturn removeDuplicatesFromAnArrayById(idToRemove, collections)\n}\nreturn collections\nfunction removeDuplicatesFromAnArrayById<T extends { id?: string }>(\nidToRemove: string,\narrayWithID: T[]\n) {\nconst duplicateEntries = arrayWithID.filter(\n(entry) => entry.id === idToRemove\n)\nif (duplicateEntries.length === 2) {\nconst duplicateEntryIndex = arrayWithID.findIndex(\n(entry) => entry.id === idToRemove\n)\narrayWithID.splice(duplicateEntryIndex, 1)\n}\nreturn arrayWithID\n}\n}"
"moveFolder(\n{ state }: RESTCollectionStoreType,\n{ path, destinationPath }: { path: string; destinationPath: string | null }\n) {\nconst newState = state\nif (destinationPath === null) {\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst folderIndex = indexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(\nnewState,\nindexPaths\n)\nif (containingFolder === null) {\nconsole.error(\n`The folder to move is already in the root. Skipping request to move folder.`\n)\nreturn {}\n}\nconst theFolder = containingFolder.folders.splice(folderIndex, 1)\nnewState.push(theFolder[0] as HoppCollection)\nreturn {\nstate: newState,\n}\n}\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst destinationIndexPaths = destinationPath\n.split(`/`)\n.map((x) => parseInt(x))\nif (indexPaths.length === 0 || destinationIndexPaths.length === 0) {\nconsole.error(\n`Given path is too short. Skipping request to move folder '${path}' to destination '${destinationPath}'.`\n)\nreturn {}\n}\nconst target = navigateToFolderWithIndexPath(\nnewState,\ndestinationIndexPaths\n)\nif (target === null) {\nconsole.error(\n`Could not resolve destination path '${destinationPath}'. Skipping moveFolder dispatch.`\n)\nreturn {}\n}\nconst folderIndex = indexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(newState, indexPaths)\nif (containingFolder === null) {\nconst theFolder = newState.splice(folderIndex, 1)\ntarget.folders.push(theFolder[0])\n} else {\nconst theFolder = containingFolder.folders.splice(folderIndex, 1)\ntarget.folders.push(theFolder[0])\n}\nreturn { state: newState }\n},"
"updateCollectionOrder(\n{ state }: RESTCollectionStoreType,\n{\ncollectionIndex,\ndestinationCollectionIndex,\n}: {\ncollectionIndex: string\ndestinationCollectionIndex: string | null\n}\n) {\nconst newState = state\nconst indexPaths = collectionIndex.split(`/`).map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nif (destinationCollectionIndex === null) {\nconst folderIndex = indexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(\nnewState,\nindexPaths\n)\nif (containingFolder === null) {\nnewState.push(newState.splice(folderIndex, 1)[0])\nreturn {\nstate: newState,\n}\n}\ncontainingFolder.folders.push(\ncontainingFolder.folders.splice(folderIndex, 1)[0]\n)\nreturn {\nstate: newState,\n}\n}\nconst destinationIndexPaths = destinationCollectionIndex\n.split(`/`)\n.map((x) => parseInt(x))\nif (destinationIndexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst folderIndex = indexPaths.pop() as number\nconst destinationFolderIndex = destinationIndexPaths.pop() as number\nconst containingFolder = navigateToFolderWithIndexPath(\nnewState,\ndestinationIndexPaths\n)\nif (containingFolder === null) {\nreorderItems(newState, folderIndex, destinationFolderIndex)\nreturn {\nstate: newState,\n}\n}\nreorderItems(containingFolder.folders, folderIndex, destinationFolderIndex)\nreturn {\nstate: newState,\n}\n},"
"duplicateCollection(\n{ state }: RESTCollectionStoreType,\n{ path, collectionSyncID }: { path: string; collectionSyncID?: string }\n) {\nconst t = getI18n()\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst isRootCollection = indexPaths.length === 1\nconst collection = navigateToFolderWithIndexPath(state, [...indexPaths])\nif (collection) {\nconst name = `${collection.name} - ${t(`action.duplicate`)}`\nfunction recursiveChangeRefIdToAvoidConflicts(\ncollection: HoppCollection\n): HoppCollection {\nconst newCollection = {\n...collection,\n_ref_id: generateUniqueRefId(`coll`),\n}\nnewCollection.folders = newCollection.folders.map((folder) =>\nrecursiveChangeRefIdToAvoidConflicts(folder)\n)\nreturn newCollection\n}\nconst duplicatedCollection = {\n...cloneDeep(collection),\nname,\n...(collection.id\n? { id: `${collection.id}-duplicate-collection` }\n: {}),\n}\nconst duplicatedCollectionWithNewRefId =\nrecursiveChangeRefIdToAvoidConflicts(duplicatedCollection)\nif (isRootCollection) {\nnewState.push(duplicatedCollectionWithNewRefId)\n} else {\nconst parentCollectionIndexPath = indexPaths.slice(0, -1)\nconst parentCollection = navigateToFolderWithIndexPath(state, [\n...parentCollectionIndexPath,\n])\nparentCollection?.folders.push(duplicatedCollectionWithNewRefId)\n}\n}\nreturn {\nstate: newState,\n}\n},"
"removeRequest(\n{ state }: RESTCollectionStoreType,\n{\npath,\nrequestIndex,\nrequestID,\n}: { path: string; requestIndex: number; requestID?: string }\n) {\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve path '${path}'. Ignoring removeRequest dispatch.`\n)\nreturn {}\n}\ntargetLocation.requests.splice(requestIndex, 1)\nconst tabService = getService(RESTTabService)\nconst tab = tabService.getTabRefWithSaveContext({\noriginLocation: `user-collection`,\nfolderPath: path,\nrequestIndex: requestIndex,\n})\nif (tab) {\ntab.value.document.saveContext = undefined\ntab.value.document.isDirty = true\n}\nreturn {\nstate: newState,\n}\n},"
"moveRequest(\n{ state }: RESTCollectionStoreType,\n{\npath,\nrequestIndex,\ndestinationPath,\n}: { path: string; requestIndex: number; destinationPath: string }\n) {\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve source path '${path}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\nconst req = targetLocation.requests[requestIndex]\nconst destIndexPaths = destinationPath.split(`/`).map((x) => parseInt(x))\nconst destLocation = navigateToFolderWithIndexPath(newState, destIndexPaths)\nif (destLocation === null) {\nconsole.log(\n`Could not resolve destination path '${destinationPath}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\ndestLocation.requests.push(req)\ntargetLocation.requests.splice(requestIndex, 1)\nconst tabService = getService(RESTTabService)\nconst possibleTab = tabService.getTabRefWithSaveContext({\noriginLocation: `user-collection`,\nfolderPath: path,\nrequestIndex,\n})\nif (possibleTab) {\npossibleTab.value.document.saveContext = {\noriginLocation: `user-collection`,\nfolderPath: destinationPath,\nrequestIndex: destLocation.requests.length - 1,\n}\n}\nreturn {\nstate: newState,\n}\n},"
"updateRequestOrder(\n{ state }: RESTCollectionStoreType,\n{\nrequestIndex,\ndestinationRequestIndex,\ndestinationCollectionPath,\n}: {\nrequestIndex: number\ndestinationRequestIndex: number | null\ndestinationCollectionPath: string\n}\n) {\nconst newState = state\nconst indexPaths = destinationCollectionPath\n.split(`/`)\n.map((x) => parseInt(x))\nif (indexPaths.length === 0) {\nconsole.log(`Given path too short. Skipping request.`)\nreturn {}\n}\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve path '${destinationCollectionPath}'. Ignoring reorderRequest dispatch.`\n)\nreturn {}\n}\nif (destinationRequestIndex === null) {\ntargetLocation.requests.push(\ntargetLocation.requests.splice(requestIndex, 1)[0]\n)\nresolveSaveContextOnRequestReorder({\nlastIndex: requestIndex,\nnewIndex: targetLocation.requests.length,\nfolderPath: destinationCollectionPath,\n})\nreturn {\nstate: newState,\n}\n}\nreorderItems(targetLocation.requests, requestIndex, destinationRequestIndex)\nresolveSaveContextOnRequestReorder({\nlastIndex: requestIndex,\nnewIndex: destinationRequestIndex,\nfolderPath: destinationCollectionPath,\n})\nreturn {\nstate: newState,\n}\n},"
"duplicateCollection(\n{ state }: GraphqlCollectionStoreType,\n{ path, collectionSyncID }: { path: string; collectionSyncID?: string }\n) {\nconst t = getI18n()\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst isRootCollection = indexPaths.length === 1\nconst collection = navigateToFolderWithIndexPath(state, [...indexPaths])\nif (collection) {\nconst name = `${collection.name} - ${t(`action.duplicate`)}`\nconst duplicatedCollection = {\n...cloneDeep(collection),\nname,\n...(collection.id\n? { id: `${collection.id}-duplicate-collection` }\n: {}),\n}\nif (isRootCollection) {\nnewState.push(duplicatedCollection)\n} else {\nconst parentCollectionIndexPath = indexPaths.slice(0, -1)\nconst parentCollection = navigateToFolderWithIndexPath(state, [\n...parentCollectionIndexPath,\n])\nparentCollection?.folders.push(duplicatedCollection)\n}\n}\nreturn {\nstate: newState,\n}\n},"
"moveRequest(\n{ state }: GraphqlCollectionStoreType,\n{\npath,\nrequestIndex,\ndestinationPath,\n}: { path: string; requestIndex: number; destinationPath: string }\n) {\nconst newState = state\nconst indexPaths = path.split(`/`).map((x) => parseInt(x))\nconst targetLocation = navigateToFolderWithIndexPath(newState, indexPaths)\nif (targetLocation === null) {\nconsole.log(\n`Could not resolve source path '${path}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\nconst req = targetLocation.requests[requestIndex]\nconst destIndexPaths = destinationPath.split(`/`).map((x) => parseInt(x))\nconst destLocation = navigateToFolderWithIndexPath(newState, destIndexPaths)\nif (destLocation === null) {\nconsole.log(\n`Could not resolve destination path '${destinationPath}'. Skipping moveRequest dispatch.`\n)\nreturn {}\n}\ndestLocation.requests.push(req)\ntargetLocation.requests.splice(requestIndex, 1)\nreturn {\nstate: newState,\n}\n},"
"export function getAggregateEnvsWithCurrentValue() {\nconst currentEnv = getCurrentEnvironment()\nreturn [\n...currentEnv.variables.map((x, index) => {\nlet currentValue = x.currentValue\nif (x.secret) {\ncurrentValue =\nsecretEnvironmentService.getSecretEnvironmentVariableValue(\ncurrentEnv.id,\nindex\n) ?? ``\n}\nreturn <AggregateEnvironment>{\nkey: x.key,\ncurrentValue:\ncurrentEnvironmentValueService.getEnvironmentVariableValue(\ncurrentEnv.id,\nindex\n) ?? currentValue,\ninitialValue: x.initialValue,\nsecret: x.secret,\nsourceEnv: currentEnv.name,\n}\n}),\n...getGlobalVariables().map((x, index) => {\nlet currentValue = x.currentValue\nif (x.secret) {\ncurrentValue =\nsecretEnvironmentService.getSecretEnvironmentVariableValue(\n`Global`,\nindex\n) ?? ``\n}\nreturn <AggregateEnvironment>{\nkey: x.key,\ncurrentValue:\ncurrentEnvironmentValueService.getEnvironmentVariableValue(\n`Global`,\nindex\n) ?? currentValue,\ninitialValue: x.initialValue,\nsecret: x.secret,\nsourceEnv: `Global`,\n}\n}),\n]\n}"
"override onServiceInit() {\nconsole.debug(`DebugService is initialized...`)\nconst container = this.getContainer()\ncontainer.getEventStream().subscribe((event) => {\nif (event.type === `SERVICE_BIND`) {\nconsole.debug(\n`[CONTAINER] Service Bind:`,\nevent.bounderID ?? `<CONTAINER>`,\n`->`,\nevent.boundeeID\n)\n} else if (event.type === `SERVICE_INIT`) {\nconsole.debug(`[CONTAINER] Service Init:`, event.serviceID)\nconst service = container.getBoundServiceWithID(event.serviceID)\n;(window as any)[event.serviceID] = service\nservice?.getEventStream().subscribe((ev: any) => {\nconsole.debug(`[${event.serviceID}] Event:`, ev)\n})\n}\n})\nfor (const [id, service] of container.getBoundServices()) {\nservice.getEventStream().subscribe((event: any) => {\nconsole.debug(`[${id}]`, event)\n})\n;(window as any)[id] = service\n}\n;(window as any)._getService = this.getService.bind(this)\n;(window as any)._getBoundServiceIDs = this.getBoundServiceIDs.bind(this)\n}"
"public async connectToVendoredInstance(): Promise<boolean> {\nif (this.isCurrentlyVendored()) {\nreturn true\n}\nthis.state$.next({\nstatus: `connecting`,\ntarget: this.getVendoredInstance().displayName,\n})\nthis.emit(this.state$.value)\ntry {\nthis.state$.next({\nstatus: `connected`,\ninstance: this.getVendoredInstance(),\n})\nthis.emit(this.state$.value)\nawait this.saveCurrentState()\nthis.toast.success(\nplatform.instance.displayConfig.connectingMessage.replace(\n`{instanceName}`,\nthis.getVendoredInstance().displayName\n)\n)\nconst loadResponse = await load({\nbundleName: `Hoppscotch`,\nwindow: { title: `Hoppscotch` },\n})\nif (!loadResponse.success) {\nthrow new Error(\n`Failed to load ${this.getVendoredInstance().type} bundle`\n)\n}\nthis.toast.success(\nplatform.instance.displayConfig.connectedMessage.replace(\n`{instanceName}`,\nthis.getVendoredInstance().displayName\n)\n)\nreturn true\n} catch (error) {\nconst errorMessage =\nerror instanceof Error ? error.message : String(error)\nthis.state$.next({\nstatus: `error`,\ntarget: this.getVendoredInstance().displayName,\nmessage: errorMessage,\n})\nthis.emit(this.state$.value)\nthis.toast.error(`Failed to connect: ${errorMessage}`)\nreturn false\n}\n}"
"public async connectToServerInstance(serverUrl: string): Promise<boolean> {\nif (this.isCurrentlyConnectedTo(serverUrl)) {\nconst currentState = this.state$.value\nif (\ncurrentState.status === `connected` &&\ncurrentState.instance.type === `server`\n) {\nconst updatedInstance: ServerInstance = {\n...currentState.instance,\nlastUsed: new Date().toISOString(),\n}\nawait this.updateRecentInstance(updatedInstance)\n}\nreturn true\n}\nconst normalizedUrl = this.normalizeUrl(serverUrl)\nconst displayName = this.getDisplayNameFromUrl(normalizedUrl)\nthis.state$.next({\nstatus: `connecting`,\ntarget: displayName,\n})\nthis.emit(this.state$.value)\ntry {\nconst downloadResponse = await download({ serverUrl: normalizedUrl })\nif (!downloadResponse.success) {\nthrow new Error(`Failed to download bundle`)\n}\nconst instance: ServerInstance = {\ntype: `server`,\nserverUrl: normalizedUrl,\ndisplayName,\nversion: downloadResponse.version,\nlastUsed: new Date().toISOString(),\nbundleName: downloadResponse.bundleName,\n}\nawait this.updateRecentInstance(instance)\nthis.state$.next({\nstatus: `connected`,\ninstance,\n})\nthis.emit(this.state$.value)\nawait this.saveCurrentState()\nthis.toast.success(`Connecting to ${displayName}`)\nconst loadResponse = await load({\nbundleName: downloadResponse.bundleName,\nwindow: { title: `Hoppscotch` },\n})\nif (!loadResponse.success) {\nthrow new Error(`Failed to load bundle`)\n}\nthis.toast.success(`Connected to ${displayName}`)\nreturn true\n} catch (error) {\nconst errorMessage =\nerror instanceof Error ? error.message : String(error)\nthis.state$.next({\nstatus: `error`,\ntarget: displayName,\nmessage: errorMessage,\n})\nthis.emit(this.state$.value)\nthis.toast.error(`Connection failed: ${errorMessage}`)\nreturn false\n}\n}"
"public async removeInstance(serverUrl: string): Promise<boolean> {\ntry {\nconst normalizedUrl = this.normalizeUrl(serverUrl)\nconst instanceToRemove = this.recentInstances$.value.find(\n(instance) => instance.serverUrl === normalizedUrl\n)\nif (!instanceToRemove) {\nreturn false\n}\nif (instanceToRemove.bundleName) {\ntry {\nawait remove({\nbundleName: instanceToRemove.bundleName,\nserverUrl: normalizedUrl,\n})\n} catch (error) {\nconsole.error(`Failed to remove bundle from storage:`, error)\n}\n}\nconst instances = this.recentInstances$.value.filter(\n(instance) => instance.serverUrl !== normalizedUrl\n)\nthis.recentInstances$.next(instances)\nawait this.saveRecentInstances()\nconst displayName = this.getDisplayNameFromUrl(serverUrl)\nthis.toast.success(`Removed ${displayName}`)\nif (this.isCurrentlyConnectedTo(serverUrl)) {\nthis.state$.next({ status: `idle` })\nthis.emit(this.state$.value)\nawait this.saveCurrentState()\n}\nreturn true\n} catch (error) {\nthis.toast.error(`Failed to remove instance`)\nreturn false\n}\n}"
"override onServiceInit() {\nwatch(\nthis.currentUser,\n(user) => {\nif (!user && this.managedTeamListAdapter.isInitialized) {\nthis.managedTeamListAdapter.dispose()\n}\nif (user && !this.managedTeamListAdapter.isInitialized) {\nthis.managedTeamListAdapter.initialize()\n}\n},\n{ immediate: true }\n)\nconst { pause: pauseListPoll, resume: resumeListPoll } = useIntervalFn(\n() => {\nif (this.managedTeamListAdapter.isInitialized) {\nthis.managedTeamListAdapter.fetchList()\nthis.emit({ type: `managed-team-list-adapter-polled` })\n}\n},\nthis.pollingTime,\n{ immediate: true }\n)\nwatch(\nthis.pollingTime,\n(pollingTime) => {\nif (pollingTime === -1) {\npauseListPoll()\n} else {\nresumeListPoll()\n}\n},\n{ immediate: true }\n)\n}"
"export async function generateDigestAuthHeader(params: DigestAuthParams) {\nconst {\nusername,\npassword,\nrealm,\nnonce,\nendpoint,\nmethod,\nalgorithm = `MD5`,\nqop,\nnc = `00000001`,\nopaque,\ncnonce,\nreqBody = ` `,\n} = params\nconst url = new URL(endpoint)\nconst uri = url.pathname + url.search\nconst generatedCnonce = cnonce || md5(`${Math.random()}`)\nconst ha1 =\nalgorithm === `MD5-sess`\n? md5(\n`${md5(`${username}:${realm}:${password}`)}:${nonce}:${generatedCnonce}`\n)\n: md5(`${username}:${realm}:${password}`)\nconst ha2 =\nqop === `auth-int`\n? md5(`${method}:${uri}:${md5(reqBody)}`)\n: md5(`${method}:${uri}`)\nconst response = md5(`${ha1}:${nonce}:${nc}:${generatedCnonce}:${qop}:${ha2}`)\nlet authHeader = `Digest username=`${username}`, realm=`${realm}`, nonce=`${nonce}`, uri=`${uri}`, algorithm=`${algorithm}`, response=`${response}`, qop=${qop}, nc=${nc}, cnonce=`${generatedCnonce}``\nif (opaque) {\nauthHeader += `, opaque=`${opaque}``\n}\nreturn authHeader\n}"
"export async function fetchInitialDigestAuthInfo(\nurl: string,\nmethod: string\n): Promise<DigestAuthInfo> {\nconst t = getI18n()\ntry {\nconst interceptorService = getService(KernelInterceptorService)\nconst exec = await interceptorService.execute({\nid: Date.now(),\nurl,\nmethod,\nversion: `HTTP/1.1`,\n})\nconst initialResponse = await exec.response\nif (E.isLeft(initialResponse)) {\nconst initialFetchFailureReason =\ninitialResponse.left === `cancellation`\n? initialResponse.left\n: initialResponse.left.humanMessage.heading(t)\nthrow new Error(initialFetchFailureReason)\n}\nif (initialResponse.right.status === 401) {\nconst authHeaderEntry = Object.keys(initialResponse.right.headers).find(\n(header) => header.toLowerCase() === `www-authenticate`\n)\nconst authHeader = authHeaderEntry\n? (initialResponse.right.headers[authHeaderEntry] ?? null)\n: null\nif (authHeader) {\nconst authParams = parseDigestAuthHeader(authHeader)\nif (\nauthParams &&\nauthParams.realm &&\nauthParams.nonce &&\nauthParams.qop\n) {\nreturn {\nrealm: authParams.realm,\nnonce: authParams.nonce,\nqop: authParams.qop,\nopaque: authParams.opaque,\nalgorithm: authParams.algorithm,\n}\n}\n}\nthrow new Error(\n`Failed to parse authentication parameters from WWW-Authenticate header`\n)\n}\nthrow new Error(`Unexpected response: ${initialResponse.right.status}`)\n} catch (error) {\nconst errMsg = error instanceof Error ? error.message : error\nconsole.error(`Failed to fetch initial Digest Auth info: ${errMsg}`)\nthrow error\n}\n}"
"export function resolveSaveContextOnCollectionReorder(\npayload: {\nlastIndex: number\nnewIndex: number\nfolderPath: string\nlength?: number\n},\ntype: `remove` | `drop` = `remove`\n) {\nconst { lastIndex, folderPath, length } = payload\nlet { newIndex } = payload\nif (newIndex > lastIndex) newIndex--\nif (lastIndex === newIndex) return\nconst affectedIndexes = getAffectedIndexes(\nlastIndex,\nnewIndex === -1 ? length! : newIndex\n)\nif (newIndex === -1) {\naffectedIndexes.delete(lastIndex)\nif (type === `remove`) {\nresetSaveContextForAffectedRequests(\nfolderPath ? `${folderPath}/${lastIndex}` : lastIndex.toString()\n)\n}\n}\nconst affectedPaths = new Map<string, string>()\nfor (const [key, value] of affectedIndexes) {\nif (folderPath) {\naffectedPaths.set(`${folderPath}/${key}`, `${folderPath}/${value}`)\n} else {\naffectedPaths.set(key.toString(), value.toString())\n}\n}\nconst tabService = getService(RESTTabService)\nconst tabs = tabService.getTabsRefTo((tab) => {\nreturn (\ntab.document.saveContext?.originLocation === `user-collection` &&\naffectedPaths.has(tab.document.saveContext.folderPath)\n)\n})\nfor (const tab of tabs) {\nif (tab.value.document.saveContext?.originLocation === `user-collection`) {\nconst newPath = affectedPaths.get(\ntab.value.document.saveContext?.folderPath\n)!\ntab.value.document.saveContext.folderPath = newPath\n}\n}\n}"
"export function updateInheritedPropertiesForAffectedRequests(\npath: string,\ninheritedProperties: HoppInheritedProperty,\ntype: `rest` | `graphql`\n) {\nconst tabService =\ntype === `rest` ? getService(RESTTabService) : getService(GQLTabService)\nconst effectedTabs = tabService.getTabsRefTo((tab) => {\nconst saveContext = tab.document.saveContext\nconst saveContextPath =\nsaveContext?.originLocation === `team-collection`\n? saveContext.collectionID\n: saveContext?.folderPath\nreturn saveContextPath?.startsWith(path) ?? false\n})\neffectedTabs.map((tab) => {\nif (!(`inheritedProperties` in tab.value.document)) return\nconst inheritedParentID =\ntab.value.document.inheritedProperties?.auth.parentID\nconst contextPath =\ntab.value.document.saveContext?.originLocation === `team-collection`\n? tab.value.document.saveContext.collectionID\n: tab.value.document.saveContext?.folderPath\nconst effectedPath = folderPathCloseToSaveContext(\ninheritedParentID,\npath,\ncontextPath ?? ``\n)\nif (effectedPath === path) {\nif (tab.value.document.inheritedProperties) {\ntab.value.document.inheritedProperties.auth = inheritedProperties.auth\n}\n}\nif (tab.value.document.inheritedProperties?.headers) {\nconst headers = tab.value.document.inheritedProperties.headers.filter(\n(header) => header.parentID !== path\n)\nconst inheritedHeaders = inheritedProperties.headers.filter(\n(header) => header.parentID === path\n)\nconst mergedHeaders = removeDuplicatesAndKeepLast([\n...new Set([...inheritedHeaders, ...headers]),\n])\ntab.value.document.inheritedProperties.headers = mergedHeaders\n}\n})\n}"
export function getSuitableLenses(response: HoppRESTResponse): Lens[] {\nif (\nresponse.type === `loading` ||\nresponse.type === `network_fail` ||\nresponse.type === `script_fail` ||\nresponse.type === `fail` ||\nresponse.type === `extension_error`\n)\nreturn []\nconst contentType = response.headers.find(\n(h) => h.key.toLowerCase() === `content-type`\n)\nif (!contentType) return [rawLens]\nif (response.type === `success`) {\nconst matchingLenses = lenses.filter((lens) =>\nlens.isSupportedContentType(contentType.value)\n)\nconst isTextBased =\ncontentType.value.includes(`text/`) ||\ncontentType.value.includes(`application/javascript`) ||\ncontentType.value.includes(`application/xml`) ||\ncontentType.value.includes(`application/xhtml+xml`) ||\nhtmlLens.isSupportedContentType(contentType.value)\nif (isTextBased && response.body) {\nif (\nisValidJSONResponse(response.body) &&\n!matchingLenses.includes(jsonLens)\n) {\nmatchingLenses.push(jsonLens)\n}\n}\nif (matchingLenses.length === 0) {\nreturn lenses\n}\nif (!matchingLenses.includes(rawLens)) {\nmatchingLenses.push(rawLens)\n}\nreturn matchingLenses\n}\nconst result = []\nfor (const lens of lenses) {\nif (lens.isSupportedContentType(contentType.value)) result.push(lens)\n}\nreturn result\n}
"connect(url: string, clientID: string, config: MQTTConnectionConfig) {\ntry {\nthis.connectionState$.next(`CONNECTING`)\nthis.addEvent({\ntime: Date.now(),\ntype: `CONNECTING`,\n})\nconst parseUrl = new URL(url)\nconst { hostname, pathname, port } = parseUrl\nthis.mqttClient = new Paho.Client(\n`${hostname + (pathname !== `/` ? pathname : ``)}`,\nport !== `` ? Number(port) : 8081,\nclientID ?? `hoppscotch`\n)\nconst connectOptions: ConnectionOptions = {\nonSuccess: this.onConnectionSuccess.bind(this),\nonFailure: this.onConnectionFailure.bind(this),\ntimeout: 3,\nkeepAliveInterval: Number(config.keepAlive) ?? 60,\ncleanSession: config.cleanSession ?? true,\nuseSSL: parseUrl.protocol !== `ws:`,\n}\nconst { username, password, lwTopic, lwMessage, lwQos, lwRetain } = config\nif (username) {\nconnectOptions.userName = username\n}\nif (password) {\nconnectOptions.password = password\n}\nif (lwTopic?.length) {\nconst willmsg = new Paho.Message(lwMessage)\nwillmsg.qos = lwQos\nwillmsg.destinationName = lwTopic\nwillmsg.retained = lwRetain\nconnectOptions.willMessage = willmsg\n}\nthis.mqttClient.connect(connectOptions)\nthis.mqttClient.onConnectionLost = this.onConnectionLost.bind(this)\nthis.mqttClient.onMessageArrived = this.onMessageArrived.bind(this)\n} catch (e) {\nthis.handleError(e)\n}\nplatform.analytics?.logEvent({\ntype: `HOPP_REQUEST_RUN`,\nplatform: `mqtt`,\n})\n}"
"connect({ url, path, clientVersion, auth }: ConnectionOption) {\nthis.connectionState$.next(`CONNECTING`)\nthis.addEvent({\ntime: Date.now(),\ntype: `CONNECTING`,\n})\ntry {\nthis.socket = new SOCKET_CLIENTS[clientVersion]()\nif (auth?.type === `Bearer`) {\nthis.socket.connect(url, {\npath,\nauth: {\ntoken: auth.token,\n},\n})\n} else {\nthis.socket.connect(url, { path })\n}\nthis.socket.on(`connect`, () => {\nthis.connectionState$.next(`CONNECTED`)\nthis.addEvent({\ntype: `CONNECTED`,\ntime: Date.now(),\n})\n})\nthis.socket.on(`*`, ({ data }: { data: string[] }) => {\nconst [eventName, message] = data\nthis.addEvent({\nmessage: { eventName, value: message },\ntype: `MESSAGE_RECEIVED`,\ntime: Date.now(),\n})\n})\nthis.socket.on(`connect_error`, (error: unknown) => {\nthis.handleError(error, `CONNECTION`)\n})\nthis.socket.on(`reconnect_error`, (error: unknown) => {\nthis.handleError(error, `RECONNECT_ERROR`)\n})\nthis.socket.on(`error`, (error: unknown) => {\nthis.handleError(error, `UNKNOWN`)\n})\nthis.socket.on(`disconnect`, () => {\nthis.connectionState$.next(`DISCONNECTED`)\nthis.addEvent({\ntype: `DISCONNECTED`,\ntime: Date.now(),\nmanual: true,\n})\n})\n} catch (error) {\nthis.handleError(error, `CONNECTION`)\n}\nplatform.analytics?.logEvent({\ntype: `HOPP_REQUEST_RUN`,\nplatform: `socketio`,\n})\n}"
"start(url: string, eventType: string) {\nthis.connectionState$.next(`STARTING`)\nthis.addEvent({\ntime: Date.now(),\ntype: `STARTING`,\n})\nif (typeof EventSource !== `undefined`) {\ntry {\nthis.sse = new EventSource(url)\nthis.sse.onopen = () => {\nthis.connectionState$.next(`STARTED`)\nthis.addEvent({\ntype: `STARTED`,\ntime: Date.now(),\n})\n}\nthis.sse.onerror = (e) => {\nthis.handleError(e)\nthis.stop()\n}\nthis.sse.addEventListener(eventType, ({ data }) => {\nthis.addEvent({\ntype: `MESSAGE_RECEIVED`,\nmessage: data,\ntime: Date.now(),\n})\n})\n} catch (error) {\nthis.handleError(error as Event)\n}\n} else {\nthis.addEvent({\ntype: `ERROR`,\ntime: Date.now(),\nerror: null,\n})\n}\nplatform.analytics?.logEvent({\ntype: `HOPP_REQUEST_RUN`,\nplatform: `sse`,\n})\n}"
"connect(url: string, protocols: string[]) {\ntry {\nthis.connectionState$.next(`CONNECTING`)\nthis.socket = new WebSocket(url, protocols)\nthis.addEvent({\ntime: Date.now(),\ntype: `CONNECTING`,\n})\nthis.socket.onopen = () => {\nthis.connectionState$.next(`CONNECTED`)\nthis.addEvent({\ntype: `CONNECTED`,\ntime: Date.now(),\n})\n}\nthis.socket.onerror = (error) => {\nthis.handleError(error)\n}\nthis.socket.onclose = () => {\nthis.connectionState$.next(`DISCONNECTED`)\nthis.addEvent({\ntype: `DISCONNECTED`,\ntime: Date.now(),\nmanual: true,\n})\n}\nthis.socket.onmessage = ({ data }) => {\nthis.addEvent({\ntime: Date.now(),\ntype: `MESSAGE_RECEIVED`,\nmessage: data,\n})\n}\n} catch (error) {\nthis.handleError(error as SyntaxError)\n}\nplatform.analytics?.logEvent({\ntype: `HOPP_REQUEST_RUN`,\nplatform: `wss`,\n})\n}"
"getChildren(id: string | null): Ref<ChildrenResult<any>> {\nreturn computed(() => {\nif (id === null) {\nconst data = this.data.value.map((item, index) => ({\nid: `folder-${index.toString()}`,\ndata: {\ntype: `collections`,\nisLastItem: index === this.data.value.length - 1,\ndata: {\nparentIndex: null,\ndata: item,\n},\n},\n}))\nreturn {\nstatus: `loaded`,\ndata: data,\n} as ChildrenResult<Collection>\n}\nconst childType = id.split(`-`)[0]\nif (childType === `request`) {\nreturn {\nstatus: `loaded`,\ndata: [],\n}\n}\nconst folderId = id.split(`-`)[1]\nconst indexPath = folderId.split(`/`).map((x) => parseInt(x))\nconst item = this.navigateToFolderWithIndexPath(\nthis.data.value,\nindexPath\n)\nif (item && Object.keys(item).length) {\nconst folderData = item.folders.map((folder, index) => ({\nid: `folder-${folderId}/${index}`,\ndata: {\nisLastItem:\nindex === item.folders.length - 1 && item.requests.length === 0,\ntype: `folders`,\nisSelected: true,\ndata: {\nparentIndex: id,\ndata: folder,\n},\n},\n}))\nconst requestData = item.requests.map((request, index) => {\nconst shouldShow = this.shouldShowRequest(\nrequest as TestRunnerRequest\n)\nreturn {\nid: `request-${id}/${index}`,\ndata: {\nisLastItem: index === item.requests.length - 1,\ntype: `requests`,\nisSelected: true,\nhidden: !shouldShow,\ndata: {\nparentIndex: id,\ndata: request,\n},\n},\n}\n})\nreturn {\nstatus: `loaded`,\ndata: [...folderData, ...requestData],\n} as ChildrenResult<Folder | Request>\n}\nreturn {\nstatus: `loaded`,\ndata: [],\n}\n})\n}"
"private registerSubscriptions() {\nconst [shortcodeCreated$, shortcodeCreatedSub] = runAuthOnlyGQLSubscription(\n{\nquery: ShortcodeCreatedDocument,\nvariables: {},\n}\n)\nthis.shortcodeCreatedSub = shortcodeCreatedSub\nthis.shortcodeCreated = shortcodeCreated$.subscribe((result) => {\nif (E.isLeft(result)) {\nconsole.error(result.left)\nthrow new Error(`Shortcode Create Error ${result.left}`)\n}\nthis.createShortcode(result.right.myShortcodesCreated)\n})\nconst [shortcodeRevoked$, shortcodeRevokedSub] = runAuthOnlyGQLSubscription(\n{\nquery: ShortcodeDeletedDocument,\nvariables: {},\n}\n)\nthis.shortcodeRevokedSub = shortcodeRevokedSub\nthis.shortcodeRevoked = shortcodeRevoked$.subscribe((result) => {\nif (E.isLeft(result)) {\nconsole.error(result.left)\nthrow new Error(`Shortcode Delete Error ${result.left}`)\n}\nthis.deleteSharedRequest(result.right.myShortcodesRevoked.id)\n})\nconst [shortcodeUpdated$, shortcodeUpdatedSub] = runAuthOnlyGQLSubscription(\n{\nquery: ShortcodeUpdatedDocument,\nvariables: {},\n}\n)\nthis.shortcodeUpdatedSub = shortcodeUpdatedSub\nthis.shortcodeUpdated = shortcodeUpdated$.subscribe((result) => {\nif (E.isLeft(result)) {\nconsole.error(result.left)\nthrow new Error(`Shortcode Update Error ${result.left}`)\n}\nthis.updateSharedRequest(result.right.myShortcodesUpdated)\n})\n}"
"private async loadRootCollections() {\nif (this.teamID === null) throw new Error(`Team ID is null`)\nthis.loadingCollections$.next([\n...this.loadingCollections$.getValue(),\n`root`,\n])\nconst totalCollections: TeamCollection[] = []\nwhile (true) {\nconst result = await runGQLQuery({\nquery: RootCollectionsOfTeamDocument,\nvariables: {\nteamID: this.teamID,\ncursor:\ntotalCollections.length > 0\n? totalCollections[totalCollections.length - 1].id\n: undefined,\n},\n})\nif (E.isLeft(result)) {\nthis.loadingCollections$.next(\nthis.loadingCollections$.getValue().filter((x) => x !== `root`)\n)\nthrow new Error(`Error fetching root collections: ${result.left.error}`)\n}\ntotalCollections.push(\n...result.right.rootCollectionsOfTeam.map(\n(x) =>\n<TeamCollection>{\n...x,\nchildren: null,\nrequests: null,\n}\n)\n)\nif (result.right.rootCollectionsOfTeam.length !== TEAMS_BACKEND_PAGE_SIZE)\nbreak\n}\nthis.loadingCollections$.next(\nthis.loadingCollections$.getValue().filter((x) => x !== `root`)\n)\ntotalCollections.forEach((coll) =>\nthis.entityIDs.add(`collection-${coll.id}`)\n)\nthis.collections$.next(totalCollections)\n}"
"public updateRequestOrder(\ndragedRequestID: string,\ndestinationRequestID: string | null,\ndestinationCollectionID: string\n) {\nconst tree = this.collections$.value\nif (destinationRequestID === null) {\nconst collection = findCollInTree(tree, destinationCollectionID)\nif (!collection) return\nif (!collection.requests) return\nconst requestIndex = collection.requests.findIndex(\n(req) => req.id === dragedRequestID\n)\nif (requestIndex === -1) return\ncollection.requests.push(collection.requests.splice(requestIndex, 1)[0])\n} else {\nconst collection = findCollInTree(tree, destinationCollectionID)\nif (!collection) return\nif (!collection.requests) return\nconst requestIndex = collection.requests.findIndex(\n(req) => req.id === dragedRequestID\n)\nconst destinationIndex = collection.requests.findIndex(\n(req) => req.id === destinationRequestID\n)\nif (requestIndex === -1) return\nthis.reorderItems(collection.requests, requestIndex, destinationIndex)\n}\nthis.collections$.next(tree)\n}"
"private async getCollectionChildren(\ncollection: TeamCollection\n): Promise<TeamCollection[]> {\nconst collections: TeamCollection[] = []\nwhile (true) {\nconst data = await runGQLQuery({\nquery: GetCollectionChildrenDocument,\nvariables: {\ncollectionID: collection.id,\ncursor:\ncollections.length > 0\n? collections[collections.length - 1].id\n: undefined,\n},\n})\nif (E.isLeft(data)) {\nthrow new Error(\n`Child Collection Fetch Error for ${collection.id}: ${data.left}`\n)\n}\ncollections.push(\n...data.right.collection!.children.map(\n(el) =>\n<TeamCollection>{\nid: el.id,\ntitle: el.title,\ndata: el.data,\nchildren: null,\nrequests: null,\n}\n)\n)\nif (data.right.collection!.children.length !== TEAMS_BACKEND_PAGE_SIZE)\nbreak\n}\nreturn collections\n}"
"async fetchList() {\nif (this.teamID === undefined) throw new Error(`Team ID is null`)\nthis.loading$.next(true)\nconst results: TeamEnvironment[] = []\nconst result = await runGQLQuery({\nquery: GetTeamEnvironmentsDocument,\nvariables: {\nteamID: this.teamID,\n},\n})\nif (E.isLeft(result)) {\nthis.error$.next(result.left)\nthis.loading$.next(false)\nconsole.error(result.left)\nthrow new Error(`Failed fetching team environments: ${result.left}`)\n}\nif (result.right.team) {\nresults.push(\n...result.right.team.teamEnvironments.map((x) => {\nconst environment = <Environment>{\nv: EnvironmentSchemaVersion,\nid: x.id,\nname: x.name,\nvariables: JSON.parse(x.variables).map(\n(variable: Environment[`variables`][number]) =>\ntranslateToNewEnvironmentVariables(variable)\n),\n}\nconst parsedEnvironment = Environment.safeParse(environment)\nreturn <TeamEnvironment>{\nid: x.id,\nteamID: x.teamID,\nenvironment:\nparsedEnvironment.type === `ok`\n? parsedEnvironment.value\n: environment,\n}\n})\n)\n}\nresults.forEach((env) => this.entityIDs.add(`environment-${env.id}`))\nthis.teamEnvironmentList$.next(results)\nthis.loading$.next(false)\n}"
"function convertToTeamCollection(\nnode: CollectionSearchNode & {\nmeta?: CollectionSearchMeta\n},\nexistingCollections: Record<string, _SearchCollection>,\nexistingRequests: Record<string, _SearchRequest>\n) {\nif (node.type === `request`) {\nexistingRequests[node.id] = {\nid: node.id,\ncollectionID: node.path[0].id,\ntitle: node.title,\nrequest: {\nname: node.title,\nmethod: node.method,\n},\nmeta: {\nisSearchResult: node.meta?.isSearchResult || false,\n},\n}\nif (node.path[0]) {\nconvertToTeamCollection(\nnode.path[0],\nexistingCollections,\nexistingRequests\n)\n}\n} else {\nexistingCollections[node.id] = {\nid: node.id,\ntitle: node.title,\nchildren: [],\nrequests: [],\ndata: null,\nparentID: node.path[0]?.id,\nmeta: {\nisSearchResult: node.meta?.isSearchResult || false,\n},\n}\nif (node.path[0]) {\nconvertToTeamCollection(\nnode.path[0],\nexistingCollections,\nexistingRequests\n)\n}\n}\nreturn {\nexistingCollections,\nexistingRequests,\n}\n}"
"function convertToTeamTree(\ncollections: (TeamCollection & { parentID: string | null })[],\nrequests: TeamRequest[]\n) {\nconst collectionTree: TeamCollection[] = []\ncollections.forEach((collection) => {\nconst parentCollection = collection.parentID\n? collections.find((c) => c.id === collection.parentID)\n: null\nconst isAlreadyInserted = parentCollection?.children?.find(\n(c) => c.id === collection.id\n)\nif (isAlreadyInserted) return\nif (parentCollection) {\nparentCollection.children = parentCollection.children || []\nparentCollection.children.push(collection)\n} else {\ncollectionTree.push(collection)\n}\n})\nrequests.forEach((request) => {\nconst parentCollection = collections.find(\n(c) => c.id === request.collectionID\n)\nconst isAlreadyInserted = parentCollection?.requests?.find(\n(r) => r.id === request.id\n)\nif (isAlreadyInserted) return\nif (parentCollection) {\nconst requestSchemaParsedResult = HoppRESTRequest.safeParse(\nrequest.request\n)\nconst effectiveRequest =\nrequestSchemaParsedResult.type === `ok`\n? requestSchemaParsedResult.value\n: getDefaultRESTRequest()\nparentCollection.requests = parentCollection.requests || []\nparentCollection.requests.push({\nid: request.id,\ncollectionID: request.collectionID,\ntitle: request.title,\nrequest: effectiveRequest,\n})\n}\n})\nreturn collectionTree\n}"
"export async function getEffectiveRESTRequest(\nrequest: HoppRESTRequest,\nenvironment: Environment,\nshowKeyIfSecret = false\n): Promise<EffectiveHoppRESTRequest> {\nconst effectiveFinalHeaders = pipe(\n(\nawait getComputedHeaders(request, environment.variables, showKeyIfSecret)\n).map((h) => h.header),\nA.concat(request.headers),\nA.filter((x) => x.active && x.key !== ``),\nA.map((x) => ({\nactive: true,\nkey: parseTemplateString(\nx.key,\nenvironment.variables,\nfalse,\nshowKeyIfSecret\n),\nvalue: parseTemplateString(\nx.value,\nenvironment.variables,\nfalse,\nshowKeyIfSecret\n),\ndescription: x.description,\n}))\n)\nconst effectiveFinalParams = pipe(\n(await getComputedParams(request, environment.variables)).map(\n(p) => p.param\n),\nA.concat(request.params),\nA.filter((x) => x.active && x.key !== ``),\nA.map((x) => ({\nactive: true,\nkey: parseTemplateString(\nx.key,\nenvironment.variables,\nfalse,\nshowKeyIfSecret\n),\nvalue: parseTemplateString(\nx.value,\nenvironment.variables,\nfalse,\nshowKeyIfSecret\n),\ndescription: x.description,\n}))\n)\nconst effectiveFinalRequestVariables = pipe(\nrequest.requestVariables,\nA.filter((x) => x.active && x.key !== ``),\nA.map((x) => ({\nactive: true,\nkey: parseTemplateString(x.key, environment.variables),\nvalue: parseTemplateString(x.value, environment.variables),\n}))\n)\nconst effectiveFinalBody = getFinalBodyFromRequest(\nrequest,\nenvironment.variables,\nshowKeyIfSecret\n)\nreturn {\n...request,\neffectiveFinalURL: parseTemplateString(\nrequest.endpoint,\nenvironment.variables,\nfalse,\nshowKeyIfSecret\n),\neffectiveFinalHeaders,\neffectiveFinalParams,\neffectiveFinalBody,\neffectiveFinalRequestVariables,\n}\n}"
"private initializeListeners() {\nwatch(\n() => [this.inspectors.entries(), this.restTab.currentActiveTab.value.id],\n() => {\nconst currentTabRequest = computed(() => {\nif (\nthis.restTab.currentActiveTab.value.document.type === `test-runner`\n)\nreturn null\nreturn this.restTab.currentActiveTab.value.document.type === `request`\n? this.restTab.currentActiveTab.value.document.request\n: this.restTab.currentActiveTab.value.document.response\n.originalRequest\n})\nconst currentTabResponse = computed(() => {\nif (this.restTab.currentActiveTab.value.document.type === `request`) {\nreturn this.restTab.currentActiveTab.value.document.response\n}\nreturn null\n})\nconst reqRef = computed(() => currentTabRequest.value)\nconst resRef = computed(() => currentTabResponse.value)\nconst debouncedReq = refDebounced(reqRef, 1000, { maxWait: 2000 })\nconst debouncedRes = refDebounced(resRef, 1000, { maxWait: 2000 })\nconst inspectorRefs = Array.from(this.inspectors.values()).map((x) =>\nx.getInspections(debouncedReq, debouncedRes)\n)\nconst activeInspections = computed(() =>\ninspectorRefs.flatMap((x) => x!.value)\n)\nwatch(\n() => [...inspectorRefs.flatMap((x) => x!.value)],\n() => {\nthis.tabs.value.set(\nthis.restTab.currentActiveTab.value.id,\nactiveInspections.value\n)\n},\n{ immediate: true }\n)\n},\n{ immediate: true, flush: `pre` }\n)\n}"
"private async setupEnvironmentsPersistence() {\nconst loadResult = await Store.get<any>(\nSTORE_NAMESPACE,\nSTORE_KEYS.ENVIRONMENTS\n)\ntry {\nif (E.isRight(loadResult)) {\nconst data = loadResult.right ?? []\nconst environments = fixBrokenEnvironmentVersion(data)\nconst result = ENVIRONMENTS_SCHEMA.safeParse(environments)\nif (result.success) {\nconst globalIndex = result.data.findIndex(\n(x) => x.name.toLowerCase() === `globals`\n)\nif (globalIndex !== -1) {\nconst globalEnv = result.data[globalIndex]\nglobalEnv.variables.forEach((variable: GlobalEnvironmentVariable) =>\naddGlobalEnvVariable(variable)\n)\nresult.data.splice(globalIndex, 1)\n}\nreplaceEnvironments(result.data)\n} else {\nthis.showErrorToast(STORE_KEYS.ENVIRONMENTS)\nawait Store.set(\nSTORE_NAMESPACE,\n`${STORE_KEYS.ENVIRONMENTS}-backup`,\ndata\n)\n}\n}\n} catch (e) {\nconsole.error(`Failed parsing persisted ENVIRONMENTS:`, loadResult)\n}\nenvironments$.subscribe(async (envs) => {\nawait Store.set(STORE_NAMESPACE, STORE_KEYS.ENVIRONMENTS, envs)\n})\n}"
"private async setupSecretEnvironmentsPersistence() {\nconst loadResult = await Store.get<any>(\nSTORE_NAMESPACE,\nSTORE_KEYS.SECRET_ENVIRONMENTS\n)\ntry {\nif (E.isRight(loadResult) && loadResult.right) {\nconst result = SECRET_ENVIRONMENT_VARIABLE_SCHEMA.safeParse(\nloadResult.right\n)\nif (result.success) {\nthis.secretEnvironmentService.loadSecretEnvironmentsFromPersistedState(\nresult.data\n)\n} else {\nthis.showErrorToast(STORE_KEYS.SECRET_ENVIRONMENTS)\nawait Store.set(\nSTORE_NAMESPACE,\n`${STORE_KEYS.SECRET_ENVIRONMENTS}-backup`,\nloadResult.right\n)\nconsole.error(\n`Failed parsing persisted SECRET_ENVIRONMENTS:`,\nJSON.stringify(loadResult.right)\n)\n}\n}\n} catch (e) {\nconsole.error(`Failed parsing persisted SECRET_ENVIRONMENTS:`, loadResult)\n}\nwatchDebounced(\nthis.secretEnvironmentService.persistableSecretEnvironments,\nasync (newData: Record<string, SecretVariable[]>) => {\nawait Store.set(\nSTORE_NAMESPACE,\nSTORE_KEYS.SECRET_ENVIRONMENTS,\nnewData\n)\n},\n{ debounce: 500 }\n)\n}"
"private async setupCurrentEnvironmentValuePersistence() {\nconst loadResult = await Store.get<any>(\nSTORE_NAMESPACE,\nSTORE_KEYS.CURRENT_ENVIRONMENT_VALUE\n)\ntry {\nif (E.isRight(loadResult) && loadResult.right) {\nconst result = CURRENT_ENVIRONMENT_VALUE_SCHEMA.safeParse(\nloadResult.right\n)\nif (result.success) {\nthis.currentEnvironmentValueService.loadEnvironmentsFromPersistedState(\nresult.data\n)\n} else {\nthis.showErrorToast(STORE_KEYS.CURRENT_ENVIRONMENT_VALUE)\nawait Store.set(\nSTORE_NAMESPACE,\n`${STORE_KEYS.CURRENT_ENVIRONMENT_VALUE}-backup`,\nloadResult.right\n)\nconsole.error(\n`Failed parsing persisted CURRENT_ENVIRONMENT_VALUE:`,\nJSON.stringify(loadResult.right)\n)\n}\n}\n} catch (e) {\nconsole.error(\n`Failed parsing persisted CURRENT_ENVIRONMENT_VALUE:`,\nloadResult\n)\n}\nwatchDebounced(\nthis.currentEnvironmentValueService.persistableEnvironments,\nasync (newData: Record<string, Variable[]>) => {\nawait Store.set(\nSTORE_NAMESPACE,\nSTORE_KEYS.CURRENT_ENVIRONMENT_VALUE,\nnewData\n)\n},\n{ debounce: 500 }\n)\n}"
"private async setupRESTTabsPersistence() {\nconst loadResult = await Store.get<any>(\nSTORE_NAMESPACE,\nSTORE_KEYS.REST_TABS\n)\ntry {\nif (E.isRight(loadResult) && loadResult.right) {\nconst orderedDocs = fixBrokenRequestVersion(\ncloneDeep(loadResult.right.orderedDocs) ?? []\n)\nconst transformedTabs = {\n...loadResult.right,\norderedDocs,\n}\nconst result = REST_TAB_STATE_SCHEMA.safeParse(transformedTabs)\nif (result.success) {\nthis.restTabService.loadTabsFromPersistedState(\nresult.data as PersistableTabState<HoppTabDocument>\n)\n} else {\nthis.showErrorToast(STORE_KEYS.REST_TABS)\nawait Store.set(\nSTORE_NAMESPACE,\n`${STORE_KEYS.REST_TABS}-backup`,\nloadResult.right\n)\nconsole.error(\n`Failed parsing persisted REST_TABS:`,\nJSON.stringify(loadResult.right)\n)\nthis.restTabService.loadTabsFromPersistedState(loadResult.right)\n}\n}\n} catch (e) {\nconsole.error(`Failed parsing persisted REST_TABS:`, loadResult)\n}\nwatchDebounced(\nthis.restTabService.persistableTabState,\nasync (newData) => {\nawait Store.set(STORE_NAMESPACE, STORE_KEYS.REST_TABS, newData)\n},\n{ debounce: 500, deep: true }\n)\n}"
"private async setupGQLTabsPersistence() {\nconst loadResult = await Store.get<any>(\nSTORE_NAMESPACE,\nSTORE_KEYS.GQL_TABS\n)\ntry {\nif (E.isRight(loadResult) && loadResult.right) {\nconst result = GQL_TAB_STATE_SCHEMA.safeParse(loadResult.right)\nif (result.success) {\nthis.gqlTabService.loadTabsFromPersistedState(\nresult.data as PersistableTabState<HoppGQLDocument>\n)\n} else {\nthis.showErrorToast(STORE_KEYS.GQL_TABS)\nawait Store.set(\nSTORE_NAMESPACE,\n`${STORE_KEYS.GQL_TABS}-backup`,\nloadResult.right\n)\nconsole.error(\n`Failed parsing persisted GQL_TABS:`,\nJSON.stringify(loadResult.right)\n)\nthis.gqlTabService.loadTabsFromPersistedState(loadResult.right)\n}\n}\n} catch (e) {\nconsole.error(`Failed parsing persisted GQL_TABS:`, loadResult)\n}\nwatchDebounced(\nthis.gqlTabService.persistableTabState,\nasync (newData) => {\nawait Store.set(STORE_NAMESPACE, STORE_KEYS.GQL_TABS, newData)\n},\n{ debounce: 500, deep: true }\n)\n}"
"public createSearchSession(\nquery: Ref<string>\n): [Ref<SpotlightSearchState>, () => void] {\nconst startTime = Date.now()\nconst searchSessions = Array.from(this.searchers.values()).map(\n(x) => [x, ...x.createSearchSession(query)] as const\n)\nconst loadingSearchers = reactive(new Set())\nconst onSessionEndList: Array<() => void> = []\nconst resultObj = ref<SpotlightSearchState>({\nloading: false,\nresults: {},\n})\nconst scopeHandle = effectScope()\nscopeHandle.run(() => {\nfor (const [searcher, state, onSessionEnd] of searchSessions) {\nwatch(\nstate,\n(newState) => {\nif (newState.loading) {\nloadingSearchers.add(searcher.searcherID)\n} else {\nloadingSearchers.delete(searcher.searcherID)\n}\nif (newState.results.length === 0) {\ndelete resultObj.value.results[searcher.searcherID]\n} else {\nresultObj.value.results[searcher.searcherID] = {\ntitle: searcher.searcherSectionTitle,\navgScore:\nnewState.results.reduce((acc, x) => acc + x.score, 0) /\nnewState.results.length,\nresults: newState.results,\n}\n}\n},\n{ immediate: true }\n)\nonSessionEndList.push(onSessionEnd)\n}\nwatch(\nquery,\n(newQuery) => {\nthis.setAnalyticsData({\ninputLength: newQuery.length,\n})\n},\n{ immediate: true }\n)\nwatch(\nloadingSearchers,\n(set) => {\nresultObj.value.loading = set.size > 0\n},\n{ immediate: true }\n)\n})\nconst onSearchEnd = () => {\nscopeHandle.stop()\nfor (const onEnd of onSessionEndList) {\nonEnd()\n}\nconst sessionDuration = `${((Date.now() - startTime) / 1000).toFixed(2)}s`\nthis.setAnalyticsData({ sessionDuration })\nplatform.analytics?.logEvent({\ntype: `HOPP_SPOTLIGHT_SESSION`,\n...this.analyticsData,\n})\nthis.setAnalyticsData({}, false)\n}\nreturn [resultObj, onSearchEnd]\n}"
"async function signAWSRequest({\nauth,\nrequest,\nenvVars,\nsignQuery = false,\n}: SignOptions) {\nconst currentDate = new Date()\nconst amzDate = currentDate.toISOString().replace(/[:-]|\.\d{3}/g, ``)\nconst baseUrl = parseTemplateString(request.endpoint, envVars)\nconst { url, sortedParams } = processQueryParameters(\nrequest.params,\nenvVars,\nbaseUrl\n)\nconst accessKeyId = parseTemplateString(auth.accessKey, envVars)\nconst secretAccessKey = parseTemplateString(auth.secretKey, envVars)\nconst region = parseTemplateString(auth.region, envVars) ?? `us-east-1`\nconst service = parseTemplateString(auth.serviceName, envVars)\nconst sessionToken = auth.serviceToken\n? parseTemplateString(auth.serviceToken, envVars)\n: undefined\nconst signerConfig: ConstructorParameters<typeof AwsV4Signer>[0] = {\nmethod: request.method,\ndatetime: amzDate,\naccessKeyId,\nsecretAccessKey,\nregion,\nservice,\nsessionToken,\nurl: url.toString(),\nsignQuery,\n}\nif (!signQuery) {\nconst body = getFinalBodyFromRequest(request, envVars)\nsignerConfig.body = body?.toString()\n}\nconst signer = new AwsV4Signer(signerConfig)\nconst sign = await signer.sign()\nreturn { sign, sortedParams }\n}"
"export async function generateDigestAuthHeaders(\nauth: HoppRESTAuth,\nrequest: HoppRESTRequest,\nenvVars: Environment[`variables`],\nshowKeyIfSecret = false\n): Promise<HoppRESTHeader[]> {\nif (auth.authType !== `digest`) return []\nconst { method, endpoint } = request\nconst authInfo = await fetchInitialDigestAuthInfo(\nparseTemplateString(endpoint, envVars),\nmethod\n)\nconst reqBody = getFinalBodyFromRequest(request, envVars, showKeyIfSecret)\nconst digestAuthParams: DigestAuthParams = {\nusername: parseTemplateString(auth.username, envVars),\npassword: parseTemplateString(auth.password, envVars),\nrealm: auth.realm\n? parseTemplateString(auth.realm, envVars)\n: authInfo.realm,\nnonce: auth.nonce\n? parseTemplateString(auth.nonce, envVars)\n: authInfo.nonce,\nendpoint: parseTemplateString(endpoint, envVars),\nmethod,\nalgorithm: auth.algorithm ?? authInfo.algorithm,\nqop: auth.qop ? parseTemplateString(auth.qop, envVars) : authInfo.qop,\nopaque: auth.opaque\n? parseTemplateString(auth.opaque, envVars)\n: authInfo.opaque,\nreqBody: typeof reqBody === `string` ? reqBody : ``,\n}\nconst authHeaderValue = await generateDigestAuthHeader(digestAuthParams)\nreturn [\n{\nactive: true,\nkey: `Authorization`,\nvalue: authHeaderValue,\ndescription: ``,\n},\n]\n}"
"export async function generateHawkAuthHeaders(\nauth: HoppRESTAuth,\nrequest: HoppRESTRequest,\nenvVars: Environment[`variables`],\nshowKeyIfSecret = false\n): Promise<HoppRESTHeader[]> {\nif (auth.authType !== `hawk`) return []\nconst { method, endpoint, body } = request\nconst payload = getFinalBodyFromRequest(request, envVars, showKeyIfSecret)\nconst hawkHeader = await calculateHawkHeader({\nurl: parseTemplateString(endpoint, envVars),\nmethod: method,\nid: parseTemplateString(auth.authId, envVars),\nkey: parseTemplateString(auth.authKey, envVars),\nalgorithm: auth.algorithm,\ncontentType: body.contentType,\npayload,\nincludePayloadHash: auth.includePayloadHash,\nnonce: auth.nonce ? parseTemplateString(auth.nonce, envVars) : undefined,\next: auth.ext ? parseTemplateString(auth.ext, envVars) : undefined,\napp: auth.app ? parseTemplateString(auth.app, envVars) : undefined,\ndlg: auth.dlg ? parseTemplateString(auth.dlg, envVars) : undefined,\ntimestamp: auth.timestamp\n? parseInt(parseTemplateString(auth.timestamp, envVars), 10)\n: undefined,\n})\nreturn [\n{\nactive: true,\nkey: `Authorization`,\nvalue: hawkHeader,\ndescription: ``,\n},\n]\n}"
"export function getFArgumentMultipartData(\nparsedArguments: parser.Arguments\n): O.Option<Record<string, string>> {\nreturn pipe(\nparsedArguments,\nO.fromPredicate(objHasProperty(`F`, `string`)),\nO.map((args) => [args.F]),\nO.alt(() =>\npipe(\nparsedArguments,\nO.fromPredicate(objHasArrayProperty(`F`, `string`)),\nO.map((args) => args.F)\n)\n),\nO.chain(\nflow(\nA.map(S.split(`=`)),\nO.fromPredicate((fArgs) => fArgs.length > 0),\nO.map(\nflow(\nA.map(([k, v]) =>\npipe(\nparsedArguments,\nO.fromPredicate(objHasProperty(`form-string`, `boolean`)),\nO.match(\n() => [k, v[0] === `@` || v[0] === `<` ? `` : v],\n() => [k, v]\n)\n)\n),\nA.map(([k, v]) => [k, v] as [string, string]),\ntupleToRecord\n)\n)\n)\n)\n)\n}"
"create() {\nconst dom = document.createElement(`div`)\nconst tooltipContainer = document.createElement(`div`)\nconst tooltipHeaderBlock = document.createElement(`div`)\ntooltipHeaderBlock.className =\n`flex items-center justify-between w-full space-x-2 `\ntooltipContainer.appendChild(tooltipHeaderBlock)\nconst iconNameContainer = document.createElement(`div`)\niconNameContainer.className =\n`flex items-center space-x-2 flex-1 mr-4 `\ntooltipHeaderBlock.appendChild(iconNameContainer)\nconst icon = document.createElement(`span`)\nicon.innerHTML = envTypeIcon\nconst envNameBlock = document.createElement(`span`)\nenvNameBlock.innerText = envName\niconNameContainer.appendChild(icon)\niconNameContainer.appendChild(envNameBlock)\nif (tooltipEnv) appendEditAction(tooltipHeaderBlock)\nconst envContainer = document.createElement(`div`)\ntooltipContainer.appendChild(envContainer)\nenvContainer.className =\n`flex flex-col items-start space-y-1 flex-1 w-full mt-2`\nconst initialValueBlock = document.createElement(`div`)\ninitialValueBlock.className = `flex items-center space-x-2`\nconst initialValueTitle = document.createElement(`div`)\nconst initialValue = document.createElement(`span`)\ninitialValue.textContent = envInitialValue || ``\ninitialValueTitle.textContent = `Initial`\ninitialValueTitle.className = `font-bold mr-4 `\ninitialValueBlock.appendChild(initialValueTitle)\ninitialValueBlock.appendChild(initialValue)\nconst currentValueBlock = document.createElement(`div`)\ncurrentValueBlock.className = `flex items-center space-x-2`\nconst currentValueTitle = document.createElement(`div`)\nconst currentValue = document.createElement(`span`)\ncurrentValue.textContent = envCurrentValue || ``\ncurrentValueTitle.textContent = `Current `\ncurrentValueTitle.className = `font-bold mr-1.5`\ncurrentValueBlock.appendChild(currentValueTitle)\ncurrentValueBlock.appendChild(currentValue)\nenvContainer.appendChild(initialValueBlock)\nenvContainer.appendChild(currentValueBlock)\ntooltipContainer.className = `tippy-content env-tooltip-content`\ndom.className = `tippy-box`\ndom.dataset.theme = `tooltip`\ndom.appendChild(tooltipContainer)\nreturn { dom }\n},"
"create() {\nconst dom = document.createElement(`div`)\nconst tooltipContainer = document.createElement(`div`)\nconst tooltipHeaderBlock = document.createElement(`div`)\ntooltipHeaderBlock.className =\n`flex items-center justify-between w-full space-x-2 `\ntooltipContainer.appendChild(tooltipHeaderBlock)\nconst iconNameContainer = document.createElement(`div`)\niconNameContainer.className =\n`flex items-center space-x-2 flex-1 mr-4 `\ntooltipHeaderBlock.appendChild(iconNameContainer)\nconst icon = document.createElement(`span`)\nicon.innerHTML = variableIcon\nconst envNameBlock = document.createElement(`span`)\nenvNameBlock.innerText = variableName\niconNameContainer.appendChild(icon)\niconNameContainer.appendChild(envNameBlock)\nconst envContainer = document.createElement(`div`)\ntooltipContainer.appendChild(envContainer)\nenvContainer.className =\n`flex flex-col items-start space-y-1 flex-1 w-full mt-2`\nconst valueBlock = document.createElement(`div`)\nvalueBlock.className = `flex items-center space-x-2`\nconst valueTitle = document.createElement(`div`)\nconst value = document.createElement(`span`)\nvalue.textContent = variableDescription || ``\nvalueTitle.textContent = `Value`\nvalueTitle.className = `font-bold mr-4 `\nvalueBlock.appendChild(valueTitle)\nvalueBlock.appendChild(value)\nenvContainer.appendChild(valueBlock)\ndom.className = `tippy-box`\ndom.dataset.theme = `tooltip`\ntooltipContainer.className = `tippy-content env-tooltip-content`\ndom.appendChild(tooltipContainer)\nreturn { dom }\n},"
"getInspections(req: Readonly<Ref<HoppRESTRequest | null>>) {\nconst currentExtensionStatus = this.extensionService.extensionStatus\nconst isExtensionInstalled = computed(\n() => currentExtensionStatus.value === `available`\n)\nconst activeInterceptor = computed(\n() => this.interceptorService.currentInterceptorID.value\n)\nconst EXTENSION_ENABLED = computed(\n() => activeInterceptor.value === `extension`\n)\nconst AGENT_ENABLED = computed(() => activeInterceptor.value === `agent`)\nreturn computed(() => {\nconst results: InspectorResult[] = []\nif (!req.value) return results\nconst url = req.value.endpoint\nconst localHostURLs = [`localhost`, `127.0.0.1`]\nconst isContainLocalhost = localHostURLs.some((host) =>\nurl.includes(host)\n)\nif (\nisContainLocalhost &&\n!AGENT_ENABLED.value &&\n(!EXTENSION_ENABLED.value || !isExtensionInstalled.value)\n) {\nlet text\nif (!isExtensionInstalled.value) {\nif (currentExtensionStatus.value === `unknown-origin`) {\ntext = this.t(`inspections.url.extension_unknown_origin`)\n} else {\ntext = this.t(`inspections.url.extension_not_installed`)\n}\n} else if (!EXTENSION_ENABLED.value) {\ntext = this.t(`inspections.url.extention_not_enabled`)\n} else {\ntext = this.t(`inspections.url.localhost`)\n}\nresults.push({\nid: `url`,\nicon: markRaw(IconAlertTriangle),\ntext: {\ntype: `text`,\ntext: text,\n},\naction: {\ntext: this.t(`inspections.url.extention_enable_action`),\napply: () => {\nthis.interceptorService.currentInterceptorID.value = `extension`\n},\n},\nseverity: 2,\nisApplicable: true,\nlocations: {\ntype: `url`,\n},\ndoc: {\ntext: this.t(`action.learn_more`),\nlink: `https:\n},\n})\n}\nreturn results\n})\n}"
"private listenForExtensionStatus() {\nconst extensionPollIntervalId = ref<ReturnType<typeof setInterval>>()\nif (window.__HOPP_EXTENSION_STATUS_PROXY__) {\nthis._extensionStatus.value =\nwindow.__HOPP_EXTENSION_STATUS_PROXY__.status\nwindow.__HOPP_EXTENSION_STATUS_PROXY__.subscribe(\n`status`,\n(status: ExtensionStatus) => {\nthis._extensionStatus.value = status\n}\n)\n} else {\nconst statusProxy = defineSubscribableObject({\nstatus: `waiting` as ExtensionStatus,\n})\nwindow.__HOPP_EXTENSION_STATUS_PROXY__ = statusProxy\nstatusProxy.subscribe(\n`status`,\n(status: ExtensionStatus) => (this._extensionStatus.value = status)\n)\nextensionPollIntervalId.value = setInterval(() => {\nif (typeof window.__POSTWOMAN_EXTENSION_HOOK__ !== `undefined`) {\nif (extensionPollIntervalId.value)\nclearInterval(extensionPollIntervalId.value)\nconst version = window.__POSTWOMAN_EXTENSION_HOOK__.getVersion()\nif (\nversion.major === 0 &&\nversion.minor <= 23 &&\nwindow.__HOPP_EXTENSION_STATUS_PROXY__\n) {\nwindow.__HOPP_EXTENSION_STATUS_PROXY__.status = `available`\n}\n}\n}, 2000)\n}\n}"
"private async runRequestOnExtension(\nreq: AxiosRequestConfig\n): RequestRunResult[`response`] {\nawait until(this.extensionStatus).toMatch(\n(status) => status !== `waiting`,\n{\ntimeout: 1000,\n}\n)\nconst extensionHook = window.__POSTWOMAN_EXTENSION_HOOK__\nif (!extensionHook) {\nreturn E.left(<InterceptorError>{\nhumanMessage: {\nheading: () => `Extension not found`,\ndescription: () => `Heading not found`,\n},\nerror: `NO_PW_EXT_HOOK`,\ncomponent: InterceptorsErrorPlaceholder,\n})\n}\ntry {\nconst result = await extensionHook.sendRequest({\n...req,\nheaders: req.headers ?? {},\nwantsBinary: true,\n})\nreturn E.right(result)\n} catch (e) {\nconsole.error(e)\nif ((e as any).response) {\nreturn E.right((e as any).response)\n}\nreturn E.left(<InterceptorError>{\nhumanMessage: {\nheading: () => `Extension error`,\ndescription: () => `Failed running request on extension`,\n},\nerror: e,\n})\n}\n}"
"async function runRequest(\nreq: AxiosRequestConfig,\ncancelToken: CancelToken\n): RequestRunResult[`response`] {\nconst defaultProxyURL = await getDefaultProxyUrl()\nconst multipartKey =\nreq.data instanceof FormData ? `proxyRequestData-${v4()}` : null\nconst headers =\nreq.data instanceof FormData\n? <ProxyHeaders>{\n`multipart-part-key`: multipartKey,\n}\n: <ProxyHeaders>{}\nconst payload = getProxyPayload(req, multipartKey)\ntry {\nconst { data } = await axios.post(\nsettingsStore.value.PROXY_URL ?? defaultProxyURL,\npayload,\n{\nheaders,\ncancelToken,\n}\n)\nif (!data.success) {\nreturn E.left({\nhumanMessage: {\nheading: (t) => t(`error.network_fail`),\ndescription: (t) => data.data?.message ?? t(`error.proxy_error`),\n},\n})\n}\nif (data.isBinary) {\ndata.data = decodeB64StringToArrayBuffer(data.data)\n}\nreturn E.right(data)\n} catch (e) {\nif (axios.isCancel(e)) {\nreturn E.left(`cancellation`)\n}\nreturn E.left({\nhumanMessage: {\nheading: (t) => t(`error.network_fail`),\ndescription: (t) => t(`helpers.network_fail`),\n},\nerror: e,\n})\n}\n}"
"getInspections(\nreq: Readonly<Ref<HoppRESTRequest | HoppRESTResponseOriginalRequest>>\n) {\nreturn computed(() => {\nconst results: InspectorResult[] = []\nif (!req.value) return results\nconst headers = req.value.headers\nconst params = req.value.params\nconst url = req.value.endpoint\nresults.push(\n...this.validateEnvironmentVariables([url], {\ntype: `url`,\n})\n)\nresults.push(\n...this.validateEmptyEnvironmentVariables([url], {\ntype: `url`,\n})\n)\nconst headerKeys = Object.values(headers).map((header) => header.key)\nresults.push(\n...this.validateEnvironmentVariables(headerKeys, {\ntype: `header`,\nposition: `key`,\n})\n)\nresults.push(\n...this.validateEmptyEnvironmentVariables(headerKeys, {\ntype: `header`,\nposition: `key`,\n})\n)\nconst headerValues = Object.values(headers).map((header) => header.value)\nresults.push(\n...this.validateEnvironmentVariables(headerValues, {\ntype: `header`,\nposition: `value`,\n})\n)\nresults.push(\n...this.validateEmptyEnvironmentVariables(headerValues, {\ntype: `header`,\nposition: `value`,\n})\n)\nconst paramsKeys = Object.values(params).map((param) => param.key)\nresults.push(\n...this.validateEnvironmentVariables(paramsKeys, {\ntype: `parameter`,\nposition: `key`,\n})\n)\nresults.push(\n...this.validateEmptyEnvironmentVariables(paramsKeys, {\ntype: `parameter`,\nposition: `key`,\n})\n)\nconst paramsValues = Object.values(params).map((param) => param.value)\nresults.push(\n...this.validateEnvironmentVariables(paramsValues, {\ntype: `parameter`,\nposition: `value`,\n})\n)\nresults.push(\n...this.validateEmptyEnvironmentVariables(paramsValues, {\ntype: `parameter`,\nposition: `value`,\n})\n)\nreturn results\n})\n}"
"getInspections(\n_req: Readonly<Ref<HoppRESTRequest | HoppRESTResponseOriginalRequest>>,\nres: Readonly<Ref<HoppRESTResponse | null | undefined>>\n) {\nreturn computed(() => {\nconst results: InspectorResult[] = []\nif (!res.value) return results\nconst hasErrors =\nres && (res.value.type !== `success` || res.value.statusCode !== 200)\nlet text: string | undefined = undefined\nif (res.value.type === `network_fail` && !navigator.onLine) {\ntext = this.t(`inspections.response.network_error`)\n} else if (res.value.type === `fail`) {\ntext = this.t(`inspections.response.default_error`)\n} else if (res.value.type === `success` && res.value.statusCode === 404) {\ntext = this.t(`inspections.response.404_error`)\n} else if (res.value.type === `success` && res.value.statusCode === 401) {\ntext = this.t(`inspections.response.401_error`)\n}\nif (hasErrors && text) {\nresults.push({\nid: `url`,\nicon: markRaw(IconAlertTriangle),\ntext: {\ntype: `text`,\ntext: text,\n},\nseverity: 2,\nisApplicable: true,\nlocations: {\ntype: `response`,\n},\ndoc: {\ntext: this.t(`action.learn_more`),\nlink: `https:\n},\n})\n}\nreturn results\n})\n}"
"createSearchSession(\nquery: Readonly<Ref<string>>\n): [Ref<SpotlightSearcherSessionState>, () => void] {\nconst loading = ref(false)\nconst results = ref<SpotlightSearcherResult[]>([])\nconst minisearch = new MiniSearch({\nfields: [`name`, `alternates`],\nstoreFields: [`name`],\n})\nconst interceptorSelection = this.interceptorService\n.currentInterceptorID as Ref<string>\nconst interceptors = this.interceptorService.availableInterceptors\nminisearch.addAll(\ninterceptors.value.map((entry) => {\nlet id = `interceptor-${entry.interceptorID}`\nif (entry.interceptorID === interceptorSelection.value) {\nid += `-selected`\n}\nconst name = unref(entry.name(this.t))\nreturn {\nid,\nname,\nalternates: [`interceptor`, `change`, name],\n}\n})\n)\nconst scopeHandle = effectScope()\nscopeHandle.run(() => {\nwatch(\n[query],\n([query]) => {\nresults.value = minisearch\n.search(query, {\nprefix: true,\nfuzzy: true,\nboost: {\nreltime: 2,\n},\nweights: {\nfuzzy: 0.2,\nprefix: 0.8,\n},\n})\n.map((x) => {\nreturn {\nid: x.id,\nicon: markRaw(\nx.id.endsWith(`-selected`) ? IconCheckCircle : IconCircle\n),\nscore: x.score,\ntext: {\ntype: `text`,\ntext: [this.t(`spotlight.section.interceptor`), x.name],\n},\n}\n})\n},\n{ immediate: true }\n)\n})\nconst onSessionEnd = () => {\nscopeHandle.stop()\nminisearch.removeAll()\n}\nconst resultObj = computed<SpotlightSearcherSessionState>(() => ({\nloading: loading.value,\nresults: results.value,\n}))\nreturn [resultObj, onSessionEnd]\n}"
"createSearchSession(\nquery: Readonly<Ref<string>>\n): [Ref<SpotlightSearcherSessionState>, () => void] {\nconst loading = ref(false)\nconst results = ref<SpotlightSearcherResult[]>([])\nconst minisearch = new MiniSearch({\nfields: [`name`, `alternates`],\nstoreFields: [`name`],\n})\nconst kernelInterceptorSelection = this.kernelInterceptorService.current\nconst kernelInterceptors = this.kernelInterceptorService.available\nminisearch.addAll(\nkernelInterceptors.value.map((entry) => {\nconst id =\nentry.id === kernelInterceptorSelection.value?.id\n? `kernelInterceptor-${entry.id}-selected`\n: `kernelInterceptor-${entry.id}`\nconst name = unref(entry.name(this.t))\nconst alternates = [`interceptor`, `change`, name]\nreturn {\nid,\nname,\nalternates,\n}\n})\n)\nconst scopeHandle = effectScope()\nscopeHandle.run(() => {\nwatch(\n[query],\n([query]) => {\nresults.value = minisearch\n.search(query, {\nprefix: true,\nfuzzy: true,\nboost: {\nreltime: 2,\n},\nweights: {\nfuzzy: 0.2,\nprefix: 0.8,\n},\n})\n.map((x) => {\nreturn {\nid: x.id,\nicon: markRaw(\nx.id.endsWith(`-selected`) ? IconCheckCircle : IconCircle\n),\nscore: x.score,\ntext: {\ntype: `text`,\ntext: [this.t(`spotlight.section.interceptor`), x.name],\n},\n}\n})\n},\n{ immediate: true }\n)\n})\nconst onSessionEnd = () => {\nscopeHandle.stop()\nminisearch.removeAll()\n}\nconst resultObj = computed<SpotlightSearcherSessionState>(() => ({\nloading: loading.value,\nresults: results.value,\n}))\nreturn [resultObj, onSessionEnd]\n}"
"public onDocSelected(id: string): void {\nswitch (id) {\ncase `send_request`:\ninvokeAction(`request.send-cancel`)\nbreak\ncase `gql_connect`:\ninvokeAction(`gql.connect`)\nbreak\ncase `gql_disconnect`:\ninvokeAction(`gql.disconnect`)\nbreak\ncase `save_to_collections`:\ninvokeAction(`request.save-as`, {\nrequestType: `rest`,\nrequest:\nthis.restTab.currentActiveTab.value?.document.type === `request`\n? this.restTab.currentActiveTab.value?.document.request\n: null,\n})\nbreak\ncase `save_request`:\ninvokeAction(`request-response.save`)\nbreak\ncase `rename_request`:\ninvokeAction(`request.rename`)\nbreak\ncase `share_request`:\ninvokeAction(`request.share-request`)\nbreak\ncase `reset_request`:\ninvokeAction(`request.reset`)\nbreak\ncase `get_method`:\ninvokeAction(`request.method.get`)\nbreak\ncase `head_method`:\ninvokeAction(`request.method.head`)\nbreak\ncase `post_method`:\ninvokeAction(`request.method.post`)\nbreak\ncase `put_method`:\ninvokeAction(`request.method.put`)\nbreak\ncase `delete_method`:\ninvokeAction(`request.method.delete`)\nbreak\ncase `import_curl`:\ninvokeAction(`request.import-curl`)\nbreak\ncase `show_code`:\ninvokeAction(`request.show-code`)\nbreak\ncase `tab_parameters`:\nthis.openRequestTab(`params`)\nbreak\ncase `tab_body`:\nthis.openRequestTab(`bodyParams`)\nbreak\ncase `tab_headers`:\nthis.openRequestTab(`headers`)\nbreak\ncase `tab_authorization`:\nthis.openRequestTab(`authorization`)\nbreak\ncase `tab_pre_request_script`:\nthis.openRequestTab(`preRequestScript`)\nbreak\ncase `tab_tests`:\nthis.openRequestTab(`tests`)\nbreak\ncase `tab_query`:\nthis.openRequestTab(`query`)\nbreak\ncase `tab_variables`:\nthis.openRequestTab(`variables`)\nbreak\n}\n}"
"onResultSelect(result: SpotlightSearcherResult): void {\nif (result.id === `create-collection`) return invokeAction(`collection.new`)\nif (result.id === `import-collection`)\nreturn invokeAction(`modals.collection.import`)\nlet inheritedProperties: HoppInheritedProperty | undefined = undefined\nconst selectedRequest = this.teamsSearch.searchResultsRequests[result.id]\nif (!selectedRequest) return\nconst collectionID = result.id\nif (!collectionID) return\ninheritedProperties =\nthis.teamsSearch.cascadeParentCollectionForHeaderAuthForSearchResults(\ncollectionID\n)\nconst possibleTab = this.tabs.getTabRefWithSaveContext({\noriginLocation: `team-collection`,\nrequestID: result.id,\n})\nif (possibleTab) {\nthis.tabs.setActiveTab(possibleTab.value.id)\n} else {\nthis.tabs.createNewTab({\nrequest: cloneDeep(selectedRequest.request as HoppRESTRequest),\nisDirty: false,\ntype: `request`,\nsaveContext: {\noriginLocation: `team-collection`,\nrequestID: selectedRequest.id,\ncollectionID: selectedRequest.collectionID,\n},\ninheritedProperties: inheritedProperties,\n})\n}\n}"
"createSearchSession(\nquery: Readonly<Ref<string>>\n): [Ref<SpotlightSearcherSessionState>, () => void] {\nconst loading = ref(false)\nconst results = ref<SpotlightSearcherResult[]>([])\nconst minisearch = new MiniSearch({\nfields: [`name`, `alternates`],\nstoreFields: [`name`],\n})\nthis.fetchMyTeams().then((teams) => {\nminisearch.addAll(\nteams.map((entry) => {\nlet id = `workspace-${entry.id}`\nif (\nthis.workspace.value.type === `team` &&\nthis.workspace.value.teamID === entry.id\n) {\nid += `-selected`\n}\nreturn {\nid,\nname: entry.name,\nalternates: [`team`, `workspace`, `change`, `switch`],\n}\n})\n)\n})\nconst scopeHandle = effectScope()\nscopeHandle.run(() => {\nwatch(\n[query],\n([query]) => {\nresults.value = minisearch\n.search(query, {\nprefix: true,\nfuzzy: true,\nboost: {\nreltime: 2,\n},\nweights: {\nfuzzy: 0.2,\nprefix: 0.8,\n},\n})\n.map((x) => {\nreturn {\nid: x.id,\nicon: markRaw(\nx.id.endsWith(`-selected`) ? IconCheckCircle : IconUsers\n),\nscore: x.score,\ntext: {\ntype: `text`,\ntext: [this.t(`workspace.change`), x.name],\n},\n}\n})\n},\n{ immediate: true }\n)\n})\nconst onSessionEnd = () => {\nscopeHandle.stop()\nminisearch.removeAll()\n}\nconst resultObj = computed<SpotlightSearcherSessionState>(() => ({\nloading: loading.value,\nresults: results.value,\n}))\nreturn [resultObj, onSessionEnd]\n}"
"async function convertToRequestDef(\naxiosReq: AxiosRequestConfig,\nreqID: number,\ncaCertificates: CACertificateEntry[],\nclientCertificates: Map<string, ClientCertificateEntry>,\nvalidateCerts: boolean,\nproxyInfo: RequestDef[`proxy`]\n): Promise<RequestDef> {\nconst clientCertDomain = getURLDomain(axiosReq.url!)\nconst clientCert = clientCertDomain\n? clientCertificates.get(clientCertDomain)\n: null\nconst urlObj = new URL(axiosReq.url ?? ``)\nif (axiosReq.params) {\nconst params = new URLSearchParams(urlObj.search)\nObject.entries(axiosReq.params as Record<string, string>).forEach(\n([key, value]) => {\nparams.append(key, value)\n}\n)\nurlObj.search = params.toString()\n}\nreturn {\nreq_id: reqID,\nmethod: axiosReq.method ?? `GET`,\nendpoint: urlObj.toString(),\nheaders: Object.entries(axiosReq.headers ?? {})\n.filter(\n([key, value]) =>\n!(\nkey.toLowerCase() === `content-type` &&\nvalue.toLowerCase() === `multipart/form-data`\n)\n)\n.map(([key, value]): KeyValuePair => ({ key, value })),\nbody: await processBody(axiosReq),\nroot_cert_bundle_files: caCertificates.map((cert) =>\nArray.from(cert.certificate)\n),\nvalidate_certs: validateCerts,\nclient_cert: clientCert ? convertClientCertToDefCert(clientCert) : null,\nproxy: proxyInfo,\n}\n}"
"public async verifyRegistration(userEnteredOTP: string) {\ntry {\nconst myPrivateKey = x25519.utils.randomPrivateKey()\nconst myPublicKey = x25519.getPublicKey(myPrivateKey)\nconst myPublicKeyB16 = base16.encode(myPublicKey).toLowerCase()\nconst verificationResponse = await axios.post(\n`http:\n{\nregistration: userEnteredOTP,\nclient_public_key_b16: myPublicKeyB16,\n}\n)\nconst newAuthKey = verificationResponse.data.auth_key\nconst agentPublicKeyB16: string =\nverificationResponse.data.agent_public_key_b16\nconst agentPublicKey = base16.decode(agentPublicKeyB16.toUpperCase())\nconst sharedSecret = x25519.getSharedSecret(myPrivateKey, agentPublicKey)\nconst sharedSecretB16 = base16.encode(sharedSecret).toLowerCase()\nif (typeof newAuthKey === `string`) {\nthis.authKey.value = newAuthKey\nthis.sharedSecretB16.value = sharedSecretB16\nthis.persistenceService.setLocalConfig(AUTH_KEY_PERSIST_KEY, newAuthKey)\nthis.persistenceService.setLocalConfig(\nSHARED_SECRET_PERSIST_KEY,\nsharedSecretB16\n)\n} else {\nthrow new Error(`Invalid auth key received`)\n}\nthis.showRegistrationModal.value = false\nthis.registrationOTP.value = null\n} catch (error) {\nconsole.error(`Verification failed:`, error)\nthrow new Error(`Verification failed`)\n}\n}"
"private setupExtensionStatusListener(): void {\nconst extensionPollIntervalId = ref<ReturnType<typeof setInterval>>()\nif (window.__HOPP_EXTENSION_STATUS_PROXY__) {\nthis._extensionStatus.value =\nwindow.__HOPP_EXTENSION_STATUS_PROXY__.status\nwindow.__HOPP_EXTENSION_STATUS_PROXY__.subscribe(\n`status`,\n(status: ExtensionStatus) => {\nthis._extensionStatus.value = status\n}\n)\n} else {\nconst statusProxy = defineSubscribableObject({\nstatus: `waiting` as ExtensionStatus,\n})\nwindow.__HOPP_EXTENSION_STATUS_PROXY__ = statusProxy\nstatusProxy.subscribe(\n`status`,\n(status: ExtensionStatus) => (this._extensionStatus.value = status)\n)\nif (this.tryDetectExtension()) {\nreturn\n}\nextensionPollIntervalId.value = setInterval(() => {\nif (this.tryDetectExtension() && extensionPollIntervalId.value) {\nclearInterval(extensionPollIntervalId.value)\n}\n}, 2000)\n}\n}"
"private async executeRequest(\nrequest: RelayRequest,\nsetRelayExecution: (execution: { cancel: () => Promise<void> }) => void\n): Promise<E.Either<any, RelayResponse>> {\ntry {\nconst effectiveRequest = this.store.completeRequest(\npreProcessRelayRequest(request)\n)\nconst relevantCookies = this.cookieJar.getCookiesForURL(\nnew URL(effectiveRequest.url!)\n)\nif (relevantCookies.length > 0) {\neffectiveRequest.headers![`Cookie`] = relevantCookies\n.map((cookie) => `${cookie.name!}=${cookie.value!}`)\n.join(`;`)\n}\nconst existingUserAgentHeader = Object.keys(\neffectiveRequest.headers || {}\n).find((header) => header.toLowerCase() === `user-agent`)\nconst effectiveRequestWithUserAgent = {\n...effectiveRequest,\nheaders: {\n...effectiveRequest.headers,\n`User-Agent`: existingUserAgentHeader\n? effectiveRequest.headers[existingUserAgentHeader]\n: `HoppscotchKernel/0.2.0`,\n},\n}\nconst nativeRequest = await relayRequestToNativeAdapter(\neffectiveRequestWithUserAgent\n)\nconst postProcessedRequest = postProcessRelayRequest(nativeRequest)\nconst relayExecution = Relay.execute(postProcessedRequest)\nsetRelayExecution(relayExecution)\nreturn await relayExecution.response\n} catch (e) {\nreturn E.left(e)\n}\n}"
"private constructProxyRequest(\nrequest: RelayRequest,\naccessToken: string\n): ProxyRequest {\nconst wantsBinary = true\nlet requestData: any = null\nif (request.content) {\nswitch (request.content.kind) {\ncase `json`:\nrequestData =\ntypeof request.content.content === `string`\n? request.content.content\n: JSON.stringify(request.content.content)\nbreak\ncase `binary`:\nif (\nrequest.content.content instanceof Blob ||\nrequest.content.content instanceof File\n) {\nrequestData = request.content.content\n} else if (typeof request.content.content === `string`) {\ntry {\nconst base64 =\nrequest.content.content.split(`,`)[1] || request.content.content\nconst binaryString = window.atob(base64)\nconst bytes = new Uint8Array(binaryString.length)\nfor (let i = 0; i < binaryString.length; i++) {\nbytes[i] = binaryString.charCodeAt(i)\n}\nrequestData = new Blob([bytes.buffer])\n} catch (e) {\nconsole.error(`Error converting binary data:`, e)\nrequestData = request.content.content\n}\n} else {\nrequestData = request.content.content\n}\nbreak\ncase `multipart`:\nrequestData = ``\nbreak\ndefault:\nrequestData = request.content.content\n}\n}\nreturn {\naccessToken,\nwantsBinary,\nurl: request.url,\nmethod: request.method,\nheaders: request.headers,\nparams: request.params,\ndata: requestData,\nauth:\nrequest.auth?.kind === `basic`\n? {\nusername: request.auth.username,\npassword: request.auth.password,\n}\n: undefined,\n}\n}"
"public createSearchSession(\nquery: Readonly<Ref<string>>\n): [Ref<SpotlightSearcherSessionState>, () => void] {\nconst results = ref<SpotlightSearcherResult[]>([])\nconst resultObj = computed<SpotlightSearcherSessionState>(() => ({\nloading: this.loading.value,\nresults: results.value,\n}))\nconst scopeHandle = effectScope()\nscopeHandle.run(() => {\nwatch(\n[query, () => this._documents],\n([query, docs]) => {\nconst searchResults = this.minisearch.search(query, {\nprefix: true,\nboost: (this.opts.fieldWeights as any) ?? {},\nweights: {\nfuzzy: this.opts.fuzzyWeight ?? 0.2,\nprefix: this.opts.prefixWeight ?? 0.6,\n},\n})\nresults.value = searchResults\n.filter(\n(result) =>\nthis._documents[result.id].excludeFromSearch === undefined ||\nthis._documents[result.id].excludeFromSearch === false\n)\n.map((result) => {\nreturn this.getSearcherResultForSearchResult({\nid: result.id,\nscore: result.score,\ndoc: docs[result.id],\n})\n})\n},\n{ immediate: true }\n)\n})\nconst onSessionEnd = () => {\nscopeHandle.stop()\n}\nreturn [resultObj, onSessionEnd]\n}"
"export function parseTemplateStringE(\nstr: string,\nvariables: Environment[`variables`],\nmaskValue = false,\nshowKeyIfSecret = false\n) {\nif (!variables || !str) {\nreturn E.right(str)\n}\nlet result = str\nlet depth = 0\nlet isSecret = false\nwhile (\nresult.match(REGEX_ENV_VAR) != null &&\ndepth <= ENV_MAX_EXPAND_LIMIT &&\n!isSecret\n) {\nresult = decodeURI(encodeURI(result)).replace(REGEX_ENV_VAR, (_, p1) => {\nconst foundPredefinedVar = HOPP_SUPPORTED_PREDEFINED_VARIABLES.find(\n(preVar) => preVar.key === p1\n)\nif (foundPredefinedVar) {\nreturn foundPredefinedVar.getValue()\n}\nconst variable = variables.find((x) => x && x.key === p1)\nif (variable && `currentValue` in variable) {\nif (variable.secret && showKeyIfSecret) {\nisSecret = true\nreturn `<<${p1}>>`\n}\nif (variable.secret && maskValue) {\nreturn `*`.repeat(\n(\nvariable as {\nsecret: true\ninitialValue: string\ncurrentValue: string\nkey: string\n}\n).currentValue.length\n)\n}\nreturn variable.currentValue\n}\nreturn ``\n})\ndepth++\n}\nreturn depth > ENV_MAX_EXPAND_LIMIT\n? E.left(ENV_EXPAND_LOOP)\n: E.right(result)\n}"
"export function safelyExtractRESTRequest(\nx: unknown,\ndefaultReq: HoppRESTRequest\n): HoppRESTRequest {\nconst req = cloneDeep(defaultReq)\nif (!!x && typeof x === `object`) {\nif (`id` in x && typeof x.id === `string`) req.id = x.id\nif (`name` in x && typeof x.name === `string`) req.name = x.name\nif (`method` in x && typeof x.method === `string`) req.method = x.method\nif (`endpoint` in x && typeof x.endpoint === `string`)\nreq.endpoint = x.endpoint\nif (`preRequestScript` in x && typeof x.preRequestScript === `string`)\nreq.preRequestScript = x.preRequestScript\nif (`testScript` in x && typeof x.testScript === `string`)\nreq.testScript = x.testScript\nif (`body` in x) {\nconst result = HoppRESTReqBody.safeParse(x.body)\nif (result.success) {\nreq.body = result.data\n}\n}\nif (`auth` in x) {\nconst result = HoppRESTAuth.safeParse(x.auth)\nif (result.success) {\nreq.auth = result.data\n}\n}\nif (`params` in x) {\nconst result = HoppRESTParams.safeParse(x.params)\nif (result.success) {\nreq.params = result.data\n}\n}\nif (`headers` in x) {\nconst result = HoppRESTHeaders.safeParse(x.headers)\nif (result.success) {\nreq.headers = result.data\n}\n}\nif (`requestVariables` in x) {\nconst result = HoppRESTRequestVariables.safeParse(x.requestVariables)\nif (result.success) {\nreq.requestVariables = result.data\n}\n}\nif (`responses` in x) {\nconst result = HoppRESTRequestResponses.safeParse(x.responses)\nif (result.success) {\nreq.responses = result.data\n}\n}\n}\nreturn req\n}"
"export async function calculateAkamaiEdgeGridHeader(params: {\naccessToken: string\nclientToken: string\nclientSecret: string\nurl: string\nmethod: string\nbody?: string\nnonce?: string\ntimestamp?: string\nhost?: string\nheadersToSign?: string\nmaxBodySize?: string\n}) {\nconst encoder = new TextEncoder()\nconst decoder = new TextDecoder()\nconst timestamp = params.timestamp || Math.floor(Date.now() / 1000).toString()\nconst nonce = params.nonce || crypto.randomUUID()\nconst host = params.host || new URL(params.url).host\nconst keyMaterial = await crypto.subtle.importKey(\n`raw`,\nencoder.encode(params.clientSecret),\n{ name: `HMAC`, hash: `SHA-256` },\nfalse,\n[`sign`]\n)\nconst signingKey = await crypto.subtle.sign(\n`HMAC`,\nkeyMaterial,\nencoder.encode(timestamp)\n)\nlet contentHash = ``\nif (params.body) {\nconst hashBuffer = await crypto.subtle.digest(\n`SHA-256`,\nencoder.encode(params.body)\n)\ncontentHash = Array.from(new Uint8Array(hashBuffer))\n.map((b) => b.toString(16).padStart(2, `0`))\n.join(``)\n}\nconst data = `${params.method} ${params.url} ${host} ${timestamp} ${nonce} ${contentHash}`\nconst signatureBuffer = await crypto.subtle.sign(\n`HMAC`,\nkeyMaterial,\nencoder.encode(data)\n)\nconst signature = btoa(\nString.fromCharCode(...new Uint8Array(signatureBuffer))\n)\nconst authorizationHeader = `EG1-HMAC-SHA256 client_token=${params.clientToken};access_token=${params.accessToken};timestamp=${timestamp};nonce=${nonce};signature=${signature}`\nreturn authorizationHeader\n}"
"async function getPayloadContent(\npayload: string | FormData | File | Blob | null,\ncontentType: string\n): Promise<string> {\nif (!payload) return ``\nif (payload instanceof FormData) {\nif (contentType === `multipart/form-data`) {\nconst parts: string[] = []\npayload.forEach((value, key) => {\nif (typeof value === `string`) {\nparts.push(`${key}=${value}`)\n} else {\nparts.push(`${key}=${value instanceof File ? value.name : `blob`}`)\n}\n})\nreturn normalizeLineEndings(parts.join(`&`))\n} else {\nconst pairs: string[] = []\npayload.forEach((value, key) => {\nif (typeof value === `string`) {\npairs.push(`${key}=${encodeURIComponent(value)}`)\n}\n})\nreturn normalizeLineEndings(pairs.join(`&`))\n}\n}\nif (payload instanceof Blob) {\ntry {\nconst text = await payload.text()\nreturn normalizeLineEndings(text)\n} catch (e) {\nconsole.error(`Failed to read blob content`, e)\nreturn ``\n}\n}\nif (contentType.includes(`application/json`) && typeof payload === `string`) {\ntry {\nconst jsonObj = JSON.parse(payload)\nreturn normalizeLineEndings(JSON.stringify(jsonObj))\n} catch (e) {\nreturn normalizeLineEndings(payload.toString())\n}\n}\nreturn normalizeLineEndings(payload.toString())\n}"
"export async function generateJWTToken(\nparams: JWTTokenParams\n): Promise<string | null> {\nconst {\nalgorithm,\nsecret,\nprivateKey,\npayload,\njwtHeaders,\nisSecretBase64Encoded,\n} = params\nlet parsedPayload = {}\nlet parsedHeaders = {}\ntry {\nconst payloadString = payload?.trim() || `{}`\nif (payloadString === ``) {\nparsedPayload = {}\n} else {\nparsedPayload = JSON.parse(payloadString)\n}\n} catch (e) {\nconsole.error(`Failed to parse JWT payload JSON:`, e)\nconsole.error(`Payload value:`, payload)\nreturn null\n}\ntry {\nconst headersString = jwtHeaders?.trim() || `{}`\nif (headersString === ``) {\nparsedHeaders = {}\n} else {\nparsedHeaders = JSON.parse(headersString)\n}\n} catch (e) {\nconsole.error(`Failed to parse JWT headers JSON:`, e)\nconsole.error(`Headers value:`, jwtHeaders)\nreturn null\n}\ntry {\nlet cryptoKey: Uint8Array\nif (\nalgorithm.startsWith(`RS`) ||\nalgorithm.startsWith(`ES`) ||\nalgorithm.startsWith(`PS`)\n) {\nif (!privateKey) {\nconsole.error(`Private key is required for RSA/ECDSA algorithms`)\nreturn null\n}\ncryptoKey = new TextEncoder().encode(privateKey)\n} else {\nif (!secret) {\nconsole.error(`Secret is required for HMAC algorithms`)\nreturn null\n}\ncryptoKey = isSecretBase64Encoded\n? Uint8Array.from(Buffer.from(secret, `base64`))\n: new TextEncoder().encode(secret)\n}\nconst token = await new jose.SignJWT(parsedPayload)\n.setProtectedHeader({\nalg: algorithm,\n...parsedHeaders,\n})\n.sign(cryptoKey)\nreturn token\n} catch (e) {\nconsole.error(`Error generating JWT token:`, e)\nreturn null\n}\n}"
"up(old: z.infer<typeof V8_SCHEMA>) {\nlet newAuth: z.infer<typeof V9_SCHEMA>[`auth`]\nif (old.auth.authType === `oauth-2`) {\nconst oldGrantTypeInfo = old.auth.grantTypeInfo\nlet newGrantTypeInfo\nif (oldGrantTypeInfo.grantType === `AUTHORIZATION_CODE`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `CLIENT_CREDENTIALS`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `PASSWORD`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `IMPLICIT`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\nrefreshRequestParams: [],\n}\n} else {\nnewGrantTypeInfo = oldGrantTypeInfo\n}\nnewAuth = {\n...old.auth,\ngrantTypeInfo: newGrantTypeInfo,\n} as z.infer<typeof V9_SCHEMA>[`auth`]\n} else {\nnewAuth = old.auth\n}\nconst result: z.infer<typeof V9_SCHEMA> = {\n...old,\nv: 9 as const,\nauth: newAuth,\nfolders: old.folders.map((folder) => {\nconst result = HoppCollection.safeParseUpToVersion(folder, 9)\nif (result.type !== `ok`) {\nthrow new Error(`Failed to migrate child collections`)\n}\nreturn result.value\n}),\n}\nreturn result\n},"
"up(old: z.infer<typeof V8_SCHEMA>) {\nlet newAuth: z.infer<typeof HoppGQLAuth>\nif (old.auth.authType === `oauth-2`) {\nconst oldGrantTypeInfo = old.auth.grantTypeInfo\nlet newGrantTypeInfo\nif (oldGrantTypeInfo.grantType === `AUTHORIZATION_CODE`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `CLIENT_CREDENTIALS`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `PASSWORD`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `IMPLICIT`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\nrefreshRequestParams: [],\n}\n} else {\nnewGrantTypeInfo = oldGrantTypeInfo\n}\nnewAuth = {\n...old.auth,\ngrantTypeInfo: newGrantTypeInfo,\n} as z.infer<typeof HoppGQLAuth>\n} else {\nnewAuth = old.auth\n}\nreturn {\n...old,\nv: 9 as const,\nauth: newAuth,\n}\n},"
"up(old: z.infer<typeof V14_SCHEMA>) {\nlet newAuth: z.infer<typeof HoppRESTAuth>\nif (old.auth.authType === `oauth-2`) {\nconst oldGrantTypeInfo = old.auth.grantTypeInfo\nlet newGrantTypeInfo\nif (oldGrantTypeInfo.grantType === `AUTHORIZATION_CODE`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `CLIENT_CREDENTIALS`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `PASSWORD`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `IMPLICIT`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\nrefreshRequestParams: [],\n}\n} else {\nnewGrantTypeInfo = oldGrantTypeInfo\n}\nnewAuth = {\n...old.auth,\ngrantTypeInfo: newGrantTypeInfo,\n} as z.infer<typeof HoppRESTAuth>\n} else {\nnewAuth = old.auth\n}\nreturn {\n...old,\nv: `15` as const,\nauth: newAuth,\n}\n},"
"up(old: z.infer<typeof V5_SCHEMA>) {\nlet newAuth: z.infer<typeof HoppRESTAuth>\nif (old.auth.authType === `oauth-2`) {\nconst oldGrantTypeInfo = old.auth.grantTypeInfo\nlet newGrantTypeInfo\nif (oldGrantTypeInfo.grantType === `AUTHORIZATION_CODE`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `CLIENT_CREDENTIALS`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `PASSWORD`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\ntokenRequestParams: [],\nrefreshRequestParams: [],\n}\n} else if (oldGrantTypeInfo.grantType === `IMPLICIT`) {\nnewGrantTypeInfo = {\n...oldGrantTypeInfo,\nauthRequestParams: [],\nrefreshRequestParams: [],\n}\n} else {\nnewGrantTypeInfo = oldGrantTypeInfo\n}\nnewAuth = {\n...old.auth,\ngrantTypeInfo: newGrantTypeInfo,\n} as z.infer<typeof HoppRESTAuth>\n} else {\nnewAuth = old.auth\n}\nreturn {\n...old,\nv: `6` as const,\nauth: newAuth,\n}\n},"
"async checkForUpdates(timeout = 5000): Promise<CheckResult> {\ntry {\nawait this.saveUpdateState({\nstatus: UpdateStatus.CHECKING\n});\nconst timeoutPromise = new Promise<null>((resolve) => {\nconst bufferTimeout = timeout + 1000;\nsetTimeout(() => {\nconsole.log(`Update check exceeded buffer timeout, likely hanging in check function`);\nresolve(null);\n}, bufferTimeout);\n});\nconst updateResult = await Promise.race([\ncheck({ timeout }),\ntimeoutPromise\n]);\nif (!updateResult) {\nconsole.log(`Update check timed out or no update available`);\nawait this.saveUpdateState({\nstatus: UpdateStatus.NOT_AVAILABLE\n});\nreturn CheckResult.TIMEOUT;\n}\nconst hasUpdates = updateResult.available;\nawait this.saveUpdateState(\nhasUpdates\n? {\nstatus: UpdateStatus.AVAILABLE,\nversion: updateResult.version,\nmessage: updateResult.body\n}\n: {\nstatus: UpdateStatus.NOT_AVAILABLE\n}\n);\nconsole.log(`Update check result:`, {\navailable: updateResult.available,\ncurrentVersion: updateResult.currentVersion,\nversion: updateResult.version\n});\nreturn hasUpdates ? CheckResult.AVAILABLE : CheckResult.NOT_AVAILABLE;\n} catch (error) {\nconsole.error(`Error checking for updates:`, error);\nawait this.saveUpdateState({\nstatus: UpdateStatus.ERROR,\nmessage: String(error)\n});\nreturn CheckResult.ERROR;\n}\n}"
"async downloadAndInstall(): Promise<void> {\ntry {\nconst updateResult = await check();\nif (!updateResult) {\nthrow new Error(`No update available to install`);\n}\nlet totalBytes: number | undefined;\nlet downloadedBytes = 0;\nawait this.saveUpdateState({\nstatus: UpdateStatus.DOWNLOADING,\n});\nawait updateResult.downloadAndInstall(\n(event: DownloadEvent) => {\ntry {\nif (event.event === 'Started') {\ntotalBytes = event.data.contentLength;\ndownloadedBytes = 0;\nconsole.log(`Download started, total size: ${totalBytes} bytes`);\n} else if (event.event === 'Progress') {\ndownloadedBytes += event.data.chunkLength;\nconsole.log(`Download progress: ${downloadedBytes}/${totalBytes} bytes`);\nthis.currentProgress = {\ndownloaded: downloadedBytes,\ntotal: totalBytes\n};\n} else if (event.event === 'Finished') {\nconsole.log(`Download finished, starting installation`);\nthis.saveUpdateState({\nstatus: UpdateStatus.INSTALLING\n});\n}\n} catch (error) {\nconsole.warn('Progress tracking error:', error);\n}\n}\n);\nawait this.saveUpdateState({\nstatus: UpdateStatus.READY_TO_RESTART\n});\n} catch (error) {\nconsole.error(`Error installing updates:`, error);\nawait this.saveUpdateState({\nstatus: UpdateStatus.ERROR,\nmessage: String(error)\n});\nthrow error;\n}\n}"
"canHandle(request: RelayRequest) {\nif (!this.capabilities.method.has(request.method)) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `method`,\nmessage: `Method ${request.method} is not supported`,\nrelay: `desktop`\n})\n}\nif (request.content && !this.capabilities.content.has(request.content.kind)) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `content`,\nmessage: `Content type ${request.content.kind} is not supported`,\nrelay: `desktop`\n})\n}\nif (request.auth && !this.capabilities.auth.has(request.auth.kind)) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `authentication`,\nmessage: `Authentication type ${request.auth.kind} is not supported`,\nrelay: `desktop`\n})\n}\nif (request.security?.certificates && !this.capabilities.security.has('clientcertificates')) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `security`,\nmessage: `Client certificates are not supported`,\nrelay: `desktop`\n})\n}\nif (request.proxy && !this.capabilities.proxy.has(request.proxy.url.startsWith('https') ? 'https' : 'http')) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `proxy`,\nmessage: `Proxy protocol ${request.proxy.url.split(':')[0]} is not supported`,\nrelay: `desktop`\n})\n}\nreturn E.right(true)\n},"
"execute(request: RelayRequest) {\nconst emitter: RelayEventEmitter<RelayRequestEvents> = {\non: () => () => {},\nonce: () => () => {},\noff: () => {}\n}\nconst responsePromise = relayRequestToNativeAdapter(request)\n.then(request => {\nconst pluginRequest = {\nid: request.id,\nurl: request.url,\nmethod: request.method,\nversion: request.version,\nheaders: request.headers,\nparams: request.params,\ncontent: request.content,\nauth: request.auth,\nsecurity: request.security,\nproxy: request.proxy,\n}\nreturn execute(pluginRequest)\n})\n.then((result: RequestResult): E.Either<RelayError, RelayResponse> => {\nif (result.kind === 'success') {\nconst response: RelayResponse = {\nid: result.response.id,\nstatus: result.response.status,\nstatusText: result.response.statusText,\nversion: result.response.version,\nheaders: result.response.headers,\ncookies: result.response.cookies,\nbody: body.body(result.response.body.body, result.response.body.mediaType),\nmeta: {\ntiming: {\nstart: result.response.meta.timing.start,\nend: result.response.meta.timing.end,\n},\nsize: result.response.meta.size,\n}\n}\nreturn E.right(response)\n}\nreturn E.left(result.error)\n})\n.catch((error: unknown): E.Either<RelayError, RelayResponse> => {\nconst networkError: RelayError = {\nkind: 'network',\nmessage: error instanceof Error ? error.message : 'Unknown error occurred',\ncause: error\n}\nreturn E.left(networkError)\n})\nreturn {\ncancel: async () => { await cancel(request.id) },\nemitter,\nresponse: responsePromise\n}\n}"
"canHandle(request: RelayRequest) {\nif (!this.capabilities.method.has(request.method)) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `method`,\nmessage: `Method ${request.method} is not supported`,\nrelay: `axios`,\n})\n}\nif (\nrequest.content &&\n!this.capabilities.content.has(request.content.kind)\n) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `content`,\nmessage: `Content type ${request.content.kind} is not supported`,\nrelay: `axios`,\n})\n}\nif (request.auth && !this.capabilities.auth.has(request.auth.kind)) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `authentication`,\nmessage: `Authentication type ${request.auth.kind} is not supported`,\nrelay: `axios`,\n})\n}\nif (request.security?.certificates) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `security`,\nmessage: `Client certificates are not supported`,\nrelay: `axios`,\n})\n}\nif (request.proxy) {\nreturn E.left({\nkind: `unsupported_feature`,\nfeature: `proxy`,\nmessage: `Proxy is not supported`,\nrelay: `axios`,\n})\n}\nreturn E.right(true)\n},"
"async watch(namespace: string, key: string): Promise<StoreEventEmitter<StoreEvents>> {\nconst watchKey = `${namespace}:${key}`;\nreturn {\non: <K extends keyof StoreEvents>(\nevent: K,\nhandler: (payload: StoreEvents[K]) => void\n) => {\nif (event !== 'change') return () => {};\nif (!this.listeners.has(watchKey)) {\nthis.listeners.set(watchKey, new Set());\n}\nthis.listeners.get(watchKey)!.add(handler as (payload: StoreEvents['change']) => void);\nreturn () => this.listeners.get(watchKey)?.delete(handler as (payload: StoreEvents['change']) => void);\n},\nonce: <K extends keyof StoreEvents>(\nevent: K,\nhandler: (payload: StoreEvents[K]) => void\n) => {\nif (event !== 'change') return () => {};\nconst wrapper = (value: StoreEvents['change']) => {\nhandler(value as StoreEvents[K]);\nthis.listeners.get(watchKey)?.delete(wrapper);\n};\nif (!this.listeners.has(watchKey)) {\nthis.listeners.set(watchKey, new Set());\n}\nthis.listeners.get(watchKey)!.add(wrapper);\nreturn () => this.listeners.get(watchKey)?.delete(wrapper);\n},\noff: <K extends keyof StoreEvents>(\nevent: K,\nhandler: (payload: StoreEvents[K]) => void\n) => {\nif (event === 'change') {\nthis.listeners.get(watchKey)?.delete(handler as (payload: StoreEvents['change']) => void);\n}\n},\n};\n}"
"export function HotkeyScopeBoundary({\nscope,\nisActive = true,\nrootScopeDisabled = false,\ncomponentName,\nchildren,\n}: HotkeyScopeBoundaryProps) {\nconst { enableScope, disableScope, activeScopes } = useHotkeysContext()\nconst entryIdRef = useRef<string>()\nconst previousScopesRef = useRef<string[]>([])\nconst hasCleanedUpRef = useRef(false)\nuseEffect(() => {\nif (!isActive) {\nreturn\n}\nhasCleanedUpRef.current = false\nconst mountId = nanoid()\nentryIdRef.current = mountId\nscopeManager.push({\nid: mountId,\nscope,\nrootDisabled: rootScopeDisabled,\ntimestamp: Date.now(),\ncomponent: componentName,\n})\nconst currentActive = [...activeScopes]\npreviousScopesRef.current = currentActive\ncurrentActive.forEach(s => {\nif (s === '*') {\nreturn\n}\nif (s === HOTKEY_SCOPES.ROOT && !rootScopeDisabled) {\nreturn\n}\ndisableScope(s)\n})\nenableScope(scope)\nif (!rootScopeDisabled) {\nenableScope(HOTKEY_SCOPES.ROOT)\n}\nreturn () => {\nif (hasCleanedUpRef.current) {\nreturn\n}\nhasCleanedUpRef.current = true\nconst cleanupId = entryIdRef.current\nsetTimeout(() => {\nif (cleanupId) {\nscopeManager.remove(cleanupId)\n}\ndisableScope(scope)\nconst stack = scopeManager.getStack()\nif (stack.length > 0) {\nconst newTop = stack[stack.length - 1]\nenableScope(newTop.scope)\nif (!newTop.rootDisabled) {\nenableScope(HOTKEY_SCOPES.ROOT)\n}\n} else {\nenableScope(HOTKEY_SCOPES.ROOT)\n}\n}, 0)\n}\n}, [isActive, scope, rootScopeDisabled, componentName, enableScope, disableScope])\nreturn <>{children}</>\n}"
"export function HotkeyScopeDebugger() {\nconst [stack, setStack] = useState(scopeManager.getStack())\nconst { activeScopes } = useHotkeysContext()\nconst { showHotkeyDebugger, setShowHotkeyDebugger } = useDebugStore()\nuseEffect(() => {\nreturn scopeManager.subscribe(setStack)\n}, [])\nuseHotkeys(\n'alt+shift+h',\n() => {\nsetShowHotkeyDebugger(!showHotkeyDebugger)\n},\n{\nenabled: import.meta.env.DEV,\npreventDefault: true,\n},\n[showHotkeyDebugger],\n)\nif (!import.meta.env.DEV || !showHotkeyDebugger) {\nreturn null\n}\nreturn (\n<div className=`fixed top-4 right-4 bg-black/90 text-white p-4 rounded-lg max-w-md z-[9999]`>\n<div className=`flex justify-between items-center mb-2`>\n<h3 className=`text-xs font-bold`>🎹 Hotkey Scope Stack</h3>\n<button\nonClick={() => setShowHotkeyDebugger(false)}\nclassName=`text-gray-400 hover:text-white text-xs`\ntitle=`Close (Alt+Shift+H)`\n>\n✕\n</button>\n</div>\n<div className=`space-y-1`>\n<div className=`text-xs`>\n<span className=`text-gray-400`>Active Scopes:</span>\n<span className=`ml-2 text-green-400`>{activeScopes.join(', ')}</span>\n</div>\n<div className=`text-xs`>\n<span className=`text-gray-400`>Stack ({stack.length}):</span>\n</div>\n{stack.map((entry, index) => (\n<div\nkey={entry.id}\nclassName={`text-xs pl-4 ${index === stack.length - 1 ? 'text-yellow-400' : 'text-gray-300'}`}\n>\n{index === stack.length - 1 && '→ '}\n{entry.scope}\n{entry.component && ` (${entry.component})`}\n{entry.rootDisabled && ' [root disabled]'}\n</div>\n))}\n</div>\n</div>\n)\n}"
"export function StackedCards({\ncards,\nonDismiss,\nclassName,\ngap = GAP,\nvisibleCards = VISIBLE_CARDS,\n}: StackedCardsProps) {\nconst [removedCards, setRemovedCards] = React.useState<Set<string>>(new Set())\nconst [mountedCards, setMountedCards] = React.useState<Set<string>>(new Set())\nconst activeCards = React.useMemo(\n() => cards.filter(card => !removedCards.has(card.id)),\n[cards, removedCards],\n)\nconst dismissCard = React.useCallback(\n(cardId: string) => {\nsetRemovedCards(prev => new Set(prev).add(cardId))\nsetTimeout(() => {\nonDismiss?.(cardId)\nsetRemovedCards(prev => {\nconst next = new Set(prev)\nnext.delete(cardId)\nreturn next\n})\n}, TIME_BEFORE_UNMOUNT)\n},\n[onDismiss],\n)\nReact.useEffect(() => {\nconst newMounted = new Set(mountedCards)\nactiveCards.forEach(card => {\nif (!newMounted.has(card.id)) {\nnewMounted.add(card.id)\n}\n})\nif (newMounted.size !== mountedCards.size) {\nsetMountedCards(newMounted)\n}\n}, [activeCards, mountedCards])\nreturn (\n<div\nclassName={cn('relative', className)}\nstyle={\n{\n'--gap': `${gap}px`,\n'--visible-cards': visibleCards,\n} as React.CSSProperties\n}\n>\n{activeCards.map((card, index) => (\n<StackedCard\nkey={card.id}\ncard={card}\nindex={index}\nvisibleCards={visibleCards}\ngap={gap}\nonDismiss={() => dismissCard(card.id)}\nisRemoved={removedCards.has(card.id)}\nisMounted={mountedCards.has(card.id)}\ntotalCards={activeCards.length}\n/>\n))}\n</div>\n)\n}"
"export function TestErrorTrigger() {\nconst [shouldCrash, setShouldCrash] = useState(false)\nuseHotkeys(\n'meta+shift+alt+e, ctrl+shift+alt+e',\ne => {\nconsole.log('[TestErrorTrigger] Hotkey triggered!')\ne.preventDefault()\nconst testError = new Error('Sentry test error - intentionally triggered')\ntestError.name = 'TestError'\ncaptureException(testError, {\ntestType: 'manual_trigger',\ntimestamp: new Date().toISOString(),\nversion: getAppVersion(),\n})\ntoast.info('Test error sent to Sentry (if telemetry is enabled)')\n},\n{\nenableOnFormTags: false,\npreventDefault: true,\n},\n)\nuseHotkeys(\n'meta+shift+alt+b, ctrl+shift+alt+b',\n() => {\nconsole.log('[TestErrorTrigger] Triggering React Error Boundary test!')\ntoast.warning('Triggering Error Boundary in 1 second...')\nsetTimeout(() => {\nsetShouldCrash(true)\n}, 1000)\n},\n{\nenableOnFormTags: false,\n},\n)\nif (shouldCrash) {\nreturn <ErrorBomb />\n}\nreturn null\n}"
"export function useApprovals(sessionId?: string): UseApprovalsReturn {\nconst [approvals, setApprovals] = useState<Approval[]>([])\nconst [loading, setLoading] = useState(true)\nconst [error, setError] = useState<string | null>(null)\nconst fetchApprovals = useCallback(async () => {\ntry {\nsetLoading(true)\nsetError(null)\nconst approvalsResponse = await daemonClient.fetchApprovals(sessionId)\nsetApprovals(approvalsResponse)\n} catch (err) {\nsetError(formatError(err))\n} finally {\nsetLoading(false)\n}\n}, [sessionId])\nuseEffect(() => {\nfetchApprovals()\n}, [fetchApprovals])\nconst approve = useCallback(\nasync (approvalId: string, comment?: string) => {\ntry {\nawait daemonClient.approveFunctionCall(approvalId, comment)\nawait fetchApprovals()\n} catch (err) {\nthrow new Error(formatError(err))\n}\n},\n[fetchApprovals],\n)\nconst deny = useCallback(\nasync (approvalId: string, reason: string) => {\ntry {\nawait daemonClient.denyFunctionCall(approvalId, reason)\nawait fetchApprovals()\n} catch (err) {\nthrow new Error(formatError(err))\n}\n},\n[fetchApprovals],\n)\nreturn {\napprovals,\nloading,\nerror,\nrefresh: fetchApprovals,\napprove,\ndeny,\n}\n}"
"export function useApprovalsWithSubscription(sessionId?: string): UseApprovalsReturn {\nconst base = useApprovals(sessionId)\nuseEffect(() => {\nlet unsubscribe: (() => void) | null = null\nlet isSubscribed = true\nconst subscribe = async () => {\ntry {\nconst handle = daemonClient.subscribeToEvents({\nevent_types: ['new_approval', 'approval_resolved', 'session_status_changed'],\nsession_id: sessionId,\nonEvent: event => {\nif (!isSubscribed) return\nif (event.type === 'new_approval' || event.type === 'approval_resolved') {\nconsole.debug('Approval event with tool_use_id:', {\ntype: event.type,\napproval_id: event.data?.approval_id,\ntool_use_id: event.data?.tool_use_id,\ndata: event.data,\n})\n}\nswitch (event.type) {\ncase 'new_approval':\ncase 'approval_resolved':\nbase.refresh()\nbreak\ncase 'session_status_changed':\nbreak\n}\n},\n})\nunsubscribe = handle.unsubscribe\n} catch (err) {\nlogger.error('Failed to subscribe to events:', err)\nconst interval = setInterval(() => {\nif (isSubscribed) {\nbase.refresh()\n}\n}, 5000)\nreturn () => clearInterval(interval)\n}\n}\nsubscribe()\nreturn () => {\nisSubscribed = false\nunsubscribe?.()\n}\n}, [sessionId, base.refresh])\nreturn base\n}"
"export function useFormattedConversation(\nsessionId?: string,\nclaudeSessionId?: string,\n): UseConversationReturn & { formattedEvents: FormattedMessage[] } {\nconst base = useConversation(sessionId, claudeSessionId)\nconst formattedEvents: FormattedMessage[] = base.events\n.filter(event => event.id !== undefined)\n.map(event => {\nlet content = event.content || ''\nlet type: FormattedMessage['type'] = 'message'\nif (event.eventType === 'tool_call') {\ntype = 'tool_call'\ncontent = `Calling ${event.toolName || 'tool'}`\nif (event.toolInputJson) {\ntry {\nconst input = JSON.parse(event.toolInputJson)\ncontent += `: ${JSON.stringify(input, null, 2)}`\n} catch {\ncontent += `: ${event.toolInputJson}`\n}\n}\n} else if (event.eventType === 'tool_result') {\ntype = 'tool_result'\ncontent = event.toolResultContent || 'Tool completed'\n} else if (event.approvalStatus) {\ntype = 'approval'\ncontent = `Approval ${event.approvalStatus}`\n}\nreturn {\nid: event.id!,\ntype,\nrole: event.role,\ncontent,\ntimestamp: new Date(event.createdAt || new Date()),\nmetadata: {\ntoolName: event.toolName,\ntoolId: event.toolId,\napprovalStatus: event.approvalStatus || undefined,\napprovalId: event.approvalId,\n},\n}\n})\nreturn {\n...base,\nformattedEvents,\n}\n}"
"export function useFocusTrap(isActive: boolean) {\nconst containerRef = useRef<HTMLDivElement>(null)\nuseEffect(() => {\nif (!isActive || !containerRef.current) return\nconst container = containerRef.current\nconst getFocusableElements = (): HTMLElement[] => {\nconst focusableSelectors = [\n'a[href]',\n'button:not([disabled])',\n'textarea:not([disabled])',\n'input:not([disabled])',\n'select:not([disabled])',\n'[tabindex]:not([tabindex=`-1`])',\n'[contenteditable=`true`]',\n].join(', ')\nconst elements = container.querySelectorAll<HTMLElement>(focusableSelectors)\nreturn Array.from(elements).filter(el => {\nconst style = window.getComputedStyle(el)\nreturn style.display !== 'none' && style.visibility !== 'hidden'\n})\n}\nconst handleKeyDown = (e: KeyboardEvent) => {\nif (e.key !== 'Tab') return\nconst focusableElements = getFocusableElements()\nif (focusableElements.length === 0) return\nconst activeElement = document.activeElement as HTMLElement\nconst currentIndex = focusableElements.indexOf(activeElement)\ne.preventDefault()\ne.stopPropagation()\nlet nextIndex: number\nif (e.shiftKey) {\nif (currentIndex <= 0) {\nnextIndex = focusableElements.length - 1\n} else {\nnextIndex = currentIndex - 1\n}\n} else {\nif (currentIndex === -1 || currentIndex === focusableElements.length - 1) {\nnextIndex = 0\n} else {\nnextIndex = currentIndex + 1\n}\n}\nfocusableElements[nextIndex].focus()\n}\ncontainer.addEventListener('keydown', handleKeyDown, true)\nconst focusableElements = getFocusableElements()\nif (focusableElements.length > 0) {\nsetTimeout(() => {\nconst firstInput = focusableElements.find(el => el.tagName === 'INPUT')\nif (firstInput) {\nfirstInput.focus()\n} else {\nfocusableElements[0].focus()\n}\n}, 50)\n}\nreturn () => {\ncontainer.removeEventListener('keydown', handleKeyDown, true)\n}\n}, [isActive])\nreturn containerRef\n}"
"export function useHotkeyUnicodeChars() {\nconst [os, setOs] = useState('macOS')\nconst [modKey, setModKey] = useState('⌘')\nconst [optKey, setOptKey] = useState('⌥')\nuseEffect(() => {\nconst userAgent = window.navigator.userAgent\nconst platform = window.navigator.platform\nif (platform.indexOf('Mac') !== -1) {\nsetOs('macOS')\nsetModKey('⌘')\nsetOptKey('⌥')\n} else if (platform.indexOf('Win') !== -1) {\nsetOs('Windows')\nsetModKey('Ctrl')\nsetOptKey('Alt')\n} else if (/Android/.test(userAgent)) {\nsetOs('Android')\nsetModKey('Ctrl')\nsetOptKey('Alt')\n} else if (/iPhone|iPad|iPod/.test(userAgent)) {\nsetOs('iOS')\nsetModKey('⌘')\nsetOptKey('⌥')\n} else if (/Linux/.test(platform)) {\nsetOs('Linux')\nsetModKey('Ctrl')\nsetOptKey('Alt')\n}\n}, [])\nreturn {\nMod: modKey,\nOpt: optKey,\nShift: '⇧',\nEnter: '↵',\nUp: '↑',\nRight: '→',\nDown: '↓',\nLeft: '←',\nTab: '⇥',\nEscape: 'Esc',\nOperatingSystem: os,\nisMac: os === 'macOS' || os === 'iOS',\n}\n}"
"export function useSessionFilter({\nsessions,\nquery,\nsearchFields = ['query'],\n}: UseSessionFilterOptions): UseSessionFilterResult {\nreturn useMemo(() => {\nconst { statusFilter, searchText } = parseStatusFilter(query)\nlet filtered = sessions\nif (statusFilter) {\nfiltered = sessions.filter(session => session.status === statusFilter)\n}\nconst matchedSessions = new Map<string, any>()\nif (searchText) {\nconst searchResults = fuzzySearch(filtered, searchText, {\nkeys: searchFields,\nthreshold: 0.1,\nincludeMatches: true,\n})\nsearchResults.forEach(result => {\nmatchedSessions.set(result.item.id, result)\n})\nfiltered = searchResults.map(result => result.item)\n}\nreturn {\nfilteredSessions: filtered,\nstatusFilter,\nsearchText,\nmatchedSessions,\n}\n}, [sessions, query, searchFields])\n}"
"export function useSessionLauncherHotkeys() {\nconst refreshSessions = useStore(state => state.refreshSessions)\nconst { open, close, isOpen, setGPrefixMode } = useSessionLauncher()\nconst isTypingInInput = () => {\nconst active = document.activeElement\nif (!active) return false\nreturn (\nactive.tagName === 'INPUT' ||\nactive.tagName === 'TEXTAREA' ||\n(active as HTMLElement).contentEditable === 'true'\n)\n}\nuseHotkeys(\n'meta+k, ctrl+k',\n() => {\nif (!isOpen) {\nopen()\n} else {\nclose()\n}\n},\n{\nscopes: [HOTKEY_SCOPES.ROOT],\npreventDefault: true,\n},\n)\nuseHotkeys(\n'c',\nasync () => {\ntry {\nconst response = await daemonClient.launchSession({\nquery: '',\nworking_dir: getLastWorkingDir() || '~/',\ndraft: true,\n})\nawait refreshSessions()\nwindow.location.hash = `#/sessions/${response.sessionId}`\n} catch (error) {\nlogger.error('Failed to create draft session:', error)\n}\n},\n{\nscopes: [HOTKEY_SCOPES.ROOT],\nenabled: !isTypingInInput(),\npreventDefault: true,\n},\n)\nuseHotkeys(\n'g',\n() => {\nsetGPrefixMode(true)\nsetTimeout(() => setGPrefixMode(false), 2000)\n},\n{\nscopes: [HOTKEY_SCOPES.ROOT],\nenabled: !isTypingInInput(),\npreventDefault: true,\n},\n)\nreturn {\nhandleKeyDown: () => {\n},\n}\n}"
"export function useSessions(): UseSessionsReturn {\nconst [sessions, setSessions] = useState<SessionSummary[]>([])\nconst [loading, setLoading] = useState(true)\nconst [error, setError] = useState<string | null>(null)\nconst fetchSessions = useCallback(async () => {\ntry {\nsetLoading(true)\nsetError(null)\nconst response = await daemonClient.getSessionLeaves()\nconst summaries: SessionSummary[] = response.sessions.map(session => ({\nid: session.id,\nrunId: session.runId,\nstatus: session.status,\nquery: session.query,\nmodel: session.model || 'default',\nstartTime: new Date(session.createdAt),\nendTime: session.completedAt ? new Date(session.completedAt) : undefined,\nhasApprovals: false,\n}))\nsummaries.sort((a, b) => b.startTime.getTime() - a.startTime.getTime())\nsetSessions(summaries)\n} catch (err) {\nsetError(formatError(err))\n} finally {\nsetLoading(false)\n}\n}, [])\nuseEffect(() => {\nfetchSessions()\n}, [fetchSessions])\nconst launchSession = useCallback(\nasync (request: LaunchSessionRequest) => {\ntry {\nconst response = await daemonClient.launchSession(request)\nawait fetchSessions()\nreturn response\n} catch (err) {\nthrow new Error(formatError(err))\n}\n},\n[fetchSessions],\n)\nreturn {\nsessions,\nloading,\nerror,\nrefresh: fetchSessions,\nlaunchSession: async (request: LaunchSessionRequest) => {\nconst response = await launchSession(request)\nreturn {\nsessionId: response.sessionId,\nrunId: response.runId,\n}\n},\n}\n}"
"export function useSessionSnapshots(sessionId: string | undefined) {\nconst [snapshots, setSnapshots] = useState<SnapshotCache>({})\nconst [loading, setLoading] = useState(false)\nconst [error, setError] = useState<string | null>(null)\nconst fetchSnapshots = useCallback(async () => {\nif (!sessionId) {\nreturn\n}\nsetLoading(true)\nsetError(null)\ntry {\nconst response = await daemonClient.getSessionSnapshots(sessionId)\nconst cache: SnapshotCache = {}\nresponse.forEach(snapshot => {\nif (\n!cache[snapshot.file_path] ||\nnew Date(snapshot.created_at) > new Date(cache[snapshot.file_path].created_at)\n) {\ncache[snapshot.file_path] = snapshot\n}\n})\nsetSnapshots(cache)\n} catch (err) {\nsetError(err instanceof Error ? err.message : 'Failed to fetch snapshots')\n} finally {\nsetLoading(false)\n}\n}, [sessionId])\nuseEffect(() => {\nfetchSnapshots()\n}, [fetchSnapshots])\nconst getSnapshot = useCallback(\n(filePath: string): FileSnapshotInfo | undefined => {\nconst snapshot = snapshots[filePath]\nreturn snapshot\n},\n[snapshots],\n)\nreturn { snapshots, getSnapshot, loading, error, refetch: fetchSnapshots }\n}"
"function fuzzyMatchString(pattern: string, text: string): { score: number; indices: number[] } {\nif (!pattern) return { score: 1, indices: [] }\nif (!text) return { score: 0, indices: [] }\npattern = pattern.toLowerCase()\ntext = text.toLowerCase()\nlet patternIdx = 0\nlet textIdx = 0\nconst indices: number[] = []\nlet score = 0\nlet consecutiveMatches = 0\nwhile (patternIdx < pattern.length && textIdx < text.length) {\nif (pattern[patternIdx] === text[textIdx]) {\nindices.push(textIdx)\nconsecutiveMatches++\nscore += consecutiveMatches * 2\nif (textIdx === 0 || text[textIdx - 1] === ' ' || text[textIdx - 1] === '/') {\nscore += 5\n}\npatternIdx++\n} else {\nconsecutiveMatches = 0\n}\ntextIdx++\n}\nif (patternIdx < pattern.length) {\nscore = 0\n} else {\nscore += Math.max(0, 100 - text.length)\nscore += (indices.length / text.length) * 50\n}\nreturn { score, indices }\n}"
"export function fuzzySearch<T>(\nitems: T[],\npattern: string,\noptions: FuzzySearchOptions = {},\n): FuzzyMatch[] {\nconst { keys = [], threshold = 0.1, minMatchCharLength = 1 } = options\nif (!pattern || pattern.length < minMatchCharLength) {\nreturn items.map(item => ({\nscore: 1,\nindices: [],\nitem,\nmatches: [],\n}))\n}\nconst results: FuzzyMatch[] = []\nfor (const item of items) {\nlet bestScore = 0\nlet bestMatches: Array<{ indices: number[]; key?: string }> = []\nif (keys.length === 0) {\nconst match = fuzzyMatchString(pattern, String(item))\nif (match.score > threshold) {\nresults.push({\nscore: match.score,\nindices: match.indices,\nitem,\nmatches: [{ indices: match.indices }],\n})\n}\n} else {\nfor (const key of keys) {\nconst value = (item as any)[key]\nif (typeof value === 'string') {\nconst match = fuzzyMatchString(pattern, value)\nif (match.score > bestScore) {\nbestScore = match.score\nbestMatches = [{ indices: match.indices, key }]\n} else if (match.score === bestScore && match.score > threshold) {\nbestMatches.push({ indices: match.indices, key })\n}\n}\n}\nif (bestScore > threshold) {\nresults.push({\nscore: bestScore,\nindices: bestMatches[0]?.indices || [],\nitem,\nmatches: bestMatches,\n})\n}\n}\n}\nreturn results.sort((a, b) => b.score - a.score)\n}"
"export function highlightMatches(\ntext: string,\nindices: number[],\n): Array<{ text: string; highlighted: boolean }> {\nif (!indices.length) {\nreturn [{ text, highlighted: false }]\n}\nconst result: Array<{ text: string; highlighted: boolean }> = []\nlet lastIndex = 0\nlet i = 0\nwhile (i < indices.length) {\nconst startIndex = indices[i]\nif (startIndex > lastIndex) {\nresult.push({\ntext: text.slice(lastIndex, startIndex),\nhighlighted: false,\n})\n}\nlet endIndex = startIndex\nwhile (i < indices.length - 1 && indices[i + 1] === indices[i] + 1) {\ni++\nendIndex = indices[i]\n}\nresult.push({\ntext: text.slice(startIndex, endIndex + 1),\nhighlighted: true,\n})\nlastIndex = endIndex + 1\ni++\n}\nif (lastIndex < text.length) {\nresult.push({\ntext: text.slice(lastIndex),\nhighlighted: false,\n})\n}\nreturn result\n}"
"export function SessionDetailPage() {\nconst { sessionId } = useParams<{ sessionId: string }>()\nconst navigate = useNavigate()\nconst activeSessionDetail = useStore(state => state.activeSessionDetail)\nconst fetchActiveSessionDetail = useStore(state => state.fetchActiveSessionDetail)\nconst clearActiveSessionDetail = useStore(state => state.clearActiveSessionDetail)\nconst sessionFromStore = useStore(state => state.sessions.find(s => s.id === sessionId))\nuseEffect(() => {\nif (sessionId) {\nfetchActiveSessionDetail(sessionId)\n}\nreturn () => {\nclearActiveSessionDetail()\n}\n}, [sessionId, fetchActiveSessionDetail, clearActiveSessionDetail])\nconst handleClose = () => {\nnavigate('/')\n}\nif (!activeSessionDetail && !sessionId) {\nreturn (\n<div className=`flex items-center justify-center h-full`>\n<div className=`text-center`>\n<h2 className=`text-lg font-semibold mb-2`>No session selected</h2>\n</div>\n</div>\n)\n}\nif (activeSessionDetail?.error && !activeSessionDetail?.session?.id) {\nreturn (\n<div className=`flex items-center justify-center h-full`>\n<div className=`text-center`>\n<h2 className=`text-lg font-semibold mb-2`>Session not found</h2>\n<p className=`text-muted-foreground mb-4`>{activeSessionDetail.error}</p>\n<button onClick={handleClose} className=`text-primary hover:underline`>\n← Back to Sessions\n</button>\n</div>\n</div>\n)\n}\nlet session = activeSessionDetail?.session?.id\n? activeSessionDetail.session\n: sessionFromStore\n? { ...sessionFromStore, fromStore: true }\n: {\nid: sessionId || '',\nrunId: '',\nquery: '',\nstatus: 'unknown' as any,\nmodel: '',\ncreatedAt: new Date(),\nlastActivityAt: new Date(),\nsummary: '',\nautoAcceptEdits: false,\ndangerouslySkipPermissions: false,\ndangerouslySkipPermissionsExpiresAt: undefined,\n}\nreturn (\n<div className=`h-full`>\n<SessionDetail session={session} onClose={handleClose} />\n</div>\n)\n}"
"private async attachFocusListeners() {\nlogger.log('NotificationService: Attaching focus listeners')\nthis.validateFocusState()\nawait this.detachFocusListeners()\ntry {\nconst appWindow = getCurrentWindow()\nthis.unlistenFocus = await appWindow.onFocusChanged(event => {\nlogger.log('Tauri window focus changed:', event)\nthis.appFocused = event.payload\n})\nthis.focusHandler = () => {\nlogger.log('window focused (standard event)')\nthis.appFocused = true\n}\nthis.blurHandler = () => {\nlogger.log('window blurred (standard event)')\nthis.appFocused = false\n}\nwindow.addEventListener('focus', this.focusHandler)\nwindow.addEventListener('blur', this.blurHandler)\nlogger.log('NotificationService: Focus listeners attached')\n} catch (error) {\nlogger.error('Failed to attach Tauri focus listeners, using standard events only:', error)\nthis.focusHandler = () => {\nlogger.log('window focused')\nthis.appFocused = true\n}\nthis.blurHandler = () => {\nlogger.log('window blurred')\nthis.appFocused = false\n}\nwindow.addEventListener('focus', this.focusHandler)\nwindow.addEventListener('blur', this.blurHandler)\n}\n}"
"async notify(options: NotificationOptions): Promise<\n| string\n| null\n| {\ntitle: string | React.ReactNode\noptions: ExternalToast\ntype: 'default' | 'success' | 'error' | 'warning' | 'info' | 'loading'\n}\n> {\nthis.validateFocusState()\nconst notificationId = this.generateNotificationId(options.type, options.metadata)\nconst isViewingSession = options.metadata.sessionId\n? this.isViewingSession(options.metadata.sessionId)\n: false\nif (options.returnToastConfig) {\nreturn this.buildToastConfig(options)\n}\nlogger.log('NotificationService.notify:', {\nappFocused: this.appFocused,\nnotificationType: options.type,\nsessionId: options.metadata.sessionId,\nisViewingSession,\n})\nif (!this.appFocused) {\nawait this.showOSNotification(options)\n}\nelse if (isViewingSession) {\nlogger.log(`Skipping in-app notification: User is viewing session ${options.metadata.sessionId}`)\nreturn null\n}\nelse {\nthis.showInAppNotification(options)\n}\nreturn notificationId\n}"
"private buildToastConfig(options: NotificationOptions): {\ntitle: string | React.ReactNode\noptions: ExternalToast\ntype: 'default' | 'success' | 'error' | 'warning' | 'info' | 'loading'\n} {\nconst toastOptions: ExternalToast = {\ncloseButton: true,\ndescription: options.body,\nduration: options.duration ?? 5000,\nposition: 'top-right',\n}\nif (options.type === 'approval_required') {\ntoastOptions.id = `${options.type}:${options.metadata.approvalId}`\n}\nif (options.actions && options.actions.length > 0) {\nconst primaryAction = options.actions[0]\nconst variant =\noptions.type === 'error' || options.type === 'session_failed'\n? 'error'\n: options.type === 'session_completed'\n? 'success'\n: 'default'\ntoastOptions.action = React.createElement(CodeLayerToastButtons, {\naction: {\nlabel: primaryAction.label,\nonClick: primaryAction.onClick,\n},\nvariant,\n})\n}\nlet toastType: 'default' | 'success' | 'error' | 'warning' | 'info' | 'loading' = 'default'\nswitch (options.type) {\ncase 'session_failed':\ncase 'error':\ntoastType = 'error'\nbreak\ncase 'session_completed':\ntoastType = 'success'\nbreak\ndefault:\ntoastType = 'default'\n}\nreturn {\ntitle: options.title,\noptions: toastOptions,\ntype: toastType,\n}\n}"
"async notifyApprovalRequired(\nsessionId: string,\napprovalId: string,\ntoolName: string,\ntoolInputJson: string,\nmodel?: string,\nsessionTitle?: string,\nreturnToastConfig?: boolean,\n) {\nconst toastId = `approval_required:${approvalId}`\nconst truncatedTitle = sessionTitle\n? sessionTitle.length > 50\n? sessionTitle.substring(0, 47) + '...'\n: sessionTitle\n: `Session ${sessionId.slice(0, 8)}`\nconst titleElement = (\n<div className=`flex flex-col gap-0.5`>\n<span className=`font-bold text-[var(--terminal-warning)]`>needs_approval</span>\n<span className=`text-xs text-muted-foreground`>{truncatedTitle}</span>\n</div>\n)\nconst bodyElement = (\n<span>\n<code className=`text-accent bg-muted/50 rounded-md px-1 py-0.5 font-mono`>{toolName}</code>\n<span> using </span>\n<code className=`text-accent bg-muted/50 rounded-md px-1 py-0.5 font-mono`>\n{toolInputJson.length > 50 ? toolInputJson.substring(0, 47) + '...' : toolInputJson}\n</code>\n</span>\n)\nreturn this.notify({\ntype: 'approval_required',\ntitle: titleElement,\nbody: bodyElement,\nmetadata: {\nsessionId,\napprovalId,\nmodel,\n},\nduration: Infinity,\nactions: [\n{\nlabel: (\n<span className=`flex items-center gap-1`>\nJump to Session\n<kbd className=`ml-1 px-1.5 py-0.5 text-sm font-medium bg-background/50 rounded border border-border`>\n{this.getModifierKey()}⇧J\n</kbd>\n</span>\n),\nonClick: () => {\nwindow.location.hash = `/sessions/${sessionId}`\ntoast.dismiss(toastId)\n},\n},\n],\nreturnToastConfig,\n})\n}"
"export function createDemoAppStore(): StoreApi<AppState> {\nreturn create<AppState>(() => ({\nsessions: [],\nfocusedSession: null,\nactiveSessionId: null,\nactiveSessionDetail: null,\napprovals: [],\nisLoading: false,\nresponseEditor: null,\nnotifiedItems: new Set<string>(),\ninitSessions: () => {},\nupdateSession: () => {},\nupdateSessionStatus: () => {},\nrefreshSessions: async () => {},\nsetFocusedSession: () => {},\nfocusNextSession: () => {},\nfocusPreviousSession: () => {},\ninterruptSession: async () => {},\nsetActiveSessionDetail: () => {},\nupdateActiveSessionDetail: () => {},\nupdateActiveSessionConversation: () => {},\nclearActiveSessionDetail: () => {},\nfetchActiveSessionDetail: async () => {},\nsetApprovals: () => {},\naddApproval: () => {},\nupdateApproval: () => {},\naddNotifiedItem: () => {},\nremoveNotifiedItem: () => {},\nisItemNotified: () => false,\nclearNotificationsForSession: () => {},\nsetLoading: () => {},\nsetActiveSessionId: () => {},\nsetResponseEditor: () => {},\nremoveResponseEditor: () => {},\n}))\n}"
"export function parseAnsiToSegments(text: string): AnsiSegment[] {\nconst segments: AnsiSegment[] = []\nconst regex = ansiRegex()\nlet lastIndex = 0\nlet currentStyle: AnsiSegment['style'] = undefined\nlet match\nwhile ((match = regex.exec(text)) !== null) {\nif (match.index > lastIndex) {\nsegments.push({\ntext: text.slice(lastIndex, match.index),\nstyle: currentStyle ? { ...currentStyle } : undefined,\n})\n}\nconst sequence = match[0]\nconst codes = sequence.match(/\d+/g)?.map(Number) || []\nfor (const code of codes) {\nif (code === 0) {\ncurrentStyle = undefined\n} else if (colorMap[code]) {\ncurrentStyle = currentStyle || {}\ncurrentStyle.color = colorMap[code]\n}\n}\nlastIndex = regex.lastIndex\n}\nif (lastIndex < text.length) {\nsegments.push({\ntext: text.slice(lastIndex),\nstyle: currentStyle ? { ...currentStyle } : undefined,\n})\n}\nreturn segments\n}"
"function extractFieldsFromToolInput(toolName: string, toolInput: any): ApprovalField[] {\nconst fields: ApprovalField[] = []\nif (!toolInput) return fields\nswitch (toolName.toLowerCase()) {\ncase 'bash':\nif (toolInput.command) {\nfields.push({\nlabel: 'Command',\nvalue: toolInput.command,\ntruncate: true,\n})\n}\nbreak\ncase 'edit':\ncase 'write':\nif (toolInput.path || toolInput.file_path) {\nfields.push({\nlabel: 'File',\nvalue: toolInput.path || toolInput.file_path,\nisPath: true,\n})\n}\nbreak\ncase 'http':\ncase 'fetch':\nif (toolInput.url) {\nfields.push({\nlabel: 'URL',\nvalue: toolInput.url,\ntruncate: true,\n})\n}\nif (toolInput.method) {\nfields.push({\nlabel: 'Method',\nvalue: toolInput.method,\n})\n}\nbreak\ndefault:\nObject.entries(toolInput).forEach(([key, value]) => {\nif (typeof value === 'string' || typeof value === 'number') {\nfields.push({\nlabel: key.replace(/_/g, ' ').replace(/\b\w/g, l => l.toUpperCase()),\nvalue: String(value),\ntruncate: true,\n})\n}\n})\n}\nreturn fields\n}"
"export function formatError(error: unknown): string {\nif (!error) return 'Unknown error'\nlet message: string\nif (error instanceof Error) {\nmessage = error.message\n} else if (typeof error === 'object' && 'message' in error) {\nmessage = String((error as any).message)\n} else {\nmessage = String(error)\n}\nif (message.includes('call already has a response')) {\nreturn 'Approval already responded to'\n}\nif (message.includes('409 Conflict')) {\nreturn 'Conflict: Resource already exists'\n}\nif (message.includes('404 Not Found')) {\nreturn 'Resource not found'\n}\nif (message.includes('500 Internal Server Error')) {\nreturn 'Server error occurred'\n}\nif (message.includes('Failed to connect')) {\nreturn 'Cannot connect to daemon. Is it running?'\n}\nconst firstLine = message.split('\n')[0]\nconst cleaned = firstLine\n.replace(/^Error:\s*/i, '')\n.replace(/^RPC error:\s*/i, '')\n.replace(/^JSON-RPC error:\s*/i, '')\nreturn cleaned\n}"
"export function SessionsEmptyState() {\nconst handleCreateSession = async () => {\ntry {\nconst response = await daemonClient.launchSession({\nquery: '',\nworking_dir: getLastWorkingDir() || '~/',\ndraft: true,\n})\nwindow.location.hash = `#/sessions/${response.sessionId}`\n} catch (error) {\nconsole.error('Failed to create draft session:', error)\n}\n}\nreturn (\n<div className=`flex justify-center py-20 px-8`>\n<div className=`flex flex-col items-start w-full max-w-xl`>\n<h1 className=`text-2xl font-semibold mb-8`>Welcome</h1>\n<div className=`text-sm text-muted-foreground mb-8 space-y-4`>\n<p>\nCodeLayer is a tool for using AI Coding Agents to solve hard problems in complex codebases.\n</p>\n<p>\nIt uses your default claude code settings and api keys and supports any agents / slash\ncommands you have configured.\n</p>\n<p>Create a session to get started.</p>\n</div>\n<Button onClick={handleCreateSession} size=`lg`>\nCreate Session{' '}\n<kbd className=`ml-2 pointer-events-none inline-flex h-5 select-none items-center gap-1 rounded border bg-muted px-1.5 font-mono text-[10px] font-medium text-muted-foreground opacity-100`>\nC\n</kbd>\n</Button>\n</div>\n</div>\n)\n}"
"async updateSession(\nsessionId: string,\nupdates: {\nmodel?: string\ntitle?: string\narchived?: boolean\nautoAcceptEdits?: boolean\ndangerouslySkipPermissions?: boolean\ndangerouslySkipPermissionsTimeoutMs?: number\nadditionalDirectories?: string[]\nworkingDir?: string\neditorState?: string\nproxyEnabled?: boolean\nproxyBaseUrl?: string\nproxyModelOverride?: string\nproxyApiKey?: string\n},\n): Promise<{ success: boolean }> {\nawait this.ensureConnected()\nconst sdkUpdates: any = {}\nif (updates.model !== undefined) {\nsdkUpdates.model = updates.model\n}\nif (updates.title !== undefined) {\nsdkUpdates.title = updates.title\n}\nif (updates.archived !== undefined) {\nsdkUpdates.archived = updates.archived\n}\nif (updates.autoAcceptEdits !== undefined) {\nsdkUpdates.auto_accept_edits = updates.autoAcceptEdits\n}\nif (updates.dangerouslySkipPermissions !== undefined) {\nsdkUpdates.dangerouslySkipPermissions = updates.dangerouslySkipPermissions\n}\nif (updates.dangerouslySkipPermissionsTimeoutMs !== undefined) {\nsdkUpdates.dangerouslySkipPermissionsTimeoutMs = updates.dangerouslySkipPermissionsTimeoutMs\n}\nif (updates.additionalDirectories !== undefined) {\nsdkUpdates.additionalDirectories = updates.additionalDirectories\n}\nif (updates.workingDir !== undefined) {\nsdkUpdates.working_dir = updates.workingDir\n}\nif (updates.editorState !== undefined) {\nsdkUpdates.editorState = updates.editorState\n}\nif (updates.proxyEnabled !== undefined) {\nsdkUpdates.proxyEnabled = updates.proxyEnabled\n}\nif (updates.proxyBaseUrl !== undefined) {\nsdkUpdates.proxyBaseUrl = updates.proxyBaseUrl\n}\nif (updates.proxyModelOverride !== undefined) {\nsdkUpdates.proxyModelOverride = updates.proxyModelOverride\n}\nif (updates.proxyApiKey !== undefined) {\nsdkUpdates.proxyApiKey = updates.proxyApiKey\n}\nawait this.client!.updateSession(sessionId, sdkUpdates)\nreturn { success: true }\n}"
"subscribeToEvents(options: SubscribeOptions): SubscriptionHandle {\nconst subscriptionId = `${Date.now()}-${Math.random()}`\nthis.ensureConnected()\n.then(async () => {\nconst unsubscribe = await this.client!.subscribeToEvents(\n{\neventTypes: options.event_types,\nsessionId: options.session_id,\nrunId: options.run_id,\n},\n{\nonMessage: event => {\noptions.onEvent({\ntype: event.type,\ndata: event.data,\ntimestamp:\ntypeof event.timestamp === 'string' ? new Date(event.timestamp) : event.timestamp,\n})\n},\nonError: error => {\nlogger.error('Event subscription error:', error)\nif (!this.connected) {\nthis.connect().catch(logger.error)\n}\n},\nonDisconnect: () => {\nthis.subscriptions.delete(subscriptionId)\n},\n},\n)\nthis.subscriptions.set(subscriptionId, unsubscribe)\n})\n.catch(error => {\nlogger.error('Failed to start event subscription:', error)\n})\nreturn {\nunsubscribe: () => {\nconst unsub = this.subscriptions.get(subscriptionId)\nif (unsub) {\nunsub()\nthis.subscriptions.delete(subscriptionId)\n}\n},\n}\n}"
"export async function initializeSentry(): Promise<void> {\nif (!shouldInitializeSentry()) {\nconsole.log('Sentry initialization skipped (development or missing config)')\nreturn\n}\ntry {\nSentry.init({\ndsn: import.meta.env.VITE_SENTRY_DSN,\nenvironment: import.meta.env.DEV ? 'development' : 'production',\nrelease: getAppVersion(),\ntracesSampleRate: 0,\nreplaysSessionSampleRate: 0,\nreplaysOnErrorSampleRate: 0,\nbeforeSend(event: Sentry.ErrorEvent) {\nconst state = useStore.getState()\nif (!state.userSettings?.optInTelemetry) {\nreturn null\n}\nreturn scrubSensitiveData(event)\n},\nbeforeBreadcrumb(breadcrumb) {\nif (breadcrumb.category === 'console') {\nreturn null\n}\nif (breadcrumb.category === 'fetch' || breadcrumb.category === 'xhr') {\nif (breadcrumb.data?.url) {\nif (breadcrumb.data.url.includes('/api/v1/sessions')) {\nreturn null\n}\nbreadcrumb.data.url = breadcrumb.data.url\n.replace(/query=[^&]*/g, 'query=[FILTERED]')\n.replace(/token=[^&]*/g, 'token=[FILTERED]')\n}\n}\nreturn breadcrumb\n},\nintegrations: [\nSentry.browserTracingIntegration({\nenableHTTPTimings: false,\n}),\nSentry.breadcrumbsIntegration({\nconsole: false,\n}),\n],\nignoreErrors: [\n'ResizeObserver loop limit exceeded',\n'Non-Error promise rejection captured',\n/extension\\n/^chrome:\/\\n/^moz-extension:\/\\n'Network request failed',\n'Failed to fetch',\n],\n})\nconsole.log('Sentry initialized for error reporting')\n} catch (error) {\nconsole.error('Failed to initialize Sentry:', error)\n}\n}"
"private playNext() {\nif (!this.isRunning || this.currentIndex >= this.sequence.length) {\nif (this.isRunning) {\nthis.currentIndex = 0\nthis.playNext()\n}\nreturn\n}\nconst step = this.sequence[this.currentIndex]\nthis.timeoutId = setTimeout(() => {\nlogger.log(\n`[Demo Animator] Step ${this.currentIndex + 1}/${this.sequence.length}: ${step.description || 'State update'}`,\n)\nconst updates: any = {}\nif (step.sessionState) {\nObject.assign(updates, step.sessionState)\n}\nif (step.launcherState) {\nObject.assign(updates, step.launcherState)\n}\nif (step.themeState) {\nObject.assign(updates, step.themeState)\n}\nif (step.appState) {\nObject.assign(updates, step.appState)\n}\nthis.store.setState(updates)\nif (step.themeState?.theme) {\nthis.store.getState().setTheme(step.themeState.theme)\n}\nthis.currentIndex++\nthis.playNext()\n}, step.delay)\n}"
"code(props) {\nconst { className, children, ...rest } = props as any\nconst codeString = String(children).replace(/\n$/, '')\nconst codeId = `code-${Math.random().toString(36).substr(2, 9)}`\nconst isBlock = rest['data-is-block'] === true\nconst match = /language-(\w+)/.exec(className || '')\nconst language = match?.[1] ?? 'plaintext'\nreturn isBlock ? (\n<div className=`relative group not-prose inline-block min-w-[250px]`>\n<div className=`overflow-x-auto`>\n{language ? (\n<SyntaxHighlighter\nlanguage={language}\nuseInlineStyles={false}\nclassName=`rsh-code-block text-sm`\nPreTag={({ children, ...props }) => (\n<pre className=`rsh-pre` {...props}>\n{children}\n</pre>\n)}\n>\n{codeString}\n</SyntaxHighlighter>\n) : (\n<pre className=`rsh-pre rsh-code-block text-sm`>\n<code>{codeString}</code>\n</pre>\n)}\n</div>\n<Button\nvariant=`ghost`\nsize=`icon`\nclassName=`absolute top-2 right-1 h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity duration-200 z-10 touch:opacity-100 md:touch:opacity-0 md:touch:group-hover:opacity-100`\nonClick={e => {\ne.stopPropagation()\nhandleCopy(codeString, codeId)\n}}\naria-label=`Copy code`\ntitle=`Copy code`\n>\n{copiedBlocks.has(codeId) ? (\n<Check className=`h-3 w-3 text-success` />\n) : (\n<Copy className=`h-3 w-3` />\n)}\n</Button>\n</div>\n) : (\n<code className=`px-1 py-0.5 bg-accent/20 text-accent rounded-none text-sm font-mono`>\n{children}\n</code>\n)\n},"
"export function createSequence(): SequenceBuilder {\nconst steps: AnimationStep[] = []\nconst builder: SequenceBuilder = {\nsteps,\naddStep(step: AnimationStep) {\nsteps.push(step)\nreturn builder\n},\naddDelay(ms: number) {\nif (steps.length > 0) {\nsteps[steps.length - 1].delay = ms\n}\nreturn builder\n},\naddSessions(sessions: Session[]) {\nsteps.push({\nsessionState: { sessions },\ndelay: 2000,\ndescription: `Add ${sessions.length} sessions`,\n})\nreturn builder\n},\nopenLauncher() {\nsteps.push({\nlauncherState: { isOpen: true, mode: 'command' },\ndelay: 1500,\ndescription: 'Open launcher in command mode',\n})\nreturn builder\n},\ncloseLauncher() {\nsteps.push({\nlauncherState: { isOpen: false },\ndelay: 1000,\ndescription: 'Close launcher',\n})\nreturn builder\n},\nsetTheme(theme: string) {\nsteps.push({\nthemeState: { theme: theme as any },\ndelay: 1000,\ndescription: `Switch to ${theme} theme`,\n})\nreturn builder\n},\nshowApproval(id: string, title: string) {\nsteps.push({\nappState: {\napprovals: [\n{\nid,\ntitle,\nstatus: 'pending',\n},\n],\n},\ndelay: 2000,\ndescription: `Show approval: ${title}`,\n})\nreturn builder\n},\nbuild() {\nreturn steps\n},\n}\nreturn builder\n}"
"export function ApprovalWrapper({\nchildren,\nevent,\napprovalStatus,\nonApprove,\nonDeny,\nisApproving,\nisDenying,\nconfirmingApprovalId,\nresponseText,\nonStartDeny,\nonCancelDeny,\n}: ApprovalWrapperProps) {\nconst needsApproval = approvalStatus === 'pending'\nconst showApprovalUI = needsApproval && event.approvalId && onApprove && onDeny\nreturn (\n<div>\n{children}\n{}\n{showApprovalUI && (\n<div className=`mt-4 flex gap-2 justify-end`>\n{!isDenying ? (\n<>\n<Button\nclassName=`cursor-pointer`\nsize=`sm`\nvariant={isApproving ? 'outline' : 'default'}\nonClick={e => {\ne.stopPropagation()\nonApprove()\n}}\ndisabled={isApproving}\n>\n{isApproving\n? 'Approving...'\n: confirmingApprovalId === event.approvalId\n? 'Approve?'\n: 'Approve'}{' '}\n<kbd className=`ml-1 px-1 py-0.5 text-xs bg-muted/50 rounded`>A</kbd>\n</Button>\n{!isApproving && (\n<Button\nclassName=`cursor-pointer`\nsize=`sm`\nvariant=`destructive`\nonClick={e => {\ne.stopPropagation()\nonStartDeny?.()\n}}\n>\nDeny <kbd className=`ml-1 px-1 py-0.5 text-xs bg-muted/50 rounded`>D</kbd>\n</Button>\n)}\n</>\n) : (\n<DenyButtons\nonCancel={onCancelDeny}\nonDeny={() => {\nif (event.approvalId && onDeny) {\nonDeny(responseText?.trim() || '')\n}\n}}\nisDenying={isDenying}\nisDisabled={!responseText?.trim()}\n/>\n)}\n</div>\n)}\n</div>\n)\n}"
"export function ExitPlanModeToolCallContent({\ntoolInput,\napprovalStatus,\nisCompleted,\ntoolResultContent,\nisFocused,\nisGroupItem,\n}: ToolCallContentProps<ExitPlanModeToolInput>) {\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nconst isDenied = approvalStatus === ApprovalStatus.Denied\nconst hasError = toolResultContent ? detectToolError('ExitPlanMode', toolResultContent) : false\nlet preview = toolResultContent ? formatToolResultPreview(toolResultContent) : null\nif (isDenied) {\npreview = `Denial Reason: ${toolResultContent ? formatToolResultPreview(toolResultContent) : null}`\n}\nconst planLines = toolInput.plan.split('\n').filter(l => l.trim())\nconst lineCount = planLines.length\nconst showPlan =\napprovalStatus === 'pending' || approvalStatus === undefined || !isCompleted || isFocused\nreturn (\n<div className=`space-y-2`>\n<ToolHeader\nname=`Exit Plan Mode`\ndescription={`${lineCount} lines`}\nnameColor={statusColor}\nstatus={<StatusBadge status={approvalStatus} />}\n/>\n{showPlan && (\n<div className=`mt-2`>\n<MarkdownRenderer content={toolInput.plan} sanitize={false} />\n</div>\n)}\n{!showPlan && isCompleted && (\n<div className=`mt-1 text-sm text-muted-foreground font-mono flex items-start gap-1`>\n<span className=`text-muted-foreground/50`>⎿</span>\n<span className={hasError ? 'text-destructive' : ''}>\n{hasError ? preview || 'Error exiting plan mode' : 'Plan mode exited successfully'}\n{isFocused && !hasError && (\n<span className=`text-xs text-muted-foreground/50 ml-2`>\n<kbd className=`px-1 py-0.5 text-xs bg-muted/50 rounded`>i</kbd> expand\n</span>\n)}\n</span>\n</div>\n)}\n</div>\n)\n}"
"export function GlobToolCallContent({\ntoolInput,\napprovalStatus,\ntoolResultContent,\nisFocused,\nisGroupItem,\n}: ToolCallContentProps<GlobToolInput>) {\nconst formatGlobResult = (content: string) => {\nconst lines = content.split('\n').filter(l => l.trim())\nif (lines.length === 0) {\nreturn 'No files matched'\n}\nif (lines.length === 1) {\nconst fileName = lines[0].split('/').pop() || lines[0]\nreturn `1 file: ${fileName}`\n}\nreturn `${lines.length} file${lines.length === 1 ? '' : 's'} matched`\n}\nconst formattedResult = toolResultContent ? formatGlobResult(toolResultContent) : null\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nreturn (\n<div className=`space-y-2`>\n<div className=`flex items-start justify-between`>\n<div className=`flex-1`>\n<div className=`flex items-baseline gap-2`>\n<span className={`font-semibold ${statusColor || ''}`}>Glob</span>\n<CommandToken>{toolInput.pattern}</CommandToken>\n</div>\n</div>\n<div className=`ml-4`>\n<StatusBadge status={approvalStatus} />\n</div>\n</div>\n{formattedResult && (\n<div className=`mt-1 text-sm text-muted-foreground font-mono flex items-start gap-1`>\n<span className=`text-muted-foreground/50`>⎿</span>\n<span>\n{formattedResult}\n{isFocused && toolResultContent && toolResultContent.split('\n').length > 1 && (\n<span className=`text-xs text-muted-foreground/50 ml-2`>\n<kbd className=`px-1 py-0.5 text-xs bg-muted/50 rounded`>i</kbd> expand\n</span>\n)}\n</span>\n</div>\n)}\n</div>\n)\n}"
"export function NotebookReadToolCallContent({\ntoolInput,\napprovalStatus,\nisCompleted,\ntoolResultContent,\nisFocused,\nisGroupItem,\n}: ToolCallContentProps<NotebookReadToolInput>) {\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nconst isDenied = approvalStatus === ApprovalStatus.Denied\nconst hasError = toolResultContent ? detectToolError('NotebookRead', toolResultContent) : false\nlet preview = toolResultContent ? formatToolResultPreview(toolResultContent) : null\nif (isDenied) {\npreview = `Denial Reason: ${toolResultContent ? formatToolResultPreview(toolResultContent) : null}`\n}\nconst lineCount = toolResultContent ? formatLineCount(toolResultContent) : null\nreturn (\n<div className=`space-y-2`>\n<ToolHeader\nname=`NotebookRead`\ndescription={toolInput.cell_id ? `Cell: ${toolInput.cell_id}` : undefined}\nprimaryParam={<span className=`font-mono text-sm`>{toolInput.notebook_path}</span>}\nnameColor={statusColor}\nstatus={<StatusBadge status={approvalStatus} />}\n/>\n{isCompleted && (\n<div className=`mt-1 text-sm text-muted-foreground font-mono flex items-start gap-1`>\n<span className=`text-muted-foreground/50`>⎿</span>\n<span className={hasError ? 'text-destructive' : ''}>\n{hasError ? (\npreview || 'Error reading notebook'\n) : (\n<>\n{lineCount && !toolInput.cell_id && `${lineCount} cells read`}\n{toolInput.cell_id && `Cell content retrieved`}\n{!lineCount && !toolInput.cell_id && 'Notebook read successfully'}\n</>\n)}\n{isFocused && !hasError && (\n<span className=`text-xs text-muted-foreground/50 ml-2`>\n<kbd className=`px-1 py-0.5 text-xs bg-muted/50 rounded`>i</kbd> expand\n</span>\n)}\n</span>\n</div>\n)}\n</div>\n)\n}"
"export function TaskToolCallContent({\ntoolInput,\napprovalStatus,\nisCompleted,\ntoolResultContent,\nisFocused,\nisGroupItem,\n}: ToolCallContentProps<TaskToolInput>) {\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nconst getResultPreview = () => {\nif (!toolResultContent) return null\nconst firstLine = toolResultContent.split('\n')[0]\nreturn formatToolResultPreview(firstLine, { truncateLength: 80 })\n}\nconst resultPreview = getResultPreview()\nreturn (\n<div className=`flex flex-col gap-1`>\n<div className=`flex items-start justify-between w-full`>\n<ToolHeader\nname={toolInput.subagent_type || 'Task'}\ndescription={toolInput.description}\nnameColor={statusColor}\n/>\n<div className=`ml-4`>\n<StatusBadge status={approvalStatus} />\n</div>\n</div>\n{!isCompleted && (\n<div className=`text-xs text-muted-foreground ml-4`>\n<ChevronRight className=`inline-block w-3 h-3 mr-1` />\n<span className=`italic`>{toolInput.prompt.substring(0, 100)}...</span>\n</div>\n)}\n{resultPreview && <div className=`text-xs text-muted-foreground ml-4 mt-1`>{resultPreview}</div>}\n{isFocused && isCompleted && toolResultContent && (\n<div className=`text-xs text-muted-foreground/60 ml-4`>Press Enter to view full result</div>\n)}\n</div>\n)\n}"
"export function UnknownToolCallContent({\ntoolName,\ntoolInput,\nisCompleted,\ntoolResultContent,\nisFocused,\nisGroupItem = false,\n}: UnknownToolCallContentProps) {\nif (import.meta.env.DEV) {\nconsole.warn(`Unmigrated tool: ${toolName}`)\n}\nconst formatToolInput = () => {\nif (!toolInput) return 'No input'\ntry {\nconst entries = Object.entries(toolInput).slice(0, 2)\nreturn entries\n.map(([key, value]) => {\nconst displayValue =\ntypeof value === 'string' && value.length > 50\n? `${value.substring(0, 50)}...`\n: JSON.stringify(value)\nreturn `${key}: ${displayValue}`\n})\n.join(', ')\n} catch {\nreturn 'Complex input'\n}\n}\nreturn (\n<div className={`overflow-hidden ${isGroupItem ? 'text-xs' : 'text-sm'}`}>\n<div className=`flex flex-col gap-1`>\n<div className=`flex items-baseline gap-2`>\n<span className=`font-medium text-muted-foreground`>{toolName || 'Unknown Tool'}</span>\n<span className=`text-muted-foreground/60 text-xs`>{formatToolInput()}</span>\n</div>\n{isCompleted && toolResultContent && !isGroupItem && (\n<div className=`text-xs text-muted-foreground/60 truncate`>\n{toolResultContent.length > 100\n? `${toolResultContent.substring(0, 100)}...`\n: toolResultContent}\n</div>\n)}\n{isFocused && !isGroupItem && (\n<span className=`text-xs text-muted-foreground italic`>Press Enter to expand</span>\n)}\n</div>\n</div>\n)\n}"
"export function WebFetchToolCallContent({\ntoolInput,\napprovalStatus,\ntoolResultContent,\nisFocused,\nisGroupItem,\n}: ToolCallContentProps<WebFetchToolInput>) {\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nconst formatFetchResult = (content: string) => {\nconst charCount = content.length\nif (charCount > 0) {\nconst kbSize = (charCount / 1024).toFixed(1)\nreturn `Fetched ${kbSize}KB of content`\n}\nreturn 'No content retrieved'\n}\nconst formattedResult = toolResultContent ? formatFetchResult(toolResultContent) : null\nreturn (\n<div className=`space-y-2`>\n<ToolHeader\nname=`Web Fetch`\nnameColor={statusColor}\nprimaryParam={\n<div className=`flex items-center gap-2`>\n<span className=`text-sm`>\n<a\nhref={toolInput.url}\ntarget=`_blank`\nrel=`noopener noreferrer`\nclassName=`text-blue-500 hover:underline`\n>\n{toolInput.url}\n</a>\n</span>\n</div>\n}\nsecondaryParam={\ntoolInput.prompt ? (\n<div className=`text-sm text-muted-foreground italic`>&ldquo;{toolInput.prompt}&rdquo;</div>\n) : undefined\n}\nstatus={<StatusBadge status={approvalStatus} />}\n/>\n{formattedResult && (\n<div className=`mt-1 text-sm text-muted-foreground font-mono flex items-start gap-1`>\n<span className=`text-muted-foreground/50`>⎿</span>\n<span>\n{formattedResult}\n{isFocused && toolResultContent && toolResultContent.length > 100 && (\n<span className=`text-xs text-muted-foreground/50 ml-2`>\n<kbd className=`px-1 py-0.5 text-xs bg-muted/50 rounded`>i</kbd> expand\n</span>\n)}\n</span>\n</div>\n)}\n</div>\n)\n}"
"export function WriteToolCallContent({\ntoolInput,\napprovalStatus,\nisCompleted,\ntoolResultContent,\nisFocused,\nfileSnapshot,\nisGroupItem,\n}: WriteToolCallContentPropsWithSnapshot) {\nconst approvalStatusColor = getApprovalStatusColor(approvalStatus)\nlet statusColor =\nisGroupItem && !approvalStatusColor ? 'text-[var(--terminal-accent)]' : approvalStatusColor\nconst isNewFile = !fileSnapshot || fileSnapshot.trim() === ''\nconst hasError = toolResultContent ? detectToolError('Write', toolResultContent) : false\nconst preview = toolResultContent ? formatToolResultPreview(toolResultContent) : null\nconst showDiff = approvalStatus === 'pending' || approvalStatus === undefined\nreturn (\n<div className=`space-y-2`>\n<ToolHeader\nname=`Write`\ndescription={isNewFile ? 'Create new file' : 'Overwrite file'}\nprimaryParam={<span className=`font-mono text-sm`>{toolInput.file_path}</span>}\nnameColor={statusColor}\nstatus={<StatusBadge status={approvalStatus} />}\n/>\n{showDiff && (\n<div className=`mt-2`>\n<DiffViewer\noldContent={fileSnapshot || ''}\nnewContent={toolInput.content || ''}\nmode=`unified`\nshowFullFile={false}\n/>\n</div>\n)}\n{!showDiff && isCompleted && (\n<div className=`mt-1 text-sm text-muted-foreground font-mono flex items-start gap-1`>\n<span className=`text-muted-foreground/50`>⎿</span>\n<span className={hasError ? 'text-destructive' : ''}>\n{hasError ? preview || 'Error writing file' : isNewFile ? 'File created' : 'File written'}\n{isFocused && !hasError && (\n<span className=`text-xs text-muted-foreground/50 ml-2`>\n<kbd className=`px-1 py-0.5 text-xs bg-muted/50 rounded`>i</kbd> expand\n</span>\n)}\n</span>\n</div>\n)}\n</div>\n)\n}"
"function computeWordDiff(oldLine: string, newLine: string) {\nconst a = tokenizeLine(oldLine)\nconst b = tokenizeLine(newLine)\nconst n = a.length\nconst m = b.length\nconst dp: number[][] = Array(n + 1)\n.fill(0)\n.map(() => Array(m + 1).fill(0))\nfor (let i = n - 1; i >= 0; i--) {\nfor (let j = m - 1; j >= 0; j--) {\nif (a[i] === b[j]) {\ndp[i][j] = 1 + dp[i + 1][j + 1]\n} else {\ndp[i][j] = Math.max(dp[i + 1][j], dp[i][j + 1])\n}\n}\n}\nlet i = 0,\nj = 0\nconst result: any[] = []\nwhile (i < n && j < m) {\nif (a[i] === b[j]) {\nresult.push({ text: a[i], type: 'equal' })\ni++\nj++\n} else if (dp[i + 1][j] >= dp[i][j + 1]) {\nresult.push({ text: a[i], type: 'remove' })\ni++\n} else {\nresult.push({ text: b[j], type: 'add' })\nj++\n}\n}\nwhile (i < n) {\nresult.push({ text: a[i], type: 'remove' })\ni++\n}\nwhile (j < m) {\nresult.push({ text: b[j], type: 'add' })\nj++\n}\nreturn result\n}"
"export function DenyButtons({\nisDenying,\nonCancel,\nonDeny,\nisDisabled,\n}: {\nisDenying: boolean\nonCancel?: () => void\nonDeny?: () => void\nisDisabled?: boolean\n}) {\nconst isMac = navigator.platform.includes('Mac')\nconst sendKey = isMac ? '⌘+⏎' : 'Ctrl+⏎'\nreturn (\n<div\nonClick={e => {\ne.stopPropagation()\n}}\nclassName=`inline-flex gap-2`\n>\n<Button\nclassName={isDisabled ? 'cursor-not-allowed' : 'cursor-pointer'}\ntype=`button`\nsize=`sm`\nvariant=`destructive`\nonClick={e => {\ne.stopPropagation()\nif (!isDisabled) {\nonDeny?.()\n}\n}}\ndisabled={isDisabled}\n>\nDeny\n{isDenying && <kbd className=`ml-1 px-1 py-0.5 text-xs bg-muted/50 rounded`>{sendKey}</kbd>}\n</Button>\n<Button\nclassName=`cursor-pointer`\ntype=`button`\nsize=`sm`\nvariant=`outline`\nonClick={e => {\ne.stopPropagation()\nonCancel?.()\n}}\n>\nCancel <kbd className=`ml-1 px-1 py-0.5 text-xs bg-muted/50 rounded`>Esc</kbd>\n</Button>\n</div>\n)\n}"
"export function ForkViewModal({\nevents,\nselectedEventIndex,\nonSelectEvent,\nisOpen,\nonOpenChange,\nsessionStatus,\nonArchiveOnForkChange,\n}: ForkViewModalProps) {\nreturn (\n<HotkeyScopeBoundary\nscope={HOTKEY_SCOPES.FORK_MODAL}\nisActive={isOpen}\nrootScopeDisabled={true}\ncomponentName=`ForkViewModal`\n>\n<Dialog\nopen={isOpen}\nonOpenChange={isOpen => {\nif (!isOpen) {\nonOpenChange(false)\n} else {\nonOpenChange(true)\n}\n}}\n>\n<DialogContent\nclassName=`max-w-2xl`\nshowCloseButton={false}\nonOpenAutoFocus={e => {\ne.preventDefault()\n}}\nonCloseAutoFocus={e => {\ne.preventDefault()\n}}\nonEscapeKeyDown={e => {\ne.preventDefault()\n}}\n>\n{isOpen && (\n<ForkViewModalContent\nevents={events}\nselectedEventIndex={selectedEventIndex}\nonSelectEvent={onSelectEvent}\nsessionStatus={sessionStatus}\nonArchiveOnForkChange={onArchiveOnForkChange}\nonClose={() => onOpenChange(false)}\n/>\n)}\n</DialogContent>\n</Dialog>\n</HotkeyScopeBoundary>\n)\n}"
"export function ModelSelector({\nsession,\nonModelChange,\nclassName,\nopen,\nonOpenChange,\n}: ModelSelectorProps) {\nconst [internalOpen, setInternalOpen] = useState(false)\nconst isOpen = open ?? internalOpen\nconst setIsOpen = onOpenChange ?? setInternalOpen\nreturn (\n<Dialog open={isOpen} onOpenChange={setIsOpen}>\n{}\n{!open && !onOpenChange && (\n<DialogTrigger asChild>\n<Button\nvariant=`ghost`\nsize=`sm`\nclassName={`h-8 w-8 p-0 ${className}`}\ntitle=`Model Configuration`\n>\n<GitBranch className=`h-4 w-4` />\n</Button>\n</DialogTrigger>\n)}\n<DialogContent\nclassName=`max-w-md`\nonInteractOutside={e => {\ne.preventDefault()\n}}\nonEscapeKeyDown={e => {\ne.stopPropagation()\n}}\n>\n{isOpen && (\n<ModelSelectorContent\nsession={session}\nonModelChange={onModelChange}\nonClose={() => setIsOpen(false)}\n/>\n)}\n</DialogContent>\n</Dialog>\n)\n}"
"export function TokenUsageBadge({\neffectiveContextTokens,\ncontextLimit,\nclassName,\n}: TokenUsageBadgeProps) {\nif (effectiveContextTokens === undefined || effectiveContextTokens === null) return null\nconst limit = contextLimit || DEFAULT_CONTEXT_LIMIT\nconst percentage = Math.round((effectiveContextTokens / limit) * 100)\nlet variant: 'default' | 'secondary' | 'destructive' = 'secondary'\nlet textColorClass = ''\nif (percentage >= TOKEN_USAGE_THRESHOLDS.CRITICAL) {\nvariant = 'destructive'\n} else if (percentage >= TOKEN_USAGE_THRESHOLDS.WARNING) {\ntextColorClass = 'text-[var(--terminal-warning)]'\n} else {\ntextColorClass = 'text-[var(--terminal-success)]'\n}\nconst formattedTokens = effectiveContextTokens.toLocaleString()\nconst formattedLimit = limit.toLocaleString()\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>\n<Badge variant={variant} className={cn('font-mono text-xs gap-1', textColorClass, className)}>\n{percentage >= TOKEN_USAGE_THRESHOLDS.CRITICAL && <AlertCircle className=`h-3 w-3` />}\n<span>\n{formattedTokens}/{formattedLimit} ({percentage}%)\n</span>\n</Badge>\n</TooltipTrigger>\n<TooltipContent>\n<div className=`font-mono text-xs`>\n<div>Context Usage: {percentage}%</div>\n<div>Tokens Used: {formattedTokens}</div>\n<div>Context Limit: {formattedLimit}</div>\n{percentage >= TOKEN_USAGE_THRESHOLDS.WARNING && (\n<div className=`mt-1 text-[var(--terminal-warning)]`>⚠️ Approaching context limit</div>\n)}\n</div>\n</TooltipContent>\n</Tooltip>\n)\n}"
function getToolIcon(toolName: string | undefined): React.ReactNode {\nconst className = 'w-3.5 h-3.5'\nif (!toolName) return <Wrench className={className} />\nif (toolName.startsWith('mcp__')) {\nreturn <Globe className={className} />\n}\nswitch (toolName) {\ncase 'Task':\nreturn <Wrench className={className} />\ncase 'Edit':\ncase 'MultiEdit':\nreturn <FilePenLine className={className} />\ncase 'Read':\nreturn <FileText className={className} />\ncase 'Write':\nreturn <FilePenLine className={className} />\ncase 'Bash':\nreturn <Terminal className={className} />\ncase 'Grep':\ncase 'Glob':\nreturn <Search className={className} />\ncase 'LS':\ncase 'List':\nreturn <FileText className={className} />\ncase 'TodoWrite':\nreturn <ListTodo className={className} />\ncase 'WebSearch':\ncase 'WebFetch':\nreturn <Globe className={className} />\ncase 'ExitPlanMode':\nreturn <ListChecks className={className} />\ncase 'NotebookRead':\ncase 'NotebookEdit':\nreturn <FileText className={className} />\ndefault:\nreturn <Wrench className={className} />\n}\n}
"function buildTaskGroups(events: ConversationEvent[]): {\ntaskGroups: Map<string, TaskEventGroup>\nrootEvents: ConversationEvent[]\nhasSubTasks: boolean\n} {\nconst hasSubTasks = events.some(e => e.parentToolUseId)\nif (!hasSubTasks) {\nreturn {\ntaskGroups: new Map(),\nrootEvents: events,\nhasSubTasks: false,\n}\n}\nconst taskGroups = new Map<string, TaskEventGroup>()\nconst rootEvents: ConversationEvent[] = []\nconst eventsByParent = new Map<string, ConversationEvent[]>()\nevents.forEach(event => {\nif (event.parentToolUseId) {\nconst siblings = eventsByParent.get(event.parentToolUseId) || []\nsiblings.push(event)\neventsByParent.set(event.parentToolUseId, siblings)\n} else {\nrootEvents.push(event)\n}\n})\nrootEvents.forEach(event => {\nif (event.toolName === 'Task' && event.toolId && eventsByParent.has(event.toolId)) {\nconst subEvents = eventsByParent.get(event.toolId)!\nconst toolCalls = subEvents.filter(e => e.eventType === ConversationEventType.ToolCall)\nconst latestEvent = subEvents[subEvents.length - 1]\ntaskGroups.set(event.toolId, {\nparentTask: event,\nsubTaskEvents: subEvents,\ntoolCallCount: toolCalls.length,\nlatestEvent: latestEvent || null,\nhasPendingApproval: subEvents.some(e => e.approvalStatus === ApprovalStatus.Pending),\n})\n}\n})\nreturn { taskGroups, rootEvents, hasSubTasks: true }\n}"
"export function useTaskGrouping(events: ConversationEvent[]) {\nconst [expandedTasks, setExpandedTasks] = useState<Set<string>>(new Set())\nconst [preApprovalExpanded, setPreApprovalExpanded] = useState<Set<string> | null>(null)\nconst { taskGroups, rootEvents, hasSubTasks } = useMemo(() => buildTaskGroups(events), [events])\nuseEffect(() => {\nif (!hasSubTasks) return\nconst tasksWithPendingApprovals = new Set<string>()\ntaskGroups.forEach((group, taskId) => {\nif (group.hasPendingApproval) {\ntasksWithPendingApprovals.add(taskId)\n}\n})\nif (tasksWithPendingApprovals.size > 0) {\nif (!preApprovalExpanded) {\nsetPreApprovalExpanded(new Set(expandedTasks))\n}\nsetExpandedTasks(prev => new Set([...prev, ...tasksWithPendingApprovals]))\n} else if (preApprovalExpanded) {\nsetExpandedTasks(preApprovalExpanded)\nsetPreApprovalExpanded(null)\n}\n}, [taskGroups, hasSubTasks])\nconst toggleTaskGroup = (taskId: string) => {\nsetExpandedTasks(prev => {\nconst next = new Set(prev)\nif (next.has(taskId)) {\nnext.delete(taskId)\n} else {\nnext.add(taskId)\n}\nreturn next\n})\n}\nreturn {\ntaskGroups,\nrootEvents,\nhasSubTasks,\nexpandedTasks,\ntoggleTaskGroup,\n}\n}"
"function computeWordDiff(oldLine: string, newLine: string) {\nconst a = tokenizeLine(oldLine)\nconst b = tokenizeLine(newLine)\nconst n = a.length\nconst m = b.length\nconst dp: number[][] = Array(n + 1)\n.fill(0)\n.map(() => Array(m + 1).fill(0))\nfor (let i = n - 1; i >= 0; i--) {\nfor (let j = m - 1; j >= 0; j--) {\nif (a[i] === b[j]) {\ndp[i][j] = 1 + dp[i + 1][j + 1]\n} else {\ndp[i][j] = Math.max(dp[i + 1][j], dp[i][j + 1])\n}\n}\n}\nlet i = 0,\nj = 0\nconst result: any[] = []\nwhile (i < n && j < m) {\nif (a[i] === b[j]) {\nresult.push({ text: a[i], type: 'equal' })\ni++\nj++\n} else if (dp[i + 1][j] >= dp[i][j + 1]) {\nresult.push({ text: a[i], type: 'remove' })\ni++\n} else {\nresult.push({ text: b[j], type: 'add' })\nj++\n}\n}\nwhile (i < n) {\nresult.push({ text: a[i], type: 'remove' })\ni++\n}\nwhile (j < m) {\nresult.push({ text: b[j], type: 'add' })\nj++\n}\nreturn result\n}"
"export function detectToolError(toolName: string, content: string): boolean {\nconst lowerContent = content.toLowerCase()\nif (toolName === 'Edit') {\nconst successPattern =\n`has been updated. Here's the result of running `cat -n` on a snippet of the edited file:`\nreturn !content.includes(successPattern)\n}\nif (toolName === 'Write') {\nif (content.trim() === '') {\nreturn false\n}\nreturn (\nlowerContent.includes('error') ||\nlowerContent.includes('failed') ||\nlowerContent.includes('file has not been read')\n)\n}\nif (toolName === 'Grep') {\nreturn (\nlowerContent.startsWith('grep:') ||\nlowerContent.includes('invalid regex') ||\nlowerContent.includes('invalid regular expression')\n)\n}\nconst hasErrorKeyword =\nlowerContent.includes('error:') ||\nlowerContent.includes('failed:') ||\nlowerContent.includes('failed to') ||\nlowerContent.includes('exception:') ||\nlowerContent.includes('traceback') ||\nlowerContent.includes('was blocked') ||\nlowerContent.includes('permission denied') ||\nlowerContent.includes('access denied') ||\nlowerContent.includes('not allowed') ||\nlowerContent.includes('forbidden') ||\nlowerContent.includes('file has not been read yet') ||\nlowerContent.includes('read it first') ||\nlowerContent.includes('file not found') ||\nlowerContent.includes('no such file') ||\n(lowerContent.includes('matches of the string to replace') &&\nlowerContent.includes('but replace_all is false'))\nconst isFalsePositive =\nlowerContent.includes('no error') ||\nlowerContent.includes('error: 0') ||\nlowerContent.includes('error code 0') ||\nlowerContent.includes('error code: 0') ||\nlowerContent.includes('(0 errors') ||\nlowerContent.includes('0 errors)') ||\nlowerContent.includes('0 error(s)')\nreturn hasErrorKeyword && !isFalsePositive\n}"
"export default function DashboardLayout({\nchildren,\n}: {\nchildren: React.ReactNode\n}) {\nconst { isAuthenticated, isLoading } = useAuth()\nconst router = useRouter()\nconst [hasCheckedAuth, setHasCheckedAuth] = useState(false)\nuseVersionCheck()\nuseEffect(() => {\nif (!isLoading) {\nsetHasCheckedAuth(true)\nif (!isAuthenticated) {\nconst currentPath = window.location.pathname + window.location.search\nsessionStorage.setItem('redirectAfterLogin', currentPath)\nrouter.push('/login')\n}\n}\n}, [isAuthenticated, isLoading, router])\nif (isLoading || !hasCheckedAuth) {\nreturn (\n<div className=`min-h-screen flex items-center justify-center`>\n<LoadingSpinner />\n</div>\n)\n}\nif (!isAuthenticated) {\nreturn null\n}\nreturn (\n<ErrorBoundary>\n{children}\n<ModalProvider />\n</ErrorBoundary>\n)\n}"
"export async function GET(request: NextRequest) {\nconst envApiUrl = process.env.API_URL || process.env.NEXT_PUBLIC_API_URL\nif (envApiUrl) {\nreturn NextResponse.json({\napiUrl: envApiUrl,\n})\n}\ntry {\nconst proto = request.headers.get('x-forwarded-proto') ||\nrequest.nextUrl.protocol.replace(':', '') ||\n'http'\nconst hostHeader = request.headers.get('host')\nif (hostHeader) {\nconst hostname = hostHeader.split(':')[0]\nconst apiUrl = `${proto}:\nconsole.log(`[runtime-config] Auto-detected API URL: ${apiUrl} (proto=${proto}, host=${hostHeader})`)\nreturn NextResponse.json({\napiUrl,\n})\n}\n} catch (error) {\nconsole.error('[runtime-config] Auto-detection failed:', error)\n}\nconsole.log('[runtime-config] Using fallback: http:\nreturn NextResponse.json({\napiUrl: 'http:\n})\n}"
"export function ConnectionGuard({ children }: ConnectionGuardProps) {\nconst [error, setError] = useState<ConnectionError | null>(null)\nconst [isChecking, setIsChecking] = useState(true)\nconst checkConnection = useCallback(async () => {\nsetIsChecking(true)\nsetError(null)\nresetConfig()\ntry {\nconst config = await getConfig()\nif (config.dbStatus === 'offline') {\nsetError({\ntype: 'database-offline',\ndetails: {\nmessage: 'The API server is running, but the database is not accessible',\nattemptedUrl: config.apiUrl,\n},\n})\nsetIsChecking(false)\nreturn\n}\nsetError(null)\nsetIsChecking(false)\n} catch (err) {\nconst errorMessage =\nerr instanceof Error ? err.message : 'Unknown error occurred'\nconst attemptedUrl =\ntypeof window !== 'undefined'\n? `${window.location.origin}/api/config`\n: undefined\nsetError({\ntype: 'api-unreachable',\ndetails: {\nmessage: 'The Open Notebook API server could not be reached',\ntechnicalMessage: errorMessage,\nstack: err instanceof Error ? err.stack : undefined,\nattemptedUrl,\n},\n})\nsetIsChecking(false)\n}\n}, [])\nuseEffect(() => {\ncheckConnection()\n}, [checkConnection])\nuseEffect(() => {\nconst handleKeyPress = (e: KeyboardEvent) => {\nif (error && (e.key === 'r' || e.key === 'R')) {\ne.preventDefault()\ncheckConnection()\n}\n}\nwindow.addEventListener('keydown', handleKeyPress)\nreturn () => window.removeEventListener('keydown', handleKeyPress)\n}, [error, checkConnection])\nif (error) {\nreturn <ConnectionErrorOverlay error={error} onRetry={checkConnection} />\n}\nif (isChecking) {\nreturn null\n}\nreturn <>{children}</>\n}"
"export function ContextToggle({ mode, hasInsights = false, onChange, className }: ContextToggleProps) {\nconst config = MODE_CONFIG[mode]\nconst Icon = config.icon\nconst availableModes: ContextMode[] = hasInsights\n? ['off', 'insights', 'full']\n: ['off', 'full']\nconst handleClick = (e: React.MouseEvent) => {\ne.stopPropagation()\nconst currentIndex = availableModes.indexOf(mode)\nconst nextIndex = (currentIndex + 1) % availableModes.length\nonChange(availableModes[nextIndex])\n}\nreturn (\n<TooltipProvider>\n<Tooltip>\n<TooltipTrigger asChild>\n<Button\nvariant=`ghost`\nsize=`sm`\nclassName={cn(\n'h-8 w-8 p-0 transition-colors',\nconfig.bgColor,\nclassName\n)}\nonClick={handleClick}\n>\n<Icon className={cn('h-4 w-4', config.color)} />\n</Button>\n</TooltipTrigger>\n<TooltipContent>\n<p className=`text-xs`>{config.label}</p>\n<p className=`text-[10px] text-muted-foreground mt-1`>\nClick to cycle\n</p>\n</TooltipContent>\n</Tooltip>\n</TooltipProvider>\n)\n}"
render() {\nif (this.state.hasError) {\nif (this.props.fallback) {\nconst FallbackComponent = this.props.fallback\nreturn <FallbackComponent error={this.state.error} resetError={this.resetError} />\n}\nreturn (\n<div className=`min-h-screen flex items-center justify-center bg-background p-4`>\n<Card className=`w-full max-w-md`>\n<CardHeader className=`text-center`>\n<div className=`mx-auto w-12 h-12 rounded-full bg-red-100 dark:bg-red-900/20 flex items-center justify-center mb-4`>\n<AlertTriangle className=`w-6 h-6 text-red-600 dark:text-red-400` />\n</div>\n<CardTitle className=`text-red-900 dark:text-red-100`>Something went wrong</CardTitle>\n<CardDescription>\nAn unexpected error occurred. Please try refreshing the page.\n</CardDescription>\n</CardHeader>\n<CardContent className=`space-y-4`>\n{process.env.NODE_ENV === 'development' && this.state.error && (\n<details className=`text-xs bg-muted p-3 rounded border`>\n<summary className=`cursor-pointer font-medium`>Error Details</summary>\n<pre className=`mt-2 whitespace-pre-wrap break-all`>\n{this.state.error.toString()}\n</pre>\n</details>\n)}\n<Button\nonClick={this.resetError}\nclassName=`w-full`\nvariant=`outline`\n>\n<RefreshCw className=`w-4 h-4 mr-2` />\nTry Again\n</Button>\n<Button\nonClick={() => window.location.reload()}\nclassName=`w-full`\n>\nRefresh Page\n</Button>\n</CardContent>\n</Card>\n</div>\n)\n}\nreturn this.props.children\n}
"export function ModelSelector({\nlabel,\nmodelType,\nvalue,\nonChange,\nplaceholder = 'Select a model',\ndisabled = false\n}: ModelSelectorProps) {\nconst { data: models, isLoading } = useModels()\nconst filteredModels = models?.filter(model => model.type === modelType) || []\nreturn (\n<div className=`space-y-2`>\n{label && <Label>{label}</Label>}\n<Select value={value} onValueChange={onChange} disabled={disabled || isLoading}>\n<SelectTrigger>\n<SelectValue placeholder={placeholder} />\n</SelectTrigger>\n<SelectContent>\n{isLoading ? (\n<div className=`flex items-center justify-center py-2`>\n<LoadingSpinner size=`sm` />\n</div>\n) : filteredModels.length === 0 ? (\n<div className=`text-sm text-muted-foreground py-2 px-2`>\nNo {modelType.replace('_', ' ')} models available\n</div>\n) : (\nfilteredModels.map((model) => (\n<SelectItem key={model.id} value={model.id}>\n<div className=`flex items-center justify-between w-full`>\n<span>{model.name}</span>\n<span className=`text-xs text-muted-foreground ml-2`>{model.provider}</span>\n</div>\n</SelectItem>\n))\n)}\n</SelectContent>\n</Select>\n</div>\n)\n}"
"export function ThemeToggle({ iconOnly = false }: ThemeToggleProps) {\nconst { theme, setTheme } = useTheme()\nreturn (\n<DropdownMenu>\n<DropdownMenuTrigger asChild>\n<Button\nvariant={iconOnly ? `ghost` : `outline`}\nsize={iconOnly ? `icon` : `default`}\nclassName={iconOnly ? `h-9 w-full` : `w-full justify-start gap-2`}\n>\n<div className=`relative h-[1.2rem] w-[1.2rem]`>\n<Sun className=`absolute inset-0 h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0` />\n<Moon className=`absolute inset-0 h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100` />\n</div>\n{!iconOnly && <span>Theme</span>}\n<span className=`sr-only`>Toggle theme</span>\n</Button>\n</DropdownMenuTrigger>\n<DropdownMenuContent align=`end`>\n<DropdownMenuItem\nonClick={() => setTheme('light')}\nclassName={theme === 'light' ? 'bg-accent' : ''}\n>\n<Sun className=`mr-2 h-4 w-4` />\n<span>Light</span>\n</DropdownMenuItem>\n<DropdownMenuItem\nonClick={() => setTheme('dark')}\nclassName={theme === 'dark' ? 'bg-accent' : ''}\n>\n<Moon className=`mr-2 h-4 w-4` />\n<span>Dark</span>\n</DropdownMenuItem>\n<DropdownMenuItem\nonClick={() => setTheme('system')}\nclassName={theme === 'system' ? 'bg-accent' : ''}\n>\n<Monitor className=`mr-2 h-4 w-4` />\n<span>System</span>\n</DropdownMenuItem>\n</DropdownMenuContent>\n</DropdownMenu>\n)\n}"
"export function AdvancedModelsDialog({\nopen,\nonOpenChange,\ndefaultModels,\nonSave\n}: AdvancedModelsDialogProps) {\nconst [strategyModel, setStrategyModel] = useState(defaultModels.strategy)\nconst [answerModel, setAnswerModel] = useState(defaultModels.answer)\nconst [finalAnswerModel, setFinalAnswerModel] = useState(defaultModels.finalAnswer)\nuseEffect(() => {\nsetStrategyModel(defaultModels.strategy)\nsetAnswerModel(defaultModels.answer)\nsetFinalAnswerModel(defaultModels.finalAnswer)\n}, [defaultModels])\nconst handleSave = () => {\nonSave({\nstrategy: strategyModel,\nanswer: answerModel,\nfinalAnswer: finalAnswerModel\n})\nonOpenChange(false)\n}\nreturn (\n<Dialog open={open} onOpenChange={onOpenChange}>\n<DialogContent className=`sm:max-w-[500px]`>\n<DialogHeader>\n<DialogTitle>Advanced Model Selection</DialogTitle>\n<DialogDescription>\nChoose specific models for each stage of the Ask process\n</DialogDescription>\n</DialogHeader>\n<div className=`space-y-4 py-4`>\n<ModelSelector\nlabel=`Strategy Model`\nmodelType=`language`\nvalue={strategyModel}\nonChange={setStrategyModel}\nplaceholder=`Select strategy model`\n/>\n<ModelSelector\nlabel=`Answer Model`\nmodelType=`language`\nvalue={answerModel}\nonChange={setAnswerModel}\nplaceholder=`Select answer model`\n/>\n<ModelSelector\nlabel=`Final Answer Model`\nmodelType=`language`\nvalue={finalAnswerModel}\nonChange={setFinalAnswerModel}\nplaceholder=`Select final answer model`\n/>\n</div>\n<DialogFooter>\n<Button variant=`outline` onClick={() => onOpenChange(false)}>\nCancel\n</Button>\n<Button onClick={handleSave}>\nSave Changes\n</Button>\n</DialogFooter>\n</DialogContent>\n</Dialog>\n)\n}"
"export function SourceInsightDialog({ open, onOpenChange, insight }: SourceInsightDialogProps) {\nconst insightIdWithPrefix = insight?.id\n? (insight.id.includes(':') ? insight.id : `source_insight:${insight.id}`)\n: ''\nconst { data: fetchedInsight, isLoading } = useInsight(insightIdWithPrefix, { enabled: open && !!insight?.id })\nconst displayInsight = fetchedInsight ?? insight\nreturn (\n<Dialog open={open} onOpenChange={onOpenChange}>\n<DialogContent className=`sm:max-w-3xl max-h-[90vh] flex flex-col`>\n<DialogHeader>\n<DialogTitle className=`flex items-center justify-between gap-2`>\n<span>Source Insight</span>\n{displayInsight?.insight_type && (\n<Badge variant=`outline` className=`text-xs uppercase`>\n{displayInsight.insight_type}\n</Badge>\n)}\n</DialogTitle>\n</DialogHeader>\n<div className=`flex-1 overflow-y-auto min-h-0`>\n{isLoading ? (\n<div className=`flex items-center justify-center py-10`>\n<span className=`text-sm text-muted-foreground`>Loading insight…</span>\n</div>\n) : displayInsight ? (\n<div className=`prose prose-sm prose-neutral dark:prose-invert max-w-none`>\n<ReactMarkdown>{displayInsight.content}</ReactMarkdown>\n</div>\n) : (\n<p className=`text-sm text-muted-foreground`>No insight selected.</p>\n)}\n</div>\n</DialogContent>\n</Dialog>\n)\n}"
"export function CheckboxList({\nitems,\nselectedIds,\nonToggle,\nloading = false,\nemptyMessage = `No items found.`,\nclassName\n}: CheckboxListProps) {\nif (loading) {\nreturn (\n<div className={cn('border border-border rounded-md p-4 bg-card', className)}>\n<div className=`animate-pulse space-y-3`>\n{[...Array(3)].map((_, i) => (\n<div key={i} className=`flex items-center gap-3`>\n<div className=`w-4 h-4 bg-muted rounded` />\n<div className=`flex-1`>\n<div className=`h-4 bg-muted rounded w-3/4 mb-1` />\n<div className=`h-3 bg-muted rounded w-1/2` />\n</div>\n</div>\n))}\n</div>\n</div>\n)\n}\nif (items.length === 0) {\nreturn (\n<div className={cn('border border-border rounded-md p-4 bg-card', className)}>\n<p className=`text-sm text-muted-foreground`>{emptyMessage}</p>\n</div>\n)\n}\nreturn (\n<div className={cn('border border-border rounded-md bg-card', className)}>\n<div className=`max-h-48 overflow-y-auto p-4`>\n<div className=`space-y-3`>\n{items.map((item) => (\n<label\nkey={item.id}\nclassName=`flex items-start gap-3 cursor-pointer hover:bg-muted p-2 rounded-md -m-2 transition-colors`\n>\n<Checkbox\nchecked={selectedIds.includes(item.id)}\nonCheckedChange={() => onToggle(item.id)}\nclassName=`mt-0.5`\n/>\n<div className=`flex-1 min-w-0`>\n<span className=`text-sm font-medium block`>\n{item.title}\n</span>\n{item.description && (\n<p className=`text-xs text-muted-foreground mt-1 line-clamp-2`>\n{item.description}\n</p>\n)}\n</div>\n</label>\n))}\n</div>\n</div>\n</div>\n)\n}"
"function StepIndicator({ currentStep, steps, onStepClick }: {\ncurrentStep: number\nsteps: readonly WizardStep[]\nonStepClick?: (step: number) => void\n}) {\nreturn (\n<div className=`flex items-center justify-between px-6 py-4 border-b border-border bg-muted`>\n{steps.map((step, index) => {\nconst isCompleted = currentStep > step.number\nconst isCurrent = currentStep === step.number\nconst isClickable = step.number <= currentStep && onStepClick\nreturn (\n<div key={step.number} className=`flex items-center flex-1`>\n<div\nclassName={cn('flex items-center', isClickable && 'cursor-pointer')}\nonClick={isClickable ? () => onStepClick(step.number) : undefined}\n>\n<div\nclassName={cn(\n'flex items-center justify-center w-8 h-8 rounded-full border-2 text-sm font-medium transition-colors',\nisCompleted\n? 'bg-primary border-primary text-primary-foreground'\n: isCurrent\n? 'border-primary text-primary bg-primary/10'\n: 'border-border text-muted-foreground bg-card'\n)}\n>\n{isCompleted ? `✓` : step.number}\n</div>\n<div className=`ml-3 min-w-0`>\n<p className={cn(\n'text-sm font-medium',\nisCurrent ? 'text-foreground' : 'text-muted-foreground'\n)}>\n{step.title}\n</p>\n<p className={cn(\n'text-xs',\nisCurrent ? 'text-muted-foreground' : 'text-muted-foreground/80'\n)}>\n{step.description}\n</p>\n</div>\n</div>\n{index < steps.length - 1 && (\n<div\nclassName={cn(\n'flex-1 border-t-2 mx-4 transition-colors',\nisCompleted ? 'border-primary' : 'border-border/60'\n)}\n/>\n)}\n</div>\n)\n})}\n</div>\n)\n}"
"export function useAuth() {\nconst router = useRouter()\nconst {\nisAuthenticated,\nisLoading,\nlogin,\nlogout,\ncheckAuth,\ncheckAuthRequired,\nerror,\nhasHydrated,\nauthRequired\n} = useAuthStore()\nuseEffect(() => {\nif (hasHydrated) {\nif (authRequired === null) {\ncheckAuthRequired().then((required) => {\nif (required) {\ncheckAuth()\n}\n})\n} else if (authRequired) {\ncheckAuth()\n}\n}\n}, [hasHydrated, authRequired])\nconst handleLogin = async (password: string) => {\nconst success = await login(password)\nif (success) {\nconst redirectPath = sessionStorage.getItem('redirectAfterLogin')\nif (redirectPath) {\nsessionStorage.removeItem('redirectAfterLogin')\nrouter.push(redirectPath)\n} else {\nrouter.push('/notebooks')\n}\n}\nreturn success\n}\nconst handleLogout = () => {\nlogout()\nrouter.push('/login')\n}\nreturn {\nisAuthenticated,\nisLoading: isLoading || !hasHydrated,\nerror,\nlogin: handleLogin,\nlogout: handleLogout\n}\n}"
"export function usePodcastEpisodes(options?: { autoRefresh?: boolean }) {\nconst { autoRefresh = true } = options ?? {}\nconst query = useQuery({\nqueryKey: QUERY_KEYS.podcastEpisodes,\nqueryFn: podcastsApi.listEpisodes,\nrefetchInterval: (current) => {\nif (!autoRefresh) {\nreturn false\n}\nconst data = current.state.data as PodcastEpisode[] | undefined\nif (!data || data.length === 0) {\nreturn false\n}\nreturn hasActiveEpisodes(data) ? 15_000 : false\n},\n})\nconst episodes = useMemo(() => query.data ?? [], [query.data])\nconst statusGroups = useMemo<EpisodeStatusGroups>(\n() => groupEpisodesByStatus(episodes),\n[episodes]\n)\nconst statusCounts = useMemo<EpisodeStatusCounts>(\n() => ({\ntotal: episodes.length,\nrunning: statusGroups.running.length,\ncompleted: statusGroups.completed.length,\nfailed: statusGroups.failed.length,\npending: statusGroups.pending.length,\n}),\n[episodes.length, statusGroups]\n)\nconst active = useMemo(() => hasActiveEpisodes(episodes), [episodes])\nreturn {\n...query,\nepisodes,\nstatusGroups,\nstatusCounts,\nhasActiveEpisodes: active,\n}\n}"
"export function useCreateSource() {\nconst queryClient = useQueryClient()\nconst { toast } = useToast()\nreturn useMutation({\nmutationFn: (data: CreateSourceRequest) => sourcesApi.create(data),\nonSuccess: (result: SourceResponse, variables) => {\nif (variables.notebooks) {\nvariables.notebooks.forEach(notebookId => {\nqueryClient.invalidateQueries({\nqueryKey: QUERY_KEYS.sources(notebookId),\nrefetchType: 'active'\n})\n})\n} else if (variables.notebook_id) {\nqueryClient.invalidateQueries({\nqueryKey: QUERY_KEYS.sources(variables.notebook_id),\nrefetchType: 'active'\n})\n}\nqueryClient.invalidateQueries({\nqueryKey: QUERY_KEYS.sources(),\nrefetchType: 'active'\n})\nif (variables.async_processing) {\ntoast({\ntitle: 'Source Queued',\ndescription: 'Source submitted for background processing. You can monitor progress in the sources list.',\n})\n} else {\ntoast({\ntitle: 'Success',\ndescription: 'Source added successfully',\n})\n}\n},\nonError: () => {\ntoast({\ntitle: 'Error',\ndescription: 'Failed to add source',\nvariant: 'destructive',\n})\n},\n})\n}"
"export function useAddSourcesToNotebook() {\nconst queryClient = useQueryClient()\nconst { toast } = useToast()\nreturn useMutation({\nmutationFn: async ({ notebookId, sourceIds }: { notebookId: string; sourceIds: string[] }) => {\nconst { notebooksApi } = await import('@/lib/api/notebooks')\nconst results = await Promise.allSettled(\nsourceIds.map(sourceId => notebooksApi.addSource(notebookId, sourceId))\n)\nconst successes = results.filter(r => r.status === 'fulfilled').length\nconst failures = results.filter(r => r.status === 'rejected').length\nreturn { successes, failures, total: sourceIds.length }\n},\nonSuccess: (result, { notebookId, sourceIds }) => {\nqueryClient.invalidateQueries({ queryKey: ['sources'] })\nqueryClient.invalidateQueries({ queryKey: QUERY_KEYS.sources(notebookId) })\nsourceIds.forEach(sourceId => {\nqueryClient.invalidateQueries({ queryKey: QUERY_KEYS.source(sourceId) })\n})\nif (result.failures === 0) {\ntoast({\ntitle: 'Success',\ndescription: `${result.successes} source${result.successes > 1 ? 's' : ''} added to notebook`,\n})\n} else if (result.successes === 0) {\ntoast({\ntitle: 'Error',\ndescription: 'Failed to add sources to notebook',\nvariant: 'destructive',\n})\n} else {\ntoast({\ntitle: 'Partial Success',\ndescription: `${result.successes} source${result.successes > 1 ? 's' : ''} added, ${result.failures} failed`,\nvariant: 'default',\n})\n}\n},\nonError: () => {\ntoast({\ntitle: 'Error',\ndescription: 'Failed to add sources to notebook',\nvariant: 'destructive',\n})\n},\n})\n}"
"export function useVersionCheck() {\nuseEffect(() => {\nconst checkVersion = async () => {\ntry {\nconst config = await getConfig()\nif (config.hasUpdate && config.latestVersion) {\nconst dismissKey = `version_notification_dismissed_${config.latestVersion}`\nconst isDismissed = sessionStorage.getItem(dismissKey)\nif (!isDismissed) {\ntoast.info(`Version ${config.latestVersion} available`, {\ndescription: 'A new version of Open Notebook is available.',\nduration: Infinity,\ncloseButton: true,\naction: {\nlabel: 'View on GitHub',\nonClick: () => {\nwindow.open(\n'https:\n'_blank',\n'noopener,noreferrer'\n)\n},\n},\nonDismiss: () => {\nsessionStorage.setItem(dismissKey, 'true')\n},\n})\nconsole.log(\n`🔔 [Version Check] Update available: ${config.version} → ${config.latestVersion}`\n)\n} else {\nconsole.log(\n`🔕 [Version Check] Notification dismissed for version ${config.latestVersion}`\n)\n}\n} else if (config.latestVersion) {\nconsole.log(\n`✅ [Version Check] Running latest version: ${config.version}`\n)\n} else {\nconsole.log(\n`⚠️ [Version Check] Could not check for updates (offline or GitHub unavailable)`\n)\n}\n} catch (error) {\nconsole.error('❌ [Version Check] Failed to check version:', error)\n}\n}\ncheckVersion()\n}, [])\n}"
"export function createReferenceLinkComponent(\nonReferenceClick: (type: ReferenceType, id: string) => void\n) {\nconst ReferenceLinkComponent = ({\nhref,\nchildren,\n...props\n}: React.AnchorHTMLAttributes<HTMLAnchorElement> & {\nhref?: string\nchildren?: React.ReactNode\n}) => {\nif (href?.startsWith('#ref-')) {\nconst parts = href.substring(5).split('-')\nconst type = parts[0] as ReferenceType\nconst id = parts.slice(1).join('-')\nconst IconComponent =\ntype === 'source' ? FileText :\ntype === 'source_insight' ? Lightbulb :\nFileEdit\nreturn (\n<button\nonClick={(e) => {\ne.preventDefault()\ne.stopPropagation()\nonReferenceClick(type, id)\n}}\nclassName=`text-primary hover:underline cursor-pointer inline font-medium`\ntype=`button`\n>\n<IconComponent className=`h-3 w-3 inline mr-1` aria-hidden=`true` />\n{children}\n</button>\n)\n}\nreturn (\n<a href={href} target=`_blank` rel=`noopener noreferrer` {...props} className=`text-primary hover:underline`>\n{children}\n</a>\n)\n}\nReferenceLinkComponent.displayName = 'ReferenceLinkComponent'\nreturn ReferenceLinkComponent\n}"
"export function convertReferencesToCompactMarkdown(text: string): string {\nconst references = parseSourceReferences(text)\nif (references.length === 0) {\nreturn text\n}\nconst referenceMap = new Map<string, ReferenceData>()\nlet nextNumber = 1\nfor (const reference of references) {\nconst key = `${reference.type}:${reference.id}`\nif (!referenceMap.has(key)) {\nreferenceMap.set(key, {\nnumber: nextNumber++,\ntype: reference.type,\nid: reference.id\n})\n}\n}\nlet result = text\nfor (let i = references.length - 1; i >= 0; i--) {\nconst reference = references[i]\nconst key = `${reference.type}:${reference.id}`\nconst refData = referenceMap.get(key)!\nconst number = refData.number\nconst refStart = reference.startIndex\nconst refEnd = reference.endIndex\nconst contextBefore = result.substring(Math.max(0, refStart - 2), refStart)\nconst contextAfter = result.substring(refEnd, Math.min(result.length, refEnd + 2))\nlet replaceStart = refStart\nlet replaceEnd = refEnd\nif (contextBefore === '[[' && contextAfter.startsWith(']]')) {\nreplaceStart = refStart - 2\nreplaceEnd = refEnd + 2\n}\nelse if (contextBefore.endsWith('[') && contextAfter.startsWith(']')) {\nreplaceStart = refStart - 1\nreplaceEnd = refEnd + 1\n}\nconst citationLink = `[${number}](#ref-${reference.type}-${reference.id})`\nresult = result.substring(0, replaceStart) + citationLink + result.substring(replaceEnd)\n}\nconst refListLines: string[] = ['\n\nReferences:']\nfor (const [, refData] of referenceMap) {\nconst refListItem = `[${refData.number}] - [${refData.type}:${refData.id}](#ref-${refData.type}-${refData.id})`\nrefListLines.push(refListItem)\n}\nresult = result + refListLines.join('\n')\nreturn result\n}"
"export function createCompactReferenceLinkComponent(\nonReferenceClick: (type: ReferenceType, id: string) => void\n) {\nconst CompactReferenceLinkComponent = ({\nhref,\nchildren,\n...props\n}: React.AnchorHTMLAttributes<HTMLAnchorElement> & {\nhref?: string\nchildren?: React.ReactNode\n}) => {\nif (href?.startsWith('#ref-')) {\nconst parts = href.substring(5).split('-')\nconst type = parts[0] as ReferenceType\nconst id = parts.slice(1).join('-')\nreturn (\n<button\nonClick={(e) => {\ne.preventDefault()\ne.stopPropagation()\nonReferenceClick(type, id)\n}}\nclassName=`text-primary hover:underline cursor-pointer inline font-medium`\ntype=`button`\n>\n{children}\n</button>\n)\n}\nreturn (\n<a href={href} target=`_blank` rel=`noopener noreferrer` {...props} className=`text-primary hover:underline`>\n{children}\n</a>\n)\n}\nCompactReferenceLinkComponent.displayName = 'CompactReferenceLinkComponent'\nreturn CompactReferenceLinkComponent\n}"
"export default function PodcastsPage() {\nconst [activeTab, setActiveTab] = useState<'episodes' | 'templates'>('episodes')\nreturn (\n<AppShell>\n<div className=`flex-1 overflow-y-auto`>\n<div className=`px-6 py-6 space-y-6`>\n<header className=`space-y-1`>\n<h1 className=`text-2xl font-semibold tracking-tight`>Podcasts</h1>\n<p className=`text-muted-foreground`>\nKeep track of generated episodes and manage reusable templates.\n</p>\n</header>\n<Tabs\nvalue={activeTab}\nonValueChange={(value) => setActiveTab(value as 'episodes' | 'templates')}\nclassName=`space-y-6`\n>\n<div className=`space-y-2`>\n<p className=`text-xs font-semibold uppercase tracking-wide text-muted-foreground`>Choose a view</p>\n<TabsList aria-label=`Podcast views` className=`w-full max-w-md`>\n<TabsTrigger value=`episodes`>\n<Mic className=`h-4 w-4` />\nEpisodes\n</TabsTrigger>\n<TabsTrigger value=`templates`>\n<LayoutTemplate className=`h-4 w-4` />\nTemplates\n</TabsTrigger>\n</TabsList>\n</div>\n<TabsContent value=`episodes`>\n<EpisodesTab />\n</TabsContent>\n<TabsContent value=`templates`>\n<TemplatesTab />\n</TabsContent>\n</Tabs>\n</div>\n</div>\n</AppShell>\n)\n}"
"export function NotebookList({\nnotebooks,\nisLoading,\ntitle,\ncollapsible = false,\nemptyTitle,\nemptyDescription,\n}: NotebookListProps) {\nconst [isExpanded, setIsExpanded] = useState(!collapsible)\nif (isLoading) {\nreturn (\n<div className=`flex items-center justify-center py-12`>\n<LoadingSpinner size=`lg` />\n</div>\n)\n}\nif (!notebooks || notebooks.length === 0) {\nreturn (\n<EmptyState\nicon={Book}\ntitle={emptyTitle ?? `No ${title.toLowerCase()}`}\ndescription={emptyDescription ?? 'Start by creating your first notebook to organize your research.'}\n/>\n)\n}\nreturn (\n<div className=`space-y-4`>\n<div className=`flex items-center gap-2`>\n{collapsible && (\n<Button\nvariant=`ghost`\nsize=`sm`\nonClick={() => setIsExpanded(!isExpanded)}\n>\n{isExpanded ? (\n<ChevronDown className=`h-4 w-4` />\n) : (\n<ChevronRight className=`h-4 w-4` />\n)}\n</Button>\n)}\n<h2 className=`text-lg font-semibold`>{title}</h2>\n<span className=`text-sm text-muted-foreground`>({notebooks.length})</span>\n</div>\n{isExpanded && (\n<div className=`grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4`>\n{notebooks.map((notebook) => (\n<NotebookCard key={notebook.id} notebook={notebook} />\n))}\n</div>\n)}\n</div>\n)\n}"
"export default function SourceDetailPage() {\nconst router = useRouter()\nconst params = useParams()\nconst sourceId = decodeURIComponent(params.id as string)\nconst navigation = useNavigation()\nconst chat = useSourceChat(sourceId)\nconst handleBack = useCallback(() => {\nconst returnPath = navigation.getReturnPath()\nrouter.push(returnPath)\nnavigation.clearReturnTo()\n}, [navigation, router])\nreturn (\n<div className=`flex flex-col h-screen`>\n{}\n<div className=`pt-6 pb-4 px-6`>\n<Button\nvariant=`ghost`\nsize=`sm`\nonClick={handleBack}\nclassName=`mb-4`\n>\n<ArrowLeft className=`mr-2 h-4 w-4` />\n{navigation.getReturnLabel()}\n</Button>\n</div>\n{}\n<div className=`flex-1 grid gap-6 lg:grid-cols-[2fr_1fr] overflow-hidden px-6`>\n{}\n<div className=`overflow-y-auto px-4 pb-6`>\n<SourceDetailContent\nsourceId={sourceId}\nshowChatButton={false}\nonClose={handleBack}\n/>\n</div>\n{}\n<div className=`overflow-y-auto px-4 pb-6`>\n<ChatPanel\nmessages={chat.messages}\nisStreaming={chat.isStreaming}\ncontextIndicators={chat.contextIndicators}\nonSendMessage={(message, model) => chat.sendMessage(message, model)}\nmodelOverride={chat.currentSession?.model_override}\nonModelChange={(model) => {\nif (chat.currentSessionId) {\nchat.updateSession(chat.currentSessionId, { model_override: model })\n}\n}}\nsessions={chat.sessions}\ncurrentSessionId={chat.currentSessionId}\nonCreateSession={(title) => chat.createSession({ title })}\nonSelectSession={chat.switchSession}\nonUpdateSession={(sessionId, title) => chat.updateSession(sessionId, { title })}\nonDeleteSession={chat.deleteSession}\nloadingSessions={chat.loadingSessions}\n/>\n</div>\n</div>\n</div>\n)\n}"
"export function DefaultPromptEditor() {\nconst [isOpen, setIsOpen] = useState(false)\nconst [prompt, setPrompt] = useState('')\nconst { data: defaultPrompt, isLoading } = useDefaultPrompt()\nconst updateDefaultPrompt = useUpdateDefaultPrompt()\nuseEffect(() => {\nif (defaultPrompt) {\nsetPrompt(defaultPrompt.transformation_instructions || '')\n}\n}, [defaultPrompt])\nconst handleSave = () => {\nupdateDefaultPrompt.mutate({ transformation_instructions: prompt })\n}\nreturn (\n<Collapsible open={isOpen} onOpenChange={setIsOpen}>\n<Card>\n<CollapsibleTrigger className=`w-full`>\n<CardHeader className=`cursor-pointer`>\n<div className=`flex items-center justify-between`>\n<div className=`flex items-center gap-2`>\n<Settings className=`h-5 w-5` />\n<div className=`text-left`>\n<CardTitle className=`text-lg`>Default Transformation Prompt</CardTitle>\n<CardDescription>\nThis will be added to all your transformation prompts\n</CardDescription>\n</div>\n</div>\n{isOpen ? (\n<ChevronDown className=`h-5 w-5` />\n) : (\n<ChevronRight className=`h-5 w-5` />\n)}\n</div>\n</CardHeader>\n</CollapsibleTrigger>\n<CollapsibleContent>\n<CardContent className=`space-y-4`>\n<Textarea\nvalue={prompt}\nonChange={(e) => setPrompt(e.target.value)}\nplaceholder=`Enter your default transformation instructions...`\nclassName=`min-h-[200px] font-mono text-sm`\ndisabled={isLoading}\n/>\n<div className=`flex justify-end`>\n<Button\nonClick={handleSave}\ndisabled={isLoading || updateDefaultPrompt.isPending}\n>\nSave\n</Button>\n</div>\n</CardContent>\n</CollapsibleContent>\n</Card>\n</Collapsible>\n)\n}"
"export function TransformationsList({ transformations, isLoading, onPlayground }: TransformationsListProps) {\nconst [editorOpen, setEditorOpen] = useState(false)\nconst [editingTransformation, setEditingTransformation] = useState<Transformation | undefined>()\nconst handleOpenEditor = (trans?: Transformation) => {\nsetEditingTransformation(trans)\nsetEditorOpen(true)\n}\nif (isLoading) {\nreturn (\n<div className=`flex items-center justify-center py-12`>\n<LoadingSpinner size=`lg` />\n</div>\n)\n}\nif (!transformations || transformations.length === 0) {\nreturn (\n<EmptyState\nicon={Wand2}\ntitle=`No transformations yet`\ndescription=`Create your first transformation to process and extract insights from your content.`\naction={\n<Button onClick={() => handleOpenEditor()}>\n<Plus className=`h-4 w-4 mr-2` />\nCreate New Transformation\n</Button>\n}\n/>\n)\n}\nreturn (\n<>\n<div className=`space-y-6`>\n<div className=`flex justify-between items-center`>\n<h2 className=`text-lg font-semibold`>Your Transformations</h2>\n<Button onClick={() => handleOpenEditor()}>\n<Plus className=`h-4 w-4 mr-2` />\nCreate New Transformation\n</Button>\n</div>\n<div className=`space-y-4`>\n{transformations.map((transformation) => (\n<TransformationCard\nkey={transformation.id}\ntransformation={transformation}\nonPlayground={onPlayground ? () => onPlayground(transformation) : undefined}\nonEdit={() => handleOpenEditor(transformation)}\n/>\n))}\n</div>\n</div>\n<TransformationEditorDialog\nopen={editorOpen}\nonOpenChange={(open) => {\nsetEditorOpen(open)\nif (!open) {\nsetEditingTransformation(undefined)\n}\n}}\ntransformation={editingTransformation}\n/>\n</>\n)\n}"
"async function publishSinglePackage(pkg: PackageDetails, opts?: { dryRun?: boolean }) {\nconst { dryRun = false } = opts ?? {}\nconsole.log(chalk.bold(`🚀 ${pkg.name} publishing...`))\ntry {\nconst cmdArgs = ['publish', '-C', pkg.packagePath, '--no-git-checks', '--json', '--tag', tag]\nif (dryRun) {\ncmdArgs.push('--dry-run')\nconsole.log(chalk.gray(`\n${logPrefix} pnpm ${cmdArgs.join(' ')}\n`))\n}\nconst { exitCode, stderr } = await execa('pnpm', cmdArgs, {\ncwd,\nstdio: ['ignore', 'ignore', 'pipe'],\n})\nif (exitCode !== 0) {\nconsole.log(chalk.bold.red(`\n\n❌ ${pkg.name} ERROR: pnpm publish failed\n\n${stderr}`))\nconsole.log(chalk.bold.yellow(`\nRetrying publish for ${pkg.name}...`))\nconst { exitCode: retryExitCode, stderr: retryStdError } = await execa('pnpm', cmdArgs, {\ncwd,\nstdio: 'inherit',\n})\nif (retryExitCode !== 0) {\nconsole.error(\nchalk.bold.red(\n`\n\n❌ ${pkg.name} ERROR: pnpm publish failed on retry\n\n${retryStdError}`,\n),\n)\n}\nreturn {\nname: pkg.name,\ndetails: `Exit Code: ${retryExitCode}, stderr: ${retryStdError}`,\nsuccess: false,\n}\n}\nconsole.log(`${logPrefix} ${chalk.green(`✅ ${pkg.name} published`)}`)\nreturn { name: pkg.name, success: true }\n} catch (err: unknown) {\nconsole.error(err)\nreturn {\nname: pkg.name,\ndetails:\nerr instanceof Error\n? `Error publishing ${pkg.name}: ${err.message}`\n: `Unexpected error publishing ${pkg.name}: ${JSON.stringify(err)}`,\nsuccess: false,\n}\n}\n}"
"async function writeEnvExample({\ndbType,\ndestDir,\nenvNames,\n}: {\ndbType: DbType\ndestDir: string\nenvNames?: TemplateVariation['envNames']\n}) {\nconst envExamplePath = path.join(destDir, '.env.example')\nconst envFileContents = await fs.readFile(envExamplePath, 'utf8')\nconst fileContents = envFileContents\n.split('\n')\n.filter((l) => {\nif (\ndbType === 'vercel-postgres' &&\n(l.startsWith('# Or use a PG connection string') ||\nl.startsWith('#DATABASE_URI=postgresql:\n) {\nreturn false\n}\nreturn true\n})\n.map((l) => {\nif (l.startsWith('DATABASE_URI')) {\nif (dbType === 'mongodb') {\nl = 'MONGODB_URI=mongodb:\n}\nif (dbType.includes('postgres')) {\nl = 'DATABASE_URI=postgresql:\n}\nif (envNames?.dbUri) {\nl = l.replace('DATABASE_URI', envNames.dbUri)\n}\n}\nreturn l\n})\n.filter((l) => l.trim() !== '')\n.join('\n')\nconsole.log(`Writing to ${envExamplePath}`)\nawait fs.writeFile(envExamplePath, fileContents)\n}"
"async function main() {\nconst all = process.argv.includes('--all')\nprocess.argv = process.argv.filter((arg) => arg !== '--all')\nconst noBuild = process.argv.includes('--no-build')\nprocess.argv = process.argv.filter((arg) => arg !== '--no-build')\nconst args = minimist(process.argv.slice(2))\nconst { dest } = args\nif (!dest) {\nthrow new Error('--dest is required')\n}\nconst resolvedDest = path.resolve(path.isAbsolute(dest) ? dest : path.join(PROJECT_ROOT, dest))\nconst packageWhitelist = all\n? undefined\n: [\n'payload',\n'db-mongodb',\n'db-postgres',\n'db-d1-sqlite',\n'db-sqlite',\n'db-vercel-postgres',\n'drizzle',\n'graphql',\n'live-preview-react',\n'next',\n'payload-cloud',\n'plugin-form-builder',\n'plugin-ecommerce',\n'plugin-nested-docs',\n'plugin-redirects',\n'plugin-search',\n'plugin-seo',\n'richtext-lexical',\n'translations',\n'ui',\n]\nconst packageDetails = await getPackageDetails(packageWhitelist)\nheader(`\n🔨 Prebuilding all packages...`)\nconst filtered = packageDetails.filter((p): p is Exclude<typeof p, null> => p !== null)\nif (!noBuild) {\nexecSync('pnpm build:all --output-logs=errors-only', execOpts)\n}\nheader(`\nOutputting ${filtered.length} packages...\n${chalk.white.bold(listPackages(filtered))}`)\nheader(`\n📦 Packing all packages to ${resolvedDest}...`)\nawait Promise.all(\nfiltered.map(async (p) => {\nawait exec(`pnpm pack -C ${p.packagePath} --pack-destination ${resolvedDest}`, execOpts)\n}),\n)\nheader(`\n🎉 Done!`)\n}"
"function configureShardingOrFallbackTo(\nfallback: ViteUserConfig,\n): ViteUserConfig {\nconst shardKey = process.env.TEST_SHARD;\nif (!shardKey) {\nreturn fallback;\n}\nif (!testShards[shardKey]) {\nconst keys = Object.keys(testShards).join(', ');\nthrow new Error(\n`Unknown value for TEST_SHARD: ${shardKey} (possible values: ${keys})`,\n);\n}\nconst include: string[] = [];\nconst exclude: string[] = [...defaultExclude];\nfor (const [key, { matchPaths: patterns }] of Object.entries(testShards)) {\nif (key === shardKey) {\nconst testMatchPatterns = patterns.map((pattern) => {\nconst filePattern = normalizePattern(pattern, '.spec.ts');\nreturn filePattern;\n});\ninclude.push(...testMatchPatterns);\nbreak;\n}\nconst testMatchPatterns = patterns.map((pattern) => {\nconst filePattern = normalizePattern(pattern, '.spec.ts');\nreturn `**/${filePattern}`;\n});\nexclude.push(...testMatchPatterns);\n}\nconst reportsDirectory = `./coverage/shard/${shardKey}`;\nreturn {\ntest: {\ninclude,\nexclude,\noutputFile: `./coverage/shard/${shardKey}/junit.xml`,\ncoverage: {\nreportsDirectory,\n},\n},\n};\n}"
"function missingHttpMockMessage(\ndone: RequestLog[],\nmissing: MissingRequestLog[],\npending: string[],\n): string {\nconst blocks: string[] = [];\nconst title = codeBlock`\n*** Missing HTTP mocks ***\n`;\nconst explanation = codeBlock`\n---\nRenovate testing strategy requires that every HTTP request\nhas a corresponding mock.\nThis error occurs when some of the request aren't mocked.\nLet's suppose your code performs two HTTP calls:\nGET   https:\nPOST  https:\nThe unit test should have this mock:\nhttpMock.scope('https:\n.get('/fail')\n.reply(404)\n.post('/success')\n.reply(200, { ok: true });\nNote: \`httpMock.scope(...)\` is the Renovate-specific construct.\nThe scope object itself is provided by the \`nock\` library.\nDetails: https:\n+++\n`;\nblocks.push(title);\nblocks.push(codeBlock`\n${missing.map(({ method, url }) => `- ${method} ${url}`).join('\n')}\n`);\nif (done.length) {\nblocks.push(codeBlock`\nRequests done:\n${done.map(({ method, url, status }) => `- ${method} ${url} [${status}]`).join('\n')}\n`);\n}\nif (pending.length) {\nblocks.push(codeBlock`\nPending mocks:\n${pending.join('\n')}\n`);\n}\nblocks.push(explanation);\nreturn blocks.join('\n\n');\n}"
"async toMigrate(\nCustomMigration: MigrationConstructor,\noriginalConfig: RenovateConfig,\nexpectedConfig: RenovateConfig,\nisMigrated = true,\n) {\nconst { MigrationsService } = await import(\n'./../lib/config/migrations/migrations-service.js'\n);\nclass CustomMigrationsService extends MigrationsService {\npublic static override getMigrations(\noriginal: RenovateConfig,\nmigrated: RenovateConfig,\n): readonly Migration[] {\nreturn [new CustomMigration(original, migrated)];\n}\n}\nconst migratedConfig = CustomMigrationsService.run(originalConfig);\nif (\nMigrationsService.isMigrated(migratedConfig, originalConfig) !==\nisMigrated\n) {\nreturn {\nmessage: (): string => `isMigrated should be ${isMigrated}`,\npass: false,\n};\n}\nif (!this.equals(migratedConfig, expectedConfig)) {\nreturn {\nmessage: (): string =>\n`Migration failed\n\nReceived config:\n${JSON.stringify(\nmigratedConfig,\n)}\n\nExpected config:\n${JSON.stringify(expectedConfig)}`,\npass: false,\n};\n}\nreturn {\nmessage: (): string => 'Migration passed successfully',\npass: true,\n};\n},"
"async function generateHash() {\nconsole.log('generating hashes');\ntry {\nconst hashMap = `export const hashMap = new Map<string, string>();`;\nlet hashes = [];\nconst managers = (\nawait fs.readdir('lib/modules/manager', { withFileTypes: true })\n)\n.filter((file) => file.isDirectory())\n.map((file) => file.name)\n.filter((mgr) => mgr !== 'custom');\nconst customManagers = (\nawait fs.readdir('lib/modules/manager/custom', { withFileTypes: true })\n)\n.filter((file) => file.isDirectory())\n.map((file) => file.name);\nfor (const manager of managers) {\nconst hash = await getManagerHash(manager, false);\nhashes.push({ manager, hash });\n}\nfor (const manager of customManagers) {\nconst hash = await getManagerHash(manager, true);\nhashes.push({ manager, hash });\n}\nconst hashStrings = hashes.map(\n({ manager, hash }) => `hashMap.set('${manager}','${hash}');`,\n);\nawait updateFile(\n'lib/modules/manager/fingerprint.generated.ts',\n[hashMap, hashStrings.join('\n')].join('\n\n'),\n);\n} catch (err) {\nconsole.log('ERROR:', err.message);\nprocess.exit(1);\n}\n}"
"async function validateDataFilesAgainstSchemas(): Promise<void> {\nconst filesAndSchemasToValidate: {\nschemaFilename: string;\nfilename: string;\n}[] = [\n{\nschemaFilename: 'tools/schemas/abandonments-schema.json',\nfilename: 'lib/data/abandonments.json',\n},\n{\nschemaFilename: 'tools/schemas/changelog-urls-schema.json',\nfilename: 'lib/data/changelog-urls.json',\n},\n{\nschemaFilename: 'tools/schemas/monorepo-schema.json',\nfilename: 'lib/data/monorepo.json',\n},\n{\nschemaFilename: 'tools/schemas/replacements-schema.json',\nfilename: 'lib/data/replacements.json',\n},\n{\nschemaFilename: 'tools/schemas/source-urls-schema.json',\nfilename: 'lib/data/source-urls.json',\n},\n];\nconst failed: {\nschemaFilename: string;\nfilename: string;\nerrors: ErrorObject[];\n}[] = [];\nfor (const filename of filesAndSchemasToValidate) {\nconst errors = await validateFileAgainstSchemaFromFile(\nfilename.schemaFilename,\nfilename.filename,\n);\nif (errors) {\nfailed.push({ ...filename, errors });\n} else {\nconsole.log(\n`${filename.filename} validated correctly against schema from ${filename.schemaFilename}!`,\n);\n}\n}\nif (failed.length > 0) {\nfor (const f of failed) {\nconsole.error(\n`${f.filename} failed to validate against schema from ${f.schemaFilename}:`,\nf.errors,\n);\n}\nprocess.exit(1);\n}\n}"
"export async function migrateAndValidate(\nconfig: RenovateConfig,\ninput: RenovateConfig,\n): Promise<RenovateConfig> {\nlogger.debug('migrateAndValidate()');\ntry {\nconst { isMigrated, migratedConfig } = configMigration.migrateConfig(input);\nif (isMigrated) {\nlogger.debug(\n{ oldConfig: input, newConfig: migratedConfig },\n'Config migration necessary',\n);\n} else {\nlogger.debug('No config migration necessary');\n}\nconst massagedConfig = configMassage.massageConfig(migratedConfig);\nif (!dequal(input, massagedConfig)) {\nlogger.debug({ config: massagedConfig }, 'Post-massage config');\n}\nconst {\nwarnings,\nerrors,\n}: {\nwarnings: ValidationMessage[];\nerrors: ValidationMessage[];\n} = await configValidation.validateConfig('repo', massagedConfig);\nif (isNonEmptyArray(warnings)) {\nlogger.warn({ warnings }, 'Found renovate config warnings');\n}\nif (isNonEmptyArray(errors)) {\nlogger.info({ errors }, 'Found renovate config errors');\n}\nmassagedConfig.errors = (config.errors ?? []).concat(errors);\nif (!config.repoIsOnboarded) {\nmassagedConfig.warnings = (config.warnings ?? []).concat(warnings);\n}\nreturn massagedConfig;\n} catch (err) {\nlogger.debug({ config: input }, 'migrateAndValidate error');\nthrow err;\n}\n}"
"export function parseFileConfig(\nfileName: string,\nfileContents: string,\n):\n| { success: true; parsedContents: unknown }\n| { success: false; validationError: string; validationMessage: string } {\nconst fileType = upath.extname(fileName);\nif (fileType === '.json5') {\ntry {\nreturn { success: true, parsedContents: JSON5.parse(fileContents) };\n} catch (err) {\nlogger.debug({ fileName, fileContents }, 'Error parsing JSON5 file');\nconst validationError = 'Invalid JSON5 (parsing failed)';\nconst validationMessage = `JSON5.parse error: \`${err.message.replaceAll(\n'`',\n`'`,\n)}\``;\nreturn {\nsuccess: false,\nvalidationError,\nvalidationMessage,\n};\n}\n} else {\nconst jsonString = stripJsonComments(fileContents);\nlet allowDuplicateKeys = true;\nlet jsonValidationError = jsonValidator.validate(\njsonString,\nallowDuplicateKeys,\n);\nif (jsonValidationError) {\nconst validationError = 'Invalid JSON (parsing failed)';\nconst validationMessage = jsonValidationError;\nreturn {\nsuccess: false,\nvalidationError,\nvalidationMessage,\n};\n}\nallowDuplicateKeys = false;\njsonValidationError = jsonValidator.validate(\njsonString,\nallowDuplicateKeys,\n);\nif (jsonValidationError) {\nconst validationError = 'Duplicate keys in JSON';\nconst validationMessage = JSON.stringify(jsonValidationError);\nreturn {\nsuccess: false,\nvalidationError,\nvalidationMessage,\n};\n}\ntry {\nreturn {\nsuccess: true,\nparsedContents: parseJson(fileContents, fileName),\n};\n} catch (err) {\nlogger.debug({ fileContents }, 'Error parsing renovate config');\nconst validationError = 'Invalid JSON (parsing failed)';\nconst validationMessage = `JSON.parse error:  \`${err.message.replaceAll(\n'`',\n`'`,\n)}\``;\nreturn { success: false, validationError, validationMessage };\n}\n}\n}"
"export function mergeChildConfig<\nT extends Record<string, any>,\nTChild extends Record<string, any> | undefined,\n>(parent: T, child: TChild): T & TChild {\nlogger.trace({ parent, child }, `mergeChildConfig`);\nif (!child) {\nreturn parent as never;\n}\nconst parentConfig = clone(parent);\nconst childConfig = clone(child);\nconst config: Record<string, any> = { ...parentConfig, ...childConfig };\nif (config?.isVulnerabilityAlert) {\nconfig.vulnerabilitySeverity = getHighestVulnerabilitySeverity(\nparent,\nchild,\n);\n}\nfor (const option of options.getOptions()) {\nif (\noption.mergeable &&\nchildConfig[option.name] &&\nparentConfig[option.name]\n) {\nlogger.trace(`mergeable option: ${option.name}`);\nif (option.name === 'constraints') {\nconfig[option.name] = {\n...parentConfig[option.name],\n...childConfig[option.name],\n};\n} else if (option.type === 'array') {\nconfig[option.name] = (parentConfig[option.name] as unknown[]).concat(\nconfig[option.name],\n);\n} else {\nconfig[option.name] = mergeChildConfig(\nparentConfig[option.name] as RenovateConfig,\nchildConfig[option.name] as RenovateConfig,\n);\n}\nlogger.trace(\n{ result: config[option.name] },\n`Merged config.${option.name}`,\n);\n}\n}\nreturn { ...config, ...config.force };\n}"
"export function init(): void {\nif (!isTracingEnabled()) {\nreturn;\n}\nconst spanProcessors: SpanProcessor[] = [];\nif (isTraceDebuggingEnabled()) {\nspanProcessors.push(new SimpleSpanProcessor(new ConsoleSpanExporter()));\n}\nif (isTraceSendingEnabled()) {\nconst exporter = new OTLPTraceExporter();\nspanProcessors.push(new BatchSpanProcessor(exporter));\n}\nconst env = getEnv();\nconst baseResource = resourceFromAttributes({\n[ATTR_SERVICE_NAME]: env.OTEL_SERVICE_NAME ?? 'renovate',\n['service.namespace']: env.OTEL_SERVICE_NAMESPACE ?? 'renovatebot.com',\n[ATTR_SERVICE_VERSION]: env.OTEL_SERVICE_VERSION ?? pkg.version,\n});\nconst detectedResource = detectResources({\ndetectors: [\nawsBeanstalkDetector,\nawsEc2Detector,\nawsEcsDetector,\nawsEksDetector,\nawsLambdaDetector,\nazureAppServiceDetector,\nazureFunctionsDetector,\nazureVmDetector,\ngcpDetector,\ngitHubDetector,\nenvDetector,\n],\n});\nconst traceProvider = new NodeTracerProvider({\nresource: baseResource.merge(detectedResource),\nspanProcessors,\n});\nconst contextManager = new AsyncLocalStorageContextManager();\ntraceProvider.register({\ncontextManager,\n});\ninstrumentations = [\nnew HttpInstrumentation({\napplyCustomAttributesOnSpan: (span, request, response) => {\nif (\nrequest instanceof ClientRequest &&\nrequest.host === `api.github.com` &&\nrequest.path.endsWith(`/protection`) &&\nresponse.statusCode === 404\n) {\nspan.setStatus({ code: SpanStatusCode.OK });\n}\n},\n}),\nnew BunyanInstrumentation(),\nnew RedisInstrumentation(),\n];\nregisterInstrumentations({\ninstrumentations,\n});\n}"
"export async function exportStats(config: RenovateConfig): Promise<void> {\ntry {\nif (isNullOrUndefined(config.reportType)) {\nreturn;\n}\nif (config.reportType === 'logging') {\nlogger.info({ report }, 'Printing report');\nreturn;\n}\nif (config.reportType === 'file') {\nconst path = config.reportPath!;\nawait writeSystemFile(path, JSON.stringify(report));\nlogger.debug({ path }, 'Writing report');\nreturn;\n}\nif (config.reportType === 's3') {\nconst s3Url = parseS3Url(config.reportPath!);\nif (isNullOrUndefined(s3Url)) {\nlogger.warn(\n{ reportPath: config.reportPath },\n'Failed to parse s3 URL',\n);\nreturn;\n}\nconst s3Params: PutObjectCommandInput = {\nBucket: s3Url.Bucket,\nKey: s3Url.Key,\nBody: JSON.stringify(report),\nContentType: 'application/json',\n};\nconst client = getS3Client(config.s3Endpoint, config.s3PathStyle);\nconst command = new PutObjectCommand(s3Params);\nawait client.send(command);\n}\n} catch (err) {\nlogger.warn({ err }, 'Reporting.exportStats() - failure');\n}\n}"
"export default function prepareError(err: Error): Record<string, unknown> {\nif (err instanceof ZodError) {\nreturn prepareZodError(err);\n}\nconst response: Record<string, unknown> = {\n...err,\n};\nif (!response.message && err.message) {\nresponse.message = err.message;\n}\nif (!response.stack && err.stack) {\nresponse.stack = err.stack;\n}\nif (err instanceof AggregateError) {\nresponse.errors = err.errors.map((error) => prepareError(error));\n}\nif (err instanceof ExecError && isNonEmptyObject(err.options?.env)) {\nconst env = Object.keys(err.options.env);\nresponse.options = { ...err.options, env };\n}\nif (err instanceof HttpError) {\nconst options: Record<string, unknown> = {\nheaders: structuredClone(err.options.headers),\nurl: err.options.url?.toString(),\nhostType: err.options.context.hostType,\n};\nresponse.options = options;\noptions.username = err.options.username;\noptions.password = err.options.password;\noptions.method = err.options.method;\noptions.http2 = err.options.http2;\nif (err.response) {\nresponse.response = {\nstatusCode: err.response.statusCode,\nstatusMessage: err.response.statusMessage,\nbody:\nerr.name === 'TimeoutError'\n? undefined\n: structuredClone(err.response.body),\nheaders: structuredClone(err.response.headers),\nhttpVersion: err.response.httpVersion,\nretryCount: err.response.retryCount,\n};\n}\n}\nreturn response;\n}"
"export function sanitizeValue(\nvalue: unknown,\nseen = new WeakMap<NestedValue, unknown>(),\n): any {\nif (isString(value)) {\nreturn sanitize(sanitizeUrls(value));\n}\nif (isDate(value)) {\nreturn value;\n}\nif (isFunction(value)) {\nreturn '[function]';\n}\nif (isBuffer(value)) {\nreturn '[content]';\n}\nif (isError(value)) {\nconst err = prepareError(value);\nreturn sanitizeValue(err, seen);\n}\nif (isArray(value)) {\nconst length = value.length;\nconst arrayResult = Array(length);\nseen.set(value, arrayResult);\nfor (let idx = 0; idx < length; idx += 1) {\nconst val = value[idx];\narrayResult[idx] =\nisNested(val) && seen.has(val)\n? seen.get(val)\n: sanitizeValue(val, seen);\n}\nreturn arrayResult;\n}\nif (isObject(value)) {\nconst objectResult: Record<string, any> = {};\nseen.set(value, objectResult);\nfor (const [key, val] of Object.entries<any>(value)) {\nlet curValue: any;\nif (!val) {\ncurValue = val;\n} else if (redactedFields.includes(key)) {\nif (isString(val) && regEx(/^{{\s*secrets\..*}}$/).test(val)) {\ncurValue = val;\n} else {\ncurValue = '***********';\n}\n} else if (contentFields.includes(key)) {\ncurValue = '[content]';\n} else if (key === 'secrets') {\ncurValue = {};\nObject.keys(val).forEach((secretKey) => {\ncurValue[secretKey] = '***********';\n});\n} else {\ncurValue = seen.has(val) ? seen.get(val) : sanitizeValue(val, seen);\n}\nconst sanitizedKey = sanitizeValue(key, seen);\nobjectResult[sanitizedKey] = curValue;\n}\nreturn objectResult;\n}\nreturn value;\n}"
"export function withSanitizer(streamConfig: bunyan.Stream): bunyan.Stream {\nif (streamConfig.type === 'rotating-file') {\nthrow new Error(`Rotating files aren't supported`);\n}\nconst stream = streamConfig.stream as BunyanStream;\nif (stream?.writable) {\nconst write = (\nchunk: BunyanRecord,\nenc: BufferEncoding,\ncb: (err?: Error | null) => void,\n): void => {\nconst raw = sanitizeValue(chunk);\nconst result =\nstreamConfig.type === 'raw'\n? raw\n: JSON.stringify(raw, bunyan.safeCycles()).replace(\nregEx(/\n?$/),\n'\n',\n);\nstream.write(result, enc, cb);\n};\nreturn {\n...streamConfig,\ntype: 'raw',\nstream: { write },\n} as bunyan.Stream;\n}\nif (streamConfig.path) {\nconst fileStream = fs.createWriteStream(streamConfig.path, {\nflags: 'a',\nencoding: 'utf8',\n});\nreturn withSanitizer({ ...streamConfig, stream: fileStream });\n}\nthrow new Error(`Missing 'stream' or 'path' for bunyan stream`);\n}"
"export function checkGithubToken(\npackageFiles: Record<string, PackageFileContent[]> = {},\n): void {\nconst { token } = hostRules.find({\nhostType: 'github',\nurl: 'https:\n});\nif (token) {\nlogger.trace('GitHub token is found');\nreturn;\n}\nif (!GlobalConfig.get('githubTokenWarn')) {\nlogger.trace('GitHub token warning is disabled');\nreturn;\n}\nconst githubDeps: string[] = [];\nconst deps = Object.values(packageFiles)\n.flat()\n.map((file) => file.deps)\n.flat();\nfor (const dep of deps) {\nif (\n!dep.skipReason &&\n(dep.datasource === GithubTagsDatasource.id ||\ndep.datasource === GithubReleasesDatasource.id ||\ndep.datasource === GithubReleaseAttachmentsDatasource.id)\n) {\ndep.skipReason = 'github-token-required';\nif (dep.depName) {\ngithubDeps.push(dep.depName);\n}\n}\n}\nif (githubDeps.length > 0) {\nconst warningLogged = memCache.get<boolean | undefined>(\n'github-token-required-warning-logged',\n);\nif (!warningLogged) {\nconst withoutDuplicates = [...new Set(githubDeps)];\nlogger.warn(\n{ githubDeps: withoutDuplicates },\n`GitHub token is required for some dependencies`,\n);\nmemCache.set('github-token-required-warning-logged', true);\n}\n}\n}"
"export function takePersonalAccessTokenIfPossible(\ngithubToken: string | undefined,\ngitTagsGithubToken: string | undefined,\n): string | undefined {\nif (gitTagsGithubToken && isGithubPersonalAccessToken(gitTagsGithubToken)) {\nlogger.debug('Using GitHub Personal Access Token (git-tags)');\nreturn gitTagsGithubToken;\n}\nif (githubToken && isGithubPersonalAccessToken(githubToken)) {\nlogger.debug('Using GitHub Personal Access Token');\nreturn githubToken;\n}\nif (\ngitTagsGithubToken &&\nisGithubFineGrainedPersonalAccessToken(gitTagsGithubToken)\n) {\nlogger.debug('Using GitHub Fine-grained Personal Access Token (git-tags)');\nreturn gitTagsGithubToken;\n}\nif (githubToken && isGithubFineGrainedPersonalAccessToken(githubToken)) {\nlogger.debug('Using GitHub Fine-grained Personal Access Token');\nreturn githubToken;\n}\nif (gitTagsGithubToken) {\nif (isGithubServerToServerToken(gitTagsGithubToken)) {\nlogger.debug('Using GitHub Server-to-Server token (git-tags)');\n} else {\nlogger.debug('Using unknown GitHub token type (git-tags)');\n}\nreturn gitTagsGithubToken;\n}\nif (githubToken) {\nif (isGithubServerToServerToken(githubToken)) {\nlogger.debug('Using GitHub Server-to-Server token');\n} else {\nlogger.debug('Using unknown GitHub token type');\n}\n}\nreturn githubToken;\n}"
"export function detectPlatform(\nurl: string,\n):\n| 'azure'\n| 'bitbucket'\n| 'bitbucket-server'\n| 'forgejo'\n| 'gitea'\n| 'github'\n| 'gitlab'\n| null {\nconst { hostname } = parseUrl(url) ?? {};\nif (hostname === 'dev.azure.com' || hostname?.endsWith('.visualstudio.com')) {\nreturn 'azure';\n}\nif (hostname === 'bitbucket.org' || hostname === 'bitbucket.com') {\nreturn 'bitbucket';\n}\nif (hostname?.includes('bitbucket')) {\nreturn 'bitbucket-server';\n}\nif (hostname?.includes('forgejo')) {\nreturn 'forgejo';\n}\nif (hostname && ['codeberg.org', 'codefloe.com'].includes(hostname)) {\nreturn 'forgejo';\n}\nif (\nhostname &&\n(['gitea.com'].includes(hostname) || hostname.includes('gitea'))\n) {\nreturn 'gitea';\n}\nif (hostname === 'github.com' || hostname?.includes('github')) {\nreturn 'github';\n}\nif (hostname === 'gitlab.com' || hostname?.includes('gitlab')) {\nreturn 'gitlab';\n}\nconst hostType = hostRules.hostType({ url });\nif (!hostType) {\nreturn null;\n}\nif (AZURE_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'azure';\n}\nif (BITBUCKET_SERVER_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'bitbucket-server';\n}\nif (BITBUCKET_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'bitbucket';\n}\nif (FORGEJO_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'forgejo';\n}\nif (GITEA_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'gitea';\n}\nif (GITHUB_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'github';\n}\nif (GITLAB_API_USING_HOST_TYPES.includes(hostType)) {\nreturn 'gitlab';\n}\nreturn null;\n}"
"export function find(search: HostRuleSearch): CombinedHostRule {\nif ([search.hostType, search.url].every(isFalsy)) {\nlogger.warn({ search }, 'Invalid hostRules search');\nreturn {};\n}\nconst sortedRules = hostRules\n.sort(fromShorterToLongerMatchHost)\n.sort(fromLowerToHigherRank);\nconst matchedRules: HostRule[] = [];\nfor (const rule of sortedRules) {\nlet hostTypeMatch = true;\nlet hostMatch = true;\nlet readOnlyMatch = true;\nif (rule.hostType) {\nhostTypeMatch = false;\nif (search.hostType === rule.hostType) {\nhostTypeMatch = true;\n}\n}\nif (rule.matchHost && rule.resolvedHost) {\nhostMatch = false;\nif (search.url) {\nhostMatch = matchesHost(search.url, rule.matchHost);\n}\n}\nif (!isUndefined(rule.readOnly)) {\nreadOnlyMatch = false;\nif (search.readOnly === rule.readOnly) {\nreadOnlyMatch = true;\nhostTypeMatch = true;\n}\n}\nif (hostTypeMatch && readOnlyMatch && hostMatch) {\nmatchedRules.push(clone(rule));\n}\n}\nconst res: HostRule = Object.assign({}, ...matchedRules);\ndelete res.hostType;\ndelete res.resolvedHost;\ndelete res.matchHost;\ndelete res.readOnly;\nreturn res;\n}"
"export function replaceInterpolatedValuesInObject(\nconfig_: RenovateConfig,\ninput: Record<string, string>,\noptions: InterpolatorOptions,\ndeleteValues = true,\n): RenovateConfig {\nconst config = { ...config_ };\nconst { name } = options;\nif (deleteValues) {\ndelete config[name];\n}\nfor (const [key, value] of Object.entries(config)) {\nif (isPlainObject(value)) {\nconfig[key] = replaceInterpolatedValuesInObject(\nvalue,\ninput,\noptions,\ndeleteValues,\n);\n}\nif (isString(value)) {\nconfig[key] = replaceInterpolatedValuesInString(\nkey,\nvalue,\ninput,\noptions,\n);\n}\nif (isArray(value)) {\nfor (const [arrayIndex, arrayItem] of value.entries()) {\nif (isPlainObject(arrayItem)) {\nvalue[arrayIndex] = replaceInterpolatedValuesInObject(\narrayItem,\ninput,\noptions,\ndeleteValues,\n);\n} else if (isString(arrayItem)) {\nvalue[arrayIndex] = replaceInterpolatedValuesInString(\nkey,\narrayItem,\ninput,\noptions,\n);\n}\n}\n}\n}\nreturn config;\n}"
"transform<U extends Val, EE extends Val, Input = unknown>(\nfn: (\nvalue: T,\n) =>\n| Result<U, E | EE>\n| AsyncResult<U, E | EE>\n| SafeParseReturnType<Input, NonNullable<U>>\n| Promise<SafeParseReturnType<Input, NonNullable<U>>>\n| Promise<Result<U, E | EE>>\n| Promise<RawValue<U>>\n| RawValue<U>,\n):\n| Result<U, E | EE | ZodError<Input>>\n| AsyncResult<U, E | EE | ZodError<Input>> {\nif (!this.res.ok) {\nreturn Result.err(this.res.err);\n}\ntry {\nconst result = fn(this.res.val);\nif (result instanceof Result) {\nreturn result;\n}\nif (result instanceof AsyncResult) {\nreturn result;\n}\nif (isZodResult<Input, U>(result)) {\nreturn fromZodResult(result);\n}\nif (result instanceof Promise) {\nreturn AsyncResult.wrap(result, (err) => {\nlogger.warn({ err }, 'Result: unhandled async transform error');\nreturn Result._uncaught(err);\n});\n}\nreturn Result.ok(result);\n} catch (err) {\nlogger.warn({ err }, 'Result: unhandled transform error');\nreturn Result._uncaught(err);\n}\n}"
"transform<U extends Val, EE extends Val, Input = unknown>(\nfn: (\nvalue: T,\n) =>\n| Result<U, E | EE>\n| AsyncResult<U, E | EE>\n| SafeParseReturnType<Input, NonNullable<U>>\n| Promise<SafeParseReturnType<Input, NonNullable<U>>>\n| Promise<Result<U, E | EE>>\n| Promise<RawValue<U>>\n| RawValue<U>,\n): AsyncResult<U, E | EE | ZodError<Input>> {\nreturn new AsyncResult(\nthis.asyncResult\n.then((oldResult) => {\nconst { ok, val: value, err: error } = oldResult.unwrap();\nif (!ok) {\nreturn Result.err(error);\n}\ntry {\nconst result = fn(value);\nif (result instanceof Result) {\nreturn result;\n}\nif (result instanceof AsyncResult) {\nreturn result;\n}\nif (isZodResult<Input, U>(result)) {\nreturn fromZodResult(result);\n}\nif (result instanceof Promise) {\nreturn AsyncResult.wrap(result, (err) => {\nlogger.warn(\n{ err },\n'AsyncResult: unhandled async transform error',\n);\nreturn Result._uncaught(err);\n});\n}\nreturn Result.ok(result);\n} catch (err) {\nlogger.warn({ err }, 'AsyncResult: unhandled transform error');\nreturn Result._uncaught(err);\n}\n})\n.catch((err) => {\nreturn Result._uncaught(err);\n}),\n);\n}"
"static getReport(): DatasourceCacheReport {\nconst data = this.getData();\nconst result: DatasourceCacheReport = { long: {}, short: {} };\nfor (const { datasource, registryUrl, packageName, action } of data) {\nresult.long[datasource] ??= {};\nresult.long[datasource][registryUrl] ??= {};\nresult.long[datasource][registryUrl] ??= {};\nresult.long[datasource][registryUrl][packageName] ??= {};\nresult.short[datasource] ??= {};\nresult.short[datasource][registryUrl] ??= {\nhit: 0,\nmiss: 0,\nset: 0,\nskip: 0,\n};\nif (action === 'hit') {\nresult.long[datasource][registryUrl][packageName].read = 'hit';\nresult.short[datasource][registryUrl].hit += 1;\ncontinue;\n}\nif (action === 'miss') {\nresult.long[datasource][registryUrl][packageName].read = 'miss';\nresult.short[datasource][registryUrl].miss += 1;\ncontinue;\n}\nif (action === 'set') {\nresult.long[datasource][registryUrl][packageName].write = 'set';\nresult.short[datasource][registryUrl].set += 1;\ncontinue;\n}\nif (action === 'skip') {\nresult.long[datasource][registryUrl][packageName].write = 'skip';\nresult.short[datasource][registryUrl].skip += 1;\ncontinue;\n}\n}\nreturn result;\n}"
"static getReport(): HttpStatsCollection {\nconst dataPoints = HttpStats.getDataPoints();\nconst requests = dataPoints.length;\nconst urls: UrlHttpStat = {};\nconst rawRequests: string[] = [];\nconst hostRequests: Record<string, HttpRequestStatsDataPoint[]> = {};\nfor (const dataPoint of dataPoints) {\nconst { url, reqMs, queueMs, status } = dataPoint;\nconst method = dataPoint.method.toUpperCase();\nconst parsedUrl = parseUrl(url);\nif (!parsedUrl) {\nlogger.debug({ url }, 'Failed to parse URL during stats reporting');\ncontinue;\n}\nconst { hostname, origin, pathname } = parsedUrl;\nconst baseUrl = `${origin}${pathname}`;\nurls[baseUrl] ??= {};\nurls[baseUrl][method] ??= {};\nurls[baseUrl][method][status] ??= 0;\nurls[baseUrl][method][status] += 1;\nrawRequests.push(`${method} ${url} ${status} ${reqMs} ${queueMs}`);\nhostRequests[hostname] ??= [];\nhostRequests[hostname].push(dataPoint);\n}\nconst hosts: Record<string, HostStatsData> = {};\nfor (const [hostname, dataPoints] of Object.entries(hostRequests)) {\nconst count = dataPoints.length;\nconst reqTimes = dataPoints.map((r) => r.reqMs);\nconst queueTimes = dataPoints.map((r) => r.queueMs);\nconst reqReport = makeTimingReport(reqTimes);\nconst queueReport = makeTimingReport(queueTimes);\nhosts[hostname] = {\ncount,\nreqAvgMs: reqReport.avgMs,\nreqMedianMs: reqReport.medianMs,\nreqMaxMs: reqReport.maxMs,\nqueueAvgMs: queueReport.avgMs,\nqueueMedianMs: queueReport.medianMs,\nqueueMaxMs: queueReport.maxMs,\n};\n}\nreturn {\nurls,\nrawRequests,\nhostRequests,\nhosts,\nrequests,\n};\n}"
"export function stripTemplates(content: string): string {\nconst result: string[] = [];\nconst len = content.length;\nlet idx = 0;\nlet lastPos = 0;\nwhile (idx < len) {\nif (content[idx] === '{' && idx + 1 < len) {\nlet closing: string | undefined;\nlet skipLength = 0;\nif (content[idx + 1] === '%') {\nif (idx + 2 < len && content[idx + 2] === '`') {\nclosing = '`%}';\nskipLength = 3;\n} else {\nclosing = '%}';\nskipLength = 2;\n}\n} else if (content[idx + 1] === '{') {\nif (idx + 2 < len && content[idx + 2] === '`') {\nclosing = '`}}';\nskipLength = 3;\n} else {\nclosing = '}}';\nskipLength = 2;\n}\n} else if (content[idx + 1] === '#') {\nclosing = '#}';\nskipLength = 2;\n}\nif (closing) {\nconst end = content.indexOf(closing, idx + skipLength);\nif (end !== -1) {\nif (idx > lastPos) {\nresult.push(content.slice(lastPos, idx));\n}\nidx = end + closing.length;\nlastPos = idx;\ncontinue;\n}\n}\n}\nidx++;\n}\nif (lastPos < len) {\nresult.push(content.slice(lastPos));\n}\nreturn result.join('');\n}"
"export function asTimestamp(input: unknown): Timestamp | null {\nif (input instanceof Date) {\nconst date = DateTime.fromJSDate(input, { zone: 'UTC' });\nif (isValid(date)) {\nreturn date.toISO() as Timestamp;\n}\nreturn null;\n}\nif (typeof input === 'number') {\nconst millisDate = DateTime.fromMillis(input, { zone: 'UTC' });\nif (isValid(millisDate)) {\nreturn millisDate.toISO() as Timestamp;\n}\nconst secondsDate = DateTime.fromSeconds(input, { zone: 'UTC' });\nif (isValid(secondsDate)) {\nreturn secondsDate.toISO() as Timestamp;\n}\nreturn null;\n}\nif (typeof input === 'string') {\nconst isoDate = DateTime.fromISO(input, { zone: 'UTC' });\nif (isValid(isoDate)) {\nreturn isoDate.toISO() as Timestamp;\n}\nconst httpDate = DateTime.fromHTTP(input, { zone: 'UTC' });\nif (isValid(httpDate)) {\nreturn httpDate.toISO() as Timestamp;\n}\nconst sqlDate = DateTime.fromSQL(input, { zone: 'UTC' });\nif (isValid(sqlDate)) {\nreturn sqlDate.toISO() as Timestamp;\n}\nconst numberLikeDate = DateTime.fromFormat(input, 'yyyyMMddHHmmss', {\nzone: 'UTC',\n});\nif (isValid(numberLikeDate)) {\nreturn numberLikeDate.toISO() as Timestamp;\n}\nconst numberLikeOffsetDate = DateTime.fromFormat(\ninput,\n'yyyyMMddHHmmssZZZ',\n{ zone: 'UTC' },\n);\nif (isValid(numberLikeOffsetDate)) {\nreturn numberLikeOffsetDate.toISO() as Timestamp;\n}\nconst fallbackDate = DateTime.fromMillis(\nDate.parse(input) - timezoneOffset,\n{ zone: 'UTC' },\n);\nif (isValid(fallbackDate)) {\nreturn fallbackDate.toISO() as Timestamp;\n}\nreturn null;\n}\nreturn null;\n}"
"export function parseYaml<ResT = unknown>(\ncontent: string,\noptions?: YamlOptionsMultiple<ResT>,\n): ResT[] {\nconst massagedContent = massageContent(content, options);\nconst rawDocuments = parseAllDocuments(\nmassagedContent,\nprepareParseOption(options),\n);\nconst schema = options?.customSchema;\nconst results: ResT[] = [];\nfor (const rawDocument of rawDocuments) {\nconst errors = rawDocument.errors;\nif (errors?.length) {\nconst error = new AggregateError(errors, 'Failed to parse YAML file');\nif (options?.failureBehaviour === 'filter') {\nlogger.debug(`Failed to parse YAML file`);\ncontinue;\n}\nthrow error;\n}\nconst document = rawDocument.toJS({ maxAliasCount: 10000 });\nif (!schema) {\nresults.push(document as ResT);\ncontinue;\n}\nconst result = schema.safeParse(document);\nif (result.success) {\nresults.push(result.data);\ncontinue;\n}\nif (options?.failureBehaviour === 'filter') {\nlogger.trace(\n{ error: result.error, document },\n'Failed to parse schema for YAML',\n);\ncontinue;\n}\nthrow new Error('Failed to parse YAML file', { cause: result.error });\n}\nreturn results;\n}"
"export async function generateConfig(dist: string, bot = false): Promise<void> {\nlet configFile = `configuration-options.md`;\nif (bot) {\nconfigFile = `self-hosted-configuration.md`;\n}\nconst configOptionsRaw = (await readFile(`docs/usage/${configFile}`)).split(\n'\n',\n);\nconst indexed = indexMarkdown(configOptionsRaw);\noptions\n.filter(\n(option) => !!option.globalOnly === bot && !managers.has(option.name),\n)\n.forEach((option) => {\nconst el: Record<string, any> = { ...option };\nif (!indexed[option.name]) {\nthrow new Error(\n`Config option `${option.name}` is missing an entry in ${configFile}`,\n);\n}\nconst [headerIndex, footerIndex] = indexed[option.name];\nel.cli = getCliName(option);\nel.env = getEnvName(option);\nstringifyArrays(el);\nconfigOptionsRaw[headerIndex] +=\n`\n${option.description}\n\n` +\ngenTable(Object.entries(el), option.type, option.default);\nif (el.advancedUse) {\nconfigOptionsRaw[headerIndex] += generateAdvancedUse();\n}\nif (el.experimental) {\nconfigOptionsRaw[footerIndex] += genExperimentalMsg(el);\n}\nif (is.nonEmptyString(el.deprecationMsg)) {\nconfigOptionsRaw[footerIndex] += genDeprecationMsg(el);\n}\n});\nawait updateFile(`${dist}/${configFile}`, configOptionsRaw.join('\n'));\n}"
"export async function getOpenGitHubItems(): Promise<RenovateOpenItems> {\nconst result: RenovateOpenItems = {\nmanagers: {},\nplatforms: {},\ndatasources: {},\nversionings: {},\n};\nif (process.env.SKIP_GITHUB_ISSUES) {\nlogger.warn('Skipping GitHub issues');\nreturn result;\n}\nif (!process.env.GITHUB_TOKEN) {\nlogger.warn(\n'No GITHUB_TOKEN found in env, cannot fetch Github issues. Skipping...',\n);\nreturn result;\n}\nif (process.env.CI) {\nreturn result;\n}\ntry {\nconst rawItems = (await getIssuesByIssueType('Bug')).concat(\nawait getIssuesByIssueType('Feature'),\n);\nresult.managers = extractIssues(rawItems, 'manager:');\nresult.platforms = extractIssues(rawItems, 'platform:');\nresult.datasources = extractIssues(rawItems, 'datasource:');\nresult.versionings = extractIssues(rawItems, 'versioning:');\nreturn result;\n} catch (err) {\nlogger.error({ err }, 'Error getting query results');\nif (process.env.CI) {\nthrow err;\n}\nreturn result;\n}\n}"
"export async function generateDocs(\nroot = 'tmp',\npack = true,\nversion = undefined,\n): Promise<void> {\ntry {\nconst dist = `${root}/docs`;\nlogger.info(`generating docs to '${dist}'`);\nawait fs.mkdir(`${dist}/`, { recursive: true });\nlogger.info('* static');\nawait fs.copy('docs/usage/.', `${dist}`);\nlogger.info('* fetching open GitHub issues');\nconst openItems = await getOpenGitHubItems();\nlogger.info('* platforms');\nawait generatePlatforms(dist, openItems.platforms);\nlogger.info('* versionings');\nawait generateVersioning(dist, openItems.versionings);\nlogger.info('* datasources');\nawait generateDatasources(dist, openItems.datasources);\nlogger.info('* managers');\nawait generateManagers(dist, openItems.managers);\nlogger.info('* managers/asdf/supported-plugins');\nawait generateManagerAsdfSupportedPlugins(dist);\nlogger.info('* managers/mise/supported-plugins');\nawait generateManagerMiseSupportedPlugins(dist);\nlogger.info('* presets');\nawait generatePresets(dist);\nlogger.info('* templates');\nawait generateTemplates(dist);\nlogger.info('* configuration-options');\nawait generateConfig(dist);\nlogger.info('* self-hosted-configuration');\nawait generateConfig(dist, true);\nlogger.info('* json-schema');\nawait generateSchema(dist, version);\nawait generateSchema(dist, {\nfilename: 'renovate-global-schema.json',\nversion,\nisGlobal: true,\n});\nif (pack) {\nawait tar.create({ file: `${root}/docs.tgz`, cwd: dist, gzip: true }, [\n'.',\n]);\n}\n} catch (err) {\nlogger.error({ err }, 'Unexpected error');\n} finally {\nconst loggerErrors = getProblems().filter((p) => p.level >= ERROR);\nif (loggerErrors.length) {\nprocess.exit(1);\n}\n}\n}"
"export async function generatePresets(dist: string): Promise<void> {\nlet index = 0;\nfor (const [name, presetConfig] of Object.entries(presetGroups)) {\nindex += 1;\nconst formattedName = jsUcfirst(name)\n.replace('Js', 'JS')\n.replace(/s$/, '')\n.replace(/^Config$/, 'Full Config');\nconst frontMatter = generateFrontMatter(formattedName, index, name);\nlet content = `\n`;\nfor (const [preset, value] of Object.entries(presetConfig)) {\nlet header = `\n### ${name === 'default' ? '' : name}:${preset}`;\nlet presetDescription = value.description as string;\ndelete value.description;\nif (!presetDescription) {\nif (value.packageRules?.[0].description) {\npresetDescription = value.packageRules[0].description as string;\ndelete value.packageRules[0].description;\n}\n}\nlet body = '';\nif (presetDescription) {\nbody += `\n\n${presetDescription}\n`;\n} else {\nlogger.warn(\n{ preset: `${name}:${preset}` },\n'Preset has no description',\n);\n}\nbody += '\n```json\n';\nbody += JSON.stringify(value, null, 2);\nbody += '\n```\n';\nbody += '\n----\n';\nif (body.includes('{{arg0}}')) {\nheader += '(`<arg0>`';\nif (body.includes('{{arg1}}')) {\nheader += ', `<arg1>`';\nif (body.includes('{{arg2}}')) {\nheader += ', `<arg2>`';\n}\n}\nheader += ')';\nbody = body.replace(/{{(arg\d+)}}/g, '$1');\n}\ncontent += header + body;\n}\nawait updateFile(`${dist}/presets-${name}.md`, frontMatter + content);\n}\n}"
"function createSingleConfig(option: RenovateOptions): Record<string, unknown> {\nconst temp: Record<string, any> & {\ntype?: JsonSchemaType;\n} & Omit<Partial<RenovateOptions>, 'type'> = {};\nif (option.description) {\ntemp.description = option.description;\n}\ntemp.type = option.type;\nif (option.type === 'array') {\nif (option.subType) {\ntemp.items = {\ntype: option.subType,\n};\nif (hasKey('format', option) && option.format) {\ntemp.items.format = option.format;\n}\nif (option.allowedValues) {\ntemp.items.enum = option.allowedValues;\n}\n}\nif (option.subType === 'string' && option.allowString === true) {\nconst items = temp.items;\ndelete temp.items;\ndelete temp.type;\ntemp.oneOf = [{ type: 'array', items }, { ...items }];\n}\n} else {\nif (hasKey('format', option) && option.format) {\ntemp.format = option.format;\n}\nif (option.name === 'versioning') {\ntemp.oneOf = [\n{ enum: option.allowedValues },\n{ type: 'string', pattern: '^regex:' },\n];\n} else if (option.allowedValues) {\ntemp.enum = option.allowedValues;\n}\n}\nif (option.default !== undefined) {\ntemp.default = option.default;\n}\nif (\nhasKey('additionalProperties', option) &&\noption.additionalProperties !== undefined\n) {\ntemp.additionalProperties = option.additionalProperties;\n}\nif (option.default === null) {\ntemp.type = [option.type, 'null'];\n}\nif (\n(temp.type === 'object' || temp.type?.includes('object')) &&\n!option.freeChoice\n) {\ntemp.$ref = '#';\n}\nreturn temp;\n}"
"export async function generateSchema(\ndist: string,\n{\nfilename = 'renovate-schema.json',\nversion = pkg.version,\nisGlobal = false,\n}: GenerateSchemaOpts = {},\n): Promise<void> {\nconst schema = {\ntitle: isGlobal\n? `JSON schema for Renovate ${version} global self-hosting configuration (https:\n: `JSON schema for Renovate ${version} config files (https:\n$schema: 'http:\n'x-renovate-version': `${version}`,\nallowComments: true,\ntype: 'object',\nproperties: {},\n};\nconst configurationOptions = getOptions();\nif (!isGlobal) {\nconfigurationOptions.map((v) => {\nif (v.globalOnly) {\nv.description =\n`Deprecated: This configuration option is only intended to be used with 'global' configuration when self-hosting, not used in a repository configuration file. Renovate likely won't use the configuration, and these fields will be removed from the repository configuration documentation in Renovate v43 (https:\nv.description;\n}\nreturn v;\n});\n}\nconfigurationOptions.sort((a, b) => {\nif (a.name < b.name) {\nreturn -1;\n}\nif (a.name > b.name) {\nreturn 1;\n}\nreturn 0;\n});\nconst properties = schema.properties as Record<string, any>;\ncreateSchemaForParentConfigs(configurationOptions, properties);\naddChildrenArrayInParents(configurationOptions, properties);\ncreateSchemaForChildConfigs(configurationOptions, properties);\nawait updateFile(\n`${dist}/${filename}`,\n`${JSON.stringify(schema, null, 2)}\n`,\n);\n}"
"export async function generateVersioning(\ndist: string,\nversioningIssuesMap: OpenItems,\n): Promise<void> {\nconst versioningList = getVersioningList();\nlet versioningContent = '\nSupported values for `versioning` are:\n\n';\nfor (const versioning of versioningList) {\nconst definition = (await import(\n`../../lib/modules/versioning/${versioning}`\n)) as Versioning;\nconst { id, displayName, urls, supportsRanges, supportedRangeStrategies } =\ndefinition;\nversioningContent += `* ${getModuleLink(\nversioning,\n`\`${versioning}\``,\n)}\n`;\nlet md = codeBlock`\n---\ntitle: ${displayName}\nedit_url: https:\n---\n# ${displayName} Versioning\n`;\nmd += '\n\n';\nmd += `## Identifier\n\n \`${id}\` \n\n`;\nmd += formatUrls(urls);\nmd += `## Ranges/Constraints\n\n`;\nif (supportsRanges) {\nmd += `✅ Ranges are supported.\n\nValid \`rangeStrategy\` values are: ${(\nsupportedRangeStrategies ?? []\n)\n.map((strategy: string) => `\`${strategy}\``)\n.join(', ')}\n\n`;\n} else {\nmd += `❌ No range support.\n\n`;\n}\nmd += await formatDescription('versioning', versioning);\nmd += `\n----\n\n`;\nmd += generateFeatureAndBugMarkdown(versioningIssuesMap, versioning);\nawait updateFile(`${dist}/modules/versioning/${versioning}/index.md`, md);\n}\nlet indexContent = await readFile(`docs/usage/modules/versioning/index.md`);\nindexContent = replaceContent(indexContent, versioningContent);\nawait updateFile(`${dist}/modules/versioning/index.md`, indexContent);\n}"
"export async function tryDecryptBcPgp(\nprivateKey: string,\nencryptedStr: string,\n): Promise<string | null> {\ntry {\nconst startBlock = '-----BEGIN PGP MESSAGE-----\n\n';\nconst endBlock = '\n-----END PGP MESSAGE-----';\nlet armoredMessage = encryptedStr.trim();\nconst hasStartHeader = armoredMessage.startsWith(startBlock);\nconst hasEndHeader = armoredMessage.endsWith(endBlock);\nif (\n!hasStartHeader &&\n!hasEndHeader &&\n!armoredMessage.includes('=') &&\n!armoredMessage.includes('\n') &&\narmoredMessage.length % 4 !== 0\n) {\nlogger.debug('Adding base64 padding to armored message');\narmoredMessage += `=`.repeat(4 - (armoredMessage.length % 4));\n}\nif (!hasStartHeader) {\narmoredMessage = `${startBlock}${armoredMessage}`;\n}\nif (!hasEndHeader) {\narmoredMessage = `${armoredMessage}${endBlock}`;\n}\nconst data = await decrypt(\nprivateKey.replace(regEx(/\n[ \t]+/g), '\n'),\narmoredMessage,\n{\nruntime: runtime(),\n},\n);\nlogger.debug('Decrypted config using bcpgp');\nreturn data;\n} catch (err) {\nlogger.debug({ err }, 'Could not decrypt using bcpgp');\nreturn null;\n}\n}"
"export async function tryDecryptOpenPgp(\nprivateKey: string,\nencryptedStr: string,\n): Promise<string | null> {\nif (pgp === undefined) {\ntry {\npgp = openpgp();\n} catch (err) {\nlogger.warn({ err }, 'Could load openpgp');\npgp = null;\n}\n}\nif (pgp === null) {\nlogger.once.warn('Cannot load openpgp, skipping decryption');\nreturn null;\n}\ntry {\nconst pk = await pgp.readPrivateKey({\narmoredKey: privateKey.replace(regEx(/\n[ \t]+/g), '\n'),\n});\nconst startBlock = '-----BEGIN PGP MESSAGE-----\n\n';\nconst endBlock = '\n-----END PGP MESSAGE-----';\nlet armoredMessage = encryptedStr.trim();\nif (!armoredMessage.startsWith(startBlock)) {\narmoredMessage = `${startBlock}${armoredMessage}`;\n}\nif (!armoredMessage.endsWith(endBlock)) {\narmoredMessage = `${armoredMessage}${endBlock}`;\n}\nconst message = await pgp.readMessage({\narmoredMessage,\n});\nconst { data } = await pgp.decrypt({\nmessage,\ndecryptionKeys: pk,\n});\nlogger.debug('Decrypted config using openpgp');\nreturn data;\n} catch (err) {\nlogger.debug({ err }, 'Could not decrypt using openpgp');\nreturn null;\n}\n}"
"async function fetchPreset(\npreset: string,\nbaseConfig: RenovateConfig | undefined,\ninputConfig: AllConfig,\nexistingPresets: string[],\n): Promise<AllConfig> {\ntry {\nreturn await getPreset(preset, baseConfig ?? inputConfig);\n} catch (err) {\nlogger.debug({ preset, err }, 'Preset fetch error');\nif (err instanceof ExternalHostError) {\nthrow err;\n}\nif (err.message === PLATFORM_RATE_LIMIT_EXCEEDED) {\nthrow err;\n}\nconst error = new Error(CONFIG_VALIDATION);\nif (err.message === PRESET_DEP_NOT_FOUND) {\nerror.validationError = `Cannot find preset's package (${preset})`;\n} else if (err.message === PRESET_RENOVATE_CONFIG_NOT_FOUND) {\nerror.validationError = `Preset package is missing a renovate-config entry (${preset})`;\n} else if (err.message === PRESET_NOT_FOUND) {\nerror.validationError = `Preset name not found within published preset config (${preset})`;\n} else if (err.message === PRESET_INVALID) {\nerror.validationError = `Preset is invalid (${preset})`;\n} else if (err.message === PRESET_PROHIBITED_SUBPRESET) {\nerror.validationError = `Sub-presets cannot be combined with a custom path (${preset})`;\n} else if (err.message === PRESET_INVALID_JSON) {\nerror.validationError = `Preset is invalid JSON (${preset})`;\n} else {\nerror.validationError = `Preset caused unexpected error (${preset})`;\n}\nif (existingPresets.length) {\nerror.validationError +=\n'. Note: this is a *nested* preset so please contact the preset author if you are unable to fix it yourself.';\n}\nlogger.info(\n{ validationError: error.validationError },\n'Throwing preset error',\n);\nthrow error;\n}\n}"
"export async function fetchPreset({\nrepo,\nfilePreset,\npresetPath,\nendpoint: _endpoint,\ntag,\nfetch,\n}: FetchPresetConfig): Promise<Nullish<Preset>> {\nconst endpoint = ensureTrailingSlash(_endpoint!);\nconst [fileName, presetName, subPresetName] = filePreset.split('/');\nconst pathPrefix = presetPath ? `${presetPath}/` : '';\nconst buildFilePath = (name: string): string => `${pathPrefix}${name}`;\nlet jsonContent: any;\nif (fileName === 'default') {\ntry {\njsonContent = await fetch(\nrepo,\nbuildFilePath('default.json'),\nendpoint,\ntag,\n);\n} catch (err) {\nif (err.message !== PRESET_DEP_NOT_FOUND) {\nthrow err;\n}\njsonContent = await fetch(\nrepo,\nbuildFilePath('renovate.json'),\nendpoint,\ntag,\n);\nlogger.warn(\n{\nrepo,\nfilePreset,\npresetPath,\nendpoint,\ntag,\n},\n'Fallback to renovate.json file as a preset is deprecated, please use a default.json file instead.',\n);\n}\n} else {\njsonContent = await fetch(\nrepo,\nbuildFilePath(\nregEx(/\.json5?$/).test(fileName) ? fileName : `${fileName}.json`,\n),\nendpoint,\ntag,\n);\n}\nif (!jsonContent) {\nthrow new Error(PRESET_DEP_NOT_FOUND);\n}\nif (presetName) {\nconst preset = jsonContent[presetName];\nif (!preset) {\nthrow new Error(PRESET_NOT_FOUND);\n}\nif (subPresetName) {\nconst subPreset = preset[subPresetName];\nif (!subPreset) {\nthrow new Error(PRESET_NOT_FOUND);\n}\nreturn subPreset;\n}\nreturn preset;\n}\nreturn jsonContent;\n}"
"export function validateRegexManagerFields(\ncustomManager: CustomManager,\ncurrentPath: string,\nerrors: ValidationMessage[],\n): void {\nif (isNonEmptyArray(customManager.matchStrings)) {\nfor (const matchString of customManager.matchStrings) {\ntry {\nregEx(matchString);\n} catch (err) {\nlogger.debug(\n{ err },\n'customManager.matchStrings regEx validation error',\n);\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `Invalid regExp for ${currentPath}: \`${matchString}\``,\n});\n}\n}\n} else {\nerrors.push({\ntopic: 'Configuration Error',\nmessage:\n'Each Custom Manager `matchStrings` array must have at least one item.',\n});\n}\nconst mandatoryFields = ['currentValue', 'datasource'];\nfor (const field of mandatoryFields) {\nif (!hasField(customManager, field)) {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `Regex Managers must contain ${field}Template configuration or regex group named ${field}`,\n});\n}\n}\nconst nameFields = ['depName', 'packageName'];\nif (!nameFields.some((field) => hasField(customManager, field))) {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `Regex Managers must contain depName or packageName regex groups or templates`,\n});\n}\n}"
"export function validateJSONataManagerFields(\ncustomManager: CustomManager,\ncurrentPath: string,\nerrors: ValidationMessage[],\n): void {\nif (!isNonEmptyString(customManager.fileFormat)) {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: 'Each JSONata manager must contain a fileFormat field.',\n});\n}\nif (isNonEmptyArray(customManager.matchStrings)) {\nfor (const matchString of customManager.matchStrings) {\ntry {\njsonata(matchString);\n} catch (err) {\nlogger.debug(\n{ err },\n'customManager.matchStrings JSONata query validation error',\n);\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `Invalid JSONata query for ${currentPath}: \`${matchString}\``,\n});\n}\n}\n} else {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `Each Custom Manager must contain a non-empty matchStrings array`,\n});\n}\nconst mandatoryFields = ['currentValue', 'datasource'];\nfor (const field of mandatoryFields) {\nif (!hasField(customManager, field)) {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `JSONata Managers must contain ${field}Template configuration or ${field} in the query `,\n});\n}\n}\nconst nameFields = ['depName', 'packageName'];\nif (!nameFields.some((field) => hasField(customManager, field))) {\nerrors.push({\ntopic: 'Configuration Error',\nmessage: `JSONata Managers must contain depName or packageName in the query or their templates`,\n});\n}\n}"
"export function applyVersionCompatibility(\nreleaseResult: ReleaseResult,\nversionCompatibility: string | undefined,\ncurrentCompatibility: string | undefined,\n): ReleaseResult {\nif (!versionCompatibility) {\nreturn releaseResult;\n}\nconst versionCompatibilityRegEx = regEx(versionCompatibility);\nreleaseResult.releases = filterMap(releaseResult.releases, (release) => {\nconst regexResult = versionCompatibilityRegEx.exec(release.version);\nif (!regexResult?.groups?.version) {\nlogger.trace(\n{ releaseVersion: release.version, versionCompatibility },\n'versionCompatibility: Does not match regex',\n);\nreturn null;\n}\nif (regexResult?.groups?.compatibility !== currentCompatibility) {\nlogger.trace(\n{ releaseVersion: release.version, versionCompatibility },\n'versionCompatibility: Does not match compatibility',\n);\nreturn null;\n}\nlogger.trace(\n{\nreleaseVersion: release.version,\nversionCompatibility,\nversion: regexResult.groups.version,\ncompatibility: regexResult.groups.compatibility,\n},\n'versionCompatibility: matches',\n);\nrelease.version = regexResult.groups.version;\nreturn release;\n});\nreturn releaseResult;\n}"
"async function getRegistryReleases(\ndatasource: DatasourceApi,\nconfig: GetReleasesConfig,\nregistryUrl: string,\n): Promise<ReleaseResult | null> {\nconst cacheNamespace: PackageCacheNamespace = `datasource-releases-${datasource.id}`;\nconst cacheKey = `${registryUrl}:${config.packageName}`;\nconst cacheEnabled = !!datasource.caching;\nconst cacheForced = GlobalConfig.get('cachePrivatePackages', false);\nif (cacheEnabled || cacheForced) {\nconst cachedResult = await packageCache.get<ReleaseResult>(\ncacheNamespace,\ncacheKey,\n);\nif (cachedResult) {\nlogger.trace({ cacheKey }, 'Returning cached datasource response');\nDatasourceCacheStats.hit(datasource.id, registryUrl, config.packageName);\nreturn cachedResult;\n}\nDatasourceCacheStats.miss(datasource.id, registryUrl, config.packageName);\n}\nconst res = await datasource.getReleases({ ...config, registryUrl });\nif (res?.releases.length) {\nres.registryUrl ??= registryUrl;\n}\nif (!res) {\nreturn null;\n}\nlet cache = false;\nif (cacheForced) {\ncache = true;\n} else if (cacheEnabled && !res.isPrivate) {\ncache = true;\n}\nif (cache) {\nlogger.trace({ cacheKey }, 'Caching datasource response');\nawait packageCache.set(cacheNamespace, cacheKey, res, 15);\nDatasourceCacheStats.set(datasource.id, registryUrl, config.packageName);\n} else {\nDatasourceCacheStats.skip(datasource.id, registryUrl, config.packageName);\n}\nreturn res;\n}"
"function resolveRegistryUrls(\ndatasource: DatasourceApi,\ndefaultRegistryUrls: string[] | undefined,\nregistryUrls: string[] | undefined | null,\nadditionalRegistryUrls: string[] | undefined,\n): string[] {\nif (!datasource.customRegistrySupport) {\nif (\nisNonEmptyArray(registryUrls) ||\nisNonEmptyArray(defaultRegistryUrls) ||\nisNonEmptyArray(additionalRegistryUrls)\n) {\nlogger.warn(\n{\ndatasource: datasource.id,\nregistryUrls,\ndefaultRegistryUrls,\nadditionalRegistryUrls,\n},\n'Custom registries are not allowed for this datasource and will be ignored',\n);\n}\nreturn isFunction(datasource.defaultRegistryUrls)\n? datasource.defaultRegistryUrls()\n: (datasource.defaultRegistryUrls ?? []);\n}\nconst customUrls = registryUrls?.filter(Boolean);\nlet resolvedUrls: string[] = [];\nif (isNonEmptyArray(customUrls)) {\nresolvedUrls = [...customUrls];\n} else if (isNonEmptyArray(defaultRegistryUrls)) {\nresolvedUrls = [...defaultRegistryUrls];\nresolvedUrls = resolvedUrls.concat(additionalRegistryUrls ?? []);\n} else if (isFunction(datasource.defaultRegistryUrls)) {\nresolvedUrls = [...datasource.defaultRegistryUrls()];\nresolvedUrls = resolvedUrls.concat(additionalRegistryUrls ?? []);\n} else if (isNonEmptyArray(datasource.defaultRegistryUrls)) {\nresolvedUrls = [...datasource.defaultRegistryUrls];\nresolvedUrls = resolvedUrls.concat(additionalRegistryUrls ?? []);\n}\nreturn massageRegistryUrls(resolvedUrls);\n}"
"async function fetchReleases(\nconfig: GetReleasesInternalConfig,\n): Promise<ReleaseResult | null> {\nconst { datasource: datasourceName } = config;\nlet { registryUrls } = config;\nif (!datasourceName || getDatasourceFor(datasourceName) === undefined) {\nlogger.warn({ datasource: datasourceName }, 'Unknown datasource');\nreturn null;\n}\nif (datasourceName === 'npm') {\nif (isString(config.npmrc)) {\nsetNpmrc(config.npmrc);\n}\nif (!isNonEmptyArray(registryUrls)) {\nregistryUrls = [resolveRegistryUrl(config.packageName)];\n}\n}\nconst datasource = getDatasourceFor(datasourceName);\nif (!datasource) {\nlogger.warn({ datasource: datasourceName }, 'Unknown datasource');\nreturn null;\n}\nregistryUrls = resolveRegistryUrls(\ndatasource,\nconfig.defaultRegistryUrls,\nregistryUrls,\nconfig.additionalRegistryUrls,\n);\nlet dep: ReleaseResult | null = null;\nconst registryStrategy =\nconfig.registryStrategy ?? datasource.registryStrategy ?? 'hunt';\ntry {\nif (isNonEmptyArray(registryUrls)) {\nif (registryStrategy === 'first') {\ndep = await firstRegistry(config, datasource, registryUrls);\n} else if (registryStrategy === 'hunt') {\ndep = await huntRegistries(config, datasource, registryUrls);\n} else if (registryStrategy === 'merge') {\ndep = await mergeRegistries(config, datasource, registryUrls);\n}\n} else {\ndep = await datasource.getReleases(config);\n}\n} catch (err) {\nif (err.message === HOST_DISABLED || err.err?.message === HOST_DISABLED) {\nreturn null;\n}\nif (err instanceof ExternalHostError) {\nthrow err;\n}\nlogError(datasource.id, config.packageName, err);\n}\nif (!dep || dequal(dep, { releases: [] })) {\nreturn null;\n}\naddMetaData(dep, datasourceName, config.packageName);\ndep = { ...dep, ...applyReplacements(config) };\nreturn dep;\n}"
"export async function postprocessRelease(\nconfig: Config,\nrelease: Release,\n): Promise<Release | null> {\nconst { datasource } = config;\nconst ds = datasource && getDatasourceFor(datasource);\nif (!ds) {\nlogger.once.warn(\n{ datasource },\n'Failed to resolve datasource during release postprocessing',\n);\nreturn release;\n}\nif (\nds.constructor.prototype.postprocessRelease ===\nDatasource.prototype.postprocessRelease\n) {\nreturn release;\n}\nconst { packageName } = config;\nif (!packageName) {\nlogger.once.warn(\n{ datasource },\n'Release postprocessing is not supported for empty `packageName` field',\n);\nreturn release;\n}\nconst registryUrl = config.registryUrl ?? config.registryUrls?.at(0) ?? null;\ntry {\nconst result = await ds.postprocessRelease(\n{ packageName, registryUrl },\nrelease,\n);\nif (result === 'reject') {\nlogger.debug(\n{\ndatasource,\npackageName,\nregistryUrl,\nversion: release.version,\nversionOrig: release.versionOrig,\n},\n'Rejected release',\n);\nreturn null;\n}\nreturn result;\n} catch (err) {\nlogger.once.warn({ err }, `Release interceptor failed for `${datasource}``);\nreturn release;\n}\n}"
"export async function initPlatform(config: AllConfig): Promise<AllConfig> {\nsetPrivateKey(config.gitPrivateKey, config.gitPrivateKeyPassphrase);\nsetNoVerify(config.gitNoVerify ?? []);\nsetPlatformApi(config.platform!);\nconst platformInfo = await platform.initPlatform(config);\nconst returnConfig: any = {\n...config,\n...platformInfo,\nhostRules: [\n...(platformInfo?.hostRules ?? []),\n...(config.hostRules ?? []),\n],\n};\nif (config?.gitAuthor) {\nlogger.debug(`Using configured gitAuthor (${config.gitAuthor})`);\nreturnConfig.gitAuthor = config.gitAuthor;\n} else if (platformInfo?.gitAuthor) {\nlogger.debug(`Using platform gitAuthor: ${String(platformInfo.gitAuthor)}`);\nreturnConfig.gitAuthor = platformInfo.gitAuthor;\n}\nsetGitAuthor(returnConfig.gitAuthor);\nconst platformRule: HostRule = {\nmatchHost: URL.parse(returnConfig.endpoint).hostname!,\n};\nif (returnConfig.token) {\nconfig.token = returnConfig.token;\n}\n(\n['token', 'username', 'password'] as ('token' | 'username' | 'password')[]\n).forEach((field) => {\nif (config[field]) {\nplatformRule[field] = config[field] as string;\ndelete returnConfig[field];\n}\n});\nconst typedPlatformRule = {\n...platformRule,\nhostType: returnConfig.platform,\n};\nreturnConfig.hostRules.push(typedPlatformRule);\nhostRules.add(typedPlatformRule);\nreturn returnConfig;\n}"
"function getSpawnStub(args: StubArgs): any {\nconst {\ncmd,\nerror,\nexitCode,\nexitSignal,\nstdout,\nstderr,\nencoding,\ntimeout,\npid = 31415,\n} = args;\nconst listeners: Events = {};\nconst on = (name: string, cb: Listener) => {\nconst event = name as keyof Events;\nif (listeners[event]) {\nreturn;\n}\nswitch (event) {\ncase 'exit':\nlisteners.exit = cb as EndListener;\nbreak;\ncase 'error':\nlisteners.error = cb as ErrorListener;\nbreak;\ndefault:\nbreak;\n}\n};\nconst stdoutStream = getReadable(stdout, encoding ?? 'utf8');\nconst stderrStream = getReadable(stderr, encoding ?? 'utf8');\nconst emit = (name: string, ...arg: (string | number | Error)[]): boolean => {\nconst event = name as keyof Events;\nswitch (event) {\ncase 'error':\nlisteners.error?.(arg[0] as Error);\nbreak;\ncase 'exit':\nlisteners.exit?.(arg[0] as number, arg[1] as NodeJS.Signals);\nbreak;\ndefault:\nbreak;\n}\nreturn !!listeners[event];\n};\nconst unref = (): void => {\n};\nconst kill = (signal?: number | NodeJS.Signals): boolean => {\nreturn true;\n};\nsetTimeout(() => {\nif (error) {\nlisteners.error?.(error);\n}\nlisteners.exit?.(exitCode, exitSignal);\n}, 0);\nif (timeout) {\nsetTimeout(() => {\nlisteners.exit?.(null, 'SIGTERM');\n}, timeout);\n}\nreturn {\non,\nspawnargs: cmd.split(regEx(/\s+/)),\nstdout: stdoutStream,\nstderr: stderrStream,\nemit,\nunref,\nkill,\npid,\n};\n}"
"export function exec(cmd: string, opts: RawExecOptions): Promise<ExecResult> {\nreturn new Promise((resolve, reject) => {\nconst maxBuffer = opts.maxBuffer ?? 10 * 1024 * 1024;\nconst cp = spawn(cmd, {\n...opts,\ndetached: process.platform !== 'win32',\nshell: typeof opts.shell === 'string' ? opts.shell : true,\n});\nconst [stdout, stderr] = initStreamListeners(cp, {\n...opts,\nmaxBuffer,\n});\ncp.on('error', (error) => {\nkill(cp, 'SIGTERM');\nreject(new ExecError(error.message, rejectInfo(), error));\n});\ncp.on('exit', (code: number, signal: NodeJS.Signals) => {\nif (NONTERM.includes(signal)) {\nreturn;\n}\nif (signal) {\nkill(cp, signal);\nreject(\nnew ExecError(`Command failed: ${cmd}\nInterrupted by ${signal}`, {\n...rejectInfo(),\nsignal,\n}),\n);\nreturn;\n}\nif (code !== 0) {\nreject(\nnew ExecError(`Command failed: ${cmd}\n${stringify(stderr)}`, {\n...rejectInfo(),\nexitCode: code,\n}),\n);\nreturn;\n}\nresolve({\nstderr: stringify(stderr),\nstdout: stringify(stdout),\n});\n});\nfunction rejectInfo(): ExecErrorData {\nreturn {\ncmd: cp.spawnargs.join(' '),\noptions: opts,\nstdout: stringify(stdout),\nstderr: stringify(stderr),\n};\n}\n});\n}"
"async function prepareRawExec(\ncmd: string | string[],\nopts: ExecOptions,\n): Promise<RawExecArguments> {\nconst { docker } = opts;\nconst preCommands = opts.preCommands ?? [];\nconst customEnvVariables = getCustomEnv();\nconst userConfiguredEnv = getUserEnv();\nconst { containerbaseDir, binarySource } = GlobalConfig.get();\nif (binarySource === 'docker' || binarySource === 'install') {\nlogger.debug(`Setting CONTAINERBASE_CACHE_DIR to ${containerbaseDir!}`);\nopts.env ??= {};\nopts.env.CONTAINERBASE_CACHE_DIR = containerbaseDir;\n}\nconst rawOptions = getRawExecOptions(opts);\nlet rawCommands = typeof cmd === 'string' ? [cmd] : cmd;\nif (isDocker(docker)) {\nlogger.debug({ image: sideCarImage }, 'Using docker to execute');\nconst extraEnv = {\n...opts.extraEnv,\n...customEnvVariables,\n...userConfiguredEnv,\n};\nconst childEnv = getChildEnv(opts);\nconst envVars = [\n...dockerEnvVars(extraEnv, childEnv),\n'CONTAINERBASE_CACHE_DIR',\n];\nconst cwd = getCwd(opts);\nconst dockerOptions: DockerOptions = { ...docker, cwd, envVars };\nconst dockerCommand = await generateDockerCommand(\nrawCommands,\n[\n...(await generateInstallCommands(opts.toolConstraints)),\n...preCommands,\n],\ndockerOptions,\n);\nrawCommands = [dockerCommand];\n} else if (isDynamicInstall(opts.toolConstraints)) {\nlogger.debug('Using containerbase dynamic installs');\nrawCommands = [\n...(await generateInstallCommands(opts.toolConstraints)),\n...preCommands,\n...rawCommands,\n];\n} else if (isHermit()) {\nconst hermitEnvVars = await getHermitEnvs(rawOptions);\nlogger.debug(\n{ hermitEnvVars },\n'merging hermit environment variables into the execution options',\n);\nrawOptions.env = {\n...rawOptions.env,\n...hermitEnvVars,\n};\n}\nreturn { rawCommands, rawOptions };\n}"
"export async function exec(\ncmd: string | string[],\nopts: ExecOptions = {},\n): Promise<ExecResult> {\nconst { docker } = opts;\nconst dockerChildPrefix = GlobalConfig.get('dockerChildPrefix', 'renovate_');\nconst { rawCommands, rawOptions } = await prepareRawExec(cmd, opts);\nconst useDocker = isDocker(docker);\nlet res: ExecResult = { stdout: '', stderr: '' };\nfor (const rawCmd of rawCommands) {\nconst startTime = Date.now();\nif (useDocker) {\nawait removeDockerContainer(sideCarImage, dockerChildPrefix);\n}\nlogger.debug({ command: rawCmd }, 'Executing command');\nlogger.trace({ commandOptions: rawOptions }, 'Command options');\ntry {\nres = await rawExec(rawCmd, rawOptions);\n} catch (err) {\nconst durationMs = Math.round(Date.now() - startTime);\nlogger.debug({ err, durationMs }, 'rawExec err');\nif (useDocker) {\nawait removeDockerContainer(sideCarImage, dockerChildPrefix).catch(\n(removeErr: Error) => {\nconst message: string = err.message;\nthrow new Error(\n`Error: `${removeErr.message}` - Original Error: `${message}``,\n);\n},\n);\n}\nif (err.signal === `SIGTERM`) {\nlogger.debug(\n{ err },\n'exec interrupted by SIGTERM - run needs to be aborted',\n);\nthrow new Error(TEMPORARY_ERROR);\n}\nthrow err;\n}\nconst durationMs = Math.round(Date.now() - startTime);\nlogger.debug(\n{\ndurationMs,\nstdout: res.stdout,\nstderr: res.stderr,\n},\n'exec completed',\n);\n}\nreturn res;\n}"
"export function getGitAuthenticatedEnvironmentVariables(\noriginalGitUrl: string,\n{ token, username, password, hostType, matchHost }: HostRule,\nenvironmentVariables?: NodeJS.ProcessEnv,\n): NodeJS.ProcessEnv {\nif (!token && !(username && password)) {\nlogger.warn(\n{ host: matchHost },\n`Could not create environment variable for host as neither token or username and password was set`,\n);\nreturn { ...environmentVariables };\n}\nconst env = getEnv();\nconst gitConfigCountEnvVariable =\nenvironmentVariables?.GIT_CONFIG_COUNT ?? env.GIT_CONFIG_COUNT;\nlet gitConfigCount = 0;\nif (gitConfigCountEnvVariable) {\ngitConfigCount = parseInt(gitConfigCountEnvVariable);\nif (Number.isNaN(gitConfigCount)) {\nlogger.warn(\n{\nGIT_CONFIG_COUNT: env.GIT_CONFIG_COUNT,\n},\n`Found GIT_CONFIG_COUNT env variable, but couldn't parse the value to an integer. Ignoring it.`,\n);\ngitConfigCount = 0;\n}\n}\nlet authenticationRules: AuthenticationRule[];\nif (token) {\nauthenticationRules = getAuthenticationRulesWithToken(\noriginalGitUrl,\nhostType,\ntoken,\n);\n} else {\nconst encodedUsername = encodeURIComponent(username!);\nconst encodedPassword = encodeURIComponent(password!);\nauthenticationRules = getAuthenticationRules(\noriginalGitUrl,\nhostType,\n`${encodedUsername}:${encodedPassword}`,\n);\n}\nconst newEnvironmentVariables = {\n...environmentVariables,\n};\nfor (const rule of authenticationRules) {\nnewEnvironmentVariables[`GIT_CONFIG_KEY_${gitConfigCount}`] =\n`url.${rule.url}.insteadOf`;\nnewEnvironmentVariables[`GIT_CONFIG_VALUE_${gitConfigCount}`] =\nrule.insteadOf;\ngitConfigCount++;\n}\nnewEnvironmentVariables.GIT_CONFIG_COUNT = gitConfigCount.toString();\nreturn newEnvironmentVariables;\n}"
"export function getAuthenticationRules(\ngitUrl: string,\nhostType: string | undefined | null,\ntoken: string,\n): AuthenticationRule[] {\nconst authenticationRules = [];\nconst hasUser = token.split(':').length > 1;\nconst insteadUrl = parseGitUrl(gitUrl);\nlet sshPort = insteadUrl.port;\nif (hostType === 'bitbucket-server') {\ninsteadUrl.source = 'bitbucket-server';\nif (!sshPort || isEmptyString(sshPort)) {\nsshPort = '7999';\n}\n}\nconst url = { ...insteadUrl };\nconst protocol = regEx(/^https?$/).test(url.protocol)\n? url.protocol\n: 'https';\nurl.token = hasUser ? token : `ssh:${token}`;\nauthenticationRules.push({\nurl: url.toString(protocol),\ninsteadOf: `ssh:\nsshPort ? `:${sshPort}` : ''\n}/${insteadUrl.full_name}${insteadUrl.git_suffix ? '.git' : ''}`,\n});\nurl.token = hasUser ? token : `git:${token}`;\nauthenticationRules.push({\nurl: url.toString(protocol),\ninsteadOf: { ...insteadUrl, port: sshPort }.toString('ssh'),\n});\nurl.token = token;\nauthenticationRules.push({\nurl: url.toString(protocol),\ninsteadOf: insteadUrl.toString(protocol),\n});\nreturn authenticationRules;\n}"
"export function getGitEnvironmentVariables(\nadditionalHostTypes: string[] = [],\n): NodeJS.ProcessEnv {\nlet environmentVariables: NodeJS.ProcessEnv = {};\nconst gitHubHostRule = find({\nhostType: 'github',\nurl: 'https:\n});\nif (gitHubHostRule?.token) {\nenvironmentVariables = getGitAuthenticatedEnvironmentVariables(\n'https:\ngitHubHostRule,\n);\n}\nconst gitAllowedHostTypes = new Set<string>([\n...PLATFORM_HOST_TYPES,\n...additionalHostTypes,\n]);\nconst hostRules = getAll()\n.filter((r) => r.matchHost && (r.token ?? (r.username && r.password)))\n.filter((r) => !gitHubHostRule || !githubApiUrls.has(r.matchHost!));\nfor (const hostRule of hostRules) {\nif (!hostRule.hostType || gitAllowedHostTypes.has(hostRule.hostType)) {\nenvironmentVariables = addAuthFromHostRule(\nhostRule,\nenvironmentVariables,\n);\n}\n}\nreturn environmentVariables;\n}"
"export function parseGitAuthor(input: string): GitAuthor | null {\nlet result: GitAuthor | null = null;\nif (!input) {\nreturn null;\n}\ntry {\nresult = addrs.parseOneAddress(input);\nif (result) {\nreturn result;\n}\nlet massagedInput: string | undefined;\nlet massagedBotEmail = false;\nif (input.includes('<') && input.includes('>')) {\nmassagedInput = '`' + input.replace(regEx(/(\s?<)/), '`$1');\n}\nif (input.includes('[bot]@')) {\nmassagedInput = (massagedInput ?? input).replace('[bot]@', '@');\nmassagedBotEmail = true;\n}\nif (!massagedInput) {\nreturn null;\n}\nconst parsed = addrs.parseOneAddress(massagedInput) as addrs.ParsedMailbox;\nif (parsed?.address) {\nresult = {\nname: parsed.name ?? input.replace(regEx(/@.*/), ''),\naddress: parsed.address,\n};\nif (massagedBotEmail) {\nresult.address = result.address?.replace('@', '[bot]@');\n}\nreturn result;\n}\n} catch (err) {\nlogger.debug({ err }, 'Unknown error parsing gitAuthor');\n}\nreturn null;\n}"
"export async function gitRetry<T>(gitFunc: () => Promise<T>): Promise<T> {\nlet round = 0;\nlet lastError: Error | undefined;\nwhile (round <= retryCount) {\nif (round > 0) {\nlogger.debug(`gitRetry round ${round}`);\n}\ntry {\nconst res = await gitFunc();\nif (round > 1) {\nlogger.debug('Successful retry of git function');\n}\nreturn res;\n} catch (err) {\nlastError = err;\nlogger.debug({ err }, `Git function thrown`);\nconst errChecked = checkForPlatformFailure(err);\nif (errChecked instanceof ExternalHostError) {\nlogger.debug(\n{ err: errChecked },\n`ExternalHostError thrown in round ${\nround + 1\n} of ${retryCount} - retrying in the next round`,\n);\n} else {\nthrow err;\n}\n}\nconst nextDelay = delayFactor ^ ((round - 1) * delaySeconds);\nlogger.trace({ nextDelay }, `Delay next round`);\nawait setTimeout(1000 * nextDelay);\nround++;\n}\nthrow lastError;\n}"
"export async function isBranchConflicted(\nbaseBranch: string,\nbranch: string,\n): Promise<boolean> {\nlogger.debug(`isBranchConflicted(${baseBranch}, ${branch})`);\nconst baseBranchSha = getBranchCommit(baseBranch);\nconst branchSha = getBranchCommit(branch);\nif (!baseBranchSha || !branchSha) {\nlogger.warn(\n{ baseBranch, branch },\n'isBranchConflicted: branch does not exist',\n);\nreturn true;\n}\nconst isConflicted = getCachedConflictResult(\nbranch,\nbranchSha,\nbaseBranch,\nbaseBranchSha,\n);\nif (isBoolean(isConflicted)) {\nlogger.debug(\n`branch.isConflicted(): using cached result `${isConflicted}``,\n);\nreturn isConflicted;\n}\nlogger.debug('branch.isConflicted(): using git to calculate');\nlet result = false;\nawait syncGit();\nawait writeGitAuthor();\nconst origBranch = config.currentBranch;\ntry {\nawait git.reset(ResetMode.HARD);\nif (origBranch !== baseBranch) {\nawait git.checkout(baseBranch);\n}\nawait git.merge(['--no-commit', '--no-ff', `origin/${branch}`]);\n} catch (err) {\nresult = true;\nif (!err?.git?.conflicts?.length) {\nlogger.debug(\n{ baseBranch, branch, err },\n'isBranchConflicted: unknown error',\n);\n}\n} finally {\ntry {\nawait git.merge(['--abort']);\nif (origBranch !== baseBranch) {\nawait git.checkout(origBranch);\n}\n} catch (err) {\nlogger.debug(\n{ baseBranch, branch, err },\n'isBranchConflicted: cleanup error',\n);\n}\n}\nsetCachedConflictResult(branch, result);\nlogger.debug(`branch.isConflicted(): ${result}`);\nreturn result;\n}"
"export async function clearRenovateRefs(): Promise<void> {\nif (!gitInitialized || !remoteRefsExist) {\nreturn;\n}\nlogger.debug(`Cleaning up Renovate refs: refs/renovate/branches\n} catch (err) {\nlogger.warn({ err }, `Renovate refs cleanup error`);\n}\nif (renovateRefs.length) {\ntry {\nconst pushOpts = ['--delete', 'origin', ...renovateRefs];\nawait git.push(pushOpts);\n} catch (err) {\nif (bulkChangesDisallowed(err)) {\nfor (const ref of renovateRefs) {\ntry {\nconst pushOpts = ['--delete', 'origin', ref];\nawait git.push(pushOpts);\n} catch (err) {\nlogger.debug({ err }, 'Error deleting `refs/renovate/branches\n} else {\nlogger.warn({ err }, 'Error deleting `refs/renovate/branches/*`');\n}\n}\n}\nremoteRefsExist = false;\n}"
"export function getHttpUrl(url: string, token?: string): string {\nconst parsedUrl = parseGitUrl(url);\nlet { protocol } = parsedUrl;\nconst origProtocol = protocol;\nif (!regEx(/^https?$/).test(protocol)) {\nparsedUrl.port = '443';\nprotocol = 'https';\n}\nparsedUrl.user = '';\nparsedUrl.token = token ?? '';\nswitch (detectPlatform(parsedUrl.toString(protocol))) {\ncase 'gitlab':\nif (token) {\nparsedUrl.token = token.includes(':')\n? token\n: `gitlab-ci-token:${token}`;\n}\nbreak;\ncase 'github':\nif (token) {\nparsedUrl.token = token.includes(':')\n? token\n: `x-access-token:${token}`;\n}\nbreak;\ncase 'bitbucket-server':\nif (origProtocol === 'ssh') {\nparsedUrl.source = 'bitbucket-server';\n}\nbreak;\n}\nreturn new URL(parsedUrl.toString(protocol)).href;\n}"
"export function applyAuthorization<GotOptions extends AuthGotOptions>(\ninOptions: GotOptions,\n): GotOptions {\nconst options: GotOptions = { ...inOptions };\nif (isNonEmptyString(options.headers?.authorization) || options.noAuth) {\nreturn options;\n}\noptions.headers ??= {};\nif (options.token) {\nconst authType = options.context?.authType;\nif (authType) {\nif (authType === 'Token-Only') {\noptions.headers.authorization = options.token;\n} else {\noptions.headers.authorization = `${authType} ${options.token}`;\n}\n} else if (\noptions.hostType &&\nGITEA_API_USING_HOST_TYPES.includes(options.hostType)\n) {\noptions.headers.authorization = `Bearer ${options.token}`;\n} else if (\noptions.hostType &&\nGITHUB_API_USING_HOST_TYPES.includes(options.hostType)\n) {\noptions.headers.authorization = `token ${options.token}`;\nif (options.token.startsWith('x-access-token:')) {\nconst appToken = options.token.replace('x-access-token:', '');\noptions.headers.authorization = `token ${appToken}`;\nif (isString(options.headers.accept)) {\noptions.headers.accept = options.headers.accept.replace(\n'application/vnd.github.v3+json',\n'application/vnd.github.machine-man-preview+json',\n);\n}\n}\n} else if (\noptions.hostType &&\nGITLAB_API_USING_HOST_TYPES.includes(options.hostType)\n) {\nif (options.token.length === 20) {\noptions.headers['Private-token'] = options.token;\n} else {\noptions.headers.authorization = `Bearer ${options.token}`;\n}\n} else {\noptions.headers.authorization = `Bearer ${options.token}`;\n}\ndelete options.token;\n} else if (options.password !== undefined) {\nconst auth = Buffer.from(\n`${options.username ?? ''}:${options.password}`,\n).toString('base64');\noptions.headers.authorization = `Basic ${auth}`;\ndelete options.username;\ndelete options.password;\n}\nreturn options;\n}"
"protected override async requestJsonUnsafe<T>(\nmethod: HttpMethod,\noptions: InternalJsonUnsafeOptions<BitbucketServerHttpOptions>,\n): Promise<HttpResponse<T>> {\nconst resolvedUrl = this.resolveUrl(options.url, options.httpOptions);\nconst opts = { ...options, url: resolvedUrl };\nopts.httpOptions ??= {};\nopts.httpOptions.headers ??= {};\nopts.httpOptions.headers['X-Atlassian-Token'] = 'no-check';\nconst paginate = opts.httpOptions.paginate;\nif (paginate) {\nconst limit = opts.httpOptions.limit ?? MAX_LIMIT;\nresolvedUrl.searchParams.set('limit', limit.toString());\n}\nconst result = await super.requestJsonUnsafe<T | PagedResult<T>>(\nmethod,\nopts,\n);\nif (paginate && isPagedResult(result.body)) {\nif (opts.httpOptions) {\ndelete opts.httpOptions.cacheProvider;\nopts.httpOptions.memCache = false;\n}\nconst collectedValues = [...result.body.values];\nlet nextPageStart = result.body.nextPageStart;\nlet maxPages = opts.httpOptions.maxPages ?? MAX_PAGES;\nwhile (nextPageStart && --maxPages > 0) {\nresolvedUrl.searchParams.set('start', nextPageStart.toString());\nconst nextResult = await super.requestJsonUnsafe<PagedResult<T>>(\nmethod,\nopts,\n);\ncollectedValues.push(...nextResult.body.values);\nnextPageStart = nextResult.body.nextPageStart;\n}\nreturn { ...result, body: collectedValues as T };\n}\nreturn result as HttpResponse<T>;\n}"
"protected override async requestJsonUnsafe<T>(\nmethod: HttpMethod,\noptions: InternalJsonUnsafeOptions<BitbucketHttpOptions>,\n): Promise<HttpResponse<T>> {\nconst resolvedUrl = this.resolveUrl(options.url, options.httpOptions);\nconst opts: InternalJsonUnsafeOptions<BitbucketHttpOptions> = {\n...options,\nurl: resolvedUrl,\n};\nconst paginate = opts.httpOptions?.paginate;\nif (paginate && !hasPagelen(resolvedUrl)) {\nconst pagelen = opts.httpOptions!.pagelen ?? MAX_PAGELEN;\nresolvedUrl.searchParams.set('pagelen', pagelen.toString());\n}\nconst result = await super.requestJsonUnsafe<T | PagedResult<T>>(\nmethod,\nopts,\n);\nif (paginate && isPagedResult(result.body)) {\nif (opts.httpOptions) {\nopts.httpOptions.memCache = false;\n}\nconst resultBody = result.body;\nlet nextURL = result.body.next;\nlet page = 1;\nfor (; nextURL && page <= MAX_PAGES; page++) {\nopts.url = nextURL;\nconst nextResult = await super.requestJsonUnsafe<PagedResult<T>>(\nmethod,\nopts,\n);\nresultBody.values.push(...nextResult.body.values);\nnextURL = nextResult.body.next;\n}\nresultBody.pagelen = resultBody.values.length;\nresultBody.size =\npage <= MAX_PAGES ? resultBody.values.length : undefined;\nresultBody.next = page <= MAX_PAGES ? nextURL : undefined;\n}\nreturn result as HttpResponse<T>;\n}"
"function getGraphqlPageSize(\nfieldName: string,\ndefaultPageSize = MAX_GRAPHQL_PAGE_SIZE,\n): number {\nconst cache = getCache();\nconst graphqlPageCache = cache?.platform?.github\n?.graphqlPageCache as GraphqlPageCache;\nconst cachedRecord = graphqlPageCache?.[fieldName];\nif (graphqlPageCache && cachedRecord) {\nlogger.debug(\n{ fieldName, ...cachedRecord },\n'GraphQL page size: found cached value',\n);\nconst oldPageSize = cachedRecord.pageSize;\nconst now = DateTime.local();\nconst then = DateTime.fromISO(cachedRecord.pageLastResizedAt);\nconst expiry = then.plus({ hours: 24 });\nif (now > expiry) {\nconst newPageSize = Math.min(oldPageSize * 2, MAX_GRAPHQL_PAGE_SIZE);\nif (newPageSize < MAX_GRAPHQL_PAGE_SIZE) {\nconst timestamp = now.toISO();\nlogger.debug(\n{ fieldName, oldPageSize, newPageSize, timestamp },\n'GraphQL page size: expanding',\n);\ncachedRecord.pageLastResizedAt = timestamp;\ncachedRecord.pageSize = newPageSize;\n} else {\nlogger.debug(\n{ fieldName, oldPageSize, newPageSize },\n'GraphQL page size: expanded to default page size',\n);\ndelete graphqlPageCache[fieldName];\n}\nreturn newPageSize;\n}\nreturn oldPageSize;\n}\nreturn defaultPageSize;\n}"
"async queryRepoField<T = Record<string, unknown>>(\nquery: string,\nfieldName: string,\noptions: GraphqlOptions = {},\n): Promise<T[]> {\nconst result: T[] = [];\nconst { paginate = true } = options;\nlet optimalCount: null | number = null;\nlet count = getGraphqlPageSize(\nfieldName,\noptions.count ?? MAX_GRAPHQL_PAGE_SIZE,\n);\nlet limit = options.limit ?? 1000;\nlet cursor: string | null = null;\nlet isIterating = true;\nwhile (isIterating) {\nconst res = await this.requestGraphql<GithubGraphqlRepoData<T>>(query, {\n...options,\ncount: Math.min(count, limit),\ncursor,\npaginate,\n});\nconst repositoryData = res?.data?.repository;\nif (\nisNonEmptyObject(repositoryData) &&\n!isNullOrUndefined(repositoryData[fieldName])\n) {\noptimalCount = count;\nconst {\nnodes = [],\nedges = [],\npageInfo,\n} = repositoryData[fieldName] as GraphqlPaginatedContent<T>;\nresult.push(...nodes);\nresult.push(...edges);\nlimit = Math.max(0, limit - nodes.length - edges.length);\nif (limit === 0) {\nisIterating = false;\n} else if (paginate && pageInfo) {\nconst { hasNextPage, endCursor } = pageInfo;\nif (hasNextPage && endCursor) {\ncursor = endCursor;\n} else {\nisIterating = false;\n}\n}\n} else {\ncount = Math.floor(count / 2);\nif (count === 0) {\nlogger.warn({ query, options, res }, 'Error fetching GraphQL nodes');\nisIterating = false;\n}\n}\nif (!paginate) {\nisIterating = false;\n}\n}\nif (optimalCount && optimalCount < MAX_GRAPHQL_PAGE_SIZE) {\nsetGraphqlPageSize(fieldName, optimalCount);\n}\nreturn result;\n}"
"protected override async requestJsonUnsafe<T = unknown>(\nmethod: HttpMethod,\noptions: InternalJsonUnsafeOptions<GitlabHttpOptions>,\n): Promise<HttpResponse<T>> {\nconst resolvedUrl = this.resolveUrl(options.url, options.httpOptions);\nconst opts = {\n...options,\nurl: resolvedUrl,\n};\nopts.httpOptions ??= {};\nopts.httpOptions.throwHttpErrors = true;\nconst result = await super.requestJsonUnsafe<T>(method, opts);\nif (opts.httpOptions.paginate && isArray(result.body)) {\nopts.httpOptions.memCache = false;\ntry {\nconst linkHeader = parseLinkHeader(result.headers.link);\nconst nextUrl = linkHeader?.next?.url\n? parseUrl(linkHeader.next.url)\n: null;\nif (nextUrl) {\nif (getEnv().GITLAB_IGNORE_REPO_URL) {\nconst defaultEndpoint = new URL(baseUrl);\nnextUrl.protocol = defaultEndpoint.protocol;\nnextUrl.host = defaultEndpoint.host;\n}\nopts.url = nextUrl;\nconst nextResult = await this.requestJsonUnsafe<T>(method, opts);\nif (isArray(nextResult.body)) {\nresult.body.push(...nextResult.body);\n}\n}\n} catch (err) {\nlogger.warn({ err }, 'Pagination error');\n}\n}\nreturn result;\n}"
"export function findMatchingRule<GotOptions extends HostRulesGotOptions>(\nurl: string,\noptions: GotOptions,\n): HostRule {\nconst { hostType, readOnly } = options;\nlet res = hostRules.find({ hostType, url, readOnly });\nif (\nisNonEmptyString(res.token) ||\nisNonEmptyString(res.username) ||\nisNonEmptyString(res.password)\n) {\nreturn res;\n}\nif (\nhostType &&\nGITHUB_API_USING_HOST_TYPES.includes(hostType) &&\nhostType !== 'github'\n) {\nres = {\n...hostRules.find({\nhostType: 'github',\nurl,\n}),\n...res,\n};\n}\nif (url.startsWith('https:\nres = {\n...hostRules.find({\nhostType: 'github',\nurl,\n}),\n...res,\n};\n}\nif (\nhostType &&\nGITLAB_API_USING_HOST_TYPES.includes(hostType) &&\nhostType !== 'gitlab'\n) {\nres = {\n...hostRules.find({\nhostType: 'gitlab',\nurl,\n}),\n...res,\n};\n}\nif (\nhostType &&\nBITBUCKET_API_USING_HOST_TYPES.includes(hostType) &&\nhostType !== 'bitbucket'\n) {\nres = {\n...hostRules.find({\nhostType: 'bitbucket',\nurl,\n}),\n...res,\n};\n}\nif (\nhostType &&\nBITBUCKET_SERVER_API_USING_HOST_TYPES.includes(hostType) &&\nhostType !== 'bitbucket-server'\n) {\nres = {\n...hostRules.find({\nhostType: 'bitbucket-server',\nurl,\n}),\n...res,\n};\n}\nif (\nhostType &&\nGITEA_API_USING_HOST_TYPES.includes(hostType) &&\nhostType !== 'gitea'\n) {\nres = {\n...hostRules.find({\nhostType: 'gitea',\nurl,\n}),\n...res,\n};\n}\nreturn res;\n}"
"export async function wrapWithRetry<T>(\ntask: Task<T>,\nurl: string,\ngetRetryAfter: (err: unknown) => number | null,\nmaxRetryAfter: number,\n): Promise<T> {\nconst key = parseUrl(url)?.host ?? url;\nlet retries = 0;\nfor (;;) {\ntry {\nawait hostDelays.get(key);\nhostDelays.delete(key);\nreturn await task();\n} catch (err) {\nconst delaySeconds = getRetryAfter(err);\nif (delaySeconds === null) {\nthrow err;\n}\nif (retries === maxRetries) {\nlogger.debug(\n`Retry-After: reached maximum retries (${maxRetries}) for ${url}`,\n);\nthrow err;\n}\nif (delaySeconds > maxRetryAfter) {\nlogger.debug(\n`Retry-After: delay ${delaySeconds} seconds exceeds maxRetryAfter ${maxRetryAfter} seconds for ${url}`,\n);\nthrow err;\n}\nlogger.debug(\n`Retry-After: will retry ${url} after ${delaySeconds} seconds`,\n);\nlet hostDelay = hostDelays.get(key);\nhostDelay ??= Promise.resolve();\nconst delay = Promise.all([hostDelay, setTimeout(1000 * delaySeconds)]);\nhostDelays.set(key, delay);\nretries += 1;\n}\n}\n}"
"export function getRetryAfter(err: unknown): number | null {\nif (!(err instanceof RequestError)) {\nreturn null;\n}\nif (!err.response) {\nreturn null;\n}\nif (err.response.statusCode < 400 || err.response.statusCode >= 500) {\nlogger.debug(\n{ url: err.response.url },\n`Retry-After: unexpected status code ${err.response.statusCode}`,\n);\nreturn null;\n}\nconst retryAfter = err.response.headers['retry-after']?.trim();\nif (!retryAfter) {\nreturn null;\n}\nconst date = DateTime.fromHTTP(retryAfter);\nif (date.isValid) {\nconst seconds = Math.floor(date.diffNow('seconds').seconds);\nif (seconds < 0) {\nlogger.debug(\n{ url: err.response.url, retryAfter },\n'Retry-After: date in the past',\n);\nreturn null;\n}\nreturn seconds;\n}\nconst seconds = parseInt(retryAfter);\nif (!Number.isNaN(seconds) && seconds >= 0) {\nreturn seconds;\n}\nlogger.debug(\n{ url: err.response.url, retryAfter },\n'Retry-After: unsupported format',\n);\nreturn null;\n}"
"async function queryApi(\ndatasource: string,\npackageName: string,\ncurrentVersion: string,\nnewVersion: string,\n): Promise<MergeConfidence> {\nif (isNullOrUndefined(apiBaseUrl) || isNullOrUndefined(token)) {\nreturn 'neutral';\n}\nconst escapedPackageName = packageName\n.replace(regEx(/\\n.replace(regEx(/:/g), '%3A');\nconst url = joinUrlParts(\napiBaseUrl,\n'api/mc/json',\ndatasource,\nescapedPackageName,\ncurrentVersion,\nnewVersion,\n);\nconst cacheKey = `${token}:${url}`;\nconst cachedResult = await packageCache.get(hostType, cacheKey);\nif (cachedResult) {\nlogger.debug(\n{\ndatasource,\npackageName,\ncurrentVersion,\nnewVersion,\ncachedResult,\n},\n'using merge confidence cached result',\n);\nreturn cachedResult;\n}\nlet confidence: MergeConfidence = 'neutral';\ntry {\nconst res = (\nawait http.getJsonUnchecked<{ confidence: MergeConfidence }>(url, {\ncacheProvider: memCacheProvider,\n})\n).body;\nif (isMergeConfidence(res.confidence)) {\nconfidence = res.confidence;\n}\n} catch (err) {\napiErrorHandler(err);\n}\nawait packageCache.set(hostType, cacheKey, confidence, 60);\nreturn confidence;\n}"
"override matches(\n{\nversioning,\nlockedVersion,\ncurrentValue,\ncurrentVersion,\n}: PackageRuleInputConfig,\n{ matchCurrentVersion }: PackageRule,\n): boolean | null {\nif (isUndefined(matchCurrentVersion)) {\nreturn null;\n}\nconst isUnconstrainedValue =\n!!lockedVersion && isNullOrUndefined(currentValue);\nconst versioningApi = allVersioning.get(versioning);\nconst matchCurrentVersionStr = matchCurrentVersion.toString();\nconst matchCurrentVersionPred = getRegexPredicate(matchCurrentVersionStr);\nif (matchCurrentVersionPred) {\nconst compareVersion = lockedVersion ?? currentVersion ?? currentValue;\nreturn (\n!isNullOrUndefined(compareVersion) &&\nmatchCurrentVersionPred(compareVersion)\n);\n}\nif (versioningApi.isVersion(matchCurrentVersionStr)) {\ntry {\nreturn (\nisUnconstrainedValue ||\n!!(\ncurrentValue &&\nversioningApi.isValid(currentValue) &&\nversioningApi.matches(matchCurrentVersionStr, currentValue)\n)\n);\n} catch {\nreturn false;\n}\n}\nconst compareVersion = versioningApi.isVersion(currentValue)\n? currentValue\n: (lockedVersion ?? currentVersion);\nif (isNullOrUndefined(compareVersion)) {\nreturn false;\n}\nif (versioningApi.isVersion(compareVersion)) {\nreturn versioningApi.matches(compareVersion, matchCurrentVersion);\n}\nlogger.debug(\n{ matchCurrentVersionStr, currentValue },\n'Could not find a version to compare',\n);\nreturn false;\n}"
"export async function applyPackageRules<T extends PackageRuleInputConfig>(\ninputConfig: T,\nstageName?: StageName,\n): Promise<T> {\nlet config = { ...inputConfig };\nconst packageRules = config.packageRules ?? [];\nlogger.trace(\n{ dependency: config.depName, packageRules },\n`Checking against ${packageRules.length} packageRules`,\n);\nfor (const packageRule of packageRules) {\nif (await matchesRule(config, packageRule)) {\nconst toApply = removeMatchers({ ...packageRule });\nif (config.groupSlug && packageRule.groupName && !packageRule.groupSlug) {\ntoApply.groupSlug = slugify(packageRule.groupName, {\nlower: true,\n});\n}\nif (toApply.enabled === false && config.enabled !== false) {\nconfig.skipReason = 'package-rules';\nif (stageName) {\nconfig.skipStage = stageName;\n}\n}\nif (toApply.enabled === true && config.enabled === false) {\ndelete config.skipReason;\ndelete config.skipStage;\n}\nif (\nisString(toApply.overrideDatasource) &&\ntoApply.overrideDatasource !== config.datasource\n) {\nlogger.debug(\n`Overriding datasource from ${config.datasource} to ${toApply.overrideDatasource} for ${config.depName}`,\n);\nconfig.datasource = toApply.overrideDatasource;\n}\nif (\nisString(toApply.overrideDepName) &&\ntoApply.overrideDepName !== config.depName\n) {\nlogger.debug(\n`Overriding depName from ${config.depName} to ${toApply.overrideDepName}`,\n);\nconfig.depName = compile(toApply.overrideDepName, config);\n}\nif (\nisString(toApply.overridePackageName) &&\ntoApply.overridePackageName !== config.packageName\n) {\nlogger.debug(\n`Overriding packageName from ${config.packageName} to ${toApply.overridePackageName} for ${config.depName}`,\n);\nconfig.packageName = compile(toApply.overridePackageName, config);\n}\ndelete toApply.overrideDatasource;\ndelete toApply.overrideDepName;\ndelete toApply.overridePackageName;\nconfig = mergeChildConfig(config, toApply);\n}\n}\nreturn config;\n}"
"export function LooseArray<Schema extends z.ZodTypeAny>(\nElem: Schema,\n{ onError }: LooseOpts<unknown[]> = {},\n): z.ZodEffects<z.ZodArray<z.ZodAny, 'many'>, z.TypeOf<Schema>[], any[]> {\nif (!onError) {\nreturn z.array(z.any()).transform((input) => {\nconst output: z.infer<Schema>[] = [];\nfor (const x of input) {\nconst parsed = Elem.safeParse(x);\nif (parsed.success) {\noutput.push(parsed.data);\n}\n}\nreturn output;\n});\n}\nreturn z.array(z.any()).transform((input) => {\nconst output: z.infer<Schema>[] = [];\nconst issues: z.ZodIssue[] = [];\nfor (let idx = 0; idx < input.length; idx += 1) {\nconst x = input[idx];\nconst parsed = Elem.safeParse(x);\nif (parsed.success) {\noutput.push(parsed.data);\ncontinue;\n}\nfor (const issue of parsed.error.issues) {\nissue.path.unshift(idx);\nissues.push(issue);\n}\n}\nif (issues.length) {\nconst error = new z.ZodError(issues);\nonError({ error, input });\n}\nreturn output;\n});\n}"
"export function calcLimit(\nupgrades: BranchUpgradeConfig[],\nlimitName: BranchLimitName,\n): number {\nconst uniqueUpgrades = new Map(upgrades.map((u) => [u.depName, u]));\nlogger.debug(\n{\nlimits: Array.from(uniqueUpgrades.values()).map((upg) => {\nreturn { depName: upg.depName, [limitName]: upg[limitName] };\n}),\n},\n`${limitName} of the upgrades present in this branch`,\n);\nif (hasMultipleLimits(upgrades, limitName)) {\nlogger.once.debug(\n`Branch has multiple ${limitName} limits. The lowest among these will be selected.`,\n);\n}\nlet lowestLimit = Number.MAX_SAFE_INTEGER;\nfor (const upgrade of upgrades) {\nlet limit = upgrade[limitName];\nif (!isNumber(limit) && limitName === 'branchConcurrentLimit') {\nlimit = upgrade.prConcurrentLimit;\n}\nif (isUndefined(limit)) {\nlimit = Number.MAX_SAFE_INTEGER;\n}\nif (limit === 0 || limit === null) {\nlogger.debug(\n`${limitName} of this branch is unlimited, because atleast one of the upgrade has it's ${limitName} set to `No limit` ie. 0 or null`,\n);\nreturn 0;\n}\nlowestLimit = limit < lowestLimit ? limit : lowestLimit;\n}\nlogger.debug(\n`Calculated lowest ${limitName} among the upgrades present in this branch is ${lowestLimit}.`,\n);\nreturn lowestLimit;\n}"
"function generateBranchUpgradeCache(\nupgrade: BranchUpgradeConfig,\n): BranchUpgradeCache {\nconst {\ndatasource,\ndepName,\ndepType,\ndisplayPending,\npackageName,\nfixedVersion,\ncurrentVersion,\nnewVersion,\ncurrentValue,\nnewValue,\ncurrentDigest,\nnewDigest,\npackageFile,\nsourceUrl,\nremediationNotPossible,\nupdateType,\n} = upgrade;\nconst result: BranchUpgradeCache = {\ndatasource,\ndepName,\ndepType,\ndisplayPending,\nfixedVersion,\ncurrentVersion,\ncurrentValue,\nnewValue,\nnewVersion,\ncurrentDigest,\nnewDigest,\npackageFile,\nsourceUrl,\nremediationNotPossible,\nupdateType,\n};\nif (packageName) {\nresult.packageName = packageName;\n}\nreturn result;\n}"
"function getBranchesListMd(\nbranches: BranchConfig[],\npredicate: (\nvalue: BranchConfig,\nindex: number,\narray: BranchConfig[],\n) => unknown,\ntitle: string,\ndescription: string,\nlistItemType = 'approvePr',\nbulkComment?: string,\nbulkMessage?: string,\nbulkIcon?: '🔐',\n): string {\nconst filteredBranches = branches.filter(predicate);\nif (filteredBranches.length === 0) {\nreturn '';\n}\nlet result = `## ${title}\n\n${description}\n\n`;\nconst { categories, uncategorized, hasCategorized, hasUncategorized } =\nsplitBranchesByCategory(filteredBranches);\nif (hasCategorized) {\nfor (const [category, branches] of Object.entries(categories).sort(\n([keyA], [keyB]) =>\nkeyA.localeCompare(keyB, undefined, { numeric: true }),\n)) {\nresult = result.trimEnd() + '\n\n';\nresult += `### ${category}\n\n`;\nresult += getBranchList(branches, listItemType);\n}\nif (hasUncategorized) {\nresult = result.trimEnd() + '\n\n';\nresult += `### Others`;\n}\n}\nresult = result.trimEnd() + '\n\n';\nresult += getBranchList(uncategorized, listItemType);\nif (bulkComment && bulkMessage && filteredBranches.length > 1) {\nif (hasCategorized) {\nresult = result.trimEnd() + '\n\n';\nresult += '### All\n\n';\n}\nresult += getCheckbox(bulkComment);\nresult += `${bulkIcon ? bulkIcon + ' ' : ''}**${bulkMessage}**${bulkIcon ? ' ' + bulkIcon : ''}`;\n}\nreturn result.trimEnd() + '\n\n';\n}"
"export function getAbandonedPackagesMd(\npackageFiles: Record<string, PackageFile[]>,\n): string {\nconst abandonedPackages: Record<\nstring,\nRecord<string, string | undefined | null>\n> = {};\nlet abandonedCount = 0;\nfor (const [manager, managerPackageFiles] of Object.entries(packageFiles)) {\nfor (const packageFile of managerPackageFiles) {\nfor (const dep of coerceArray(packageFile.deps)) {\nif (dep.depName && dep.isAbandoned) {\nabandonedCount++;\nabandonedPackages[manager] = abandonedPackages[manager] || {};\nabandonedPackages[manager][dep.depName] = dep.mostRecentTimestamp;\n}\n}\n}\n}\nif (abandonedCount === 0) {\nreturn '';\n}\nlet abandonedMd = '> ℹ **Note**\n> \n';\nabandonedMd +=\n'These dependencies have not received updates for an extended period and may be unmaintained:\n\n';\nabandonedMd += '<details>\n';\nabandonedMd += `<summary>View abandoned dependencies (${abandonedCount})</summary>\n\n`;\nabandonedMd += '| Datasource | Name | Last Updated |\n';\nabandonedMd += '|------------|------|-------------|\n';\nfor (const manager of Object.keys(abandonedPackages).sort()) {\nconst deps = abandonedPackages[manager];\nfor (const depName of Object.keys(deps).sort()) {\nconst mostRecentTimestamp = deps[depName];\nconst formattedDate = mostRecentTimestamp\n? DateTime.fromISO(mostRecentTimestamp).toFormat('yyyy-MM-dd')\n: 'unknown';\nabandonedMd += `| ${manager} | \`${depName}\` | \`${formattedDate}\` |\n`;\n}\n}\nabandonedMd += '\n</details>\n\n';\nabandonedMd +=\n'Packages are marked as abandoned when they exceed the [`abandonmentThreshold`](https:\nabandonedMd +=\n'Unlike deprecated packages with official notices, abandonment is detected by release inactivity.\n\n';\nreturn abandonedMd + '\n';\n}"
"async function raiseWarningIssue(\nconfig: RenovateConfig,\nnotificationName: string,\ntitle: string,\ninitialBody: string,\nerror: Error,\n): Promise<void> {\nif (config.mode === 'silent') {\nlogger.debug(\n`Config warning issues are not created, updated or closed when mode=silent`,\n);\nreturn;\n}\nlet body = initialBody;\nif (error.validationSource) {\nbody += `Location: \`${error.validationSource}\`\n`;\n}\nif (error.validationError) {\nbody += `Error type: ${error.validationError}\n`;\n}\nif (error.validationMessage) {\nbody += `Message: ${error.validationMessage}\n`;\n}\nconst pr = await platform.getBranchPr(\nconfig.onboardingBranch!,\nconfig.baseBranch,\n);\nif (pr?.state === 'open') {\nawait handleOnboardingPr(pr, body);\nreturn;\n}\nif (GlobalConfig.get('dryRun')) {\nlogger.info(\n{ configError: error },\n'DRY-RUN: Would ensure configuration error issue',\n);\nreturn;\n}\nif (config.suppressNotifications?.includes(notificationName)) {\nlogger.info(\n{ notificationName },\n'Configuration failure, issues will be suppressed',\n);\nreturn;\n}\nconst res = await platform.ensureIssue({\ntitle,\nbody,\nonce: false,\nshouldReOpen: config.configWarningReuseIssue,\nconfidential: config.confidential,\n});\nif (res === 'updated' || res === 'created') {\nlogger.warn({ configError: error, res }, 'Configuration Warning');\n}\n}"
"static getDashboardMarkdown(maxLength: number, setHeader = true): string {\nconst note =\n'> ℹ **Note**\n> \n> Detected dependencies section has been truncated\n\n';\nconst title = `## Detected dependencies\n\n`;\nconst maxHeaderLen = setHeader ? (title + note).length : 0;\nconst mdMaxLength = maxLength - maxHeaderLen;\nlet md: string;\nlet header = '';\nlet removed = false;\nlet truncated = false;\nconst data = new Map(clone(Array.from(this.data)));\nfor (const managers of [...data.values()].filter(isTruthy)) {\nfor (const files of Object.values(managers).filter(isTruthy)) {\nfor (const file of files.filter((f) => isTruthy(f.deps))) {\nfile.deps = file.deps.filter(isTruthy).filter((d) => !d.skipReason);\n}\n}\n}\ndo {\nmd = PackageFiles.getDashboardMarkdownInternal(data);\nif (md.length > mdMaxLength) {\nremoved = PackageFiles.pop(data);\n}\nif (removed) {\ntruncated = true;\n}\n} while (removed && md.length > mdMaxLength);\nheader += title;\nheader += truncated ? note : '';\nreturn (setHeader ? header : '') + md;\n}"
"private static getDashboardMarkdownInternal(\ndata: Map<string, Record<string, PackageFile[]> | null>,\n): string {\nconst none = 'None detected\n\n';\nconst pad = data.size > 1;\nlet deps = '';\nfor (const [branch, packageFiles] of Array.from(data).sort(([a], [b]) =>\na.localeCompare(b, undefined, { numeric: true }),\n)) {\ndeps += pad\n? `<details><summary>Branch ${branch}</summary>\n<blockquote>\n\n`\n: '';\nif (packageFiles === null) {\ndeps += none;\ndeps += pad ? '</blockquote>\n</details>\n\n' : '';\ncontinue;\n}\nconst managers = Object.keys(packageFiles).sort();\nif (managers.length === 0) {\ndeps += none;\ndeps += pad ? '</blockquote>\n</details>\n\n' : '';\ncontinue;\n}\nfor (const manager of managers) {\ndeps += `<details><summary>${manager}</summary>\n<blockquote>\n\n`;\nfor (const packageFile of Array.from(packageFiles[manager]).sort(\n(a, b) => a.packageFile.localeCompare(b.packageFile),\n)) {\ndeps += `<details><summary>${packageFile.packageFile}</summary>\n\n`;\nfor (const dep of packageFile.deps) {\nconst ver = dep.currentValue;\nconst digest = dep.currentDigest;\nconst lock = dep.lockedVersion;\nlet version;\nif (ver || digest) {\nversion = ver && digest ? `${ver}@${digest}` : `${digest ?? ver}`;\n} else if (lock) {\nversion = `lock file @ ${lock}`;\n} else {\nversion = 'unknown version';\n}\ndeps += ` - \`${dep.depName!} ${version}\`\n`;\n}\ndeps += '\n</details>\n\n';\n}\ndeps += `</blockquote>\n</details>\n\n`;\n}\ndeps += pad ? '</blockquote>\n</details>\n\n' : '';\n}\nreturn deps;\n}"
"export function processResult(\nconfig: RenovateConfig,\nres: string,\n): ProcessResult {\nconst disabledStatuses = [\nREPOSITORY_ACCESS_FORBIDDEN,\nREPOSITORY_ARCHIVED,\nREPOSITORY_BLOCKED,\nREPOSITORY_CLOSED_ONBOARDING,\nREPOSITORY_DISABLED,\nREPOSITORY_DISABLED_BY_CONFIG,\nREPOSITORY_EMPTY,\nREPOSITORY_FORK_MODE_FORKED,\nREPOSITORY_FORKED,\nREPOSITORY_MIRRORED,\nREPOSITORY_NOT_FOUND,\nREPOSITORY_NO_CONFIG,\nREPOSITORY_NO_PACKAGE_FILES,\nREPOSITORY_RENAMED,\nREPOSITORY_UNINITIATED,\n];\nconst enabledStatuses = [\nCONFIG_SECRETS_EXPOSED,\nCONFIG_VALIDATION,\nMISSING_API_CREDENTIALS,\n];\nlet status: ProcessStatus;\nlet enabled: boolean | undefined;\nlet onboarded: boolean | undefined;\nif (disabledStatuses.includes(res)) {\nstatus = 'disabled';\nenabled = false;\n} else if (config.repoIsActivated) {\nstatus = 'activated';\nenabled = true;\nonboarded = true;\n} else if (enabledStatuses.includes(res) || config.repoIsOnboarded) {\nstatus = 'onboarded';\nenabled = true;\nonboarded = true;\n} else if (config.repoIsOnboarded === false) {\nstatus = 'onboarding';\nenabled = true;\nonboarded = false;\n} else {\nlogger.debug(`Unknown res: ${res}`);\nstatus = 'unknown';\n}\nlogger.debug(\n`Repository result: ${res}, status: ${status}, enabled: ${enabled!}, onboarded: ${onboarded!}`,\n);\nreturn { res, status, enabled, onboarded };\n}"
"override run(value: (LegacyHostRule & HostRule)[]): void {\nconst newHostRules: HostRule[] = [];\nfor (const hostRule of value) {\nvalidateHostRule(hostRule);\nconst newRule: any = {};\nfor (const [key, value] of Object.entries(hostRule)) {\nif (key === 'platform') {\nif (isString(value)) {\nnewRule.hostType ??= value;\n}\ncontinue;\n}\nif (key === 'matchHost') {\nif (isString(value)) {\nnewRule.matchHost ??= massageHostUrl(value);\n}\ncontinue;\n}\nif (key === 'hostType') {\nif (isString(value)) {\nnewRule.hostType ??= migrateDatasource(value);\n}\ncontinue;\n}\nif (\nkey === 'endpoint' ||\nkey === 'host' ||\nkey === 'baseUrl' ||\nkey === 'hostName' ||\nkey === 'domainName'\n) {\nif (isString(value)) {\nnewRule.matchHost ??= massageHostUrl(value);\n}\ncontinue;\n}\nnewRule[key] = value;\n}\nnewHostRules.push(newRule);\n}\nthis.rewrite(newHostRules);\n}"
"override run(value: unknown): void {\nif (value) {\nlet schedules: string[] = [];\nif (isString(value)) {\nschedules = [value];\n}\nif (isArray<string>(value)) {\nschedules = [...value];\n}\nconst schedulesLength = schedules.length;\nfor (let i = 0; i < schedulesLength; i += 1) {\nif (\nschedules[i].includes(' and ') &&\nschedules[i].includes('before ') &&\nschedules[i].includes('after ')\n) {\nconst parsedSchedule = later.parse.text(\nschedules[i].replace(shortHoursRegex, '$1:00$2'),\n).schedules[0];\nif (!parsedSchedule?.t_a || !parsedSchedule.t_b) {\ncontinue;\n}\nif (parsedSchedule.t_a[0] > parsedSchedule.t_b[0]) {\nconst toSplit = schedules[i];\nschedules[i] = toSplit\n.replace(afterBeforeRegex, '$1$2 $3 $7')\n.trim();\nschedules.push(\ntoSplit.replace(afterBeforeRegex, '$1$4 $5 $7').trim(),\n);\n}\n}\n}\nfor (let i = 0; i < schedules.length; i += 1) {\nif (schedules[i].includes('on the last day of the month')) {\nschedules[i] = schedules[i].replace(\n'on the last day of the month',\n'on the first day of the month',\n);\n}\nif (schedules[i].includes('on every weekday')) {\nschedules[i] = schedules[i].replace(\n'on every weekday',\n'every weekday',\n);\n}\nif (schedules[i].endsWith(' every day')) {\nschedules[i] = schedules[i].replace(' every day', '');\n}\nif (dayRegex1.test(schedules[i])) {\nschedules[i] = schedules[i].replace(dayRegex2, 'on $1');\n}\nif (schedules[i].endsWith('days')) {\nschedules[i] = schedules[i].replace('days', 'day');\n}\n}\nif (isString(value) && schedules.length === 1) {\nthis.rewrite(schedules[0]);\n} else {\nthis.rewrite(schedules);\n}\n}\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nlogger.warn(\n{ packageName },\n'artifactory datasource requires custom registryUrl. Skipping datasource',\n);\nreturn null;\n}\nconst url = joinUrlParts(registryUrl, packageName);\nconst result: ReleaseResult = {\nreleases: [],\n};\ntry {\nconst response = await this.http.getText(url);\nconst body = parse(response.body, {\nblockTextElements: {\nscript: true,\nnoscript: true,\nstyle: true,\n},\n});\nconst nodes = body.querySelectorAll('a');\nnodes\n.filter(\n(node) => node.innerHTML !== '../' && node.innerHTML !== '..',\n)\n.forEach(\n(node) => {\nconst version: string = node.innerHTML.endsWith('/')\n? node.innerHTML.slice(0, -1)\n: node.innerHTML;\nconst releaseTimestamp = asTimestamp(\nnode.nextSibling?.text?.trimStart()?.split(regEx(/\s{2,}/))?.[0],\n);\nconst thisRelease: Release = {\nversion,\nreleaseTimestamp,\n};\nresult.releases.push(thisRelease);\n},\n);\nif (result.releases.length) {\nlogger.trace(\n{ registryUrl, packageName, versions: result.releases.length },\n'artifactory: Found versions',\n);\n} else {\nlogger.trace(\n{ registryUrl, packageName },\n'artifactory: No versions found',\n);\n}\n} catch (err) {\nif (err instanceof HttpError) {\nif (err.response?.statusCode === 404) {\nlogger.warn(\n{ registryUrl, packageName },\n'artifactory: `Not Found` error',\n);\nreturn null;\n}\n}\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length ? result : null;\n}"
"@cache({\nnamespace: `datasource-${AwsEKSAddonDataSource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => `getReleases:${packageName}`,\n})\nasync getReleases({\npackageName: serializedFilter,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst res = EksAddonsFilter.safeParse(serializedFilter);\nif (!res.success) {\nlogger.warn(\n{ err: res.error, serializedFilter },\n'Error parsing eks-addons config.',\n);\nreturn null;\n}\nconst filter = res.data;\nconst cmd = new DescribeAddonVersionsCommand({\nkubernetesVersion: filter.kubernetesVersion,\naddonName: filter.addonName,\nmaxResults: 1,\n});\nconst response = await this.getClient(filter).send(cmd);\nconst addons = coerceArray(response.addons);\nreturn {\nreleases: addons\n.flatMap((addon) => {\nreturn addon.addonVersions;\n})\n.filter(isTruthy)\n.map((versionInfo) => ({\nversion: versionInfo.addonVersion ?? '',\ndefault:\nversionInfo.compatibilities?.some((comp) => comp.defaultVersion) ??\nfalse,\ncompatibleWith: versionInfo.compatibilities?.flatMap(\n(comp) => comp.clusterVersion,\n),\n}))\n.filter((release) => release.version && release.version !== '')\n.filter((release) => {\nif (filter.default) {\nreturn release.default && release.default === filter.default;\n}\nreturn true;\n}),\n};\n}"
"async getReleases({\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst platform = GlobalConfig.get('platform');\nconst endpoint = GlobalConfig.get('endpoint');\nconst { token } = hostRules.find({\nhostType: AzurePipelinesTasksDatasource.id,\nurl: endpoint,\n});\nif (platform === 'azure' && endpoint && token) {\nconst auth = Buffer.from(`renovate:${token}`).toString('base64');\nconst opts: HttpOptions = {\nheaders: { authorization: `Basic ${auth}` },\n};\nconst results = await this.getTasks(\n`${endpoint}/_apis/distributedtask/tasks/`,\nopts,\nAzurePipelinesJSON,\n);\nconst result: ReleaseResult = { releases: [] };\nresults.value\n.filter((task) => {\nconst matchers = [\ntask.id === packageName,\ntask.name === packageName,\ntask.contributionIdentifier !== null &&\n`${task.contributionIdentifier}.${task.id}` === packageName,\ntask.contributionIdentifier !== null &&\n`${task.contributionIdentifier}.${task.name}` === packageName,\n];\nreturn matchers.some((match) => match);\n})\n.sort(AzurePipelinesTasksDatasource.compareSemanticVersions('version'))\n.forEach((task) => {\nconst release: Release = {\nversion: `${task.version!.major}.${task.version!.minor}.${task.version!.patch}`,\nchangelogContent: task.releaseNotes,\nisDeprecated: task.deprecated,\n};\nif (task.serverOwned) {\nrelease.changelogUrl = BUILT_IN_TASKS_CHANGELOG_URL;\n}\nresult.releases.push(release);\n});\nreturn result;\n} else {\nconst versions =\n(\nawait this.getTasks(\nBUILT_IN_TASKS_URL,\n{},\nAzurePipelinesFallbackTasks,\n)\n)[packageName.toLowerCase()] ??\n(\nawait this.getTasks(\nMARKETPLACE_TASKS_URL,\n{},\nAzurePipelinesFallbackTasks,\n)\n)[packageName.toLowerCase()];\nif (versions) {\nconst releases = versions.map((version) => ({ version }));\nreturn { releases };\n}\n}\nreturn null;\n}"
"@cache({\nnamespace: `datasource-${BazelDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl!}:${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst path = BazelDatasource.packageMetadataPath(packageName);\nconst url = joinUrlParts(registryUrl!, path);\nconst result: ReleaseResult = { releases: [] };\ntry {\nlet metadata: BazelModuleMetadata;\nconst FILE_PREFIX = 'file:\nif (url.startsWith(FILE_PREFIX)) {\nconst filePath = url.slice(FILE_PREFIX.length);\nif (!isValidLocalPath(filePath)) {\nreturn null;\n}\nconst fileContent = await readLocalFile(filePath, 'utf8');\nif (!fileContent) {\nreturn null;\n}\nmetadata = BazelModuleMetadata.parse(JSON.parse(fileContent));\n} else {\nconst response = await this.http.getJson(url, BazelModuleMetadata);\nmetadata = response.body;\n}\nresult.releases = metadata.versions\n.map((v) => new BzlmodVersion(v))\n.sort(BzlmodVersion.defaultCompare)\n.map((bv) => {\nconst release: Release = { version: bv.original };\nif (isTruthy(metadata.yanked_versions?.[bv.original])) {\nrelease.isDeprecated = true;\n}\nreturn release;\n});\nif (metadata.homepage) {\nresult.homepage = metadata.homepage;\n}\n} catch (err) {\nif (err instanceof HttpError) {\nif (err.response?.statusCode === 404) {\nreturn null;\n}\nthrow new ExternalHostError(err);\n}\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length ? result : null;\n}"
"@cache({\nnamespace: BitbucketServerTagsDatasource.cacheNamespace,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\nBitbucketServerTagsDatasource.getCacheKey(\nregistryUrl,\npackageName,\n'tags',\n),\n})\nasync getReleases(config: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst { registryUrl, packageName } = config;\nconst [projectKey, repositorySlug] = packageName.split('/');\nif (!registryUrl) {\nlogger.debug('Missing registryUrl');\nreturn null;\n}\nconst result = Result.parse(config, ReleasesConfig)\n.transform(({ registryUrl }) => {\nconst url = `${BitbucketServerTagsDatasource.getApiUrl(registryUrl)}projects/${projectKey}/repos/${repositorySlug}/tags`;\nreturn this.http.getJsonSafe(\nurl,\n{ paginate: true },\nBitbucketServerTags,\n);\n})\n.transform((tags) =>\ntags.map(({ displayId, hash }) => ({\nversion: displayId,\ngitRef: displayId,\nnewDigest: hash ?? undefined,\n})),\n)\n.transform((versions): ReleaseResult => {\nreturn {\nsourceUrl: BitbucketServerTagsDatasource.getSourceUrl(\nprojectKey,\nrepositorySlug,\nregistryUrl,\n),\nregistryUrl:\nBitbucketServerTagsDatasource.getRegistryURL(registryUrl),\nreleases: versions,\n};\n});\nconst { val, err } = await result.unwrap();\nif (err instanceof ZodError) {\nlogger.debug({ err }, 'bitbucket-server-tags: validation error');\nreturn null;\n}\nif (err) {\nthis.handleGenericErrors(err);\n}\nreturn val;\n}"
"@cache({\nnamespace: BitbucketServerTagsDatasource.cacheNamespace,\nkey: ({ registryUrl, packageName }: DigestConfig) =>\nBitbucketServerTagsDatasource.getCacheKey(\nregistryUrl,\npackageName,\n'digest',\n),\n})\noverride async getDigest(\nconfig: DigestConfig,\nnewValue?: string,\n): Promise<string | null> {\nconst { registryUrl, packageName } = config;\nconst [projectKey, repositorySlug] = packageName.split('/');\nif (!registryUrl) {\nlogger.debug('Missing registryUrl');\nreturn null;\n}\nconst baseUrl = `${BitbucketServerTagsDatasource.getApiUrl(registryUrl)}projects/${projectKey}/repos/${repositorySlug}`;\nif (newValue?.length) {\nreturn this.getTagCommit(baseUrl, newValue);\n}\nconst result = Result.parse(config, DigestsConfig)\n.transform(() => {\nconst url = `${baseUrl}/commits?ignoreMissing=true`;\nreturn this.http.getJsonSafe(\nurl,\n{\npaginate: true,\nlimit: 1,\nmaxPages: 1,\n},\nBitbucketServerCommits,\n);\n})\n.transform((commits) => {\nreturn commits[0]?.id;\n});\nconst { val = null, err } = await result.unwrap();\nif (err instanceof ZodError) {\nlogger.debug({ err }, 'bitbucket-server-tags: validation error');\nreturn null;\n}\nif (err) {\nthis.handleGenericErrors(err);\n}\nreturn val;\n}"
"@cache({\nnamespace: `datasource-${BuildpacksRegistryDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases(config: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst result = Result.parse(config, ReleasesConfig)\n.transform(({ packageName, registryUrl }) => {\nconst url = urlJoin(\nregistryUrl,\n'api',\n'v1',\n'buildpacks',\npackageName,\n);\nreturn this.http.getJsonSafe(url, BuildpacksRegistryResponse);\n})\n.transform(({ versions, latest }): ReleaseResult => {\nconst releases: Release[] = versions;\nconst res: ReleaseResult = { releases };\nif (latest?.homepage) {\nres.homepage = latest.homepage;\n}\nreturn res;\n});\nconst { val, err } = await result.unwrap();\nif (err instanceof ZodError) {\nlogger.debug({ err }, 'buildpacks: validation error');\nreturn null;\n}\nif (err) {\nthis.handleGenericErrors(err);\n}\nreturn val;\n}"
"@cache({\nnamespace: `datasource-${CdnjsDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => {\nconst library = packageName.split('/')[0];\nreturn `getReleases:${library}`;\n},\n})\nasync getReleases(config: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst result = Result.parse(config, ReleasesConfig)\n.transform(({ packageName, registryUrl }) => {\nconst [library] = packageName.split('/');\nconst url = `${registryUrl}libraries/${library}?fields=homepage,repository,versions`;\nreturn this.http.getJsonSafe(\nurl,\n{ cacheProvider: memCacheProvider },\nCdnjsAPIVersionResponse,\n);\n})\n.transform(({ versions, homepage, repository }): ReleaseResult => {\nconst releases: Release[] = versions;\nconst res: ReleaseResult = { releases };\nif (homepage) {\nres.homepage = homepage;\n}\nif (repository) {\nres.sourceUrl = repository;\n}\nreturn res;\n});\nconst { val, err } = await result.unwrap();\nif (err instanceof ZodError) {\nlogger.debug({ err }, 'cdnjs: validation error');\nreturn null;\n}\nif (err) {\nthis.handleGenericErrors(err);\n}\nreturn val;\n}"
"function mockGenericPackage(opts: MockOpts = {}) {\nconst {\ndep = 'org.example:package',\nbase = baseUrl,\nlatest = '2.0.0',\nsnapshots,\n} = opts;\nconst meta =\nopts.meta === undefined\n? Fixtures.get('metadata.xml', upath.join('..', 'maven'))\n: opts.meta;\nconst pom =\nopts.pom === undefined\n? Fixtures.get('pom.xml', upath.join('..', 'maven'))\n: opts.pom;\nconst scope = httpMock.scope(base);\nconst [group, artifact] = dep.split(':');\nconst packagePath = `${group.replace(/\./g, '/')}/${artifact}`;\nif (meta) {\nscope.get(`/${packagePath}/maven-metadata.xml`).reply(200, meta);\n}\nif (pom) {\nscope\n.get(`/${packagePath}/${latest}/${artifact}-${latest}.pom`)\n.reply(200, pom);\n}\nif (snapshots) {\nsnapshots.forEach((snapshot) => {\nif (snapshot.meta) {\nscope\n.get(`/${packagePath}/${snapshot.version}/maven-metadata.xml`)\n.reply(200, snapshot.meta);\n} else {\nscope\n.get(`/${packagePath}/${snapshot.version}/maven-metadata.xml`)\n.reply(404, '');\n}\n});\n}\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nlogger.trace({ registryUrl, packageName }, 'fetching conda package');\nif (!registryUrl) {\nreturn null;\n}\nif (\nregistryUrl.startsWith('https:\nregistryUrl.startsWith('https:\n) {\nconst channel = ensureTrailingSlash(registryUrl).split('/').at(-2)!;\nreturn prefixDev.getReleases(this.http, channel, packageName);\n}\nconst url = joinUrlParts(registryUrl, packageName);\nconst result: ReleaseResult = {\nreleases: [],\n};\nlet response: { body: CondaPackage };\ntry {\nresponse = await this.http.getJsonUnchecked(url);\nresult.homepage = response.body.html_url;\nresult.sourceUrl = response.body.dev_url;\nconst releaseDate: Record<string, Timestamp> = {};\nfor (const file of coerceArray(response.body.files)) {\nreleaseDate[file.version] ??= Timestamp.parse(file.upload_time);\n}\nresponse.body.versions.forEach((version: string) => {\nconst thisRelease: Release = {\nversion,\nreleaseTimestamp: releaseDate[version],\n};\nresult.releases.push(thisRelease);\n});\n} catch (err) {\nif (err instanceof HttpError) {\nif (err.response?.statusCode !== 404) {\nthrow new ExternalHostError(err);\n}\n}\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length ? result : null;\n}"
"export async function getReleases(\nhttp: Http,\nchannel: string,\npackageName: string,\n): Promise<ReleaseResult | null> {\nlogger.debug(\n{ channel, packageName },\n'lookup package from prefix.dev graphql API',\n);\nconst files = await getPagedResponse(http, query, {\nchannel,\npackage: packageName,\n});\nif (!files.length) {\nreturn null;\n}\nlet homepage: string | undefined = undefined;\nlet sourceUrl: string | undefined = undefined;\nconst releases: Record<string, Release> = {};\nfor (const file of files) {\nconst version = file.version;\nhomepage ??= file.urls.HOME;\nsourceUrl ??= file.urls.DEV;\nreleases[version] ??= { version };\nreleases[version].releaseTimestamp =\nreleases[version].releaseTimestamp ??\nMaybeTimestamp.parse(file.createdAt);\nreleases[version].isDeprecated ??= isNotNullOrUndefined(file.yankedReason);\n}\nreturn {\nhomepage,\nsourceUrl,\nreleases: Object.values(releases),\n};\n}"
"@cache({\nnamespace: `datasource-${CpanDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => `${packageName}`,\n})\noverride async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nlet result: ReleaseResult | null = null;\nconst searchUrl = joinUrlParts(registryUrl, 'v1/file/_search');\nlet releases: CpanRelease[] | null = null;\ntry {\nconst body = {\nquery: {\nfiltered: {\nquery: { match_all: {} },\nfilter: {\nand: [\n{ term: { 'module.name': packageName } },\n{ term: { 'module.authorized': true } },\n{ exists: { field: 'module.associated_pod' } },\n],\n},\n},\n},\n_source: [\n'module.name',\n'module.version',\n'distribution',\n'date',\n'deprecated',\n'maturity',\n'status',\n],\nsort: [{ date: 'desc' }],\n};\nreleases = (\nawait this.http.postJson(\nsearchUrl,\n{ body },\nMetaCpanApiFileSearchResponse,\n)\n).body;\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nlet latestDistribution: string | null = null;\nlet latestVersion: string | null = null;\nif (releases) {\nfor (const release of releases) {\nlatestDistribution ??= release.distribution;\nif (!latestVersion && release.isLatest) {\nlatestVersion = release.version;\n}\n}\n}\nif (releases.length > 0 && latestDistribution) {\nresult = {\nreleases,\nchangelogUrl: `https:\nhomepage: `https:\n};\nif (latestVersion) {\nresult.tags ??= {};\nresult.tags.latest = latestVersion;\n}\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${CrateDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}/${packageName}`,\ncacheable: ({ registryUrl }: GetReleasesConfig) =>\nCrateDatasource.areReleasesCacheable(registryUrl),\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nlogger.warn(\n'crate datasource: No registryUrl specified, cannot perform getReleases',\n);\nreturn null;\n}\nconst registryInfo = await CrateDatasource.fetchRegistryInfo({\npackageName,\nregistryUrl,\n});\nif (!registryInfo) {\nlogger.debug(`Could not fetch registry info from ${registryUrl}`);\nreturn null;\n}\nconst dependencyUrl = CrateDatasource.getDependencyUrl(\nregistryInfo,\npackageName,\n);\nconst payload = await this.fetchCrateRecordsPayload(\nregistryInfo,\npackageName,\n);\nconst lines = payload\n.split(newlineRegex)\n.map((line) => line.trim())\n.filter((line) => line.length !== 0)\n.map((line) => JSON.parse(line) as CrateRecord);\nconst metadata = await this.getCrateMetadata(registryInfo, packageName);\nconst result: ReleaseResult = {\ndependencyUrl,\nreleases: [],\n};\nif (metadata?.homepage) {\nresult.homepage = metadata.homepage;\n}\nif (metadata?.repository) {\nresult.sourceUrl = metadata.repository;\n}\nresult.releases = lines\n.map((line) => {\nconst versionOrig = line.vers;\nconst version = versionOrig.replace(/\+.*$/, '');\nconst release: Release = { version };\nif (versionOrig !== version) {\nrelease.versionOrig = versionOrig;\n}\nif (line.yanked) {\nrelease.isDeprecated = true;\n}\nif (line.rust_version) {\nrelease.constraints = { rust: [line.rust_version] };\n}\nreturn release;\n})\n.filter((release) => release.version);\nif (!result.releases.length) {\nreturn null;\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${CrateDatasource.id}-metadata`,\nkey: (info: RegistryInfo, packageName: string) =>\n`${info.rawUrl}/${packageName}`,\ncacheable: (info: RegistryInfo) =>\nCrateDatasource.areReleasesCacheable(info.rawUrl),\nttlMinutes: 24 * 60,\n})\npublic async getCrateMetadata(\ninfo: RegistryInfo,\npackageName: string,\n): Promise<CrateMetadata | null> {\nif (info.flavor !== 'crates.io') {\nreturn null;\n}\nconst crateUrl = `${CrateDatasource.CRATES_IO_API_BASE_URL}crates/${packageName}?include=`;\nlogger.debug(\n{ crateUrl, packageName, registryUrl: info.rawUrl },\n'downloading crate metadata',\n);\ntry {\ninterface Response {\ncrate: CrateMetadata;\n}\nconst response = await this.http.getJsonUnchecked<Response>(crateUrl);\nreturn response.body.crate;\n} catch (err) {\nlogger.warn(\n{ err, packageName, registryUrl: info.rawUrl },\n'failed to download crate metadata',\n);\n}\nreturn null;\n}"
"private static async clone(\nregistryFetchUrl: string,\nclonePath: string,\npackageName: string,\n): Promise<CloneResult> {\nlogger.info(\n{ clonePath, registryFetchUrl },\n`Cloning private cargo registry`,\n);\nconst git = Git({\n...simpleGitConfig(),\nmaxConcurrentProcesses: 1,\n}).env(getChildEnv());\ntry {\nawait git.clone(registryFetchUrl, clonePath, {\n'--depth': 1,\n});\nreturn { clonePath };\n} catch (err) {\nif (\nerr.message.includes(\n'fatal: dumb http transport does not support shallow capabilities',\n)\n) {\nlogger.info(\n{ packageName, registryFetchUrl },\n'failed to shallow clone git registry, doing full clone',\n);\ntry {\nawait git.clone(registryFetchUrl, clonePath);\nreturn { clonePath };\n} catch (err) {\nlogger.warn(\n{ err, packageName, registryFetchUrl },\n'failed cloning git registry',\n);\nreturn { err };\n}\n} else {\nlogger.warn(\n{ err, packageName, registryFetchUrl },\n'failed cloning git registry',\n);\nreturn { err };\n}\n}\n}"
"async getReleases(\ngetReleasesConfig: GetReleasesConfig,\n): Promise<ReleaseResult | null> {\nconst config = getCustomConfig(getReleasesConfig);\nif (isNullOrUndefined(config)) {\nreturn null;\n}\nconst { defaultRegistryUrlTemplate, transformTemplates, format } = config;\nconst fetcher = fetchers[format];\nconst isLocalRegistry = defaultRegistryUrlTemplate.startsWith('file:\nlet data: unknown;\ntry {\nif (isLocalRegistry) {\ndata = await fetcher.readFile(\ndefaultRegistryUrlTemplate.replace('file:\n);\n} else {\ndata = await fetcher.fetch(this.http, defaultRegistryUrlTemplate);\n}\n} catch (e) {\nthis.handleHttpErrors(e);\nreturn null;\n}\nlogger.trace(\n{ data },\n`Custom datasource API fetcher '${format}' received data. Starting transformation.`,\n);\nfor (const transformTemplate of transformTemplates) {\nconst expression = getExpression(transformTemplate);\nif (expression instanceof Error) {\nlogger.once.warn(\n{ errorMessage: expression.message },\n`Invalid JSONata expression: ${transformTemplate}`,\n);\nreturn null;\n}\ntry {\nconst modifiedData = await expression.evaluate(data);\nlogger.trace(\n{ before: data, after: modifiedData },\n`Custom datasource transformed data.`,\n);\ndata = modifiedData;\n} catch (err) {\nlogger.once.warn(\n{ err },\n`Error while evaluating JSONata expression: ${transformTemplate}`,\n);\nreturn null;\n}\n}\ntry {\nconst parsed = ReleaseResultZod.parse(data);\nreturn structuredClone(parsed);\n} catch (err) {\nlogger.debug({ err }, `Response has failed validation`);\nlogger.trace({ data }, 'Response that has failed validation');\nreturn null;\n}\n}"
"export function massageCustomDatasourceConfig(\ncustomDatasourceName: string,\n{\ncustomDatasources,\npackageName,\ncurrentValue,\nregistryUrl: defaultRegistryUrl,\n}: GetReleasesConfig,\n): Required<CustomDatasourceConfig> | null {\nconst customDatasource = customDatasources?.[customDatasourceName];\nif (isNullOrUndefined(customDatasource)) {\nlogger.debug(\n`No custom datasource config provided while ${packageName} has been requested`,\n);\nreturn null;\n}\nconst templateInput = { packageName, currentValue };\nconst registryUrlTemplate =\ndefaultRegistryUrl ?? customDatasource.defaultRegistryUrlTemplate;\nif (isNullOrUndefined(registryUrlTemplate)) {\nlogger.debug(\n'No registry url provided by extraction nor datasource configuration',\n);\nreturn null;\n}\nconst registryUrl = template.compile(registryUrlTemplate, templateInput);\nconst transformTemplates = customDatasource.transformTemplates ?? [];\nconst transform: string[] = [];\nfor (const transformTemplate of transformTemplates) {\nconst templated = template.compile(transformTemplate, templateInput);\ntransform.push(templated);\n}\nlogger.trace({ transform }, `Custom datasource compiled data.`);\nreturn {\nformat: customDatasource.format ?? 'json',\ndefaultRegistryUrlTemplate: registryUrl,\ntransformTemplates: transform,\n};\n}"
"async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nlet result: ReleaseResult | null = null;\nconst pkgUrl = `${ensureTrailingSlash(\nregistryUrl,\n)}api/packages/${packageName}`;\nlet raw: HttpResponse<DartResult> | null = null;\ntry {\nraw = await this.http.getJsonUnchecked<DartResult>(pkgUrl);\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nconst body = raw?.body;\nif (body) {\nconst { versions, latest } = body;\nconst releases = versions\n?.filter(({ retracted }) => !retracted)\n?.map(({ version, published }) => ({\nversion,\nreleaseTimestamp: asTimestamp(published),\n}));\nif (releases && latest) {\nresult = { releases };\nconst pubspec = latest.pubspec;\nif (pubspec) {\nif (pubspec.homepage) {\nresult.homepage = pubspec.homepage;\n}\nif (pubspec.repository) {\nresult.sourceUrl = pubspec.repository;\n}\n}\n}\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${DebDatasource.id}`,\nkey: (extractedFile: string, lastTimestamp: Date) =>\n`${extractedFile}:${lastTimestamp.getTime()}`,\nttlMinutes: 24 * 60,\n})\nasync parseExtractedPackageIndex(\nextractedFile: string,\n_lastTimestamp: Date,\n): Promise<Record<string, PackageDescription[]>> {\nconst rl = readline.createInterface({\ninput: fs.createCacheReadStream(extractedFile),\nterminal: false,\n});\nlet currentPackage: PackageDescription = {};\nconst allPackages: Record<string, PackageDescription[]> = {};\nfor await (const line of rl) {\nif (line === '') {\nif (requiredPackageKeys.every((key) => key in currentPackage)) {\nif (!allPackages[currentPackage.Package!]) {\nallPackages[currentPackage.Package!] = [];\n}\nallPackages[currentPackage.Package!].push(currentPackage);\ncurrentPackage = {};\n}\n} else {\nfor (const key of packageKeys) {\nif (line.startsWith(`${key}:`)) {\ncurrentPackage[key] = line.substring(key.length + 1).trim();\nbreak;\n}\n}\n}\n}\nif (requiredPackageKeys.every((key) => key in currentPackage)) {\nif (!allPackages[currentPackage.Package!]) {\nallPackages[currentPackage.Package!] = [];\n}\nallPackages[currentPackage.Package!].push(currentPackage);\n}\nreturn allPackages;\n}"
"@cache({\nnamespace: `datasource-${DebDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst componentUrls = constructComponentUrls(registryUrl);\nlet aggregatedRelease: ReleaseResult | null = null;\nfor (const componentUrl of componentUrls) {\ntry {\nconst packageIndex = await this.getPackageIndex(componentUrl);\nconst parsedPackages = packageIndex[packageName];\nif (parsedPackages) {\nconst newRelease = formatReleaseResult(parsedPackages);\nif (aggregatedRelease === null) {\naggregatedRelease = newRelease;\n} else {\nif (!releaseMetaInformationMatches(aggregatedRelease, newRelease)) {\nlogger.warn(\n{ packageName },\n'Package occurred in more than one repository with different meta information. Aggregating releases anyway.',\n);\n}\naggregatedRelease.releases.push(...newRelease.releases);\n}\n}\n} catch (error) {\nlogger.debug(\n{ componentUrl, error },\n'Skipping component due to an error',\n);\n}\n}\nreturn aggregatedRelease;\n}"
"export async function downloadAndExtractPackage(\ncomponentUrl: string,\nhttp: Http,\n): Promise<{ extractedFile: string; lastTimestamp: Date }> {\nconst packageUrlHash = toSha256(componentUrl);\nconst fullCacheDir = await fs.ensureCacheDir(cacheSubDir);\nconst extractedFile = upath.join(fullCacheDir, `${packageUrlHash}.txt`);\nlet lastTimestamp = await getFileCreationTime(extractedFile);\nconst compression = 'gz';\nconst compressedFile = upath.join(\nfullCacheDir,\n`${nanoid()}_${packageUrlHash}.${compression}`,\n);\nconst wasUpdated = await downloadPackageFile(\ncomponentUrl,\ncompression,\ncompressedFile,\nhttp,\nlastTimestamp,\n);\nif (wasUpdated || !lastTimestamp) {\ntry {\nawait extract(compressedFile, compression, extractedFile);\nlastTimestamp = await getFileCreationTime(extractedFile);\n} catch (error) {\nlogger.warn(\n{\ncompressedFile,\ncomponentUrl,\ncompression,\nerror: error.message,\n},\n'Failed to extract package file from compressed file',\n);\n} finally {\nawait fs.rmCache(compressedFile);\n}\n}\nif (!lastTimestamp) {\nthrow new Error('Missing metadata in extracted package index file!');\n}\nreturn { extractedFile, lastTimestamp };\n}"
"export async function downloadPackageFile(\nbasePackageUrl: string,\ncompression: string,\ncompressedFile: string,\nhttp: Http,\nlastDownloadTimestamp?: Date,\n): Promise<boolean> {\nconst baseSuiteUrl = getBaseSuiteUrl(basePackageUrl);\nconst packageUrl = joinUrlParts(basePackageUrl, `Packages.${compression}`);\nlet needsToDownload = true;\nif (lastDownloadTimestamp) {\nneedsToDownload = await checkIfModified(\npackageUrl,\nlastDownloadTimestamp,\nhttp,\n);\n}\nif (!needsToDownload) {\nlogger.debug(`No need to download ${packageUrl}, file is up to date.`);\nreturn false;\n}\nconst readStream = http.stream(packageUrl);\nconst writeStream = fs.createCacheWriteStream(compressedFile);\nawait fs.pipeline(readStream, writeStream);\nlogger.debug(\n{ url: packageUrl, targetFile: compressedFile },\n'Downloading Debian package file',\n);\nlet inReleaseContent = '';\ntry {\ninReleaseContent = await fetchInReleaseFile(baseSuiteUrl, http);\n} catch (error) {\nlogger.debug(\n{ url: baseSuiteUrl, err: error },\n'Could not fetch InRelease file',\n);\n}\nif (inReleaseContent) {\nconst actualChecksum = await computeFileChecksum(compressedFile);\nconst expectedChecksum = parseChecksumsFromInRelease(\ninReleaseContent,\npackageUrl.replace(`${baseSuiteUrl}/`, ''),\n);\nif (actualChecksum !== expectedChecksum) {\nawait fs.rmCache(compressedFile);\nthrow new Error('SHA256 checksum validation failed');\n}\n}\nreturn needsToDownload;\n}"
"@cache({\nnamespace: `datasource-${DenoDatasource.id}`,\nkey: (moduleAPIURL) => `getReleaseResult:${moduleAPIURL}`,\n})\nasync getReleaseResult(moduleAPIURL: string): Promise<ReleaseResult> {\nconst detailsCacheKey = `details:${moduleAPIURL}`;\nconst releasesCache: Record<string, Release> =\n(await packageCache.get(\n`datasource-${DenoDatasource.id}`,\ndetailsCacheKey,\n)) ?? {};\nlet cacheModified = false;\nconst {\nbody: { versions, tags },\n} = await this.http.getJson(moduleAPIURL, DenoAPIModuleResponse);\nconst releases = await pMap(\nversions,\nasync (version) => {\nconst cacheRelease = releasesCache[version];\nif (cacheRelease) {\nreturn cacheRelease;\n}\nconst url = joinUrlParts(moduleAPIURL, version);\nconst { body: release } = await this.http.getJson(\nurl,\nDenoAPIModuleVersionResponse.catch(({ error: err }) => {\nlogger.warn(\n{ err, version },\n'Deno: failed to get version details',\n);\nreturn { version };\n}),\n);\nreleasesCache[release.version] = release;\ncacheModified = true;\nreturn release;\n},\n{ concurrency: 5 },\n);\nif (cacheModified) {\nawait packageCache.set(\n`datasource-${DenoDatasource.id}`,\ndetailsCacheKey,\nreleasesCache,\n10080,\n);\n}\nreturn { releases, tags };\n}"
"export function getRegistryRepository(\npackageName: string,\nregistryUrl: string,\n): RegistryRepository {\nif (registryUrl !== DOCKER_HUB) {\nconst registryEndingWithSlash = ensureTrailingSlash(\nregistryUrl.replace(regEx(/^https?:\/\\n);\nif (packageName.startsWith(registryEndingWithSlash)) {\nlet registryHost = trimTrailingSlash(registryUrl);\nif (!regEx(/^https?:\/\\nregistryHost = `https:\n}\nlet dockerRepository = packageName.replace(registryEndingWithSlash, '');\nconst fullUrl = `${registryHost}/${dockerRepository}`;\nconst { origin, pathname } = parseUrl(fullUrl)!;\nregistryHost = origin;\ndockerRepository = pathname.substring(1);\nreturn {\nregistryHost,\ndockerRepository,\n};\n}\n}\nlet registryHost = registryUrl;\nconst split = packageName.split('/');\nif (split.length > 1 && (split[0].includes('.') || split[0].includes(':'))) {\n[registryHost] = split;\nsplit.shift();\n}\nlet dockerRepository = split.join('/');\nif (!regEx(/^https?:\/\\nregistryHost = `https:\n}\nconst { path, base } =\nregEx(/^(?<base>https:\/\/[^/]+)\/(?<path>.+)$/).exec(registryHost)\n?.groups ?? {};\nif (base && path) {\nregistryHost = base;\ndockerRepository = `${trimTrailingSlash(path)}/${dockerRepository}`;\n}\nregistryHost = registryHost\n.replace('https:\n.replace('https:\nconst opts = hostRules.find({\nhostType: dockerDatasourceId,\nurl: registryHost,\n});\nif (opts?.insecureRegistry) {\nregistryHost = registryHost.replace('https', 'http');\n}\nif (registryHost.endsWith('.docker.io') && !dockerRepository.includes('/')) {\ndockerRepository = 'library/' + dockerRepository;\n}\nreturn {\nregistryHost,\ndockerRepository,\n};\n}"
"reconcile(items: DockerHubTag[], expectedCount: number): boolean {\nlet needNextPage = true;\nlet earliestDate = null;\nlet { updatedAt } = this.cache;\nlet latestDate = updatedAt ? DateTime.fromISO(updatedAt) : null;\nfor (const newItem of items) {\nconst id = newItem.id;\nthis.reconciledIds.add(id);\nconst oldItem = this.cache.items[id];\nconst itemDate = DateTime.fromISO(newItem.last_updated);\nif (!earliestDate || earliestDate > itemDate) {\nearliestDate = itemDate;\n}\nif (!latestDate || latestDate < itemDate) {\nlatestDate = itemDate;\nupdatedAt = newItem.last_updated;\n}\nif (dequal(oldItem, newItem)) {\nneedNextPage = false;\ncontinue;\n}\nthis.cache.items[newItem.id] = newItem;\nthis.isChanged = true;\n}\nthis.cache.updatedAt = updatedAt;\nif (earliestDate && latestDate) {\nfor (const [key, item] of Object.entries(this.cache.items)) {\nconst id = parseInt(key);\nconst itemDate = DateTime.fromISO(item.last_updated);\nif (\nitemDate < earliestDate ||\nitemDate > latestDate ||\nthis.reconciledIds.has(id)\n) {\ncontinue;\n}\ndelete this.cache.items[id];\nthis.isChanged = true;\n}\nif (Object.keys(this.cache.items).length > expectedCount) {\nreturn true;\n}\n}\nreturn needNextPage;\n}"
"@cache({\nnamespace: 'datasource-docker-imageconfig',\nkey: (\nregistryHost: string,\ndockerRepository: string,\nconfigDigest: string,\n) => `${registryHost}:${dockerRepository}@${configDigest}`,\nttlMinutes: 1440 * 28,\n})\nasync getImageConfig(\nregistryHost: string,\ndockerRepository: string,\nconfigDigest: string,\n): Promise<HttpResponse<OciImageConfig> | undefined> {\nlogger.trace(\n`getImageConfig(${registryHost}, ${dockerRepository}, ${configDigest})`,\n);\nconst headers = await getAuthHeaders(\nthis.http,\nregistryHost,\ndockerRepository,\n);\nif (!headers) {\nlogger.warn('No docker auth found - returning');\nreturn undefined;\n}\nconst url = joinUrlParts(\nregistryHost,\n'v2',\ndockerRepository,\n'blobs',\nconfigDigest,\n);\nreturn await this.http.getJson(\nurl,\n{\nheaders,\nnoAuth: true,\n},\nOciImageConfig,\n);\n}"
"@cache({\nnamespace: 'datasource-docker-imageconfig',\nkey: (\nregistryHost: string,\ndockerRepository: string,\nconfigDigest: string,\n) => `${registryHost}:${dockerRepository}@${configDigest}`,\nttlMinutes: 1440 * 28,\n})\nasync getHelmConfig(\nregistryHost: string,\ndockerRepository: string,\nconfigDigest: string,\n): Promise<HttpResponse<OciHelmConfig> | undefined> {\nlogger.trace(\n`getImageConfig(${registryHost}, ${dockerRepository}, ${configDigest})`,\n);\nconst headers = await getAuthHeaders(\nthis.http,\nregistryHost,\ndockerRepository,\n);\nif (!headers) {\nlogger.warn('No docker auth found - returning');\nreturn undefined;\n}\nconst url = joinUrlParts(\nregistryHost,\n'v2',\ndockerRepository,\n'blobs',\nconfigDigest,\n);\nreturn await this.http.getJson(\nurl,\n{\nheaders,\nnoAuth: true,\n},\nOciHelmConfig,\n);\n}"
"private async getManifest(\nregistry: string,\ndockerRepository: string,\ntag: string,\n): Promise<OciImageManifest | DistributionManifest | null> {\nconst manifestResponse = await this.getManifestResponse(\nregistry,\ndockerRepository,\ntag,\n);\nif (!manifestResponse) {\nreturn null;\n}\nconst parsed = ManifestJson.safeParse(manifestResponse.body);\nif (!parsed.success) {\nlogger.debug(\n{\nregistry,\ndockerRepository,\ntag,\nbody: manifestResponse.body,\nheaders: manifestResponse.headers,\nerr: parsed.error,\n},\n'Invalid manifest response',\n);\nreturn null;\n}\nconst manifest = parsed.data;\nswitch (manifest.mediaType) {\ncase 'application/vnd.docker.distribution.manifest.v2+json':\ncase 'application/vnd.oci.image.manifest.v1+json':\nreturn manifest;\ncase 'application/vnd.docker.distribution.manifest.list.v2+json':\ncase 'application/vnd.oci.image.index.v1+json':\nif (!manifest.manifests.length) {\nlogger.debug(\n{ manifest },\n'Invalid manifest list with no manifests - returning',\n);\nreturn null;\n}\nlogger.trace(\n{ registry, dockerRepository, tag },\n'Found manifest list, using first image',\n);\nreturn this.getManifest(\nregistry,\ndockerRepository,\nmanifest.manifests[0].digest,\n);\ndefault:\nreturn null;\n}\n}"
"@cache({\nnamespace: 'datasource-docker-architecture',\nkey: (\nregistryHost: string,\ndockerRepository: string,\ncurrentDigest: string,\n) => `${registryHost}:${dockerRepository}@${currentDigest}`,\nttlMinutes: 1440 * 28,\n})\nasync getImageArchitecture(\nregistryHost: string,\ndockerRepository: string,\ncurrentDigest: string,\n): Promise<string | null | undefined> {\ntry {\nlet manifestResponse: HttpResponse<string> | null;\ntry {\nmanifestResponse = await this.getManifestResponse(\nregistryHost,\ndockerRepository,\ncurrentDigest,\n'head',\n);\n} catch (_err) {\nconst err =\n_err instanceof ExternalHostError\n? _err.err\n:  _err;\nif (\ntypeof err.statusCode === 'number' &&\nerr.statusCode >= 500 &&\nerr.statusCode < 600\n) {\nreturn null;\n}\nthrow _err;\n}\nif (\nmanifestResponse?.headers['content-type'] !==\n'application/vnd.docker.distribution.manifest.v2+json' &&\nmanifestResponse?.headers['content-type'] !==\n'application/vnd.oci.image.manifest.v1+json'\n) {\nreturn null;\n}\nconst configDigest = await this.getConfigDigest(\nregistryHost,\ndockerRepository,\ncurrentDigest,\n);\nif (!configDigest) {\nreturn null;\n}\nconst configResponse = await this.getImageConfig(\nregistryHost,\ndockerRepository,\nconfigDigest,\n);\nif (\nconfigResponse &&\n('config' in configResponse.body ||\n'architecture' in configResponse.body)\n) {\nconst architecture = configResponse.body.architecture ?? null;\nlogger.debug(\n`Current digest ${currentDigest} relates to architecture ${\narchitecture ?? 'null'\n}`,\n);\nreturn architecture;\n}\n} catch (err)  {\nif (err.statusCode !== 404 || err.message === PAGE_NOT_FOUND_ERROR) {\nthrow err;\n}\nlogger.debug(\n{ registryHost, dockerRepository, currentDigest, err },\n'Unknown error getting image architecture',\n);\n}\nreturn undefined;\n}"
"@cache({\nnamespace: 'datasource-docker-hub-tags',\nkey: (dockerRepository: string) => `${dockerRepository}`,\n})\nasync getDockerHubTags(dockerRepository: string): Promise<Release[] | null> {\nlet url = `https:\nconst cache = await DockerHubCache.init(dockerRepository);\nconst maxPages = GlobalConfig.get('dockerMaxPages', 20);\nlet page = 0,\nneedNextPage = true;\nwhile (needNextPage && page < maxPages) {\nconst { val, err } = await this.http\n.getJsonSafe(url, DockerHubTagsPage)\n.unwrap();\nif (err) {\nlogger.debug({ err }, `Docker: error fetching data from DockerHub`);\nreturn null;\n}\npage++;\nconst { results, next, count } = val;\nneedNextPage = cache.reconcile(results, count);\nif (!next) {\nbreak;\n}\nurl = next;\n}\nawait cache.save();\nconst items = cache.getItems();\nreturn items.map(\n({ name: version, tag_last_pushed, digest: newDigest }) => {\nconst release: Release = { version };\nconst releaseTimestamp = asTimestamp(tag_last_pushed);\nif (releaseTimestamp) {\nrelease.releaseTimestamp = releaseTimestamp;\n}\nif (newDigest) {\nlogger.once.debug(\n{\ndocumentationUrl:\n'https:\n},\n'Using the `tag_last_pushed` to determine the age of a release from Docker Hub. If this is a digest update, it may lead to inconsistent behaviour, showing the digest as newer than it actually is',\n);\nrelease.newDigest = newDigest;\n}\nreturn release;\n},\n);\n}"
"@cache({\nnamespace: 'datasource-galaxy',\nkey: (getReleasesConfig: GetReleasesConfig) =>\ngetReleasesConfig.packageName,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst lookUp = packageName.split('.');\nconst userName = lookUp[0];\nconst projectName = lookUp[1];\nconst galaxyAPIUrl = `${registryUrl}api/v1/roles/?owner__username=${userName}&name=${projectName}`;\nconst galaxyProjectUrl = `${registryUrl}${userName}/${projectName}`;\nlet body: GalaxyV1 | null = null;\ntry {\nconst raw = await this.http.getJson(galaxyAPIUrl, GalaxyV1);\nbody = raw.body;\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nif (body.results.length > 1) {\nbody.results = body.results.filter(\n(result) => result.github_user === userName,\n);\nif (!body.results.length) {\nlogger.warn(\n{ dependency: packageName, userName },\n`No matching result from galaxy for package`,\n);\nreturn null;\n}\n}\nif (body.results.length === 0) {\nlogger.debug(\n`Received no results for ${packageName} from ${galaxyAPIUrl} `,\n);\nreturn null;\n}\nconst resultObject = body.results[0];\nconst versions = resultObject.summary_fields.versions;\nconst result: ReleaseResult = {\nreleases: [],\n};\nresult.dependencyUrl = galaxyProjectUrl;\nconst { github_user: user, github_repo: repo } = resultObject;\nif (isNonEmptyString(user) && isNonEmptyString(repo)) {\nresult.sourceUrl = `https:\n}\nresult.releases = versions.map(({ version, releaseTimestamp }) => {\nconst release: Release = { version };\nif (releaseTimestamp) {\nrelease.releaseTimestamp = releaseTimestamp;\n}\nreturn release;\n});\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${GalaxyCollectionDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => `getReleases:${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst baseUrl = this.constructBaseUrl(registryUrl!, packageName);\nconst { val: baseProject, err: baseErr } = await this.http\n.getJsonSafe(baseUrl, GalaxyV3)\n.onError((err) => {\nif (!(err instanceof HttpError && err.response?.statusCode === 404)) {\nlogger.warn(\n{ url: baseUrl, datasource: this.id, packageName, err },\n'Error fetching from url',\n);\n}\n})\n.unwrap();\nif (baseErr) {\nthis.handleGenericErrors(baseErr);\n}\nconst versionsUrl = ensureTrailingSlash(joinUrlParts(baseUrl, 'versions'));\nconst { val: rawReleases, err: versionsErr } = await this.http\n.getJsonSafe(versionsUrl, GalaxyV3Versions)\n.onError((err) => {\nlogger.warn(\n{ url: versionsUrl, datasource: this.id, packageName, err },\n'Error fetching from url',\n);\n})\n.unwrap();\nif (versionsErr) {\nthis.handleGenericErrors(versionsErr);\n}\nconst releases = rawReleases.map((value) => {\nreturn {\n...value,\nisDeprecated: baseProject.deprecated,\n};\n});\nconst enrichedReleases = await p.map(\nreleases,\n(release) => this.getVersionDetails(packageName, versionsUrl, release),\n{ concurrency: 4 },\n);\nconst filteredReleases = enrichedReleases.filter(isTruthy);\nconst sourceUrlOfHighestRelease = enrichedReleases.find(\n(release) => baseProject.highest_version.version === release.version,\n)?.sourceUrl;\nreturn {\nreleases: filteredReleases,\nsourceUrl: sourceUrlOfHighestRelease,\n};\n}"
"@cache({\nnamespace: `datasource-${gitId}`,\nkey: ({ packageName }: GetReleasesConfig) => packageName,\n})\nasync getRawRefs({\npackageName,\n}: GetReleasesConfig): Promise<RawRefs[] | null> {\nconst gitSubmoduleAuthEnvironmentVariables = getGitEnvironmentVariables([\nthis.id,\n]);\nconst gitEnv = getChildEnv({ env: gitSubmoduleAuthEnvironmentVariables });\nconst git = simpleGit(simpleGitConfig()).env(gitEnv);\nconst lsRemote = await git.listRemote([\ngetRemoteUrlWithToken(packageName, this.id),\n]);\nif (!lsRemote) {\nreturn null;\n}\nconst refs = lsRemote\n.trim()\n.split(newlineRegex)\n.map((line) => line.trim())\n.map((line) => {\nlet match = refMatch.exec(line);\nif (match?.groups) {\nreturn {\ntype: match.groups.type,\nvalue: match.groups.value,\nhash: match.groups.hash,\n};\n}\nmatch = headMatch.exec(line);\nif (match?.groups) {\nreturn {\ntype: '',\nvalue: 'HEAD',\nhash: match.groups.hash,\n};\n}\nlogger.trace(`malformed ref: ${line}`);\nreturn null;\n})\n.filter(isTruthy)\n.filter((ref) => ref.type !== 'pull' && !ref.value.endsWith('^{}'));\nreturn refs;\n}"
"async mapDigestAssetToRelease(\ndigestAsset: GithubDigestFile,\nrelease: GithubRestRelease,\n): Promise<string | null> {\nconst current = digestAsset.currentVersion.replace(regEx(/^v/), '');\nconst next = release.tag_name.replace(regEx(/^v/), '');\nif (digestAsset.digestedFileName) {\nconst checksumAssetName = digestAsset.assetName.replace(current, next);\nconst checksumAsset = release.assets.find(\n(a: GithubRestAsset) => a.name === checksumAssetName,\n);\nif (checksumAsset) {\nconst releaseFilename = digestAsset.digestedFileName.replace(\ncurrent,\nnext,\n);\nconst res = await this.http.getText(checksumAsset.browser_download_url);\nfor (const line of res.body.split(newlineRegex)) {\nconst [lineDigest, lineFn] = line.split(regEx(/\s+/), 2);\nif (lineFn === releaseFilename) {\nreturn lineDigest;\n}\n}\nreturn null;\n}\n}\nconst oldFileName = digestAsset.digestedFileName ?? digestAsset.assetName;\nconst fileName = oldFileName.replace(current, next);\nconst asset = release.assets.find(\n(a: GithubRestAsset) => a.name === fileName,\n);\nif (!asset) {\nreturn null;\n}\nconst algorithm = inferHashAlg(digestAsset.currentDigest);\nconst newDigest = await this.downloadAndDigest(asset, algorithm);\nreturn newDigest;\n}"
"override async getDigest(\n{\npackageName: repo,\ncurrentValue,\ncurrentDigest,\nregistryUrl,\n}: DigestConfig,\nnewValue: string,\n): Promise<string | null> {\nlogger.debug(\n{ repo, currentValue, currentDigest, registryUrl, newValue },\n'getDigest',\n);\nif (!currentDigest) {\nreturn null;\n}\nif (!currentValue) {\nreturn currentDigest;\n}\nconst apiBaseUrl = getApiBaseUrl(registryUrl);\nconst { body: currentRelease } =\nawait this.http.getJsonUnchecked<GithubRestRelease>(\n`${apiBaseUrl}repos/${repo}/releases/tags/${currentValue}`,\n);\nconst digestAsset = await this.findDigestAsset(\ncurrentRelease,\ncurrentDigest,\n);\nlet newDigest: string | null;\nif (!digestAsset || newValue === currentValue) {\nnewDigest = currentDigest;\n} else {\nconst { body: newRelease } =\nawait this.http.getJsonUnchecked<GithubRestRelease>(\n`${apiBaseUrl}repos/${repo}/releases/tags/${newValue}`,\n);\nnewDigest = await this.mapDigestAssetToRelease(digestAsset, newRelease);\n}\nreturn newDigest;\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}-${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst [projectPart, packagePart] = packageName.split(':', 2);\nconst apiUrl = GitlabPackagesDatasource.getGitlabPackageApiUrl(\nregistryUrl,\nprojectPart,\npackagePart,\n);\nconst result: ReleaseResult = {\nreleases: [],\n};\nlet response: GitlabPackage[];\ntry {\nresponse = (\nawait this.http.getJsonUnchecked<GitlabPackage[]>(apiUrl, {\npaginate: true,\n})\n).body;\nresult.releases = response\n.filter((r) => (r.conan_package_name ?? r.name) === packagePart)\n.map(({ version, created_at }) => ({\nversion,\nreleaseTimestamp: asTimestamp(created_at),\n}));\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nreturn result.releases?.length ? result : null;\n}"
"@cache({\nnamespace: `datasource-${GitlabTagsDatasource.id}`,\nkey: ({ registryUrl, packageName }: DigestConfig) =>\n`getDigest:${getDepHost(registryUrl)}:${packageName}`,\n})\noverride async getDigest(\n{ packageName: repo, registryUrl }: DigestConfig,\nnewValue?: string,\n): Promise<string | null> {\nconst depHost = getDepHost(registryUrl);\nconst urlEncodedRepo = encodeURIComponent(repo);\nlet digest: string | null = null;\ntry {\nif (newValue) {\nconst url = joinUrlParts(\ndepHost,\n`api/v4/projects`,\nurlEncodedRepo,\n`repository/commits/`,\nnewValue,\n);\nconst gitlabCommits =\nawait this.http.getJsonUnchecked<GitlabCommit>(url);\ndigest = gitlabCommits.body.id;\n} else {\nconst url = joinUrlParts(\ndepHost,\n`api/v4/projects`,\nurlEncodedRepo,\n`repository/commits?per_page=1`,\n);\nconst gitlabCommits =\nawait this.http.getJsonUnchecked<GitlabCommit[]>(url);\ndigest = gitlabCommits.body[0].id;\n}\n} catch (err) {\nlogger.debug(\n{ gitlabRepo: repo, err, registryUrl },\n'Error getting latest commit from Gitlab repo',\n);\n}\nif (!digest) {\nreturn null;\n}\nreturn digest;\n}"
"@cache({\nnamespace: `datasource-${GlasskubePackagesDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\noverride async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst result: ReleaseResult = { releases: [] };\nconst { val: versions, err: versionsErr } = await this.http\n.getYamlSafe(\njoinUrlParts(registryUrl!, packageName, 'versions.yaml'),\nGlasskubePackageVersions,\n)\n.unwrap();\nif (versionsErr) {\nthis.handleGenericErrors(versionsErr);\n}\nresult.releases = versions.versions.map((it) => ({\nversion: it.version,\n}));\nresult.tags = { latest: versions.latestVersion };\nconst { val: latestManifest, err: latestManifestErr } = await this.http\n.getYamlSafe(\njoinUrlParts(\nregistryUrl!,\npackageName,\nversions.latestVersion,\n'package.yaml',\n),\nGlasskubePackageManifest,\n)\n.unwrap();\nif (latestManifestErr) {\nthis.handleGenericErrors(latestManifestErr);\n}\nfor (const ref of latestManifest?.references ?? []) {\nif (ref.label.toLowerCase() === 'github') {\nresult.sourceUrl = ref.url;\n} else if (ref.label.toLowerCase() === 'website') {\nresult.homepage = ref.url;\n}\n}\nreturn result;\n}"
"private static detectDatasource(\nmetadataUrl: string,\ngoModule: string,\n): DataSource | null {\nif (metadataUrl.startsWith('https:\nreturn {\ndatasource: GithubTagsDatasource.id,\npackageName: metadataUrl\n.replace('https:\n.replace(regEx(/\/$/), ''),\nregistryUrl: 'https:\n};\n}\nconst gitlabModuleName =\nBaseGoDatasource.gitlabRegExp.exec(goModule)?.groups?.regExpPath;\nconst vcsIndicatedModule =\nBaseGoDatasource.gitVcsRegexp.exec(goModule)?.groups?.module;\nconst metadataUrlMatchGroups =\nBaseGoDatasource.gitlabHttpsRegExp.exec(metadataUrl)?.groups;\nif (metadataUrlMatchGroups) {\nconst { httpsRegExpUrl, httpsRegExpName } = metadataUrlMatchGroups;\nlet packageName = vcsIndicatedModule ?? gitlabModuleName;\nif (!vcsIndicatedModule && httpsRegExpName && gitlabModuleName) {\nconst metadataPath = httpsRegExpName;\nconst modulePath = gitlabModuleName;\nif (modulePath.startsWith(metadataPath + '/')) {\npackageName = metadataPath;\n}\n}\npackageName = packageName ?? httpsRegExpName;\nreturn {\ndatasource: GitlabTagsDatasource.id,\nregistryUrl: httpsRegExpUrl,\npackageName,\n};\n}\nif (hostRules.hostType({ url: metadataUrl }) === 'gitlab') {\nconst parsedUrl = parseUrl(metadataUrl);\nif (!parsedUrl) {\nlogger.trace({ goModule }, 'Could not parse go-source URL');\nreturn null;\n}\nconst endpoint = GlobalConfig.get('endpoint', '');\nconst endpointPrefix = regEx(\n/https:\/\/[^/]+\/(?<prefix>.*?\/)(?:api\/v4\/?)?/,\n).exec(endpoint)?.groups?.prefix;\nlet packageName =\nvcsIndicatedModule ?? trimLeadingSlash(parsedUrl.pathname);\nif (endpointPrefix && endpointPrefix !== 'api/') {\npackageName = packageName.replace(endpointPrefix, '');\n}\nconst registryUrl = endpointPrefix\n? endpoint.replace(regEx(/\/api\/v4\/?$/), '/')\n: `${parsedUrl.protocol}\nreturn {\ndatasource: GitlabTagsDatasource.id,\nregistryUrl,\npackageName,\n};\n}\nreturn null;\n}"
"private static goImportHeader(\nhtml: string,\ngoModule: string,\n): DataSource | null {\nconst importMatchGroups = regEx(\n/<meta\s+name=`?go-import`?\s+content=`(?<prefix>[^`\s]+)\s+(?<proto>[^`\s]+)\s+(?<goImportURL>[^`\s]+)/,\n).exec(html)?.groups;\nif (!importMatchGroups) {\nlogger.trace({ goModule }, 'No go-source or go-import header found');\nreturn null;\n}\nconst { prefix, proto, goImportURL } = importMatchGroups;\nif (!goModule.startsWith(prefix)) {\nlogger.trace({ goModule }, 'go-import header prefix not match');\nreturn null;\n}\nif (proto !== 'git') {\nlogger.trace({ goModule }, 'go-import header proto not git');\nreturn null;\n}\nconst parsedUrl = parseUrl(goImportURL);\nif (!parsedUrl) {\nlogger.trace({ goModule }, 'Could not parse go-import URL');\nreturn null;\n}\nlogger.debug(`Go module: ${goModule} lookup import url ${goImportURL}`);\nconst datasource = this.detectDatasource(\ngoImportURL.replace(regEx(/\.git$/), ''),\ngoModule,\n);\nif (datasource !== null) {\nreturn datasource;\n}\nswitch (detectPlatform(goImportURL)) {\ncase 'github': {\nconst packageName = trimTrailingSlash(`${parsedUrl.pathname}`)\n.replace(regEx(/\.git$/), '')\n.split('/')\n.slice(-2)\n.join('/');\nreturn {\ndatasource: GithubTagsDatasource.id,\nregistryUrl: `${parsedUrl.protocol}\npackageName,\n};\n}\ncase 'azure': {\nreturn {\ndatasource: GitTagsDatasource.id,\npackageName: goImportURL.replace(regEx(/\.git$/), ''),\n};\n}\ndefault: {\nreturn {\ndatasource: GitTagsDatasource.id,\npackageName: goImportURL,\n};\n}\n}\n}"
"@cache({\nnamespace: `datasource-${GoDatasource.id}`,\nkey: ({ packageName }: DigestConfig, newValue?: string) =>\n`getDigest:${packageName}:${newValue}`,\n})\noverride async getDigest(\n{ packageName }: DigestConfig,\nnewValue?: string,\n): Promise<string | null> {\nif (parseGoproxy().some(({ url }) => url === 'off')) {\nlogger.debug(\n`Skip digest fetch for ${packageName} with GOPROXY containing `off``,\n);\nreturn null;\n}\nconst source = await BaseGoDatasource.getDatasource(packageName);\nif (!source) {\nreturn null;\n}\nconst tag =\nnewValue &&\n!GoDatasource.pversionRegexp.test(newValue) &&\nnewValue !== 'v0.0.0'\n? newValue\n: undefined;\nswitch (source.datasource) {\ncase ForgejoTagsDatasource.id: {\nreturn this.direct.forgejo.getDigest(source, tag);\n}\ncase GitTagsDatasource.id: {\nreturn this.direct.git.getDigest(source, tag);\n}\ncase GiteaTagsDatasource.id: {\nreturn this.direct.gitea.getDigest(source, tag);\n}\ncase GithubTagsDatasource.id: {\nreturn this.direct.github.getDigest(source, tag);\n}\ncase BitbucketTagsDatasource.id: {\nreturn this.direct.bitbucket.getDigest(source, tag);\n}\ncase GitlabTagsDatasource.id: {\nreturn this.direct.gitlab.getDigest(source, tag);\n}\ndefault: {\nreturn null;\n}\n}\n}"
"@cache({\nnamespace: `datasource-${GoDirectDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => packageName,\n})\nasync getReleases(config: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst { packageName } = config;\nlet res: ReleaseResult | null = null;\nlogger.trace(`go.getReleases(${packageName})`);\nconst source = await BaseGoDatasource.getDatasource(packageName);\nif (!source) {\nlogger.info(\n{ packageName },\n'Unsupported go host - cannot look up versions',\n);\nreturn null;\n}\nswitch (source.datasource) {\ncase ForgejoTagsDatasource.id: {\nres = await this.forgejo.getReleases(source);\nbreak;\n}\ncase GitTagsDatasource.id: {\nres = await this.git.getReleases(source);\nbreak;\n}\ncase GiteaTagsDatasource.id: {\nres = await this.gitea.getReleases(source);\nbreak;\n}\ncase GithubTagsDatasource.id: {\nres = await this.github.getReleases(source);\nbreak;\n}\ncase GitlabTagsDatasource.id: {\nres = await this.gitlab.getReleases(source);\nbreak;\n}\ncase BitbucketTagsDatasource.id: {\nres = await this.bitbucket.getReleases(source);\nbreak;\n}\ndefault: {\nreturn null;\n}\n}\nif (!res) {\nreturn null;\n}\nconst sourceUrl = res.sourceUrl ?? getSourceUrl(source) ?? null;\nreturn {\n...res,\nreleases: filterByPrefix(packageName, res.releases),\nsourceUrl,\n};\n}"
"@cache({\nnamespace: `datasource-${GoProxyDatasource.id}`,\nkey: (config: GetReleasesConfig) => GoProxyDatasource.getCacheKey(config),\n})\nasync getReleases(config: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst { packageName } = config;\nlogger.trace(`goproxy.getReleases(${packageName})`);\nconst goproxy = getEnv().GOPROXY ?? 'https:\nif (goproxy === 'direct') {\nreturn this.direct.getReleases(config);\n}\nconst proxyList = parseGoproxy(goproxy);\nconst noproxy = parseNoproxy();\nlet result: ReleaseResult | null = null;\nif (noproxy?.test(packageName)) {\nlogger.debug(`Fetching ${packageName} via GONOPROXY match`);\nresult = await this.direct.getReleases(config);\nreturn result;\n}\nfor (const { url, fallback } of proxyList) {\ntry {\nif (url === 'off') {\nbreak;\n} else if (url === 'direct') {\nresult = await this.direct.getReleases(config);\nbreak;\n}\nconst res = await this.getVersionsWithInfo(url, packageName);\nif (res.releases.length) {\nresult = res;\nbreak;\n}\n} catch (err) {\nconst potentialHttpError =\nerr instanceof ExternalHostError ? err.err : err;\nconst statusCode = potentialHttpError?.response?.statusCode;\nconst canFallback =\nfallback === '|' ? true : statusCode === 404 || statusCode === 410;\nconst msg = canFallback\n? 'Goproxy error: trying next URL provided with GOPROXY'\n: 'Goproxy error: skipping other URLs provided with GOPROXY';\nlogger.debug({ err }, msg);\nif (!canFallback) {\nbreak;\n}\n}\n}\nif (result && !result.sourceUrl) {\ntry {\nconst datasource = await BaseGoDatasource.getDatasource(packageName);\nconst sourceUrl = getSourceUrl(datasource);\nif (sourceUrl) {\nresult.sourceUrl = sourceUrl;\n}\n} catch (err) {\nlogger.trace({ err }, `Can't get datasource for ${packageName}`);\n}\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${GradleVersionDatasource.id}`,\nkey: ({ registryUrl }: GetReleasesConfig) => `${registryUrl}`,\n})\nasync getReleases({\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nlet releases: Release[];\ntry {\nconst response =\nawait this.http.getJsonUnchecked<GradleRelease[]>(registryUrl);\nreleases = response.body\n.filter((release) => !release.snapshot && !release.nightly)\n.map((release) => {\nconst { version, buildTime } = release;\nconst gitRef = GradleVersionDatasource.getGitRef(release.version);\nconst releaseTimestamp = asTimestamp(buildTime);\nconst result: Release = { version, gitRef, releaseTimestamp };\nif (release.broken) {\nresult.isDeprecated = true;\n}\nreturn result;\n});\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nconst res: ReleaseResult = {\nreleases,\nhomepage: 'https:\nsourceUrl: 'https:\n};\nif (res.releases.length) {\nreturn res;\n}\nreturn null;\n}"
"@cache({\nnamespace: `datasource-${HermitDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`getReleases:${registryUrl ?? ''}-${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nlogger.trace(`HermitDataSource.getReleases()`);\nif (!registryUrl) {\nlogger.error('registryUrl must be supplied');\nreturn null;\n}\nconst parsedUrl = parseUrl(registryUrl);\nif (parsedUrl === null) {\nlogger.warn({ registryUrl }, 'invalid registryUrl given');\nreturn null;\n}\nif (!registryUrl.startsWith('https:\nlogger.warn({ registryUrl }, 'Only Github registryUrl is supported');\nreturn null;\n}\nconst items = await this.getHermitSearchManifest(parsedUrl);\nif (items === null) {\nreturn null;\n}\nconst res = items.find((i) => i.Name === packageName);\nif (!res) {\nlogger.debug(\n`Could not find hermit package ${packageName} at URL ${registryUrl}`,\n);\nreturn null;\n}\nconst sourceUrl = res.Repository;\nreturn {\nsourceUrl,\nreleases: [\n...res.Versions.map((v) => ({\nversion: v,\nsourceUrl,\n})),\n...res.Channels.map((v) => ({\nversion: v,\nsourceUrl,\n})),\n],\n};\n}"
"@cache({\nnamespace: `datasource-${HermitDatasource.id}`,\nkey: (u) => `getHermitSearchManifest:${u.toString()}`,\n})\nasync getHermitSearchManifest(u: URL): Promise<HermitSearchResult[] | null> {\nconst registryUrl = u.toString();\nconst host = coerceString(u.host);\nconst groups = this.pathRegex.exec(coerceString(u.pathname))?.groups;\nif (!groups) {\nlogger.warn(\n{ registryUrl },\n'failed to get owner and repo from given url',\n);\nreturn null;\n}\nconst { owner, repo } = groups;\nconst apiBaseUrl = getApiBaseUrl(`https:\nconst indexRelease = await this.http.getJsonUnchecked<GithubRestRelease>(\n`${apiBaseUrl}repos/${owner}/${repo}/releases/tags/index`,\n);\nconst asset = indexRelease.body.assets.find(\n(asset) => asset.name === 'index.json',\n);\nif (!asset) {\nlogger.warn(\n{ registryUrl },\n`can't find asset index.json in the given registryUrl`,\n);\nreturn null;\n}\nconst indexContent = await streamToString(\nthis.http.stream(asset.url, {\nheaders: {\naccept: 'application/octet-stream',\n},\n}),\n);\ntry {\nreturn JSON.parse(indexContent) as HermitSearchResult[];\n} catch {\nlogger.warn('error parsing hermit search manifest from remote respond');\n}\nreturn null;\n}"
"@cache({\nnamespace: `datasource-${HexDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => packageName,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst [hexPackageName, organizationName] = packageName.split(':');\nconst organizationUrlPrefix = organizationName\n? `repos/${organizationName}/`\n: '';\nconst hexUrl = joinUrlParts(\nregistryUrl,\n`/api/${organizationUrlPrefix}packages/${hexPackageName}`,\n);\nconst { val: result, err } = await this.http\n.getJsonSafe(hexUrl, HexRelease)\n.onError((err) => {\nlogger.warn(\n{ url: hexUrl, datasource: 'hex', packageName, err },\n'Error fetching from url',\n);\n})\n.unwrap();\nif (err) {\nthis.handleGenericErrors(err);\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst packageType = HexpmBobDatasource.getPackageType(packageName);\nif (!packageType) {\nreturn null;\n}\nlogger.trace(\n{ registryUrl, packageName },\n`fetching hex.pm bob ${packageName} release`,\n);\nconst url = `${registryUrl!}/builds/${packageName}/builds.txt`;\nconst result: ReleaseResult = {\nreleases: [],\n...HexpmBobDatasource.getPackageDetails(packageType),\n};\ntry {\nconst { body } = await this.http.getText(url);\nresult.releases = body\n.split('\n')\n.map((line) => line.trim())\n.filter(isNonEmptyString)\n.map((line) => {\nconst [version, gitRef, buildDate] = line.split(' ');\nreturn {\ngitRef,\nisStable: HexpmBobDatasource.isStable(version, packageType),\nreleaseTimestamp: asTimestamp(buildDate),\nversion: HexpmBobDatasource.cleanVersion(version, packageType),\n};\n});\n} catch (err) {\nif (err instanceof HttpError && err.response?.statusCode !== 404) {\nthrow new ExternalHostError(err);\n}\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length > 0 ? result : null;\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\nregistryUrl,\npackageName,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst pkgConfig = parsePackage(packageName);\nlogger.trace(\n{ registryUrl, packageName, pkgConfig },\n'fetching java release',\n);\nlet url = `${registryUrl}v3/info/release_versions?page_size=${pageSize}&image_type=${pkgConfig.imageType}&project=jdk&release_type=ga&sort_method=DATE&sort_order=DESC`;\nif (pkgConfig.architecture) {\nurl += `&architecture=${pkgConfig.architecture}`;\n}\nif (pkgConfig.os) {\nurl += `&os=${pkgConfig.os}`;\n}\nconst result: ReleaseResult = {\nhomepage: 'https:\nreleases: [],\n};\ntry {\nlet page = 0;\nlet releases = await this.getPageReleases(url, page);\nwhile (releases) {\nresult.releases.push(...releases);\nif (releases.length !== pageSize || page >= 50) {\nbreak;\n}\npage += 1;\nreleases = await this.getPageReleases(url, page);\n}\n} catch (err) {\nif (err instanceof HttpError) {\nif (err.response?.statusCode !== 404) {\nthrow new ExternalHostError(err);\n}\n}\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length ? result : null;\n}"
"@cache({\nnamespace: `datasource-${JsrDatasource.id}`,\nkey: ({ packageName, registryUrl }: GetReleasesConfig) =>\n`getReleases:${registryUrl}:${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst validJsrPackageName = extractJsrPackageName(packageName);\nif (isNull(validJsrPackageName)) {\nlogger.debug(`Could not extract packageName: `${packageName}``);\nreturn null;\n}\nconst packageInfoUrl = joinUrlParts(registryUrl, packageName, 'meta.json');\nconst result: ReleaseResult = {\nhomepage: joinUrlParts(registryUrl, packageName),\nregistryUrl,\nreleases: [],\n};\ntry {\nconst { body } = await this.http.getJson(\npackageInfoUrl,\nJsrPackageMetadata,\n);\nresult.releases.push(...body);\n} catch (err) {\nlogger.warn({ err }, 'JSR: failed to get package details');\nthis.handleGenericErrors(err);\n}\nreturn result.releases.length ? result : null;\n}"
"function mockGenericPackage(opts: MockOpts = {}) {\nconst {\ndep = 'org.example:package',\nbase = baseUrl,\nlatest = '2.0.0',\nsnapshots,\n} = opts;\nconst meta =\nopts.meta === undefined ? Fixtures.get('metadata.xml') : opts.meta;\nconst pom = opts.pom === undefined ? Fixtures.get('pom.xml') : opts.pom;\nconst scope = httpMock.scope(base);\nconst [group, artifact] = dep.split(':');\nconst packagePath = `${group.replace(/\./g, '/')}/${artifact}`;\nif (meta) {\nscope.get(`/${packagePath}/maven-metadata.xml`).reply(200, meta);\n}\nif (pom) {\nif (latest.endsWith('-SNAPSHOT')) {\nconst [major, minor, patch] = latest\n.replace('-SNAPSHOT', '')\n.split('.')\n.map((x) => parseInt(x))\n.map((x) => (x < 10 ? `0${x}` : `${x}`));\nscope\n.get(\n`/${packagePath}/${latest}/${artifact}-${latest.replace(\n'-SNAPSHOT',\n'',\n)}-20200101.${major}${minor}${patch}-${parseInt(patch)}.pom`,\n)\n.reply(200, pom);\n} else {\nscope\n.get(`/${packagePath}/${latest}/${artifact}-${latest}.pom`)\n.reply(200, pom);\n}\n}\nif (snapshots) {\nsnapshots.forEach((snapshot) => {\nif (snapshot.meta) {\nscope\n.get(`/${packagePath}/${snapshot.version}/maven-metadata.xml`)\n.reply(200, snapshot.meta);\n} else {\nscope\n.get(`/${packagePath}/${snapshot.version}/maven-metadata.xml`)\n.reply(404, '');\n}\n});\n}\n}"
"async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst dependency = getDependencyParts(packageName);\nconst repoUrl = ensureTrailingSlash(registryUrl);\nlogger.debug(`Looking up ${dependency.display} in repository ${repoUrl}`);\nconst metadata = await this.fetchVersionsFromMetadata(dependency, repoUrl);\nif (!metadata.versions?.length) {\nreturn null;\n}\nconst releases = metadata.versions.map((version) => ({ version }));\nlogger.debug(\n`Found ${releases.length} new releases for ${dependency.display} in repository ${repoUrl}`,\n);\nconst latestSuitableVersion = getLatestSuitableVersion(releases);\nconst dependencyInfo =\nlatestSuitableVersion &&\n(await getDependencyInfo(\nthis.http,\ndependency,\nrepoUrl,\nlatestSuitableVersion,\n));\nconst result: ReleaseResult = {\n...dependency,\n...dependencyInfo,\nreleases,\n};\nif (metadata.tags) {\nresult.tags = metadata.tags;\nif (result.tags.latest) {\nlogger.debug(`Setting respectLatest=false for maven ${packageName}`);\nresult.respectLatest = false;\n}\n}\nif (!this.defaultRegistryUrls.includes(registryUrl)) {\nresult.isPrivate = true;\n}\nreturn result;\n}"
"override async postprocessRelease(\n{ packageName, registryUrl }: PostprocessReleaseConfig,\nrelease: Release,\n): Promise<PostprocessReleaseResult> {\nconst { version, versionOrig } = release;\nconst cacheKey = versionOrig\n? `postprocessRelease:${registryUrl}:${packageName}:${versionOrig}:${version}`\n: `postprocessRelease:${registryUrl}:${packageName}:${version}`;\nconst cachedResult = await packageCache.get<PostprocessReleaseResult>(\n'datasource-maven:postprocess-reject',\ncacheKey,\n);\nif (cachedResult) {\nreturn cachedResult;\n}\nif (!packageName || !registryUrl) {\nreturn release;\n}\nconst dependency = getDependencyParts(packageName);\nconst pomUrl = await createUrlForDependencyPom(\nthis.http,\nrelease.versionOrig ?? release.version,\ndependency,\nregistryUrl,\n);\nconst artifactUrl = getMavenUrl(dependency, registryUrl, pomUrl);\nconst fetchResult = await downloadMaven(this.http, artifactUrl);\nconst { val, err } = fetchResult.unwrap();\nif (err) {\nconst result: PostprocessReleaseResult =\nerr.type === 'not-found' ? 'reject' : release;\nif (result === 'reject') {\nawait packageCache.set(\n'datasource-maven:postprocess-reject',\ncacheKey,\nresult,\n24 * 60,\n);\n}\nreturn result;\n}\nif (val.lastModified) {\nrelease.releaseTimestamp = asTimestamp(val.lastModified);\n}\nreturn release;\n}"
"@cache({\nnamespace: `datasource-${NextcloudDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst response = await this.http.getJson(registryUrl, Applications);\nconst application = response.body.find((a) => a.id === packageName);\nif (!application) {\nreturn null;\n}\nconst sourceUrlMatches = NextcloudDatasource.sourceUrlRegex.exec(\napplication.website,\n);\nconst result: ReleaseResult = {\nreleases: [],\nhomepage: application.website,\nregistryUrl,\nchangelogUrl: sourceUrlMatches?.groups\n? `${sourceUrlMatches.groups.prefix}-releases${sourceUrlMatches.groups.suffix}`\n: application.website,\n};\nif (sourceUrlMatches !== null) {\nresult.sourceUrl = application.website;\n}\nfor (const release of application.releases) {\nconst translation =\nrelease.translations[NextcloudDatasource.defaultTranslationLanguage];\nconst changelogContent = translation?.changelog ?? null;\nresult.releases.push({\nversion: release.version,\nreleaseTimestamp: asTimestamp(release.created),\nchangelogContent:\nchangelogContent !== null && changelogContent.length > 0\n? changelogContent\n: undefined,\nisStable: !release.isNightly,\n});\n}\nreturn result;\n}"
"export function setNpmrc(input?: string): void {\nif (input) {\nif (input === npmrcRaw) {\nreturn;\n}\nconst existingNpmrc = npmrc;\nnpmrcRaw = input;\nlogger.debug('Setting npmrc');\nnpmrc = ini.parse(input.replace(regEx(/\\n/g), '\n'));\nconst exposeAllEnv = GlobalConfig.get('exposeAllEnv');\nfor (const [key, val] of Object.entries(npmrc)) {\nif (\n!exposeAllEnv &&\nkey.endsWith('registry') &&\nisString(val) &&\nval.includes('localhost')\n) {\nlogger.debug(\n{ key, val },\n'Detected localhost registry - rejecting npmrc file',\n);\nnpmrc = existingNpmrc;\nreturn;\n}\n}\nif (exposeAllEnv) {\nfor (const key of Object.keys(npmrc)) {\nnpmrc[key] = envReplace(npmrc[key]);\n}\n}\nconst npmrcRules = convertNpmrcToRules(npmrc);\nif (npmrcRules.hostRules?.length) {\nnpmrcRules.hostRules.forEach((hostRule) => hostRules.add(hostRule));\n}\npackageRules = npmrcRules.packageRules;\n} else if (npmrc) {\nlogger.debug('Resetting npmrc');\nnpmrc = {};\nnpmrcRaw = '';\npackageRules = [];\n}\n}"
"async getReleases(\nhttp: Http,\nfeedUrl: string,\npkgName: string,\n): Promise<ReleaseResult | null> {\nconst dep: ReleaseResult = {\nreleases: [],\n};\nlet pkgUrlList: string | null = `${feedUrl.replace(\nregEx(/\/+$/),\n'',\n)}/FindPackagesById()?id=%27${pkgName}%27&$select=Version,IsLatestVersion,ProjectUrl,Published`;\nwhile (pkgUrlList !== null) {\nconst pkgVersionsListRaw = await http.getText(pkgUrlList);\nconst pkgVersionsListDoc = new XmlDocument(pkgVersionsListRaw.body);\nconst pkgInfoList = pkgVersionsListDoc.childrenNamed('entry');\nfor (const pkgInfo of pkgInfoList) {\nconst version = this.getPkgProp(pkgInfo, 'Version');\nconst releaseTimestamp = asTimestamp(\nthis.getPkgProp(pkgInfo, 'Published'),\n);\ndep.releases.push({\nversion: removeBuildMeta(`${version}`),\nreleaseTimestamp,\n});\ntry {\nconst pkgIsLatestVersion = this.getPkgProp(\npkgInfo,\n'IsLatestVersion',\n);\nif (pkgIsLatestVersion === 'true') {\ndep.tags = { latest: removeBuildMeta(`${version}`) };\nconst projectUrl = this.getPkgProp(pkgInfo, 'ProjectUrl');\nif (projectUrl) {\ndep.sourceUrl = massageUrl(projectUrl);\n}\n}\n} catch (err)  {\nlogger.debug(\n{ err, pkgName, feedUrl },\n`nuget registry failure: can't parse pkg info for project url`,\n);\n}\n}\nconst nextPkgUrlListLink = pkgVersionsListDoc\n.childrenNamed('link')\n.find((node) => node.attr.rel === 'next');\npkgUrlList = nextPkgUrlListLink ? nextPkgUrlListLink.attr.href : null;\n}\nif (dep.releases.length === 0) {\nreturn null;\n}\nreturn dep;\n}"
"@cache({\nnamespace: NugetV3Api.cacheNamespace,\nkey: (\n_http: Http,\nregistryUrl: string,\npackageName: string,\n_packageVersion: string | null,\n_nupkgUrl: string,\n) => `source-url:${registryUrl}:${packageName}`,\nttlMinutes: 10080,\n})\nasync getSourceUrlFromNupkg(\nhttp: Http,\n_registryUrl: string,\npackageName: string,\npackageVersion: string | null,\nnupkgUrl: string,\n): Promise<string | null> {\nif (!getEnv().RENOVATE_X_NUGET_DOWNLOAD_NUPKGS) {\nlogger.once.debug('RENOVATE_X_NUGET_DOWNLOAD_NUPKGS is not set');\nreturn null;\n}\nconst cacheDir = await ensureCacheDir('nuget');\nconst nupkgFile = upath.join(\ncacheDir,\n`${packageName}.${packageVersion}.nupkg`,\n);\nconst nupkgContentsDir = upath.join(\ncacheDir,\n`${packageName}.${packageVersion}`,\n);\nconst readStream = http.stream(nupkgUrl);\ntry {\nconst writeStream = fs.createCacheWriteStream(nupkgFile);\nawait fs.pipeline(readStream, writeStream);\nawait extract(nupkgFile, { dir: nupkgContentsDir });\nconst nuspecFile = upath.join(nupkgContentsDir, `${packageName}.nuspec`);\nconst nuspec = new XmlDocument(\nawait fs.readCacheFile(nuspecFile, 'utf8'),\n);\nreturn nuspec.valueWithPath('metadata.repository@url') ?? null;\n} finally {\nawait fs.rmCache(nupkgFile);\nawait fs.rmCache(nupkgContentsDir);\n}\n}"
"@cache({\nnamespace: `datasource-${OrbDatasource.id}`,\nkey: ({ packageName }: GetReleasesConfig) => packageName,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst url = joinUrlParts(registryUrl, 'graphql-unstable');\nconst body = {\nquery,\nvariables: { packageName, maxVersions: MAX_VERSIONS },\n};\nconst res = (\nawait this.http.postJson<OrbResponse>(url, {\nbody,\n})\n).body;\nif (!res?.data?.orb) {\nlogger.debug({ res }, `Failed to look up orb ${packageName}`);\nreturn null;\n}\nconst { orb } = res.data;\nconst homepage = orb.homeUrl?.length\n? orb.homeUrl\n: `https:\nconst releases = orb.versions.map(({ version, createdAt }) => ({\nversion,\nreleaseTimestamp: asTimestamp(createdAt),\n}));\nconst dep = { homepage, isPrivate: !!orb.isPrivate, releases };\nlogger.trace({ dep }, 'dep');\nreturn dep;\n}"
"public override async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nlogger.trace(`getReleases(${packageName})`);\nif (!registryUrl) {\nreturn null;\n}\ntry {\nconst meta = await this.getRegistryMeta(registryUrl);\nif (\nmeta.availablePackages &&\n!meta.availablePackages.includes(packageName)\n) {\nreturn null;\n}\nif (meta.metadataUrl) {\nconst packagistResult = await this.packagistV2Lookup(\nregistryUrl,\nmeta.metadataUrl,\npackageName,\n);\nreturn packagistResult;\n}\nif (meta.packages[packageName]) {\nconst result = extractDepReleases(meta.packages[packageName]);\nreturn result;\n}\nawait this.fetchIncludesPackages(registryUrl, meta);\nif (meta.includesPackages[packageName]) {\nreturn meta.includesPackages[packageName];\n}\nawait this.fetchProviderPackages(registryUrl, meta);\nconst pkgUrl = this.getPkgUrl(packageName, registryUrl, meta);\nif (!pkgUrl) {\nreturn null;\n}\nconst pkgRes = await this.getJson(pkgUrl, PackagesResponse);\nconst dep = extractDepReleases(pkgRes.packages[packageName]);\nlogger.trace({ dep }, 'dep');\nreturn dep;\n} catch (err)  {\nif (err.host === 'packagist.org') {\nif (err.code === 'ECONNRESET' || err.code === 'ETIMEDOUT') {\nthrow new ExternalHostError(err);\n}\nif (err.statusCode && err.statusCode >= 500 && err.statusCode < 600) {\nthrow new ExternalHostError(err);\n}\n}\nthrow err;\n}\n}"
"export function extractReleaseResult(\n...composerReleasesArrays: ComposerReleases[]\n): ReleaseResult | null {\nconst releases: Release[] = [];\nlet homepage: string | null | undefined;\nlet sourceUrl: string | null | undefined;\nfor (const composerReleasesArray of composerReleasesArrays) {\nfor (const composerRelease of composerReleasesArray) {\nconst version = composerRelease.version.replace(/^v/, '');\nconst gitRef = composerRelease.version;\nconst dep: Release = { version, gitRef };\nif (composerRelease.time) {\ndep.releaseTimestamp = composerRelease.time;\n}\nif (composerRelease.require?.php) {\ndep.constraints = { php: [composerRelease.require.php] };\n}\nreleases.push(dep);\nif (!homepage && composerRelease.homepage) {\nhomepage = composerRelease.homepage;\n}\nif (!sourceUrl && composerRelease.source?.url) {\nsourceUrl = composerRelease.source.url;\n}\n}\n}\nif (releases.length === 0) {\nreturn null;\n}\nconst result: ReleaseResult = { releases };\nif (homepage) {\nresult.homepage = homepage;\n}\nif (sourceUrl) {\nresult.sourceUrl = sourceUrl;\n}\nreturn result;\n}"
"private async getReleasesFromGithub(\npackageName: string,\nopts: { hostURL: string; account: string; repo: string },\nuseShard = true,\nuseSpecs = true,\nurlFormatOptions: URLFormatOptions = 'withShardWithSpec',\n): Promise<ReleaseResult | null> {\nconst url = releasesGithubUrl(packageName, { ...opts, useShard, useSpecs });\nconst resp = await this.requestGithub<{ name: string }[]>(url, packageName);\nif (resp) {\nconst releases = resp.map(({ name }) => ({ version: name }));\nreturn { releases };\n}\nswitch (urlFormatOptions) {\ncase 'withShardWithSpec':\nreturn this.getReleasesFromGithub(\npackageName,\nopts,\ntrue,\nfalse,\n'withShardWithoutSpec',\n);\ncase 'withShardWithoutSpec':\nreturn this.getReleasesFromGithub(\npackageName,\nopts,\nfalse,\ntrue,\n'withSpecsWithoutShard',\n);\ncase 'withSpecsWithoutShard':\nreturn this.getReleasesFromGithub(\npackageName,\nopts,\nfalse,\nfalse,\n'withoutSpecsWithoutShard',\n);\ncase 'withoutSpecsWithoutShard':\ndefault:\nreturn null;\n}\n}"
"private async getSimpleDependency(\npackageName: string,\nhostUrl: string,\n): Promise<ReleaseResult | null> {\nconst lookupUrl = url.resolve(\nhostUrl,\nensureTrailingSlash(normalizePythonDepName(packageName)),\n);\nconst dependency: ReleaseResult = { releases: [] };\nconst headers = await this.getAuthHeaders(lookupUrl);\nconst response = await this.http.getText(lookupUrl, { headers });\nconst dep = response?.body;\nif (!dep) {\nlogger.trace({ dependency: packageName }, 'pip package not found');\nreturn null;\n}\nif (response.authorization) {\ndependency.isPrivate = true;\n}\nconst root = parse(PypiDatasource.cleanSimpleHtml(dep));\nconst links = root.querySelectorAll('a');\nconst releases: Releases = {};\nfor (const link of Array.from(links)) {\nconst version = PypiDatasource.extractVersionFromLinkText(\nlink.text?.trim(),\npackageName,\n);\nif (version) {\nconst release: PypiJSONRelease = {\nyanked: link.hasAttribute('data-yanked'),\n};\nconst requiresPython = link.getAttribute('data-requires-python');\nif (requiresPython) {\nrelease.requires_python = requiresPython;\n}\nif (!releases[version]) {\nreleases[version] = [];\n}\nreleases[version].push(release);\n}\n}\nconst versions = Object.keys(releases);\ndependency.releases = versions.map((version) => {\nconst versionReleases = coerceArray(releases[version]);\nconst isDeprecated = versionReleases.some(({ yanked }) => yanked);\nconst result: Release = { version };\nif (isDeprecated) {\nresult.isDeprecated = isDeprecated;\n}\nresult.constraints = {\npython: versionReleases.map(\n({ requires_python }) => requires_python,\n) as any,\n};\nreturn result;\n});\nreturn dependency;\n}"
"@cache({\nnamespace: `datasource-${datasource}`,\nkey: ({ registryUrl }: GetReleasesConfig) => `${registryUrl}`,\n})\nasync getReleases({\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst pythonPrebuildReleases = await this.getPrebuildReleases();\nconst pythonPrebuildVersions = new Set<string>(\npythonPrebuildReleases?.releases.map((release) => release.version),\n);\nconst pythonEolReleases = await this.getEolReleases();\nconst pythonEolVersions = new Map(\npythonEolReleases?.releases\n.filter((release) => release.isDeprecated !== undefined)\n.map((release) => [\nrelease.version.split('.').slice(0, 2).join('.'),\nrelease.isDeprecated,\n]),\n);\nconst result: ReleaseResult = {\nhomepage: 'https:\nsourceUrl: 'https:\nregistryUrl,\nreleases: [],\n};\ntry {\nconst response = await this.http.getJson(registryUrl, PythonRelease);\nresult.releases.push(\n...response.body\n.filter((release) => release.isStable)\n.filter((release) => pythonPrebuildVersions.has(release.version)),\n);\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nfor (const release of result.releases) {\nrelease.isDeprecated = pythonEolVersions.get(\nrelease.version.split('.').slice(0, 2).join('.'),\n);\n}\nreturn result.releases.length ? result : null;\n}"
"@cache({\nttlMinutes: 60,\nnamespace: `datasource-${RepologyDatasource.id}`,\nkey: (registryUrl: string, repoName: string, pkgName: string) =>\njoinUrlParts(registryUrl, repoName, pkgName),\n})\nasync queryPackage(\nregistryUrl: string,\nrepoName: string,\npkgName: string,\n): Promise<RepologyPackage[] | undefined> {\nlet response: RepologyPackage[];\ntry {\nfor (const pkgType of packageTypes) {\nresponse = await this.queryPackagesViaResolver(\nregistryUrl,\nrepoName,\npkgName,\npkgType,\n);\nif (response) {\nconst pkg = findPackageInResponse(response, repoName, pkgName, [\npkgType,\n]);\nif (isNonEmptyArray(pkg)) {\nreturn pkg;\n}\n}\n}\n} catch (err) {\nif (err.statusCode === 403) {\nlogger.debug(\n{ repoName, pkgName },\n'Repology does not support tools/project-by lookups for repository. Will try direct API access now',\n);\nresponse = await this.queryPackagesViaAPI(registryUrl, pkgName);\nconst pkg = findPackageInResponse(\nresponse,\nrepoName,\npkgName,\npackageTypes,\n);\nif (isNonEmptyArray(pkg)) {\nreturn pkg;\n}\n} else if (err.statusCode === 300) {\nlogger.warn(\n{ repoName, pkgName },\n'Ambiguous redirection from package name to project name in Repology. Skipping this package',\n);\nreturn undefined;\n}\nthrow err;\n}\nlogger.debug(\n{ repoName, pkgName },\n'Repository or package not found on Repology',\n);\nreturn undefined;\n}"
"async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst [repoName, pkgName] = packageName.split('/', 2);\nif (!repoName || !pkgName) {\nthrow new ExternalHostError(\nnew Error(\n'Repology lookup name must contain repository and package separated by slash (<repo>/<pkg>)',\n),\n);\n}\nlogger.trace(`repology.getReleases(${repoName}, ${pkgName})`);\ntry {\nconst pkg = await this.queryPackage(registryUrl, repoName, pkgName);\nif (!pkg) {\nreturn null;\n}\nconst releases = pkg.map((item) => ({\nversion: item.origversion ?? item.version,\n}));\nreturn { releases };\n} catch (err) {\nif (err.message === HOST_DISABLED) {\nlogger.trace({ packageName, err }, 'Host disabled');\n} else {\nlogger.warn(\n{ packageName, err },\n'Repology lookup failed with unexpected error',\n);\n}\nthrow new ExternalHostError(err);\n}\n}"
"@cache({\nnamespace: `datasource-${RpmDatasource.id}`,\nkey: (registryUrl: string) => registryUrl,\nttlMinutes: 1440,\n})\nasync getPrimaryGzipUrl(registryUrl: string): Promise<string | null> {\nconst repomdUrl = joinUrlParts(\nregistryUrl,\nRpmDatasource.repomdXmlFileName,\n);\nconst response = await this.http.getText(repomdUrl.toString());\nif (!response.body.startsWith('<?xml')) {\nlogger.debug(\n{ datasource: RpmDatasource.id, url: repomdUrl },\n'Invalid response format',\n);\nthrow new Error(\n`${repomdUrl} is not in XML format. Response body: ${response.body}`,\n);\n}\nconst xml = new XmlDocument(response.body);\nconst primaryData = xml.childWithAttribute('type', 'primary');\nif (!primaryData) {\nlogger.debug(\n`No primary data found in ${repomdUrl}, xml contents: ${response.body}`,\n);\nthrow new Error(`No primary data found in ${repomdUrl}`);\n}\nconst locationElement = primaryData.childNamed('location');\nif (!locationElement) {\nthrow new Error(`No location element found in ${repomdUrl}`);\n}\nconst href = locationElement.attr.href;\nif (!href) {\nthrow new Error(`No href found in ${repomdUrl}`);\n}\nconst registryUrlWithoutRepodata = registryUrl.replace(\n/\/repodata\/?$/,\n'/',\n);\nreturn joinUrlParts(registryUrlWithoutRepodata, href);\n}"
"@cache({ namespace: `datasource-${RubyVersionDatasource.id}`, key: 'all' })\nasync getReleases({\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst res: ReleaseResult = {\nhomepage: 'https:\nsourceUrl: 'https:\nreleases: [],\n};\nconst rubyVersionsUrl = `${registryUrl}en/downloads/releases/`;\ntry {\nconst response = await this.http.getText(rubyVersionsUrl);\nconst root = parse(response.body);\nconst rows =\nroot.querySelector('.release-list')?.querySelectorAll('tr') ?? [];\nrows.forEach((row) => {\nconst tds = row.querySelectorAll('td');\nconst columns: string[] = [];\ntds.forEach((td) => columns.push(td.innerHTML));\nif (columns.length) {\nconst version = columns[0].replace('Ruby ', '');\nif (isVersion(version)) {\nconst releaseTimestamp = asTimestamp(columns[1]);\nconst changelogUrl = columns[2]\n.replace('<a href=`', 'https:\n.replace('`>more...</a>', '');\nres.releases.push({ version, releaseTimestamp, changelogUrl });\n}\n}\n});\nif (!res.releases.length) {\nlogger.warn({ registryUrl }, 'Missing ruby releases');\nreturn null;\n}\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nreturn res;\n}"
"@cache({\nnamespace: `datasource-${RubygemsDatasource.id}`,\nkey: ({ packageName, registryUrl }: GetReleasesConfig) =>\n`releases:${registryUrl!}:${packageName}`,\ncacheable: ({ registryUrl }: GetReleasesConfig) => {\nconst registryHostname = parseUrl(registryUrl)?.hostname;\nreturn registryHostname === 'rubygems.org';\n},\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst registryHostname = parseUrl(registryUrl)?.hostname;\nlet result: AsyncResult<ReleaseResult, Error | string>;\nif (registryHostname === 'rubygems.org') {\nresult = Result.wrap(\nthis.versionsEndpointCache.getVersions(registryUrl, packageName),\n).transform((versions) =>\nthis.metadataCache.getRelease(registryUrl, packageName, versions),\n);\n} else if (\nregistryHostname === 'rubygems.pkg.github.com' ||\nregistryHostname === 'gitlab.com'\n) {\nresult = this.getReleasesViaDeprecatedAPI(registryUrl, packageName);\n} else {\nresult = getV1Releases(this.http, registryUrl, packageName)\n.catch((err) =>\nunlessServerSide(err, () =>\nthis.getReleasesViaInfoEndpoint(registryUrl, packageName),\n),\n)\n.catch((err) =>\nunlessServerSide(err, () =>\nthis.getReleasesViaDeprecatedAPI(registryUrl, packageName),\n),\n);\n}\nconst { val, err } = await result.unwrap();\nif (val) {\nreturn val;\n}\nif (err instanceof Error) {\nthis.handleGenericErrors(err);\n}\nlogger.debug({ packageName, registryUrl }, `Rubygems fetch error: ${err}`);\nreturn null;\n}"
"private async deltaSync(\noldCache: VersionsEndpointData,\nregistryUrl: string,\n): Promise<VersionsEndpointResult> {\ntry {\nconst url = `${registryUrl}/versions`;\nconst startByte = oldCache.contentLength - oldCache.contentTail.length;\nconst opts: HttpOptions = {\nheaders: {\n['Accept-Encoding']: 'deflate, compress, br',\n['Range']: `bytes=${startByte}-`,\n},\n};\nconst { statusCode, body } = await this.http.getText(url, opts);\nif (statusCode === 200) {\nreturn parseFullBody(body);\n}\nconst contentHead = getContentHead(body);\nif (contentHead !== oldCache.contentTail) {\nreturn this.fullSync(registryUrl);\n}\nconst delta = stripContentHead(body);\nconst packageVersions = reconcilePackageVersions(\noldCache.packageVersions,\nVersionLines.parse(delta),\n);\nconst syncedAt = new Date();\nconst contentLength = oldCache.contentLength + delta.length;\nconst contentTail = getContentTail(body);\nreturn Result.ok({\npackageVersions,\nsyncedAt,\ncontentLength,\ncontentTail,\n});\n} catch (err) {\nif (err instanceof HttpError) {\nconst responseStatus = err.response?.statusCode;\nif (responseStatus === 416) {\nreturn this.fullSync(registryUrl);\n}\nif (responseStatus === 404) {\nreturn Result.err('unsupported-api');\n}\n}\nthrow err;\n}\n}"
"async getUrls(\nsearchRoot: string,\nartifactDirs: string[] | null,\nversion: string | null,\n): Promise<Partial<ReleaseResult>> {\nconst result: Partial<ReleaseResult> = {};\nif (!artifactDirs?.length) {\nreturn result;\n}\nif (!version) {\nreturn result;\n}\nfor (const artifactDir of artifactDirs) {\nconst [artifact] = artifactDir.split('_');\nconst pomFileNames = [\n`${artifactDir}-${version}.pom`,\n`${artifact}-${version}.pom`,\n];\nfor (const pomFileName of pomFileNames) {\nconst pomUrl = `${searchRoot}/${artifactDir}/${version}/${pomFileName}`;\nconst content = await downloadHttpContent(this.http, pomUrl);\nif (content) {\nconst pomXml = new XmlDocument(content);\nconst homepage = pomXml.valueWithPath('url');\nif (homepage) {\nresult.homepage = homepage;\n}\nconst sourceUrl = pomXml.valueWithPath('scm.url');\nif (sourceUrl) {\nresult.sourceUrl = sourceUrl\n.replace(regEx(/^scm:/), '')\n.replace(regEx(/^git:/), '')\n.replace(regEx(/^git@github.com:/), 'https:\n.replace(regEx(/\.git$/), '');\n}\nreturn result;\n}\n}\n}\nreturn result;\n}"
"async resolvePluginReleases(\nrootUrl: string,\nartifact: string,\nscalaVersion: string,\n): Promise<string[] | null> {\nconst searchRoot = `${rootUrl}/${artifact}`;\nconst hrefFilterMap = (href: string): string | null => {\nif (href.startsWith('.')) {\nreturn null;\n}\nreturn href;\n};\nconst searchRootContent = await downloadHttpContent(\nthis.http,\nensureTrailingSlash(searchRoot),\n);\nif (searchRootContent) {\nconst releases: string[] = [];\nconst scalaVersionItems = extractPageLinks(\nsearchRootContent,\nhrefFilterMap,\n);\nconst scalaVersions = scalaVersionItems.map((x) =>\nx.replace(regEx(/^scala_/), ''),\n);\nconst searchVersions = scalaVersions.includes(scalaVersion)\n? [scalaVersion]\n: scalaVersions;\nfor (const searchVersion of searchVersions) {\nconst searchSubRoot = `${searchRoot}/scala_${searchVersion}`;\nconst subRootContent = await downloadHttpContent(\nthis.http,\nensureTrailingSlash(searchSubRoot),\n);\nif (subRootContent) {\nconst sbtVersionItems = extractPageLinks(\nsubRootContent,\nhrefFilterMap,\n);\nfor (const sbtItem of sbtVersionItems) {\nconst releasesRoot = `${searchSubRoot}/${sbtItem}`;\nconst releasesIndexContent = await downloadHttpContent(\nthis.http,\nensureTrailingSlash(releasesRoot),\n);\nif (releasesIndexContent) {\nconst releasesParsed = extractPageLinks(\nreleasesIndexContent,\nhrefFilterMap,\n);\nreleasesParsed.forEach((x) => releases.push(x));\n}\n}\n}\n}\nif (releases.length) {\nreturn [...new Set(releases)].sort(compare);\n}\n}\nreturn null;\n}"
"override async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nconst [groupId, artifactId] = packageName.split(':');\nconst groupIdSplit = groupId.split('.');\nconst artifactIdSplit = artifactId.split('_');\nconst [artifact, scalaVersion] = artifactIdSplit;\nconst repoRoot = ensureTrailingSlash(registryUrl);\nconst searchRoots: string[] = [];\nif (!registryUrl.startsWith(MAVEN_REPO)) {\nsearchRoots.push(`${repoRoot}${groupIdSplit.join('.')}`);\n}\nsearchRoots.push(`${repoRoot}${groupIdSplit.join('/')}`);\nfor (const searchRoot of searchRoots) {\nlet versions = await this.resolvePluginReleases(\nsearchRoot,\nartifact,\nscalaVersion,\n);\nlet urls = {};\nif (!versions?.length) {\nconst artifactSubdirs = await this.getArtifactSubdirs(\nsearchRoot,\nartifact,\nscalaVersion,\n);\nversions = await this.getPackageReleases(searchRoot, artifactSubdirs);\nconst latestVersion = getLatestVersion(versions);\nurls = await this.getUrls(searchRoot, artifactSubdirs, latestVersion);\n}\nconst dependencyUrl = `${searchRoot}/${artifact}`;\nlogger.trace({ dependency: packageName, versions }, `Package versions`);\nif (versions) {\nreturn {\n...urls,\ndependencyUrl,\nreleases: versions.map((v) => ({ version: v })),\n};\n}\n}\nlogger.debug(\n`No versions found for ${packageName} in ${searchRoots.length} repositories`,\n);\nreturn null;\n}"
"private async queryRegistryExtendedApi(\nserviceDiscovery: ServiceDiscoveryResult,\nregistryUrl: string,\nrepository: string,\n): Promise<ReleaseResult | null> {\nlet res: TerraformRelease;\nlet pkgUrl: string;\ntry {\npkgUrl = createSDBackendURL(\nregistryUrl,\n'modules.v1',\nserviceDiscovery,\nrepository,\n);\nres = (await this.http.getJsonUnchecked<TerraformRelease>(pkgUrl)).body;\nconst returnedName = res.namespace + '/' + res.name + '/' + res.provider;\nif (returnedName !== repository) {\nlogger.warn({ pkgUrl }, 'Terraform registry result mismatch');\nreturn null;\n}\n} catch (err) {\nthis.handleGenericErrors(err);\n}\nconst dep: ReleaseResult = {\nreleases: res.versions.map((version) => ({\nversion,\n})),\n};\nif (res.source) {\ndep.sourceUrl = res.source;\n}\ndep.homepage = `${registryUrl}/modules/${repository}`;\nconst latestVersion = dep.releases.find(\n(release) => res.version === release.version,\n);\nif (latestVersion) {\nlatestVersion.releaseTimestamp = asTimestamp(res.published_at);\n}\nreturn dep;\n}"
"@cache({\nnamespace: `datasource-${TerraformProviderDatasource.id}`,\nkey: (getReleasesConfig: GetReleasesConfig) => {\nconst url = getReleasesConfig.registryUrl;\nconst repo = TerraformProviderDatasource.getRepository(getReleasesConfig);\nreturn `getReleases:${url}/${repo}`;\n},\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nif (!registryUrl) {\nreturn null;\n}\nlogger.trace(\n`terraform-provider.getDependencies() packageName: ${packageName}`,\n);\nif (registryUrl === this.defaultRegistryUrls[1]) {\nreturn await this.queryReleaseBackend(packageName, registryUrl);\n}\nconst repository = TerraformProviderDatasource.getRepository({\npackageName,\n});\nconst serviceDiscovery =\nawait this.getTerraformServiceDiscoveryResult(registryUrl);\nif (registryUrl === this.defaultRegistryUrls[0]) {\nreturn await this.queryRegistryExtendedApi(\nserviceDiscovery,\nregistryUrl,\nrepository,\n);\n}\nreturn await this.queryRegistryVersions(\nserviceDiscovery,\nregistryUrl,\nrepository,\n);\n}"
"@cache({\nnamespace: `datasource-${TypstDatasource.id}:releases`,\nkey: ({ packageName }: GetReleasesConfig) => packageName,\nttlMinutes: 180,\n})\noverride async getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst [namespace, pkg] = packageName.split('/');\nif (namespace !== 'preview') {\nlogger.debug(`Unsupported namespace for @${packageName}`);\nreturn null;\n}\nconst versionsUrl = `/repos/typst/packages/contents/packages/preview/${pkg}`;\nconst cacheProvider = new PackageHttpCacheProvider({\nnamespace: 'datasource-typst:cache-provider',\ncheckAuthorizationHeader: false,\ncheckCacheControlHeader: false,\nsoftTtlMinutes: 180,\n});\nconst { body: versions } = await this.githubHttp.getJson(\nversionsUrl,\n{\ncacheProvider,\nbaseUrl: registryUrl,\n},\nVersions,\n);\nconst latestRelease = versions\n.sort((x, y) => semverApi.sortVersions(x, y))\n.at(-1);\nif (!latestRelease) {\nreturn null;\n}\nconst releases: Release[] = versions.map((version) => ({ version }));\nconst result: ReleaseResult = { releases };\nconst manifestUrl = `/repos/typst/packages/contents/packages/preview/${pkg}/${latestRelease}/typst.toml`;\nconst { body: sourceUrl } = await this.githubHttp.getJson(\nmanifestUrl,\n{\ncacheProvider,\nbaseUrl: registryUrl,\n},\nSourceUrl,\n);\nif (sourceUrl) {\nresult.sourceUrl = sourceUrl;\n}\nreturn result;\n}"
"async getByStream(\nregistryUrl: string | undefined,\nwithHash: boolean,\n): Promise<ReleaseResult | null> {\nconst translatedRegistryUrl = this.translateStream(registryUrl!);\nconst isStable: boolean =\ntranslatedRegistryUrl === Unity3dDatasource.streams.lts;\nlet total: number | null = null;\nconst result: ReleaseResult = {\nreleases: [],\nhomepage: Unity3dDatasource.homepage,\nregistryUrl: translatedRegistryUrl,\n};\nfor (\nlet offset = 0;\ntotal === null || offset < total;\noffset += Unity3dDatasource.limit\n) {\nconst response = await this.http.getJson(\n`${translatedRegistryUrl}&limit=${Unity3dDatasource.limit}&offset=${offset}`,\nUnityReleasesJSON,\n);\nfor (const release of response.body.results) {\nresult.releases.push({\nversion: withHash\n? `${release.version} (${release.shortRevision})`\n: release.version,\nreleaseTimestamp: asTimestamp(release.releaseDate),\nchangelogUrl: release.releaseNotes.url,\nisStable,\n});\n}\ntotal ??= response.body.total;\n}\nreturn result;\n}"
"@cache({\nnamespace: `datasource-${Unity3dPackagesDatasource.id}`,\nkey: ({ registryUrl, packageName }: GetReleasesConfig) =>\n`${registryUrl}:${packageName}`,\n})\nasync getReleases({\npackageName,\nregistryUrl,\n}: GetReleasesConfig): Promise<ReleaseResult | null> {\nconst response = await this.http.getJson(\n`${registryUrl}/${packageName}`,\nUnityPackageReleasesJSON,\n);\nconst usingDefaultRegistry =\nregistryUrl === Unity3dPackagesDatasource.defaultRegistryUrl;\nconst versions = Object.values(response.body.versions);\nconst result: ReleaseResult = {\nreleases: [],\nhomepage: versions?.[0]?.documentationUrl,\nregistryUrl,\nsourceUrl: versions?.[0]?.repository?.url,\n};\nfor (const release of versions) {\nresult.releases.push({\nversion: release.version,\nreleaseTimestamp: asTimestamp(response.body.time[release.version]),\nchangelogContent: release._upm?.changelog,\nchangelogUrl: usingDefaultRegistry\n? release.documentationUrl?.replace(\n'manual/index.html',\n'changelog/CHANGELOG.html',\n)\n: undefined,\nisStable: Unity3dPackagesVersioning.default.isStable(release.version),\nregistryUrl,\n});\n}\nreturn result;\n}"
"function finalize(dependency: AnsibleGalaxyPackageDependency): boolean {\nconst dep = dependency;\ndep.depName = dep.managerData.name;\nconst name = dep.managerData.name;\nconst nameMatch = nameMatchRegex.exec(name);\nswitch (dependency.managerData.type) {\ncase 'galaxy':\nhandleGalaxyDep(dep);\nbreak;\ncase 'git':\nhandleGitDep(dep, nameMatch);\nbreak;\ncase 'file':\ndep.skipReason = 'local-dependency';\nbreak;\ncase null:\nif (nameMatch) {\nhandleGitDep(dep, nameMatch);\nbreak;\n}\nif (galaxyDepRegex.exec(dep.managerData.name)) {\ndep.datasource = GalaxyCollectionDatasource.id;\ndep.depName = dep.managerData.name;\nbreak;\n}\ndep.skipReason = 'no-source-match';\nbreak;\ndefault:\ndep.skipReason = 'unsupported';\nreturn true;\n}\nif (!dependency.currentValue && !dep.skipReason) {\ndep.skipReason = 'unspecified-version';\n}\nreturn true;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n): PackageFileContent | null {\nlogger.trace(`ansible-galaxy.extractPackageFile(${packageFile})`);\nconst galaxyFileNameRegEx = regEx(/galaxy\.ya?ml$/);\nconst deps: PackageDependency[] = [];\nconst lines = content.split(newlineRegex);\ntry {\nif (galaxyFileNameRegEx.exec(packageFile)) {\nconst galaxyDeps = extractCollectionsMetaDataFile(lines);\ndeps.push(...galaxyDeps);\n} else {\nconst positions = {\ncollections: -1,\nroles: -1,\n};\nlines.forEach((line, index) => {\nif (regEx(/^collections:/).exec(line)) {\npositions.collections = index;\n}\nif (regEx(/^roles:/).exec(line)) {\npositions.roles = index;\n}\n});\nif (positions.collections >= 0 || positions.roles >= 0) {\nconst collectionLines = lines.slice(\npositions.collections,\ngetSliceEndNumber(\npositions.collections,\nlines.length,\npositions.roles,\n),\n);\nconst collectionDeps = extractCollections(collectionLines);\ndeps.push(...collectionDeps);\nconst roleLines = lines.slice(\npositions.roles,\ngetSliceEndNumber(\npositions.roles,\nlines.length,\npositions.collections,\n),\n);\nconst roleDeps = extractRoles(roleLines);\ndeps.push(...roleDeps);\n} else {\nconst galaxyDeps = extractRoles(lines);\ndeps.push(...galaxyDeps);\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n} catch (err)  {\nlogger.debug({ err, packageFile }, 'Error extracting ansible-galaxy deps');\nreturn null;\n}\n}"
"function processSource(source: ApplicationSource): PackageDependency[] {\nif (source.chart) {\nif (isOCIRegistry(source.repoURL) || !source.repoURL.includes(':\nconst registryURL = trimTrailingSlash(removeOCIPrefix(source.repoURL));\nreturn [\n{\ndepName: `${registryURL}/${source.chart}`,\ncurrentValue: source.targetRevision,\ndatasource: DockerDatasource.id,\n},\n];\n}\nreturn [\n{\ndepName: source.chart,\nregistryUrls: [source.repoURL],\ncurrentValue: source.targetRevision,\ndatasource: HelmDatasource.id,\n},\n];\n}\nif (isOCIRegistry(source.repoURL)) {\nconst registryURL = trimTrailingSlash(removeOCIPrefix(source.repoURL));\nreturn [\n{\ndepName: registryURL,\ncurrentValue: source.targetRevision,\ndatasource: DockerDatasource.id,\n},\n];\n}\nconst dependencies: PackageDependency[] = [\n{\ndepName: source.repoURL,\ncurrentValue: source.targetRevision,\ndatasource: GitTagsDatasource.id,\n},\n];\nif (source.kustomize?.images) {\ndependencies.push(\n...source.kustomize.images.map(processKustomizeImage).filter(isTruthy),\n);\n}\nreturn dependencies;\n}"
"export function extractPackageFile(content: string): PackageFileContent | null {\nlogger.trace(`asdf.extractPackageFile()`);\nconst regex = regEx(\n/^(?<toolName>([\w_-]+)) +(?<version>[^\s#]+)(?: +[^\s#]+)* *(?: #(?<comment>.*))?$/gm,\n);\nconst deps: PackageDependency[] = [];\nfor (const groups of [...content.matchAll(regex)]\n.map((m) => m.groups)\n.filter(isTruthy)) {\nconst depName = groups.toolName.trim();\nconst version = groups.version.trim();\nconst toolConfig = upgradeableTooling[depName];\nconst toolDefinition = toolConfig\n? typeof toolConfig.config === 'function'\n? toolConfig.config(version)\n: toolConfig.config\n: undefined;\nif (toolDefinition) {\nconst dep: PackageDependency = {\ncurrentValue: version,\ndepName,\n...toolDefinition,\n};\nif (isSkipComment((groups.comment ?? '').trim())) {\ndep.skipReason = 'ignored';\n}\ndeps.push(dep);\n} else {\nconst dep: PackageDependency = {\ndepName,\nskipReason: 'unsupported-datasource',\n};\ndeps.push(dep);\n}\n}\nreturn deps.length ? { deps } : null;\n}"
"export function extractRepository(\nrepository: Repository,\ncurrentRepository?: string,\n): PackageDependency | null {\nlet repositoryUrl = null;\nlet depName = repository.name;\nif (repository.type === 'github') {\nrepositoryUrl = `https:\n} else if (repository.type === 'git') {\nconst platform = GlobalConfig.get('platform');\nconst endpoint = GlobalConfig.get('endpoint');\nif (platform === 'azure' && endpoint) {\nif (repository.name.includes('/')) {\nconst [projectName, repoName] = repository.name.split('/');\nrepositoryUrl = joinUrlParts(\nendpoint,\nencodeURIComponent(projectName),\n'_git',\nencodeURIComponent(repoName),\n);\n} else if (currentRepository?.includes('/')) {\nconst projectName = currentRepository.split('/')[0];\ndepName = `${projectName}/${repository.name}`;\nrepositoryUrl = joinUrlParts(\nendpoint,\nencodeURIComponent(projectName),\n'_git',\nencodeURIComponent(repository.name),\n);\n} else {\nlogger.debug(\n'Renovate cannot update Azure pipelines in git repositories when neither the current repository nor the target repository contains the Azure DevOps project name.',\n);\n}\n}\n}\nif (repositoryUrl === null) {\nreturn null;\n}\nif (!repository.ref?.startsWith('refs/tags/')) {\nreturn null;\n}\nreturn {\nautoReplaceStringTemplate: 'refs/tags/{{newValue}}',\ncurrentValue: repository.ref.replace('refs/tags/', ''),\ndatasource: GitTagsDatasource.id,\ndepName,\ndepType: 'gitTags',\npackageName: repositoryUrl,\nreplaceString: repository.ref,\n};\n}"
"export function transformRulesImgCalls(fragments: any[]): PackageDependency[] {\nconst deps: PackageDependency[] = [];\nconst repoRuleVariables = new Map<\nstring,\n{ bzlFile: string; ruleName: string }\n>();\nfor (const fragment of fragments) {\nif (fragment.type === 'useRepoRule') {\nrepoRuleVariables.set(fragment.variableName, {\nbzlFile: fragment.bzlFile,\nruleName: fragment.ruleName,\n});\n}\n}\nfor (const fragment of fragments) {\nif (fragment.type === 'repoRuleCall') {\nconst functionName = fragment.functionName;\nif (!repoRuleVariables.has(functionName)) {\ncontinue;\n}\nconst ruleInfo = repoRuleVariables.get(functionName);\nif (!ruleInfo?.bzlFile.includes('@rules_img\ncontinue;\n}\ntry {\nconst dep = RulesImgPullCallToDep.parse(fragment);\ndeps.push(dep);\n} catch {\ncontinue;\n}\n}\n}\nreturn deps;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFileContent | null {\nconst deps: PackageDependency[] = [];\ntry {\nconst lines = content\n.replaceAll(/^\s*\r?\n/gm, '')\n.replaceAll(/^\s*#.*\r?\n/gm, '')\n.split(newlineRegex);\nconst len = lines.length;\nfor (let lineIdx = 0; lineIdx < len; lineIdx++) {\nconst line = lines[lineIdx];\nconst dockerImageObjectGroups = dockerImageObjectRegex.exec(line)?.groups;\nif (dockerImageObjectGroups) {\nlineIdx = addDepFromObject(\ndeps,\nlines,\nlineIdx,\nlen,\ndockerImageObjectGroups.spaces,\nconfig.registryAliases,\n);\ncontinue;\n}\nconst pipeMatch = pipeRegex.exec(line);\nif (pipeMatch) {\nconst pipe = pipeMatch[1];\nif (pipe.startsWith('docker:\nconst currentPipe = pipe.replace('docker:\naddDepAsDockerImage(deps, currentPipe, config.registryAliases);\n} else {\naddDepAsBitbucketTag(deps, pipe);\n}\ncontinue;\n}\nconst dockerImageMatch = dockerImageRegex.exec(line);\nif (dockerImageMatch) {\nconst currentFrom = dockerImageMatch[1];\naddDepAsDockerImage(deps, currentFrom, config.registryAliases);\n}\n}\n} catch (err)  {\nlogger.debug(\n{ err, packageFile },\n'Error extracting Bitbucket Pipes dependencies',\n);\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"export function parseStepRef(\nref: string,\ndefaultRegistry?: string,\n): PackageDependency {\nif (ref.startsWith('path::')) {\nreturn {\ndepName: ref.split('::', 2)[1],\nskipReason: 'local-dependency',\n};\n}\nif (ref.startsWith('git::')) {\nconst [, packageName] = ref.split('::');\nreturn {\npackageName,\ndatasource: GitTagsDatasource.id,\n};\n}\nconst splitted = ref.split('::', 2);\nif (splitted.length === 1) {\nconst [packageName] = splitted;\nreturn {\npackageName,\ndatasource: BitriseDatasource.id,\nregistryUrls: defaultRegistry ? [defaultRegistry] : undefined,\n};\n}\nconst [registryUrl, packageName] = splitted;\nreturn {\npackageName,\ndatasource: BitriseDatasource.id,\nregistryUrls: [registryUrl],\n};\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFileContent | null {\nconst deps: PackageDependency[] = [];\nconst descriptor = parseProjectToml(content, packageFile);\nif (!descriptor) {\nreturn null;\n}\nif (\ndescriptor.io?.buildpacks?.builder &&\nisDockerRef(descriptor.io.buildpacks.builder)\n) {\nconst dep = getDockerDep(\ndescriptor.io.buildpacks.builder.replace(DOCKER_PREFIX, ''),\ntrue,\nconfig.registryAliases,\n);\nlogger.trace(\n{\ndepName: dep.depName,\ncurrentValue: dep.currentValue,\ncurrentDigest: dep.currentDigest,\n},\n'Cloud Native Buildpacks builder',\n);\ndeps.push({ ...dep, commitMessageTopic: 'builder {{depName}}' });\n}\nif (\ndescriptor.io?.buildpacks?.group &&\nisArray(descriptor.io.buildpacks.group)\n) {\nfor (const group of descriptor.io.buildpacks.group) {\nif (isBuildpackByURI(group) && isDockerRef(group.uri)) {\nconst dep = getDockerDep(\ngroup.uri.replace(DOCKER_PREFIX, ''),\ntrue,\nconfig.registryAliases,\n);\nlogger.trace(\n{\ndepName: dep.depName,\ncurrentValue: dep.currentValue,\ncurrentDigest: dep.currentDigest,\n},\n'Cloud Native Buildpack',\n);\ndeps.push(dep);\n} else if (isBuildpackByURI(group) && isBuildpackRegistryRef(group.uri)) {\nconst dep = getDep(group.uri.replace(BUILDPACK_REGISTRY_PREFIX, ''));\nif (dep) {\ndeps.push(dep);\n}\n} else if (isBuildpackByName(group)) {\nconst version = group.version;\nif (version) {\nconst dep: PackageDependency = {\ndatasource: BuildpacksRegistryDatasource.id,\ncurrentValue: version,\npackageName: group.id,\n};\ndeps.push(dep);\n}\n}\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\nmatchedFiles: string[],\n): Promise<PackageFile[]> {\nconst packageFiles: PackageFile<NpmManagerData>[] = [];\nconst allLockFiles = matchedFiles.filter(\n(file) =>\nmatchesFileName(file, 'bun.lock') || matchesFileName(file, 'bun.lockb'),\n);\nif (allLockFiles.length === 0) {\nlogger.debug('No bun lockfiles found');\nreturn packageFiles;\n}\nconst allPackageJson = matchedFiles.filter((file) =>\nmatchesFileName(file, 'package.json'),\n);\nfor (const lockFile of allLockFiles) {\nconst packageFile = getSiblingFileName(lockFile, 'package.json');\nconst res = await processPackageFile(packageFile);\nif (res) {\npackageFiles.push({ ...res, lockFiles: [lockFile] });\n}\nconst workspaces = res?.managerData?.workspaces;\nif (!isArray(workspaces, isString)) {\ncontinue;\n}\nlogger.debug(`Found bun workspaces in ${packageFile}`);\nconst pwd = getParentDir(packageFile);\nconst workspacePackageFiles = filesMatchingWorkspaces(\npwd,\nallPackageJson,\nworkspaces,\n);\nif (workspacePackageFiles.length) {\nlogger.debug({ workspacePackageFiles }, 'Found bun workspace files');\nfor (const workspaceFile of workspacePackageFiles) {\nconst res = await processPackageFile(workspaceFile);\nif (res) {\npackageFiles.push({ ...res, lockFiles: [lockFile] });\n}\n}\n}\n}\nreturn packageFiles;\n}"
"function extractFromSection(\ndependencies: PackageDependency<CargoManagerData>[] | undefined,\ncargoRegistries: CargoRegistries,\ntarget?: string,\n): PackageDependency[] {\nif (!dependencies) {\nreturn [];\n}\nconst deps: PackageDependency<CargoManagerData>[] = [];\nfor (const dep of Object.values(dependencies)) {\nlet registryUrls: string[] | undefined;\nif (dep.managerData?.registryName) {\nconst registryUrl =\ngetCargoIndexEnv(dep.managerData.registryName) ??\ncargoRegistries[dep.managerData?.registryName];\nif (registryUrl) {\nif (registryUrl !== DEFAULT_REGISTRY_URL) {\nregistryUrls = [registryUrl];\n}\n} else {\ndep.skipReason = 'unknown-registry';\n}\n}\nif (registryUrls) {\ndep.registryUrls = registryUrls;\n} else {\nif (cargoRegistries[DEFAULT_REGISTRY_ID]) {\nif (cargoRegistries[DEFAULT_REGISTRY_ID] !== DEFAULT_REGISTRY_URL) {\ndep.registryUrls = [cargoRegistries[DEFAULT_REGISTRY_ID]];\n}\n} else {\ndep.skipReason = 'unknown-registry';\n}\n}\nif (target) {\ndep.target = target;\n}\ndeps.push(dep);\n}\nreturn deps;\n}"
"function resolveRegistryIndex(\nregistryName: string,\nconfig: CargoConfig,\noriginalNames = new Set<string>(),\n): CargoRegistryUrl {\nconst replacementName = config.source?.[registryName]?.['replace-with'];\nif (replacementName) {\nlogger.debug(\n`Replacing index of cargo registry ${registryName} with ${replacementName}`,\n);\nif (originalNames.has(replacementName)) {\nlogger.warn({ registryName }, 'cargo registry resolves to itself');\nreturn null;\n}\nreturn resolveRegistryIndex(\nreplacementName,\nconfig,\noriginalNames.add(replacementName),\n);\n}\nconst sourceRegistry = config.source?.[registryName]?.registry;\nif (sourceRegistry) {\nlogger.debug(\n`Replacing cargo source registry with ${sourceRegistry} for ${registryName}`,\n);\nreturn sourceRegistry;\n}\nconst registryIndex = config.registries?.[registryName]?.index;\nif (registryIndex) {\nreturn registryIndex;\n} else {\nif (registryName === DEFAULT_REGISTRY_ID) {\nreturn DEFAULT_REGISTRY_URL;\n} else {\nlogger.debug(`${registryName} cargo registry is missing index`);\nreturn null;\n}\n}\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump Cargo.toml version',\n);\nlet bumpedContent = content;\nif (!semver.valid(currentValue)) {\nlogger.warn(\n{ currentValue },\n'Unable to bump Cargo.toml version, not a valid semver',\n);\nreturn { bumpedContent };\n}\ntry {\nconst newCrateVersion = semver.inc(currentValue, bumpVersion);\nif (!newCrateVersion) {\nthrow new Error('semver inc failed');\n}\nlogger.debug({ newCrateVersion });\nbumpedContent = content.replace(\nregEx(`^(?<version>version[ \\t]*=[ \\t]*['`])[^'`]*`, 'm'),\n`$<version>${newCrateVersion}`,\n);\nif (bumpedContent === content) {\nlogger.debug('Version was already bumped');\n} else {\nlogger.debug('Bumped Cargo.toml version');\n}\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n): Promise<PackageFileContent | null> {\nlogger.trace(`cocoapods.extractPackageFile(${packageFile})`);\nconst deps: PackageDependency[] = [];\nconst lines: string[] = content.split(newlineRegex);\nconst registryUrls: string[] = [];\nfor (let lineNumber = 0; lineNumber < lines.length; lineNumber += 1) {\nconst line = lines[lineNumber];\nconst parsedLine = parseLine(line);\nconst {\ndepName,\nspecName,\ncurrentValue,\ngit,\ntag,\npath,\nsource,\n}: ParsedLine = parsedLine;\nif (source) {\nregistryUrls.push(source.replace(regEx(/\/*$/), ''));\n}\nif (depName) {\nconst managerData = { lineNumber };\nlet dep: PackageDependency = {\ndepName,\nsharedVariableName: specName,\nskipReason: 'unspecified-version',\n};\nif (currentValue) {\ndep = {\ndepName,\nsharedVariableName: specName,\ndatasource: PodDatasource.id,\ncurrentValue,\nmanagerData,\nregistryUrls,\n};\n} else if (git) {\nif (tag) {\ndep = { ...gitDep(parsedLine), managerData };\n} else {\ndep = {\ndepName,\nsharedVariableName: specName,\nskipReason: 'git-dependency',\n};\n}\n} else if (path) {\ndep = {\ndepName,\nsharedVariableName: specName,\nskipReason: 'path-dependency',\n};\n}\ndeps.push(dep);\n}\n}\nconst res: PackageFileContent = { deps };\nconst lockFile = getSiblingFileName(packageFile, 'Podfile.lock');\nif (await localPathExists(lockFile)) {\nres.lockFiles = [lockFile];\n}\nreturn res;\n}"
"function getAuthJson(): string | null {\nconst authJson: AuthJson = {};\nconst githubHostRule = hostRules.find({\nhostType: 'github',\nurl: 'https:\n});\nconst gitTagsHostRule = hostRules.find({\nhostType: GitTagsDatasource.id,\nurl: 'https:\n});\nconst selectedGithubToken = takePersonalAccessTokenIfPossible(\nisArtifactAuthEnabled(githubHostRule)\n? findGithubToken(githubHostRule)\n: undefined,\nisArtifactAuthEnabled(gitTagsHostRule)\n? findGithubToken(gitTagsHostRule)\n: undefined,\n);\nif (selectedGithubToken) {\nauthJson['github-oauth'] = {\n'github.com': selectedGithubToken,\n};\n}\nfor (const gitlabHostRule of hostRules.findAll({ hostType: 'gitlab' })) {\nif (!isArtifactAuthEnabled(gitlabHostRule)) {\ncontinue;\n}\nif (gitlabHostRule?.token) {\nconst host = coerceString(gitlabHostRule.resolvedHost, 'gitlab.com');\nauthJson['gitlab-token'] = authJson['gitlab-token'] ?? {};\nauthJson['gitlab-token'][host] = gitlabHostRule.token;\nauthJson['gitlab-domains'] = [\nhost,\n...(authJson['gitlab-domains'] ?? []),\n];\n}\n}\nfor (const packagistHostRule of hostRules.findAll({\nhostType: PackagistDatasource.id,\n})) {\nif (!isArtifactAuthEnabled(packagistHostRule)) {\ncontinue;\n}\nconst { resolvedHost, username, password, token } = packagistHostRule;\nif (resolvedHost && username && password) {\nauthJson['http-basic'] = authJson['http-basic'] ?? {};\nauthJson['http-basic'][resolvedHost] = { username, password };\n} else if (resolvedHost && token) {\nauthJson.bearer = authJson.bearer ?? {};\nauthJson.bearer[resolvedHost] = token;\n}\n}\nreturn isEmptyObject(authJson) ? null : JSON.stringify(authJson);\n}"
"export function extractConstraints(\n{ config, require, requireDev }: PackageFile,\n{ pluginApiVersion }: Lockfile,\n): Record<string, string> {\nconst res: Record<string, string> = { composer: '1.*' };\nconst phpVersion = config?.platform.php;\nif (phpVersion) {\nconst major = api.getMajor(phpVersion);\nconst minor = coerceNumber(api.getMinor(phpVersion));\nconst patch = coerceNumber(api.getPatch(phpVersion));\nres.php = `<=${major}.${minor}.${patch}`;\n} else if (require.php) {\nres.php = require.php;\n}\nif (require['composer/composer']) {\nres.composer = require['composer/composer'];\n} else if (requireDev['composer/composer']) {\nres.composer = requireDev['composer/composer'];\n}\nelse if (require.composer) {\nres.composer = require.composer;\n} else if (requireDev.composer) {\nres.composer = requireDev.composer;\n}\nelse if (pluginApiVersion) {\nconst major = api.getMajor(pluginApiVersion);\nconst minor = api.getMinor(pluginApiVersion);\nres.composer = `^${major}.${minor}`;\n}\nelse if (require['composer-runtime-api']) {\nconst major = api.getMajor(require['composer-runtime-api']);\nconst minor = api.getMinor(require['composer-runtime-api']);\nres.composer = `^${major}.${minor}`;\n}\nreturn res;\n}"
"export async function updateArtifacts(\nupdateArtifact: UpdateArtifact,\n): Promise<UpdateArtifactsResult[] | null> {\nconst { packageFileName, updatedDeps, newPackageFileContent, config } =\nupdateArtifact;\nlogger.trace(`conan.updateArtifacts(${packageFileName})`);\nconst { isLockFileMaintenance } = config;\nif (updatedDeps.length === 0 && !isLockFileMaintenance) {\nlogger.trace('No conan.lock dependencies to update');\nreturn null;\n}\nconst lockFileName = await findLocalSiblingOrParent(\npackageFileName,\n'conan.lock',\n);\nif (!lockFileName) {\nlogger.trace('No conan.lock found');\nreturn null;\n}\nconst existingLockFileContent = await readLocalFile(lockFileName);\nif (!existingLockFileContent) {\nlogger.debug(`${lockFileName} read operation failed`);\nreturn null;\n}\ntry {\nawait writeLocalFile(packageFileName, newPackageFileContent);\nlogger.trace(`Updating ${lockFileName}`);\nawait conanLockUpdate(\npackageFileName,\nisLockFileMaintenance,\nconfig.constraints?.conan,\nconfig.constraints?.python,\n);\nconst newLockFileContent = await readLocalFile(lockFileName);\nif (!newLockFileContent) {\nlogger.debug(`New ${lockFileName} read operation failed`);\nreturn null;\n}\nif (existingLockFileContent === newLockFileContent) {\nlogger.trace(`${lockFileName} is unchanged`);\nreturn null;\n}\nlogger.trace(`Returning updated ${lockFileName}`);\nreturn [\n{\nfile: {\ntype: 'addition',\npath: lockFileName,\ncontents: newLockFileContent,\n},\n},\n];\n} catch (err) {\nif (err.message === TEMPORARY_ERROR) {\nthrow err;\n}\nlogger.debug(\n{ err, packageFileName, lockFileName },\n'Lockfile update failed',\n);\nreturn [\n{\nartifactError: {\nlockFile: lockFileName,\nstderr: err.message,\n},\n},\n];\n}\n}"
"export function extractPackageFile(content: string): PackageFileContent | null {\nconst sections = content.split(regEx(/def |\n\[/)).filter(\n(part) =>\npart.includes('python_requires') ||\npart.includes('build_require') ||\npart.includes('require'),\n);\nconst deps: PackageDependency[] = [];\nfor (const section of sections) {\nlet depType = setDepType(section, 'requires');\nconst rawLines = section.split('\n').filter(isNonEmptyString);\nfor (const rawLine of rawLines) {\nif (!isComment(rawLine)) {\ndepType = setDepType(rawLine, depType);\nconst lines = rawLine.split(regEx(/[`'],/));\nfor (const line of lines) {\nconst matches = regex.exec(line.trim());\nif (matches?.groups) {\nlet dep: PackageDependency = {};\nconst depName = matches.groups?.name;\nconst currentValue = matches.groups?.version.trim();\nlet replaceString = `${depName}/${currentValue}`;\nlet userAndChannel = '@_/_';\nif (matches.groups.userChannel) {\nuserAndChannel = matches.groups.userChannel;\nreplaceString = `${depName}/${currentValue}${userAndChannel}`;\nif (!userAndChannel.includes('/')) {\nuserAndChannel = `${userAndChannel}/_`;\n}\n}\nconst packageName = `${depName}/${currentValue}${userAndChannel}`;\ndep = {\n...dep,\ndepName,\npackageName,\ncurrentValue,\nreplaceString,\ndepType,\n};\nif (matches.groups.revision) {\ndep.currentDigest = matches.groups.revision;\ndep.autoReplaceStringTemplate = `{{depName}}/{{newValue}}${userAndChannel}{{#if newDigest}}#{{newDigest}}{{/if}}`;\ndep.replaceString = `${replaceString}#${dep.currentDigest}`;\n}\ndeps.push(dep);\n}\n}\n}\n}\n}\nreturn deps.length ? { deps } : null;\n}"
"function extractDependency(\nkey: string,\nval: ParsedEdnData,\nmetadata: ParsedEdnMetadata,\nmavenRegistries: string[],\ndepType?: string,\n): PackageDependency | null {\nif (!isPlainObject(val)) {\nreturn null;\n}\nconst packageName = getPackageName(key);\nif (!packageName) {\nreturn null;\n}\nconst depName = key;\nconst dep: PackageDependency = {\ndepName,\npackageName,\ncurrentValue: null,\n...metadata.get(val),\n};\nif (depType) {\ndep.depType = depType;\n}\nconst mvnVersion = val['mvn/version'];\nif (isString(mvnVersion)) {\ndep.datasource = ClojureDatasource.id;\ndep.currentValue = mvnVersion;\ndep.packageName = packageName.replace('/', ':');\ndep.registryUrls = [...mavenRegistries];\nreturn dep;\n}\nresolveGitPackageFromEdnVal(dep, val);\nresolveGitPackageFromEdnKey(dep, key);\nif (dep.datasource) {\nconst gitTag = val['git/tag'];\nif (isString(gitTag)) {\ndep.currentValue = gitTag;\n}\nconst gitSha = val['git/sha'] ?? val.sha;\nif (isString(gitSha)) {\ndep.currentDigest = gitSha;\ndep.currentDigestShort = gitSha.slice(0, 7);\n}\nreturn dep;\n}\nreturn null;\n}"
"export function extractPackageFile(content: string): PackageFileContent | null {\nconst parsed = parseDepsEdnFile(content);\nif (!parsed) {\nreturn null;\n}\nconst { data, metadata } = parsed;\nconst deps: PackageDependency[] = [];\nconst registryMap: Record<string, string> = {\nclojars: CLOJARS_REPO,\ncentral: MAVEN_REPO,\n};\nconst mavenRepos = data['mvn/repos'];\nif (isPlainObject(mavenRepos)) {\nfor (const [repoName, repoSpec] of Object.entries(mavenRepos)) {\nif (isString(repoName)) {\nif (isPlainObject(repoSpec) && isString(repoSpec.url)) {\nregistryMap[repoName] = repoSpec.url;\n} else if (isString(repoSpec) && repoSpec === 'nil') {\ndelete registryMap[repoName];\n}\n}\n}\n}\nconst mavenRegistries: string[] = [...Object.values(registryMap)];\ndeps.push(...extractSection(data.deps, metadata, mavenRegistries));\nconst aliases = data.aliases;\nif (isPlainObject(aliases)) {\nfor (const [depType, aliasSection] of Object.entries(aliases)) {\nif (isPlainObject(aliasSection)) {\ndeps.push(\n...extractSection(\naliasSection['extra-deps'],\nmetadata,\nmavenRegistries,\ndepType,\n),\n);\ndeps.push(\n...extractSection(\naliasSection['override-deps'],\nmetadata,\nmavenRegistries,\ndepType,\n),\n);\n}\n}\n}\nreturn { deps };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nextractConfig: ExtractConfig,\n): PackageFileContent | null {\nlogger.debug(`docker-compose.extractPackageFile(${packageFile})`);\nlet config: DockerComposeFile;\ntry {\nconfig = parseSingleYaml(content, {\ncustomSchema: DockerComposeFile,\nremoveTemplates: true,\n});\n} catch (err) {\nlogger.debug(\n{ err, packageFile },\n`Parsing Docker Compose config YAML failed`,\n);\nreturn null;\n}\ntry {\nconst lineMapper = new LineMapper(content, regEx(/^\s*image:/));\nconst services = config.services ?? config;\nconst extensions = config.extensions ?? {};\nconst deps = Object.values(\nservices ||  {},\n)\n.concat(Object.values(extensions))\n.filter((service) => isString(service?.image) && !service?.build)\n.map((service) => {\nconst dep = getDep(service.image, true, extractConfig.registryAliases);\nconst lineNumber = lineMapper.pluckLineNumber(service.image);\nif (!lineNumber) {\nreturn null;\n}\nreturn dep;\n})\n.filter(isTruthy);\nlogger.trace({ deps }, 'Docker Compose image');\nreturn { deps };\n} catch (err)  {\nlogger.debug({ packageFile, err }, 'Error extracting Docker Compose file');\nreturn null;\n}\n}"
"function processDepForAutoReplace(\ndep: PackageDependency,\nlineNumberRanges: number[][],\nlines: string[],\nlinefeed: string,\n): void {\nconst lineNumberRangesToReplace: number[][] = [];\nfor (const lineNumberRange of lineNumberRanges) {\nfor (const lineNumber of lineNumberRange) {\nif (\n(isString(dep.currentValue) &&\nlines[lineNumber].includes(dep.currentValue)) ||\n(isString(dep.currentDigest) &&\nlines[lineNumber].includes(dep.currentDigest))\n) {\nlineNumberRangesToReplace.push(lineNumberRange);\n}\n}\n}\nlineNumberRangesToReplace.sort((a, b) => {\nreturn a[0] - b[0];\n});\nconst minLine = lineNumberRangesToReplace[0]?.[0];\nconst maxLine =\nlineNumberRangesToReplace[lineNumberRangesToReplace.length - 1]?.[1];\nif (\nlineNumberRanges.length === 1 ||\nminLine === undefined ||\nmaxLine === undefined\n) {\nreturn;\n}\nconst unfoldedLineNumbers = Array.from(\n{ length: maxLine - minLine + 1 },\n(_v, k) => k + minLine,\n);\ndep.replaceString = unfoldedLineNumbers\n.map((lineNumber) => lines[lineNumber])\n.join(linefeed);\nif (!dep.currentDigest) {\ndep.replaceString += linefeed;\n}\ndep.autoReplaceStringTemplate = getAutoReplaceTemplate(dep);\n}"
"export function splitImageParts(currentFrom: string): PackageDependency {\nlet isVariable = false;\nlet cleanedCurrentFrom = currentFrom;\nif (cleanedCurrentFrom?.includes(variableMarker)) {\nconst defaultValueRegex = regEx(/^\${.+?:-`?(?<value>.*?)`?}$/);\nconst defaultValueMatch =\ndefaultValueRegex.exec(cleanedCurrentFrom)?.groups;\nif (defaultValueMatch?.value) {\nisVariable = true;\ncleanedCurrentFrom = defaultValueMatch.value;\n}\nif (cleanedCurrentFrom?.includes(variableMarker)) {\nreturn {\nskipReason: 'contains-variable',\n};\n}\n}\nconst [currentDepTag, currentDigest] = cleanedCurrentFrom.split('@');\nconst depTagSplit = currentDepTag.split(':');\nlet depName: string;\nlet currentValue: string | undefined;\nif (\ndepTagSplit.length === 1 ||\ndepTagSplit[depTagSplit.length - 1].includes('/')\n) {\ndepName = currentDepTag;\n} else {\ncurrentValue = depTagSplit.pop();\ndepName = depTagSplit.join(':');\n}\nconst dep: PackageDependency = {\ndepName,\npackageName: depName,\ncurrentValue,\ncurrentDigest,\n};\nif (isVariable) {\ndep.replaceString = cleanedCurrentFrom;\nif (!dep.currentValue) {\ndelete dep.currentValue;\n}\nif (!dep.currentDigest) {\ndelete dep.currentDigest;\n}\n}\nreturn dep;\n}"
"function extractFleetHelmBlock(doc: FleetHelmBlock): PackageDependency {\nconst dep: PackageDependency = {\ndepType: 'fleet',\ndatasource: HelmDatasource.id,\n};\nif (!doc.chart) {\nreturn {\n...dep,\nskipReason: 'missing-depname',\n};\n}\nif (isOCIRegistry(doc.chart)) {\nconst dockerDep = getDep(\n`${removeOCIPrefix(doc.chart)}:${doc.version}`,\nfalse,\n);\nreturn {\n...dockerDep,\ndepType: 'fleet',\npinDigests: false,\n};\n}\ndep.depName = doc.chart;\ndep.packageName = doc.chart;\nif (!doc.repo) {\nif (checkIfStringIsPath(doc.chart)) {\nreturn {\n...dep,\nskipReason: 'local-chart',\n};\n}\nreturn {\n...dep,\nskipReason: 'no-repository',\n};\n}\ndep.registryUrls = [doc.repo];\nconst currentValue = doc.version;\nif (!doc.version) {\nreturn {\n...dep,\nskipReason: 'unspecified-version',\n};\n}\nreturn {\n...dep,\ncurrentValue,\n};\n}"
"export async function updateArtifacts({\npackageFileName,\nupdatedDeps,\nconfig,\n}: UpdateArtifact<FluxManagerData>): Promise<UpdateArtifactsResult[] | null> {\nconst systemDep = updatedDeps[0];\nif (!isSystemManifest(packageFileName) || !systemDep?.newVersion) {\nreturn null;\n}\nconst existingFileContent = await readLocalFile(packageFileName);\ntry {\nlogger.debug(`Updating Flux system manifests`);\nconst args: string[] = ['--export'];\nif (systemDep.managerData?.components) {\nargs.push('--components', quote(systemDep.managerData.components));\n}\nconst cmd = `flux install ${args.join(' ')} > ${quote(packageFileName)}`;\nconst execOptions: ExecOptions = {\ndocker: {},\ntoolConstraints: [\n{\ntoolName: 'flux',\nconstraint: updatedDeps[0].newVersion,\n},\n],\n};\nconst result = await exec(cmd, execOptions);\nconst newFileContent = await readLocalFile(packageFileName);\nif (!newFileContent) {\nlogger.debug('Cannot read new flux file content');\nreturn [\n{\nartifactError: {\nlockFile: packageFileName,\nstderr: result.stderr,\n},\n},\n];\n}\nif (newFileContent === existingFileContent) {\nlogger.debug('Flux contents are unchanged');\nreturn null;\n}\nreturn [\n{\nfile: {\ntype: 'addition',\npath: packageFileName,\ncontents: newFileContent,\n},\n},\n];\n} catch (err) {\nlogger.debug({ err }, 'Error generating new Flux system manifests');\nreturn [\n{\nartifactError: {\nlockFile: packageFileName,\nstderr: err.message,\n},\n},\n];\n}\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile<FluxManagerData>[] | null> {\nconst manifests: FluxManifest[] = [];\nconst results: PackageFile<FluxManagerData>[] = [];\nfor (const file of packageFiles) {\nconst content = await readLocalFile(file, 'utf8');\nconst manifest = readManifest(content!, file);\nif (manifest) {\nmanifests.push(manifest);\n}\n}\nconst helmRepositories = collectHelmRepos(manifests);\nfor (const manifest of manifests) {\nlet deps: PackageDependency[] | null = null;\nswitch (manifest.kind) {\ncase 'system':\ndeps = resolveSystemManifest(manifest);\nbreak;\ncase 'resource': {\ndeps = resolveResourceManifest(\nmanifest,\nhelmRepositories,\nconfig.registryAliases,\n);\nbreak;\n}\n}\nif (deps?.length) {\nresults.push({\npackageFile: manifest.file,\ndeps,\n});\n}\n}\nreturn results.length ? results : null;\n}"
"export default async function extractPackageFile(\n_content: string,\npackageFile: string,\n_config: ExtractConfig,\n): Promise<PackageFileContent | null> {\nconst localDir = GlobalConfig.get('localDir');\nconst git = Git(localDir, simpleGitConfig());\nconst gitModulesPath = upath.join(localDir, packageFile);\nconst depNames = await getModules(git, gitModulesPath);\nif (!depNames.length) {\nreturn null;\n}\nconst deps = [];\nfor (const { name, path } of depNames) {\ntry {\nconst [currentDigest] = (\nawait git.subModule(['status', '--cached', path])\n)\n.trim()\n.replace(regEx(/^[-+]/), '')\n.split(regEx(/\s/));\nconst subModuleUrl = await getUrl(git, gitModulesPath, name);\nconst httpSubModuleUrl = getHttpUrl(subModuleUrl);\nconst branch = await getBranch(git, gitModulesPath, name);\ndeps.push({\ndepName: path,\npackageName: httpSubModuleUrl,\ncurrentValue: branch ?? undefined,\ncurrentDigest,\n...(semVerVersioning.api.isVersion(branch)\n? { versioning: semVerVersioning.id }\n: {}),\n});\n} catch (err)  {\nlogger.warn(\n{ err, packageFile },\n'Error mapping git submodules during extraction',\n);\n}\n}\nreturn { deps, datasource: GitRefsDatasource.id };\n}"
"function extractWithRegex(\ncontent: string,\nconfig: ExtractConfig,\n): PackageDependency[] {\nconst customRegistryUrlsPackageDependency =\ndetectCustomGitHubRegistryUrlsForActions();\nlogger.trace('github-actions.extractWithRegex()');\nconst deps: PackageDependency[] = [];\nfor (const line of content.split(newlineRegex)) {\nif (line.trim().startsWith('#')) {\ncontinue;\n}\nconst dockerMatch = dockerActionRe.exec(line);\nif (dockerMatch) {\nconst [, currentFrom] = dockerMatch;\nconst dep = getDep(currentFrom, true, config.registryAliases);\ndep.depType = 'docker';\ndeps.push(dep);\ncontinue;\n}\nconst tagMatch = actionRe.exec(line);\nif (tagMatch?.groups) {\nconst {\ndepName,\npackageName,\ncurrentValue,\npath = '',\ntag,\nreplaceString,\nregistryUrl = '',\ncommentWhiteSpaces = ' ',\n} = tagMatch.groups;\nlet quotes = '';\nif (replaceString.includes(`'`)) {\nquotes = `'`;\n}\nif (replaceString.includes('`')) {\nquotes = '`';\n}\nconst dep: PackageDependency = {\ndepName,\n...(packageName !== depName && { packageName }),\ncommitMessageTopic: '{{{depName}}} action',\ndatasource: GithubTagsDatasource.id,\nversioning: dockerVersioning.id,\ndepType: 'action',\nreplaceString,\nautoReplaceStringTemplate: `${quotes}{{depName}}${path}@{{#if newDigest}}{{newDigest}}${quotes}{{#if newValue}}${commentWhiteSpaces}# {{newValue}}{{/if}}{{/if}}{{#unless newDigest}}{{newValue}}${quotes}{{/unless}}`,\n...(registryUrl\n? detectDatasource(registryUrl)\n: customRegistryUrlsPackageDependency),\n};\nif (shaRe.test(currentValue)) {\ndep.currentValue = tag;\ndep.currentDigest = currentValue;\n} else if (shaShortRe.test(currentValue)) {\ndep.currentValue = tag;\ndep.currentDigestShort = currentValue;\n} else {\ndep.currentValue = currentValue;\n}\ndeps.push(dep);\n}\n}\nreturn deps;\n}"
"function extractWithYAMLParser(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageDependency[] {\nlogger.trace('github-actions.extractWithYAMLParser()');\nconst deps: PackageDependency[] = [];\nconst obj = withMeta({ packageFile }, () => Workflow.parse(content));\nif (!obj) {\nreturn deps;\n}\nif ('runs' in obj && obj.runs.steps) {\nextractSteps(obj.runs.steps, deps);\n} else if ('jobs' in obj) {\nfor (const job of Object.values(obj.jobs)) {\nif (job.container) {\nconst dep = getDep(job.container, true, config.registryAliases);\nif (dep) {\ndep.depType = 'container';\ndeps.push(dep);\n}\n}\nfor (const service of job.services) {\nconst dep = getDep(service, true, config.registryAliases);\nif (dep) {\ndep.depType = 'service';\ndeps.push(dep);\n}\n}\nfor (const runner of job['runs-on']) {\nconst dep = extractRunner(runner);\nif (dep) {\ndeps.push(dep);\n}\n}\nextractSteps(job.steps, deps);\n}\n}\nreturn deps;\n}"
"function extractDepFromIncludeComponent(\ncomponent: string,\nregistryAliases?: Record<string, string>,\n): PackageDependency | null {\nlet componentUrl = component;\nif (registryAliases) {\nfor (const key in registryAliases) {\ncomponentUrl = componentUrl.replace(key, registryAliases[key]);\n}\n}\nconst componentReference = componentReferenceRegex.exec(componentUrl)?.groups;\nif (!componentReference) {\nlogger.debug(\n{ componentReference: componentUrl },\n'Ignoring malformed component reference',\n);\nreturn null;\n}\nconst projectPathParts = componentReference.projectPath.split('/');\nif (projectPathParts.length < 2) {\nlogger.debug(\n{ componentReference: componentUrl },\n'Ignoring component reference with incomplete project path',\n);\nreturn null;\n}\nconst dep: PackageDependency = {\ndatasource: GitlabTagsDatasource.id,\ndepName: componentReference.projectPath,\ndepType: 'repository',\ncurrentValue: componentReference.specificVersion,\nregistryUrls: [`https:\nversioning: semverPartialId,\n};\nif (dep.currentValue === componentReferenceLatestVersion) {\nlogger.debug(\n{ componentVersion: dep.currentValue },\n'Ignoring component version',\n);\ndep.skipReason = 'unsupported-version';\n}\nreturn dep;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFileContent | null {\nconst deps: PackageDependency[] = [];\ntry {\nconst docs = parseYaml(content, { uniqueKeys: false });\nfor (const doc of docs) {\nconst topLevel = Job.parse(doc);\nconst jobs = Jobs.parse(doc);\nfor (const job of [topLevel, ...jobs]) {\nconst { image, services } = job;\nif (image) {\nconst dep = getGitlabDep(image.value, config.registryAliases);\ndep.depType = image.type;\ndeps.push(dep);\n}\nfor (const service of services) {\nconst dep = getGitlabDep(service, config.registryAliases);\ndep.depType = 'service-image';\ndeps.push(dep);\n}\n}\nconst includedComponents = GitlabDocument.parse(doc);\nfor (const includedComponent of includedComponents) {\nconst dep = extractDepFromIncludeComponent(\nincludedComponent,\nconfig.registryAliases,\n);\nif (dep) {\ndeps.push(dep);\n}\n}\n}\n} catch (err)  {\nif (err.stack?.startsWith('YAMLException:')) {\nlogger.debug(\n{ err, packageFile },\n'YAML exception extracting GitLab CI includes',\n);\n} else {\nlogger.debug(\n{ err, packageFile },\n'Error extracting GitLab CI dependencies',\n);\n}\n}\nreturn deps.length ? { deps } : null;\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile[] | null> {\nconst filesToExamine = [...packageFiles];\nconst seen = new Set<string>(packageFiles);\nconst results: PackageFile[] = [];\nwhile (filesToExamine.length > 0) {\nconst file = filesToExamine.pop()!;\nconst content = await readLocalFile(file, 'utf8');\nif (!content) {\nlogger.debug(\n{ packageFile: file },\n`Empty or non existent gitlabci file`,\n);\ncontinue;\n}\nconst { val: docs, err } = Result.wrap(() =>\nparseYaml(content, { uniqueKeys: false }),\n).unwrap();\nif (err) {\nlogger.debug(\n{ err, packageFile: file },\n'Error extracting GitLab CI dependencies',\n);\ncontinue;\n}\nconst localIncludes = MultiDocumentLocalIncludes.parse(docs);\nfor (const file of localIncludes) {\nif (!seen.has(file)) {\nseen.add(file);\nfilesToExamine.push(file);\n}\n}\nconst result = extractPackageFile(content, file, config);\nif (result !== null) {\nresults.push({\npackageFile: file,\ndeps: result.deps,\n});\n}\n}\nlogger.trace(\n{ packageFiles, files: filesToExamine.entries() },\n'extracted all GitLab CI files',\n);\nif (!results.length) {\nreturn null;\n}\nreturn results;\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n): Promise<PackageFileContent | null> {\nconst result = GleamToml.safeParse(content);\nif (!result.success) {\nlogger.debug(\n{ err: result.error, packageFile },\n'Error parsing Gleam package file content',\n);\nreturn null;\n}\nconst deps = extractGleamTomlDeps(result.data);\nif (!deps.length) {\nlogger.debug(`No dependencies found in Gleam package file ${packageFile}`);\nreturn null;\n}\nconst packageFileContent: PackageFileContent = { deps };\nconst lockFileName = getSiblingFileName(packageFile, 'manifest.toml');\nconst lockFileExists = await localPathExists(lockFileName);\nif (!lockFileExists) {\nlogger.debug(`Lock file ${lockFileName} does not exist.`);\nreturn packageFileContent;\n}\nconst versionsByPackage = await extractLockFileVersions(lockFileName);\nif (!versionsByPackage) {\nreturn packageFileContent;\n}\npackageFileContent.lockFiles = [lockFileName];\nfor (const dep of packageFileContent.deps) {\nconst packageName = dep.depName!;\nconst versions = coerceArray(versionsByPackage.get(packageName));\nconst lockedVersion = versioning.getSatisfyingVersion(\nversions,\ndep.currentValue!,\n);\nif (lockedVersion) {\ndep.lockedVersion = lockedVersion;\n} else {\nlogger.debug(\n`No locked version found for package ${dep.depName} in the range of ${dep.currentValue}.`,\n);\n}\n}\nreturn packageFileContent;\n}"
"export function getExtraDeps(\ngoModBefore: string,\ngoModAfter: string,\nexcludeDeps: string[],\n): ExtraDep[] {\nconst result: ExtraDep[] = [];\nconst diff = diffLines(goModBefore, goModAfter, {\nnewlineIsToken: true,\n});\nconst addDeps: Record<string, string> = {};\nconst rmDeps: Record<string, string> = {};\nfor (const { added, removed, value } of diff) {\nif (!added && !removed) {\ncontinue;\n}\nconst res = parseLine(value);\nif (!res) {\ncontinue;\n}\nconst { depName, depType, currentValue } = res;\nif (!depName || !currentValue) {\ncontinue;\n}\nlet expandedDepName = depName;\nif (depType === 'toolchain') {\nexpandedDepName = `${depName} (${depType})`;\n}\nif (added) {\naddDeps[expandedDepName] = currentValue;\n} else {\nrmDeps[expandedDepName] = currentValue;\n}\n}\nfor (const [depName, currentValue] of Object.entries(rmDeps)) {\nif (excludeDeps.includes(depName)) {\ncontinue;\n}\nconst newValue = addDeps[depName];\nif (newValue) {\nresult.push({\ndepName,\ncurrentValue,\nnewValue,\n});\n}\n}\nreturn result;\n}"
"export function getExtraDepsNotice(\ngoModBefore: string | null,\ngoModAfter: string | null,\nexcludeDeps: string[],\n): string | null {\nif (!goModBefore || !goModAfter) {\nreturn null;\n}\nconst extraDeps = getExtraDeps(goModBefore, goModAfter, excludeDeps);\nif (extraDeps.length === 0) {\nreturn null;\n}\nconst noticeLines: string[] = [\n'In order to perform the update(s) described in the table above, Renovate ran the `go get` command, which resulted in the following additional change(s):',\n'\n',\n];\nconst goUpdated = extraDeps.some(({ depName }) => depName === 'go');\nconst toolchainUpdated = extraDeps.some(\n({ depName }) => depName === 'go (toolchain)',\n);\nconst otherDepsCount =\nextraDeps.length - (goUpdated ? 1 : 0) - (toolchainUpdated ? 1 : 0);\nif (otherDepsCount === 1) {\nnoticeLines.push(`- ${otherDepsCount} additional dependency was updated`);\n} else if (otherDepsCount > 1) {\nnoticeLines.push(\n`- ${otherDepsCount} additional dependencies were updated`,\n);\n}\nif (goUpdated) {\nnoticeLines.push(\n'- The `go` directive was updated for compatibility reasons',\n);\n}\nnoticeLines.push('\n');\nnoticeLines.push('Details:');\nnoticeLines.push('\n');\nnoticeLines.push(extraDepsTable(extraDeps));\nreturn noticeLines.join('\n');\n}"
"function getUpdateImportPathCmds(\nupdatedDeps: PackageDependency[],\n{ constraints }: UpdateArtifactsConfig,\n): string[] {\nconst invalidMajorDeps = updatedDeps.filter(\n({ newVersion }) => !valid(newVersion),\n);\nif (invalidMajorDeps.length > 0) {\ninvalidMajorDeps.forEach(({ depName }) =>\nlogger.warn(\n{ depName },\n'Ignoring dependency: Could not get major version',\n),\n);\n}\nconst updateImportCommands = updatedDeps\n.filter(\n({ newVersion }) =>\nvalid(newVersion) && !newVersion!.endsWith('+incompatible'),\n)\n.map(({ depName, newVersion }) => ({\ndepName: depName!,\nnewMajor: major(newVersion!),\n}))\n.filter(\n({ depName, newMajor }) =>\ndepName.startsWith('gopkg.in/') || newMajor > 1,\n)\n.map(\n({ depName, newMajor }) =>\n`mod upgrade --mod-name=${depName} -t=${newMajor}`,\n);\nif (updateImportCommands.length > 0) {\nlet installMarwanModArgs =\n'install github.com/marwan-at-work/mod/cmd/mod@latest';\nconst gomodModCompatibility = constraints?.gomodMod;\nif (gomodModCompatibility) {\nif (\ngomodModCompatibility.startsWith('v') &&\nisValid(gomodModCompatibility.replace(regEx(/^v/), ''))\n) {\ninstallMarwanModArgs = installMarwanModArgs.replace(\nregEx(/@latest$/),\n`@${gomodModCompatibility}`,\n);\n} else {\nlogger.debug(\n{ gomodModCompatibility },\n'marwan-at-work/mod compatibility range is not valid - skipping',\n);\n}\n} else {\nlogger.debug(\n'No marwan-at-work/mod compatibility range found - installing marwan-at-work/mod latest',\n);\n}\nupdateImportCommands.unshift(`go ${installMarwanModArgs}`);\n}\nreturn updateImportCommands;\n}"
"export function extractPackageFile(content: string): PackageFileContent | null {\nconst deps: PackageDependency[] = [];\nconst tools: PackageDependency[] = [];\nlet inExcludeBlock = false;\nconst lines = content.split(newlineRegex);\nfor (let lineNumber = 0; lineNumber < lines.length; lineNumber += 1) {\nconst line = lines[lineNumber];\nconst dep = parseLine(line);\nif (inExcludeBlock) {\nif (endBlockRegex.test(line)) {\ninExcludeBlock = false;\n}\ncontinue;\n}\nif (!dep) {\nif (excludeBlockStartRegex.test(line)) {\ninExcludeBlock = true;\n}\ncontinue;\n}\nif (dep.depType === 'tool') {\ntools.push(dep);\ncontinue;\n}\ndep.managerData ??= {};\ndep.managerData.lineNumber = lineNumber;\ndeps.push(dep);\n}\nfor (const tool of tools) {\nconst match = findMatchingModule(tool, deps);\nif (match?.depType === 'indirect') {\ndelete match.enabled;\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"async function buildUpdateVerificationMetadataCmd(\nverificationMetadataFile: string | undefined,\nbaseCmd: string,\n): Promise<string | null> {\nif (!verificationMetadataFile) {\nreturn null;\n}\nconst verificationMetadata = await readLocalFile(verificationMetadataFile);\nconst verifiesChecksums = verificationMetadata?.includes(\n'<verify-metadata>true</verify-metadata>',\n);\nconst verifiesSignatures = verificationMetadata?.includes(\n'<verify-signatures>true</verify-signatures>',\n);\nconst hashTypes = ['sha256', 'sha512'].filter((type) =>\nverificationMetadata?.includes(`<${type} `),\n);\nif (verifiesChecksums || hashTypes.length) {\nlogger.debug(\n'Dependency metadata verification enabled or checksums present - generating checksums',\n);\n}\nif ((verifiesChecksums || verifiesSignatures) && !hashTypes.length) {\nhashTypes.push('sha256');\n}\nif (verifiesSignatures) {\nlogger.debug(\n'Dependency signature verification enabled - generating PGP signatures',\n);\nhashTypes.push('pgp');\n}\nif (!hashTypes.length) {\nreturn null;\n}\nreturn `${baseCmd} --write-verification-metadata ${hashTypes.join(',')} dependencies`;\n}"
"export function matchesContentDescriptor(\ndep: PackageDependency<GradleManagerData>,\ncontentDescriptors?: ContentDescriptorSpec[],\n): boolean {\nconst [groupId, artifactId] = (dep.packageName ?? dep.depName!).split(':');\nlet hasIncludes = false;\nlet hasExcludes = false;\nlet matchesInclude = false;\nlet matchesExclude = false;\nfor (const content of coerceArray(contentDescriptors)) {\nconst {\nmode,\nmatcher,\ngroupId: contentGroupId,\nartifactId: contentArtifactId,\nversion: contentVersion,\n} = content;\nlet groupMatch = false;\nif (matcher === 'regex') {\ngroupMatch = regEx(contentGroupId).test(groupId);\n} else if (matcher === 'subgroup') {\ngroupMatch =\ngroupId === contentGroupId || `${groupId}.`.startsWith(contentGroupId);\n} else {\ngroupMatch = groupId === contentGroupId;\n}\nlet artifactMatch = true;\nif (groupMatch && contentArtifactId) {\nif (matcher === 'regex') {\nartifactMatch = regEx(contentArtifactId).test(artifactId);\n} else {\nartifactMatch = artifactId === contentArtifactId;\n}\n}\nlet versionMatch = true;\nif (groupMatch && artifactMatch && contentVersion && dep.currentValue) {\nif (matcher === 'regex') {\nversionMatch = regEx(contentVersion).test(dep.currentValue);\n} else {\nversionMatch = gradleVersioning.matches(\ndep.currentValue,\ncontentVersion,\n);\n}\n}\nconst isMatch = groupMatch && artifactMatch && versionMatch;\nif (mode === 'include') {\nhasIncludes = true;\nif (isMatch) {\nmatchesInclude = true;\n}\n} else if (mode === 'exclude') {\nhasExcludes = true;\nif (isMatch) {\nmatchesExclude = true;\n}\n}\n}\nif (hasIncludes && hasExcludes) {\nreturn matchesInclude && !matchesExclude;\n} else if (hasIncludes) {\nreturn matchesInclude;\n} else if (hasExcludes) {\nreturn !matchesExclude;\n}\nreturn true;\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile[] | null> {\nconst packageFilesByName: Record<string, PackageFile> = {};\nconst packageRegistries: PackageRegistry[] = [];\nconst extractedDeps: PackageDependency<GradleManagerData>[] = [];\nconst kotlinSourceFiles = packageFiles.filter(isKotlinSourceFile);\nconst gradleFiles = reorderFiles(\npackageFiles.filter((e) => !kotlinSourceFiles.includes(e)),\n);\nawait parsePackageFiles(\nconfig,\n[...kotlinSourceFiles, ...kotlinSourceFiles, ...gradleFiles],\nextractedDeps,\npackageFilesByName,\npackageRegistries,\n);\nif (!extractedDeps.length) {\nreturn null;\n}\nfor (const dep of extractedDeps) {\ndep.fileReplacePosition = dep?.managerData?.fileReplacePosition;\nconst key = dep.managerData?.packageFile;\nif (key) {\nlet pkgFile: PackageFile = packageFilesByName[key];\nif (!pkgFile) {\npkgFile = {\npackageFile: key,\ndatasource: mavenDatasource,\ndeps: [],\n};\n}\ndep.datasource ??= mavenDatasource;\nif (dep.datasource === mavenDatasource) {\ndep.registryUrls = getRegistryUrlsForDep(packageRegistries, dep);\ndep.depType ??=\nkey.startsWith('buildSrc') && !kotlinSourceFiles.length\n? 'devDependencies'\n: 'dependencies';\n}\nconst depAlreadyInPkgFile = pkgFile.deps.some(\n(item) =>\nitem.depName === dep.depName &&\nitem.managerData?.fileReplacePosition ===\ndep.managerData?.fileReplacePosition,\n);\nif (!depAlreadyInPkgFile) {\npkgFile.deps.push(dep);\n}\npackageFilesByName[key] = pkgFile;\n} else {\nlogger.debug({ dep }, `Failed to process Gradle dependency`);\n}\n}\nreturn Object.values(packageFilesByName);\n}"
"export function parseGradle(\ninput: string,\ninitVars: PackageVariables = {},\npackageFile = '',\nfileContents: Record<string, string | null> = {},\nrecursionDepth = 0,\n): ParseGradleResult {\nlet vars: PackageVariables = { ...initVars };\nconst deps: PackageDependency<GradleManagerData>[] = [];\nconst urls: PackageRegistry[] = [];\nconst query = q.tree<Ctx>({\ntype: 'root-tree',\nsearch: q.alt<Ctx>(\nqKotlinImport,\nqAssignments,\nqKotlinMultiObjectVarAssignment,\nqDependencies,\nqPlugins,\nqRegistryUrls,\nqVersionCatalogs,\nqLongFormDep,\nqApplyFrom,\n),\n});\nconst parsedResult = groovy.query(input, query, {\n...ctx,\npackageFile,\nfileContents,\nrecursionDepth,\nglobalVars: vars,\n});\nif (parsedResult) {\ndeps.push(...parsedResult.deps);\nvars = { ...vars, ...parsedResult.globalVars };\nurls.push(...parsedResult.registryUrls);\n}\nreturn { deps, urls, vars };\n}"
"export async function updateBuildFile(\nlocalGradleDir: string,\nwrapperProperties: Record<string, string | undefined | null>,\n): Promise<string> {\nlet buildFileName = upath.join(localGradleDir, 'build.gradle');\nif (!(await localPathExists(buildFileName))) {\nbuildFileName = upath.join(localGradleDir, 'build.gradle.kts');\n}\nconst buildFileContent = await readLocalFile(buildFileName, 'utf8');\nif (!buildFileContent) {\nlogger.debug('build.gradle or build.gradle.kts not found');\nreturn buildFileName;\n}\nlet buildFileUpdated = buildFileContent;\nfor (const [propertyName, newValue] of Object.entries(wrapperProperties)) {\nif (!newValue) {\ncontinue;\n}\nconst query = q.tree({\ntype: 'wrapped-tree',\nmaxDepth: 1,\nsearch: q\n.sym<Ctx>(propertyName)\n.op('=')\n.str((ctx, { value, offset }) => {\nbuildFileUpdated = replaceAt(\nbuildFileUpdated,\noffset,\nvalue,\nnewValue,\n);\nreturn ctx;\n}),\n});\ngroovy.query(buildFileUpdated, query, []);\n}\nawait writeLocalFile(buildFileName, buildFileUpdated);\nreturn buildFileName;\n}"
"export function findExtents(indent: number, content: string): number {\nlet blockIdx = 0;\nlet mode: 'finding-newline' | 'finding-indention' = 'finding-newline';\nfor (;;) {\nif (mode === 'finding-newline') {\nwhile (content[blockIdx++] !== '\n') {\nif (blockIdx >= content.length) {\nbreak;\n}\n}\nif (blockIdx >= content.length) {\nreturn content.length;\n}\nmode = 'finding-indention';\n} else {\nlet thisIndent = 0;\nfor (;;) {\nif ([' ', '\t'].includes(content[blockIdx])) {\nthisIndent += 1;\nblockIdx++;\nif (blockIdx >= content.length) {\nreturn content.length;\n}\ncontinue;\n}\nmode = 'finding-newline';\nblockIdx++;\nbreak;\n}\nif (thisIndent < indent) {\nif (content.slice(blockIdx - 1, blockIdx + 1) === '--') {\nmode = 'finding-newline';\ncontinue;\n}\nfor (;;) {\nif (content[blockIdx--] === '\n') {\nbreak;\n}\n}\nreturn blockIdx + 1;\n}\nmode = 'finding-newline';\n}\n}\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFileContent | null {\nlet deps = [];\nlet doc: any;\ntry {\ndoc = parseSingleYaml(content);\n} catch {\nlogger.debug({ packageFile }, `Failed to parse helm requirements.yaml`);\nreturn null;\n}\nif (!(doc && isArray(doc.dependencies))) {\nlogger.debug({ packageFile }, `requirements.yaml has no dependencies`);\nreturn null;\n}\ndeps = doc.dependencies.map((dep: Record<string, any>) => {\nlet currentValue: string | undefined;\nswitch (typeof dep.version) {\ncase 'number':\ncurrentValue = String(dep.version);\nbreak;\ncase 'string':\ncurrentValue = dep.version;\n}\nconst res: PackageDependency = {\ndepName: dep.name,\ncurrentValue,\n};\nif (!res.depName) {\nres.skipReason = 'invalid-name';\nreturn res;\n}\nif (!res.currentValue) {\nres.skipReason = 'invalid-version';\nreturn res;\n}\nif (!dep.repository) {\nres.skipReason = 'no-repository';\nreturn res;\n}\nres.registryUrls = [dep.repository];\nif (dep.repository.startsWith('@') || dep.repository.startsWith('alias:')) {\nconst repoWithPrefixRemoved = dep.repository.slice(\ndep.repository[0] === '@' ? 1 : 6,\n);\nconst alias = config.registryAliases?.[repoWithPrefixRemoved];\nif (alias) {\nres.registryUrls = [alias];\nreturn res;\n}\nres.skipReason = 'placeholder-url';\n} else {\ntry {\nconst url = new URL(dep.repository);\nif (url.protocol === 'file:') {\nres.skipReason = 'local-dependency';\n}\n} catch (err) {\nlogger.debug(\n{ err, packageFile, url: dep.repository },\n'Error parsing url',\n);\nres.skipReason = 'invalid-url';\n}\n}\nreturn res;\n});\nconst res = {\ndeps,\ndatasource: HelmDatasource.id,\n};\nreturn res;\n}"
"function createDep(\nkey: string,\ndoc: HelmsmanDocument,\n): PackageDependency | null {\nconst dep: PackageDependency = {\ndepName: key,\ndatasource: HelmDatasource.id,\n};\nconst anApp = doc.apps[key];\nif (!anApp) {\nreturn null;\n}\nif (!anApp.version) {\ndep.skipReason = 'unspecified-version';\nreturn dep;\n}\ndep.currentValue = anApp.version;\nif (isOCIRegistry(anApp.chart)) {\ndep.datasource = DockerDatasource.id;\ndep.packageName = removeOCIPrefix(anApp.chart!);\nreturn dep;\n}\nconst regexResult = anApp.chart ? chartRegex.exec(anApp.chart) : null;\nif (!regexResult?.groups) {\ndep.skipReason = 'invalid-url';\nreturn dep;\n}\nif (!isNonEmptyString(regexResult.groups.packageName)) {\ndep.skipReason = 'invalid-name';\nreturn dep;\n}\ndep.packageName = regexResult.groups.packageName;\nconst registryUrl = doc.helmRepos[regexResult.groups.registryRef];\nif (!isNonEmptyString(registryUrl)) {\ndep.skipReason = 'no-repository';\nreturn dep;\n}\ndep.registryUrls = [registryUrl];\nreturn dep;\n}"
"async function helmCommands(\nexecOptions: ExecOptions,\nmanifestPath: string,\nrepositories: Repository[],\n): Promise<void> {\nconst cmd: string[] = [];\nconst registries: RepositoryRule[] = repositories\n.filter(isOCIRegistry)\n.map((value) => {\nreturn {\n...value,\nrepository: removeOCIPrefix(value.repository),\nhostRule: hostRules.find({\nurl: value.repository.replace('oci:\nhostType: DockerDatasource.id,\n}),\n};\n});\nawait pMap(registries, async (value) => {\nconst loginCmd = await generateLoginCmd(value);\nif (loginCmd) {\ncmd.push(loginCmd);\n}\n});\nconst classicRepositories: RepositoryRule[] = repositories\n.filter((repository) => !isOCIRegistry(repository))\n.map((value) => {\nreturn {\n...value,\nhostRule: hostRules.find({\nurl: value.repository,\nhostType: HelmDatasource.id,\n}),\n};\n});\nclassicRepositories.forEach((value) => {\nconst { username, password } = value.hostRule;\nconst parameters = [`${quote(value.repository)}`, `--force-update`];\nconst isPrivateRepo = username && password;\nif (isPrivateRepo) {\nparameters.push(`--username ${quote(username)}`);\nparameters.push(`--password ${quote(password)}`);\n}\ncmd.push(`helm repo add ${quote(value.name)} ${parameters.join(' ')}`);\n});\ncmd.push(`helm dependency update ${quote(getParentDir(manifestPath))}`);\nawait exec(cmd, execOptions);\n}"
"async function getUpdateResult(\npackageFileName: string,\n): Promise<UpdateArtifactsResult[]> {\nconst hermitFolder = `${upath.dirname(packageFileName)}/`;\nconst hermitChanges = await getRepoStatus(hermitFolder);\nlogger.debug(\n{ hermitChanges, hermitFolder },\n`hermit changes after package update`,\n);\nconst added = await p.map(\n[...hermitChanges.created, ...hermitChanges.not_added],\nasync (path: string): Promise<UpdateArtifactsResult> => {\nconst contents = await getContent(path);\nreturn getAddResult(path, contents);\n},\n);\nconst deleted = hermitChanges.deleted.map(getDeleteResult);\nconst modified = await p.map(\nhermitChanges.modified,\nasync (path: string): Promise<UpdateArtifactsResult[]> => {\nconst contents = await getContent(path);\nreturn [\ngetDeleteResult(path),\ngetAddResult(path, contents),\n];\n},\n);\nconst renamed = await p.map(\nhermitChanges.renamed,\nasync (renamed): Promise<UpdateArtifactsResult[]> => {\nconst from = renamed.from;\nconst to = renamed.to;\nconst toContents = await getContent(to);\nreturn [getDeleteResult(from), getAddResult(to, toContents)];\n},\n);\nreturn [\n...renamed.flat(),\n...modified.flat(),\n...added,\n...deleted,\n];\n}"
"async function listHermitPackages(\npackageFile: string,\n): Promise<HermitListItem[] | null> {\nlogger.trace('hermit.listHermitPackages()');\nconst hermitFolder = upath.dirname(packageFile);\nlet files: string[] = [];\ntry {\nfiles = await readLocalDirectory(hermitFolder);\n} catch (err) {\nlogger.debug(\n{ hermitFolder, err, packageFile },\n'error listing hermit package references',\n);\nreturn null;\n}\nlogger.trace({ files, hermitFolder }, 'files for hermit package list');\nconst out = [] as HermitListItem[];\nfor (const f of files) {\nif (!minimatch('.*.pkg').match(f)) {\ncontinue;\n}\nconst fileName = f\n.replace(`${hermitFolder}/`, '')\n.substring(1)\n.replace(/\.pkg$/, '');\nconst channelParts = fileName.split('@');\nif (channelParts.length > 1) {\nout.push({\nName: channelParts[0],\nChannel: channelParts[1],\nVersion: '',\n});\n}\nconst groups = pkgReferenceRegex.exec(fileName)?.groups;\nif (!groups) {\nlogger.debug(\n{ fileName },\n'invalid hermit package reference file name found',\n);\ncontinue;\n}\nout.push({\nName: groups.packageName,\nVersion: groups.version,\nChannel: '',\n});\n}\nreturn out;\n}"
"export function parseUrlPath(\nurlStr: string | null | undefined,\n): UrlPathParsedResult | null {\nif (!urlStr) {\nreturn null;\n}\ntry {\nconst url = new URL(urlStr);\nif (url.hostname !== 'github.com') {\nreturn null;\n}\nlet s = url.pathname.split('/');\ns = s.filter((val) => val);\nconst ownerName = s[0];\nconst repoName = s[1];\nlet currentValue: string | undefined;\nif (s[2] === 'archive') {\ncurrentValue = s[3];\nif (currentValue === 'refs') {\ncurrentValue = s[5];\n}\nconst targz = currentValue.slice(\ncurrentValue.length - 7,\ncurrentValue.length,\n);\nif (targz === '.tar.gz') {\ncurrentValue = currentValue.substring(0, currentValue.length - 7);\n}\n} else if (s[2] === 'releases' && s[3] === 'download') {\ncurrentValue = s[4];\n}\nif (!currentValue) {\nreturn null;\n}\nreturn { currentValue, ownerName, repoName };\n} catch {\nreturn null;\n}\n}"
"export function extractPackageFile(content: string): PackageFileContent | null {\nlogger.trace('extractPackageFile()');\nconst cleanContent = removeComments(content);\nconst className = extractClassName(cleanContent);\nif (!className) {\nlogger.debug('Invalid class definition');\nreturn null;\n}\nconst url = extractUrl(cleanContent);\nif (!url) {\nlogger.debug('Invalid URL field');\n}\nconst urlPathResult = parseUrlPath(url);\nlet skipReason: SkipReason | undefined;\nlet currentValue: string | null = null;\nlet ownerName: string | null = null;\nlet repoName: string | null = null;\nif (urlPathResult) {\ncurrentValue = urlPathResult.currentValue;\nownerName = urlPathResult.ownerName;\nrepoName = urlPathResult.repoName;\n} else {\nlogger.debug('Error: Unsupported URL field');\nskipReason = 'unsupported-url';\n}\nconst sha256 = extractSha256(cleanContent);\nif (sha256?.length !== 64) {\nlogger.debug('Error: Invalid sha256 field');\nskipReason = 'invalid-sha256';\n}\nconst dep: PackageDependency = {\ndepName: `${ownerName}/${repoName}`,\nmanagerData: { ownerName, repoName, sha256, url },\ncurrentValue,\ndatasource: GithubTagsDatasource.id,\n};\nif (skipReason) {\ndep.skipReason = skipReason;\nif (skipReason === 'unsupported-url') {\ndep.depName = className;\ndep.datasource = undefined;\n}\n}\nconst deps = [dep];\nreturn { deps };\n}"
"async function inflateHelmChart(\nflagEnabled: boolean,\nexecOptions: ExecOptions,\nchartHome: string,\ndepName: string,\nrepository: string,\ncurrentVersion: string,\nnewVersion?: string,\ndatasource?: string,\n): Promise<void> {\nconst currentChartExistingPath = await localExistingChartPath(\nchartHome,\ndepName,\ncurrentVersion,\n);\nif (!flagEnabled && isNullOrUndefined(currentChartExistingPath)) {\nlogger.debug(\n`Not inflating Helm chart for ${depName} as kustomizeInflateHelmCharts is not enabled and the current version isn't inflated`,\n);\nreturn;\n}\nif (\nisNonEmptyString(currentChartExistingPath) &&\nisNonEmptyString(newVersion)\n) {\nlogger.debug(`Deleting previous helm chart: ${currentChartExistingPath}`);\nawait deleteLocalFile(currentChartExistingPath);\n}\nconst versionToPull = newVersion ?? currentVersion;\nconst versionToPullExistingPath = await localExistingChartPath(\nchartHome,\ndepName,\nversionToPull,\n);\nif (isNonEmptyString(versionToPullExistingPath)) {\nlogger.debug(\n`Helm chart ${depName} version ${versionToPull} already exists at ${versionToPullExistingPath}`,\n);\nreturn;\n}\nconst folderName = `${depName}-${versionToPull}`;\nconst untarDir = upath.join(chartHome, folderName);\nlogger.debug(\n`Pulling helm chart ${depName} version ${versionToPull} to ${untarDir}`,\n);\nconst cmd =\n`helm pull --untar --untardir ${quote(untarDir)} ` +\n`--version ${quote(versionToPull)} ${helmRepositoryArgs(repository, depName, datasource)}`;\nawait exec(cmd, execOptions);\n}"
"export function extractResource(base: string): PackageDependency | null {\nlet match: RegExpExecArray | null;\nif (base.includes('_git')) {\nmatch = underscoreGitRegex.exec(base);\n} else if (base.includes('.git')) {\nmatch = dotGitRegex.exec(base);\n} else if (gitUrlWithPath.test(base)) {\nmatch = gitUrlWithPath.exec(base);\n} else {\nmatch = gitUrl.exec(base);\n}\nif (!match?.groups) {\nreturn null;\n}\nconst { path, queryString } = match.groups;\nconst params = querystring.parse(queryString);\nconst refParam = Array.isArray(params.ref) ? params.ref[0] : params.ref;\nconst versionParam = Array.isArray(params.version)\n? params.version[0]\n: params.version;\nconst currentValue = refParam ?? versionParam;\nif (!currentValue) {\nreturn null;\n}\nif (regEx(/(?:github\.com)(:|\/)/).test(path)) {\nreturn {\ncurrentValue,\ndatasource: GithubTagsDatasource.id,\ndepName: match.groups.project.replace('.git', ''),\n};\n}\nreturn {\ndatasource: GitTagsDatasource.id,\ndepName: path.replace('.git', ''),\npackageName: match.groups.url,\ncurrentValue,\n};\n}"
"export function extractImage(\nimage: Image,\naliases?: Record<string, string>,\n): PackageDependency | null {\nif (!image.name) {\nreturn null;\n}\nconst nameToSplit = image.newName ?? image.name;\nif (!isString(nameToSplit)) {\nlogger.debug({ image }, 'Invalid image name');\nreturn null;\n}\nconst nameDep = getDep(nameToSplit, false, aliases);\nconst { depName } = nameDep;\nconst { digest, newTag } = image;\nif (digest && newTag) {\nlogger.debug(\n{ newTag, digest },\n'Kustomize ignores newTag when digest is provided. Pick one, or use `newTag: tag@digest`',\n);\nreturn {\ndepName,\ncurrentValue: newTag,\ncurrentDigest: digest,\nskipReason: 'invalid-dependency-specification',\n};\n}\nif (digest) {\nif (!isString(digest) || !digest.startsWith('sha256:')) {\nreturn {\ndepName,\ncurrentValue: digest,\nskipReason: 'invalid-value',\n};\n}\nreturn {\n...nameDep,\ncurrentDigest: digest,\nreplaceString: digest,\n};\n}\nif (newTag) {\nif (!isString(newTag) || newTag.startsWith('sha256:')) {\nreturn {\ndepName,\ncurrentValue: newTag,\nskipReason: 'invalid-value',\n};\n}\nconst dep = getDep(`${depName}:${newTag}`, false, aliases);\nreturn {\n...dep,\nreplaceString: newTag,\nautoReplaceStringTemplate:\n'{{newValue}}{{#if newDigest}}@{{newDigest}}{{/if}}',\n};\n}\nif (image.newName) {\nreturn {\n...nameDep,\nreplaceString: image.newName,\n};\n}\nreturn null;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFileContent | null {\nlogger.trace(`kustomize.extractPackageFile(${packageFile})`);\nconst deps: PackageDependency[] = [];\nconst pkg = parseKustomize(content, packageFile);\nif (!pkg) {\nreturn null;\n}\nfor (const base of coerceArray(pkg.bases).filter(isString)) {\nconst dep = extractResource(base);\nif (dep) {\ndeps.push({\n...dep,\ndepType: pkg.kind,\n});\n}\n}\nfor (const resource of coerceArray(pkg.resources).filter(isString)) {\nconst dep = extractResource(resource);\nif (dep) {\ndeps.push({\n...dep,\ndepType: pkg.kind,\n});\n}\n}\nfor (const component of coerceArray(pkg.components).filter(isString)) {\nconst dep = extractResource(component);\nif (dep) {\ndeps.push({\n...dep,\ndepType: pkg.kind,\n});\n}\n}\nfor (const image of coerceArray(pkg.images)) {\nconst dep = extractImage(image, config.registryAliases);\nif (dep) {\ndeps.push({\n...dep,\ndepType: pkg.kind,\n});\n}\n}\nfor (const helmChart of coerceArray(pkg.helmCharts)) {\nconst dep = extractHelmChart(helmChart, config.registryAliases);\nif (dep) {\ndeps.push({\n...dep,\ndepType: 'HelmChart',\n});\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"function getAllCNBDependencies(\nnode: XmlDocument,\nconfig: ExtractConfig,\n): PackageDependency[] | null {\nconst pluginNodes =\nnode.childNamed('build')?.childNamed('plugins')?.childrenNamed('plugin') ??\n[];\nconst pluginNode = pluginNodes.find((pluginNode) => {\nreturn (\npluginNode.valueWithPath('groupId')?.trim() ===\n'org.springframework.boot' &&\npluginNode.valueWithPath('artifactId')?.trim() ===\n'spring-boot-maven-plugin'\n);\n});\nif (!pluginNode) {\nreturn null;\n}\nconst deps: PackageDependency[] = [];\nconst imageNode = pluginNode.childNamed('configuration')?.childNamed('image');\nif (!imageNode) {\nreturn null;\n}\nconst builder = getCNBDependencies(\nimageNode.childrenNamed('builder'),\nconfig,\n);\nconst runImage = getCNBDependencies(\nimageNode.childrenNamed('runImage'),\nconfig,\n);\nconst buildpacks = getCNBDependencies(\nimageNode.childNamed('buildpacks')?.childrenNamed('buildpack') ?? [],\nconfig,\n);\ndeps.push(...builder, ...runImage, ...buildpacks);\nreturn deps.length ? deps : null;\n}"
"function depFromNode(\nnode: XmlElement,\nunderBuildSettingsElement: boolean,\n): PackageDependency | null {\nif (!('valueWithPath' in node)) {\nreturn null;\n}\nlet groupId = node.valueWithPath('groupId')?.trim();\nconst artifactId = node.valueWithPath('artifactId')?.trim();\nconst currentValue = node.valueWithPath('version')?.trim();\nlet depType: string | undefined;\nif (!groupId && node.name === 'plugin') {\ngroupId = 'org.apache.maven.plugins';\n}\nif (groupId && artifactId && currentValue) {\nconst depName = `${groupId}:${artifactId}`;\nconst versionNode = node.descendantWithPath('version')!;\nconst fileReplacePosition = versionNode.position!;\nconst datasource = MavenDatasource.id;\nconst result: PackageDependency = {\ndatasource,\ndepName,\ncurrentValue,\nfileReplacePosition,\nregistryUrls: [],\n};\nswitch (node.name) {\ncase 'plugin':\ncase 'extension':\ndepType = 'build';\nbreak;\ncase 'parent':\ndepType = 'parent';\nbreak;\ncase 'dependency':\nif (underBuildSettingsElement) {\ndepType = 'build';\n} else if (node.valueWithPath('optional')?.trim() === 'true') {\ndepType = 'optional';\n} else {\ndepType = node.valueWithPath('scope')?.trim() ?? 'compile';\n}\nbreak;\n}\nif (depType) {\nresult.depType = depType;\n}\nreturn result;\n}\nreturn null;\n}"
"export function extractPackage(\nrawContent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): PackageFile | null {\nif (!rawContent) {\nreturn null;\n}\nconst project = parsePom(rawContent, packageFile);\nif (!project) {\nreturn null;\n}\nconst result: MavenInterimPackageFile = {\ndatasource: MavenDatasource.id,\npackageFile,\ndeps: [],\n};\nresult.deps = deepExtract(project);\nconst CNBDependencies = getAllCNBDependencies(project, config);\nif (CNBDependencies) {\nresult.deps.push(...CNBDependencies);\n}\nconst propsNode = project.childNamed('properties');\nconst props: Record<string, MavenProp> = {};\nif (propsNode?.children) {\nfor (const propNode of propsNode.children as XmlElement[]) {\nconst key = propNode.name;\nconst val = propNode?.val?.trim();\nif (key && val && propNode.position) {\nconst fileReplacePosition = propNode.position;\nprops[key] = { val, fileReplacePosition, packageFile };\n}\n}\n}\nresult.mavenProps = props;\nconst repositories = project.childNamed('repositories');\nif (repositories?.children) {\nconst repoUrls: string[] = [];\nfor (const repo of repositories.childrenNamed('repository')) {\nconst repoUrl = repo.valueWithPath('url')?.trim();\nif (repoUrl) {\nrepoUrls.push(repoUrl);\n}\n}\nresult.deps.forEach((dep) => {\nif (isArray(dep.registryUrls)) {\nrepoUrls.forEach((url) => dep.registryUrls!.push(url));\n}\n});\n}\nif (packageFile && project.childNamed('parent')) {\nconst parentPath =\nproject.valueWithPath('parent.relativePath')?.trim() ?? '../pom.xml';\nresult.parent = resolveParentFile(packageFile, parentPath);\n}\nif (project.childNamed('version')) {\nresult.packageFileVersion = project.valueWithPath('version')!.trim();\n}\nreturn result;\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile[]> {\nconst packages: PackageFile[] = [];\nconst additionalRegistryUrls: string[] = [];\nfor (const packageFile of packageFiles) {\nconst content = await readLocalFile(packageFile, 'utf8');\nif (!content) {\nlogger.debug({ packageFile }, 'packageFile has no content');\ncontinue;\n}\nif (packageFile.endsWith('settings.xml')) {\nconst registries = extractRegistries(content);\nif (registries) {\nlogger.debug(\n{ registries, packageFile },\n'Found registryUrls in settings.xml',\n);\nadditionalRegistryUrls.push(...registries);\n}\n} else if (packageFile.endsWith('.mvn/extensions.xml')) {\nconst extensions = extractExtensions(content, packageFile);\nif (extensions) {\npackages.push(extensions);\n} else {\nlogger.trace({ packageFile }, 'can not read extensions');\n}\n} else {\nconst pkg = extractPackage(content, packageFile, config);\nif (pkg) {\npackages.push(pkg);\n} else {\nlogger.trace({ packageFile }, 'can not read dependencies');\n}\n}\n}\nif (additionalRegistryUrls) {\nfor (const pkgFile of packages) {\nfor (const dep of pkgFile.deps) {\nif (dep.registryUrls) {\ndep.registryUrls.unshift(...additionalRegistryUrls);\n}\n}\n}\n}\nreturn cleanResult(resolveParents(packages));\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump pom.xml version',\n);\nlet bumpedContent = content;\nif (!semver.valid(currentValue)) {\nlogger.warn(\n{ currentValue },\n'Unable to bump pom.xml version, not a valid semver',\n);\nreturn { bumpedContent };\n}\ntry {\nconst project = new XmlDocument(content);\nconst versionNode = project.childNamed('version')!;\nconst startTagPosition = versionNode.startTagPosition!;\nconst versionPosition = content.indexOf(versionNode.val, startTagPosition);\nlet newPomVersion: string | null = null;\nconst currentPrereleaseValue = semver.prerelease(currentValue);\nif (isSnapshot(currentPrereleaseValue)) {\nlet releaseType = bumpVersion;\nif (!bumpVersion.startsWith('pre')) {\nreleaseType = `pre${bumpVersion}` as ReleaseType;\n}\nnewPomVersion = semver.inc(\ncurrentValue,\nreleaseType,\ncurrentPrereleaseValue!.join('.'),\nfalse,\n);\n} else if (currentPrereleaseValue) {\nnewPomVersion = semver.inc(currentValue, bumpVersion);\n} else {\nnewPomVersion = semver.inc(currentValue, bumpVersion, 'SNAPSHOT', false);\n}\nif (!newPomVersion) {\nthrow new Error('semver inc failed');\n}\nlogger.debug({ newPomVersion });\nbumpedContent = replaceAt(\ncontent,\nversionPosition,\ncurrentValue,\nnewPomVersion,\n);\nif (bumpedContent === content) {\nlogger.debug('Version was already bumped');\n} else {\nlogger.debug('pom.xml version bumped');\n}\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"export async function updateArtifacts({\npackageFileName,\nnewPackageFileContent,\nupdatedDeps,\nconfig,\n}: UpdateArtifact): Promise<UpdateArtifactsResult[] | null> {\ntry {\nlogger.debug({ updatedDeps }, 'maven-wrapper.updateArtifacts()');\nif (!updatedDeps.some((dep) => dep.depName === 'maven-wrapper')) {\nlogger.info(\n'Maven wrapper version not updated - skipping Artifacts update',\n);\nreturn null;\n}\nconst cmd = await createWrapperCommand(packageFileName);\nif (!cmd) {\nlogger.info('No mvnw found - skipping Artifacts update');\nreturn null;\n}\nconst extraEnv = getExtraEnvOptions(updatedDeps);\nawait executeWrapperCommand(cmd, config, packageFileName, extraEnv);\nconst status = await getRepoStatus();\nconst artifactFileNames = [\n'.mvn/wrapper/maven-wrapper.properties',\n'.mvn/wrapper/maven-wrapper.jar',\n'.mvn/wrapper/MavenWrapperDownloader.java',\n'mvnw',\n'mvnw.cmd',\n].map(\n(filename) =>\npackageFileName.replace('.mvn/wrapper/maven-wrapper.properties', '') +\nfilename,\n);\nconst updateArtifactsResult = (\nawait getUpdatedArtifacts(status, artifactFileNames)\n).filter(isTruthy);\nlogger.debug(\n{ files: updateArtifactsResult.map((r) => r.file?.path) },\n`Returning updated maven-wrapper files`,\n);\nreturn updateArtifactsResult;\n} catch (err) {\nlogger.debug({ err }, 'Error setting new Maven Wrapper release value');\nreturn [\n{\nartifactError: {\nlockFile: packageFileName,\nstderr: err.message,\n},\n},\n];\n}\n}"
"export function createCargoToolConfig(\nname: string,\nversion: string,\n): BackendToolingConfig {\nif (!isUrlString(name)) {\nreturn {\npackageName: name,\ndatasource: CrateDatasource.id,\n};\n}\nconst matchGroups = cargoGitVersionRegex.exec(version)?.groups;\nif (isUndefined(matchGroups)) {\nreturn {\npackageName: name,\nskipReason: 'invalid-version',\n};\n}\nconst { type, version: gitVersion } = matchGroups;\nswitch (type as 'tag' | 'branch' | 'rev') {\ncase 'tag':\nreturn {\npackageName: name,\ndatasource: GitTagsDatasource.id,\ncurrentValue: gitVersion,\n};\ncase 'branch':\nreturn {\npackageName: name,\ndatasource: GitRefsDatasource.id,\ncurrentValue: gitVersion,\n};\ncase 'rev':\nreturn {\npackageName: name,\ndatasource: GitRefsDatasource.id,\ncurrentValue: gitVersion,\n};\n}\n}"
"function getToolConfig(\nbackend: string,\ntoolName: string,\nversion: string,\ntoolOptions: MiseToolOptions,\n): ToolingConfig | BackendToolingConfig | null {\nswitch (backend) {\ncase '':\nreturn getRegistryToolConfig(toolName, version);\ncase 'core':\nreturn getConfigFromTooling(miseTooling, toolName, version);\ncase 'asdf':\nreturn getConfigFromTooling(asdfTooling, toolName, version);\ncase 'vfox':\nreturn getRegistryToolConfig(toolName, version);\ncase 'aqua':\nreturn (\ngetRegistryToolConfig(toolName, version) ??\ncreateAquaToolConfig(toolName, version)\n);\ncase 'cargo':\nreturn createCargoToolConfig(toolName, version);\ncase 'dotnet':\nreturn createDotnetToolConfig(toolName);\ncase 'gem':\nreturn createGemToolConfig(toolName);\ncase 'go':\nreturn createGoToolConfig(toolName);\ncase 'npm':\nreturn createNpmToolConfig(toolName);\ncase 'pipx':\nreturn createPipxToolConfig(toolName);\ncase 'spm':\nreturn createSpmToolConfig(toolName);\ncase 'ubi':\nreturn createUbiToolConfig(toolName, version, toolOptions);\ndefault:\nreturn null;\n}\n}"
"export async function updateArtifacts({\npackageFileName,\nconfig,\nupdatedDeps,\n}: UpdateArtifact): Promise<UpdateArtifactsResult[] | null> {\nconst lockFileName = packageFileName.replace(regEx(/\.nix$/), '.lock');\nconst existingLockFileContent = await readLocalFile(lockFileName, 'utf8');\nif (!existingLockFileContent) {\nlogger.debug('No flake.lock found');\nreturn null;\n}\nlet cmd = `nix --extra-experimental-features 'nix-command flakes' `;\nconst token = findGithubToken(\nhostRules.find({\nhostType: 'github',\nurl: 'https:\n}),\n);\nif (token) {\ncmd += `--extra-access-tokens github.com=${token} `;\n}\nif (config.isLockFileMaintenance) {\ncmd += 'flake update';\n} else {\nconst inputs = updatedDeps\n.map(({ depName }) => depName)\n.filter(isNonEmptyStringAndNotWhitespace)\n.map((depName) => quote(depName))\n.join(' ');\ncmd += `flake update ${inputs}`;\n}\nconst execOptions: ExecOptions = {\ncwdFile: packageFileName,\ntoolConstraints: [\n{\ntoolName: 'nix',\nconstraint: config.constraints?.nix,\n},\n],\ndocker: {},\n};\ntry {\nawait exec(cmd, execOptions);\nconst status = await getRepoStatus();\nif (!status.modified.includes(lockFileName)) {\nreturn null;\n}\nlogger.debug('Returning updated flake.lock');\nreturn [\n{\nfile: {\ntype: 'addition',\npath: lockFileName,\ncontents: await readLocalFile(lockFileName),\n},\n},\n];\n} catch (err) {\nlogger.warn({ err }, 'Error updating flake.lock');\nreturn [\n{\nartifactError: {\nlockFile: lockFileName,\nstderr: err.message,\n},\n},\n];\n}\n}"
"async function runDotnetRestore(\npackageFileName: string,\ndependentPackageFileNames: string[],\nconfig: UpdateArtifactsConfig,\n): Promise<void> {\nconst nugetCacheDir = upath.join(privateCacheDir(), 'nuget');\nconst nugetConfigFile = await createCachedNuGetConfigFile(\nnugetCacheDir,\npackageFileName,\n);\nconst dotnetVersion =\nconfig.constraints?.dotnet ??\n(await findGlobalJson(packageFileName))?.sdk?.version;\nconst execOptions: ExecOptions = {\ndocker: {},\nextraEnv: {\nNUGET_PACKAGES: upath.join(nugetCacheDir, 'packages'),\nMSBUILDDISABLENODEREUSE: '1',\n},\ntoolConstraints: [{ toolName: 'dotnet', constraint: dotnetVersion }],\n};\nconst cmds = [\n...dependentPackageFileNames.map(\n(fileName) =>\n`dotnet restore ${quote(\nfileName,\n)} --force-evaluate --configfile ${quote(nugetConfigFile)}`,\n),\n];\nif (config.postUpdateOptions?.includes('dotnetWorkloadRestore')) {\ncmds.unshift(\n`dotnet workload restore --configfile ${quote(nugetConfigFile)}`,\n);\n}\nawait exec(cmds, execOptions);\n}"
"export function createNuGetConfigXml(registries: Registry[]): string {\nlet contents = `<?xml version=`1.0` encoding=`utf-8`?>\n<configuration>\n<packageSources>\n`;\nlet unnamedRegistryCount = 0;\nconst credentials: PackageSourceCredential[] = [];\nconst packageSourceMaps: PackageSourceMap[] = [];\nfor (const registry of registries) {\nconst registryName =\nregistry.name ?? `Package source ${++unnamedRegistryCount}`;\nconst registryInfo = parseRegistryUrl(registry.url);\ncontents += formatPackageSourceElement(registryInfo, registryName);\nconst { password, username } = hostRules.find({\nhostType: NugetDatasource.id,\nurl: registry.url,\n});\nif (isNonEmptyString(password) || isNonEmptyString(username)) {\ncredentials.push({\nname: registryName,\npassword,\nusername,\n});\n}\nif (registry.sourceMappedPackagePatterns) {\npackageSourceMaps.push({\nname: registryName,\npatterns: registry.sourceMappedPackagePatterns,\n});\n}\n}\ncontents += '</packageSources>\n';\nif (credentials.length > 0) {\ncontents += '<packageSourceCredentials>\n';\nfor (const credential of credentials) {\ncontents += formatPackageSourceCredentialElement(credential);\n}\ncontents += '</packageSourceCredentials>\n';\n}\nif (packageSourceMaps.length > 0) {\ncontents += '<packageSourceMapping>\n';\nfor (const packageSourceMap of packageSourceMaps) {\ncontents += formatPackageSource(packageSourceMap);\n}\ncontents += '</packageSourceMapping>';\n}\ncontents += '</configuration>\n';\nreturn contents;\n}"
"export async function getDependentPackageFiles(\npackageFileName: string,\nisCentralManagement = false,\nisGlobalJson = false,\n): Promise<ProjectFile[]> {\nconst packageFiles = await getAllPackageFiles();\nconst graph = new Graph();\nif (isCentralManagement) {\ngraph.addNode(packageFileName);\n}\nif (isGlobalJson) {\ngraph.addNode(GLOBAL_JSON);\n}\nconst parentDir =\npackageFileName === NUGET_CENTRAL_FILE ||\npackageFileName === MSBUILD_CENTRAL_FILE ||\npackageFileName === GLOBAL_JSON\n? ''\n: upath.dirname(packageFileName);\nfor (const f of packageFiles) {\ngraph.addNode(f);\nif (\n(isCentralManagement || isGlobalJson) &&\nupath.dirname(f).startsWith(parentDir)\n) {\ngraph.addEdge(packageFileName, f);\n}\n}\nfor (const f of packageFiles) {\nconst doc = await readFileAsXmlDocument(f);\nif (!doc) {\ncontinue;\n}\nconst projectReferenceAttributes = doc\n.childrenNamed('ItemGroup')\n.map((ig) => ig.childrenNamed('ProjectReference'))\n.flat()\n.map((pf) => pf.attr.Include)\n.filter(isNonEmptyString);\nconst projectReferences = projectReferenceAttributes.map((a) =>\nupath.normalize(a),\n);\nconst normalizedRelativeProjectReferences = projectReferences.map((r) =>\nreframeRelativePathToRootOfRepo(f, r),\n);\nfor (const ref of normalizedRelativeProjectReferences) {\ngraph.addEdge(ref, f);\n}\nif (hasCycle(graph)) {\nthrow new Error('Circular reference detected in NuGet package files');\n}\n}\nconst deps = new Map<string, boolean>();\nrecursivelyGetDependentPackageFiles(packageFileName, graph, deps);\nif (isCentralManagement || isGlobalJson) {\ndeps.delete(packageFileName);\n}\nreturn Array.from(deps).map(([name, isLeaf]) => ({ name, isLeaf }));\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump project version',\n);\nlet bumpedContent = content;\nif (!semver.valid(currentValue)) {\nlogger.warn(\n{ currentValue },\n'Unable to bump project version, not a valid semver',\n);\nreturn { bumpedContent };\n}\ntry {\nconst project = new XmlDocument(content);\nconst versionNode = findVersion(project);\nif (!versionNode) {\nlogger.warn(\n`Couldn't find Version or VersionPrefix in any PropertyGroup`,\n);\nreturn { bumpedContent };\n}\nconst currentProjVersion = versionNode.val;\nif (currentProjVersion !== currentValue) {\nlogger.warn(\n{ currentValue, currentProjVersion },\n`currentValue passed to bumpPackageVersion() doesn't match value found`,\n);\nreturn { bumpedContent };\n}\nconst startTagPosition = versionNode.startTagPosition!;\nconst versionPosition = content.indexOf(\ncurrentProjVersion,\nstartTagPosition,\n);\nconst newProjVersion = semver.inc(currentValue, bumpVersion);\nif (!newProjVersion) {\nthrow new Error('semver inc failed');\n}\nlogger.debug(`newProjVersion: ${newProjVersion}`);\nbumpedContent = replaceAt(\ncontent,\nversionPosition,\ncurrentValue,\nnewProjVersion,\n);\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n_config?: ExtractConfig,\n): PackageFileContent | null {\nlet definition: OCBConfig | null = null;\ntry {\nconst yaml = parseSingleYaml(content);\nconst parsed = OCBConfig.safeParse(yaml);\nif (!parsed.success) {\nlogger.trace(\n{ packageFile, error: parsed.error },\n'Failed to parse OCB schema',\n);\nreturn null;\n}\ndefinition = parsed.data;\n} catch (error) {\nlogger.debug(\n{ packageFile, error },\n'OCB manager failed to parse file as YAML',\n);\nreturn null;\n}\nconst deps: PackageDependency[] = [];\nif (definition.dist.otelcol_version) {\ndeps.push({\ndatasource: GoDatasource.id,\ndepType: 'collector',\ndepName: 'go.opentelemetry.io/collector',\ncurrentValue: definition.dist.otelcol_version,\nextractVersion: '^v(?<version>\\S+)',\n});\n}\ndeps.push(...processModule(definition.connectors, 'connectors'));\ndeps.push(...processModule(definition.exporters, 'exports'));\ndeps.push(...processModule(definition.extensions, 'extensions'));\ndeps.push(...processModule(definition.processors, 'processors'));\ndeps.push(...processModule(definition.providers, 'providers'));\ndeps.push(...processModule(definition.receivers, 'receivers'));\nreturn {\npackageFileVersion: definition.dist.version,\ndeps,\n};\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump OCB version',\n);\nlet bumpedContent = content;\ntry {\nconst newProjectVersion = inc(currentValue, bumpVersion);\nif (!newProjectVersion) {\nthrow new Error('semver inc failed');\n}\nlogger.debug(`newProjectVersion: ${newProjectVersion}`);\nbumpedContent = content.replace(\nregEx(/\b(?<version>version:\s+[`']?)(?<currentValue>[^'`\s]*)/),\n`$<version>${newProjectVersion}`,\n);\nif (bumpedContent === content) {\nlogger.debug('Version was already bumped');\n} else {\nlogger.debug('Bumped OCB version');\n}\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\nmanager: 'ocb',\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n_config?: ExtractConfig,\n): PackageFileContent | null {\nlogger.trace(`osgi.extractPackageFile($packageFile)`);\nconst deps: PackageDependency[] = [];\nlet featureModel: FeatureModel;\ntry {\nfeatureModel = json5.parse<FeatureModel>(content);\n} catch (err) {\nlogger.warn({ packageFile, err }, 'Failed to parse osgi file');\nreturn null;\n}\nif (\nisNullOrUndefined(featureModel) ||\n!isSupportedFeatureResourceVersion(featureModel, packageFile)\n) {\nreturn null;\n}\nconst allBundles = featureModel.bundles ?? [];\nconst execEnvFramework =\nfeatureModel['execution-environment:JSON|false']?.framework;\nif (!isNullOrUndefined(execEnvFramework)) {\nallBundles.push(execEnvFramework);\n}\nfor (const [section, value] of Object.entries(featureModel)) {\nlogger.trace({ fileName: packageFile, section }, 'Parsing section');\nconst customSectionEntries = extractArtifactList(section, value);\nallBundles.push(...customSectionEntries);\n}\nfor (const entry of allBundles) {\nconst rawGav = typeof entry === 'string' ? entry : entry.id;\nif (!rawGav) {\ncontinue;\n}\nconst gav = rawGav.replace(/\\nconst parts = gav.split(':');\nif (parts.length < 3 || parts.length > 5) {\ndeps.push({\ndepName: gav,\nskipReason: 'invalid-value',\n});\ncontinue;\n}\nconst currentValue = parts[parts.length - 1];\nconst result: PackageDependency = {\ndatasource: MavenDatasource.id,\ndepName: `${parts[0]}:${parts[1]}`,\n};\nif (currentValue.includes('${')) {\nresult.skipReason = 'contains-variable';\n} else {\nresult.currentValue = currentValue;\n}\ndeps.push(result);\n}\nreturn deps.length ? { deps } : null;\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n_config?: ExtractConfig,\n): Promise<PackageFileContent | null> {\nlogger.trace(`pep621.extractPackageFile(${packageFile})`);\nconst def = parsePyProject(content, packageFile);\nif (!def) {\nreturn null;\n}\nconst deps: PackageDependency[] = [];\nconst pythonConstraint = def.project?.['requires-python'];\nconst extractedConstraints: Record<string, string> = {};\nif (pythonConstraint) {\nextractedConstraints.python = pythonConstraint;\ndeps.push({\npackageName: 'python',\ndepType: 'requires-python',\ncurrentValue: pythonConstraint,\ncommitMessageTopic: 'Python',\ndatasource: PythonVersionDatasource.id,\nversioning: pep440.id,\n});\n}\nconst projectDependencies = def.project?.dependencies;\nif (projectDependencies) {\ndeps.push(...projectDependencies);\n}\nconst dependencyGroups = def['dependency-groups'];\nif (dependencyGroups) {\ndeps.push(...dependencyGroups);\n}\nconst projectOptionalDependencies = def.project?.['optional-dependencies'];\nif (projectOptionalDependencies) {\ndeps.push(...projectOptionalDependencies);\n}\nconst buildSystemRequires = def['build-system']?.requires;\nif (buildSystemRequires) {\ndeps.push(...buildSystemRequires);\n}\nlet processedDeps = deps;\nconst lockFiles: string[] = [];\nfor (const processor of processors) {\nprocessedDeps = processor.process(def, processedDeps);\nprocessedDeps = await processor.extractLockedVersions(\ndef,\nprocessedDeps,\npackageFile,\n);\nconst processedLockFiles = await processor.getLockfiles(def, packageFile);\nlockFiles.push(...processedLockFiles);\n}\nconst packageFileVersion = def.project?.version;\nreturn processedDeps.length || lockFiles.length\n? {\nextractedConstraints,\ndeps: processedDeps,\npackageFileVersion,\nlockFiles,\n}\n: null;\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump pyproject.toml version',\n);\nlet bumpedContent = content;\ntry {\nconst newProjectVersion = inc(currentValue, bumpVersion);\nif (!newProjectVersion) {\nthrow new Error('pep440 inc failed');\n}\nlogger.debug(`newProjectVersion: ${newProjectVersion}`);\nbumpedContent = content.replace(\nregEx(`^(?<version>version[ \\t]*=[ \\t]*['`])[^'`]*`, 'm'),\n`$<version>${newProjectVersion}`,\n);\nif (bumpedContent === content) {\nlogger.debug('Version was already bumped');\n} else {\nlogger.debug('Bumped pyproject.toml version');\n}\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\nmanager: 'pep621',\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"export function inferCommandExecDir(\noutputFilePath: string,\noutputFileArg: string | undefined,\n): string {\nif (!outputFileArg) {\nreturn upath.normalize(upath.dirname(outputFilePath));\n}\nif (upath.normalize(outputFileArg).startsWith('..')) {\nthrow new Error(\n`Cannot infer command execution directory from path ${outputFileArg}`,\n);\n}\nif (upath.basename(outputFileArg) !== upath.basename(outputFilePath)) {\nthrow new Error(\n`Output file name mismatch: ${upath.basename(outputFileArg)} vs ${upath.basename(outputFilePath)}`,\n);\n}\nconst outputFileDir = upath.normalize(upath.dirname(outputFileArg));\nlet commandExecDir = upath.normalize(upath.dirname(outputFilePath));\nfor (const dir of outputFileDir.split('/').reverse()) {\nif (commandExecDir.endsWith(dir)) {\ncommandExecDir = upath.join(commandExecDir.slice(0, -dir.length), '.');\n} else {\nbreak;\n}\n}\ncommandExecDir = upath.normalizeTrim(commandExecDir);\nif (commandExecDir !== '.') {\nlogger.debug(\n{\ncommandExecDir,\noutputFileArg,\noutputFilePath,\n},\n`pip-compile: command was not executed in repository root`,\n);\n}\nreturn commandExecDir;\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n): Promise<PackageFileContent | null> {\nlogger.trace(`pipenv.extractPackageFile(${packageFile})`);\nlet pipfile: PipFile;\ntry {\npipfile = parseToml(content) as any;\n} catch (err) {\nlogger.debug({ err, packageFile }, 'Error parsing Pipfile');\nreturn null;\n}\nconst res: PackageFileContent = { deps: [] };\nconst sources = pipfile?.source;\nif (sources) {\nres.registryUrls = sources.map((source) => source.url);\n}\nres.deps = Object.entries(pipfile)\n.map(([category, section]) => {\nif (\ncategory === 'source' ||\ncategory === 'requires' ||\n!isPipRequirements(section)\n) {\nreturn [];\n}\nreturn extractFromSection(category, section, sources);\n})\n.flat();\nif (!res.deps.length) {\nreturn null;\n}\nconst extractedConstraints: Record<string, any> = {};\nconst pipfileDir = getParentDir(ensureLocalPath(packageFile));\nconst pythonConstraint = await pipenvDetect.getPythonConstraint(pipfileDir);\nif (pythonConstraint) {\nextractedConstraints.python = pythonConstraint;\n}\nconst pipenvConstraint = await pipenvDetect.getPipenvConstraint(pipfileDir);\nif (pipenvConstraint) {\nextractedConstraints.pipenv = pipenvConstraint;\n}\nconst lockFileName = `${packageFile}.lock`;\nif (await localPathExists(lockFileName)) {\nres.lockFiles = [lockFileName];\n}\nres.extractedConstraints = extractedConstraints;\nreturn res;\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n): Promise<PackageFileContent | null> {\nlogger.trace(`pixi.extractPackageFile(${packageFile})`);\nconst val = getUserPixiConfig(content, packageFile);\nif (!val) {\nreturn null;\n}\nconst lockfileName = getSiblingFileName(packageFile, 'pixi.lock');\nconst lockFiles: string[] = [];\nif (await localPathExists(lockfileName)) {\nlockFiles.push(lockfileName);\n}\nconst project = val.project;\nconst channelPriority = project['channel-priority'];\nlet registryStrategy: RegistryStrategy | undefined;\nif (channelPriority === 'disabled') {\nregistryStrategy = 'merge';\n}\nconst conda: PixiPackageDependency[] = [];\nfor (const item of val.conda) {\nconda.push(\naddRegistryUrls({\n...item,\nchannels: project.channels,\nregistryStrategy,\n}),\n);\n}\nfor (const item of val.feature.conda) {\nconda.push(\naddRegistryUrls({\n...item,\nregistryStrategy,\nchannels: [...coerceArray(item.channels), ...project.channels],\n}),\n);\n}\nreturn {\nlockFiles,\ndeps: [conda, val.pypi, val.feature.pypi].flat(),\n};\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\n): Promise<PackageFileContent | null> {\nlogger.trace(`poetry.extractPackageFile(${packageFile})`);\nconst { val: res, err } = Result.parse(\nmassageToml(content),\nPoetryPyProject.transform(({ packageFileContent }) => packageFileContent),\n).unwrap();\nif (err) {\nlogger.debug({ packageFile, err }, `Poetry: error parsing pyproject.toml`);\nreturn null;\n}\nconst lockfileName = getSiblingFileName(packageFile, 'poetry.lock');\nconst lockContents = (await readLocalFile(lockfileName, 'utf8'))!;\nconst lockfileMapping = Result.parse(\nlockContents,\nLockfile.transform(({ lock }) => lock),\n).unwrapOr({});\nlet pythonVersion: string | undefined;\nfilterMap(res.deps, (dep) => {\nif (dep.depName === 'python') {\nif (dep.currentValue) {\npythonVersion = dep.currentValue;\n}\nreturn {\n...dep,\npackageName: 'containerbase/python-prebuild',\ndatasource: GithubReleasesDatasource.id,\ncommitMessageTopic: 'Python',\nregistryUrls: null,\n};\n}\nconst packageName = dep.packageName ?? dep.depName;\nif (packageName && packageName in lockfileMapping) {\ndep.lockedVersion = lockfileMapping[packageName];\n}\nreturn dep;\n});\nif (!res.deps.length) {\nreturn null;\n}\nconst extractedConstraints: Record<string, any> = {};\nif (isNonEmptyString(pythonVersion)) {\nextractedConstraints.python = pythonVersion;\n}\nres.extractedConstraints = extractedConstraints;\nlet lockFile = getSiblingFileName(packageFile, 'poetry.lock');\nif (await localPathExists(lockFile)) {\nres.lockFiles = [lockFile];\n} else {\nlockFile = getSiblingFileName(packageFile, 'pyproject.lock');\nif (await localPathExists(lockFile)) {\nres.lockFiles = [lockFile];\n}\n}\nreturn res;\n}"
"function determineDatasource(\nrepository: string,\nhostname: string,\n): { datasource?: string; registryUrls?: string[]; skipReason?: SkipReason } {\nif (hostname === 'github.com' || detectPlatform(repository) === 'github') {\nlogger.debug({ repository, hostname }, 'Found github dependency');\nreturn { datasource: GithubTagsDatasource.id };\n}\nif (hostname === 'gitlab.com') {\nlogger.debug({ repository, hostname }, 'Found gitlab dependency');\nreturn { datasource: GitlabTagsDatasource.id };\n}\nif (detectPlatform(repository) === 'gitlab') {\nlogger.debug(\n{ repository, hostname },\n'Found gitlab dependency with custom registryUrl',\n);\nreturn {\ndatasource: GitlabTagsDatasource.id,\nregistryUrls: ['https:\n};\n}\nconst hostUrl = 'https:\nconst res = find({ url: hostUrl });\nif (isEmptyObject(res)) {\nlogger.debug(\n{ repository, hostUrl },\n'Provided hostname does not match any hostRules. Ignoring',\n);\nreturn { skipReason: 'unknown-registry', registryUrls: [hostname] };\n}\nfor (const [hostType, sourceId] of [\n['github', GithubTagsDatasource.id],\n['gitlab', GitlabTagsDatasource.id],\n]) {\nif (isNonEmptyObject(find({ hostType, url: hostUrl }))) {\nlogger.debug(\n{ repository, hostUrl, hostType },\n`Provided hostname matches a ${hostType} hostrule.`,\n);\nreturn { datasource: sourceId, registryUrls: [hostname] };\n}\n}\nlogger.debug(\n{ repository, registry: hostUrl },\n'Provided hostname did not match any of the hostRules of hostType github nor gitlab',\n);\nreturn { skipReason: 'unknown-registry', registryUrls: [hostname] };\n}"
"function extractDependency(\ntag: string,\nrepository: string,\n): {\ndepName?: string;\ndepType?: string;\ndatasource?: string;\npackageName?: string;\nskipReason?: SkipReason;\ncurrentValue?: string;\n} {\nlogger.debug(`Found version ${tag}`);\nconst urlMatchers = [\nregEx('^https?:\nregEx('^git@(?<hostname>[^:]+):(?<depName>\\S*)'),\nregEx(/^git:\/\/(?<hostname>[^/]+)\/(?<depName>\S*)/),\nregEx(/^ssh:\/\/git@(?<hostname>[^/]+)\/(?<depName>\S*)/),\n];\nfor (const urlMatcher of urlMatchers) {\nconst match = urlMatcher.exec(repository);\nif (match?.groups) {\nconst hostname = match.groups.hostname;\nconst depName = match.groups.depName.replace(gitUrlRegex, '');\nconst sourceDef = determineDatasource(repository, hostname);\nreturn {\n...sourceDef,\ndepName,\ndepType: 'repository',\npackageName: depName,\ncurrentValue: tag,\n};\n}\n}\nlogger.info(\n{ repository },\n'Could not separate hostname from full dependency url.',\n);\nreturn {\ndepName: undefined,\ndepType: 'repository',\ndatasource: undefined,\npackageName: undefined,\nskipReason: 'invalid-url',\ncurrentValue: tag,\n};\n}"
"function findDependencies(precommitFile: PreCommitConfig): PackageDependency[] {\nif (!precommitFile.repos) {\nlogger.debug(`No repos section found, skipping file`);\nreturn [];\n}\nconst packageDependencies: PackageDependency[] = [];\nprecommitFile.repos.forEach((item) => {\nif (item.repo !== 'meta') {\nitem.hooks?.forEach((hook) => {\nif (hook.language === 'node') {\nhook.additional_dependencies?.map((req) => {\nconst match = regEx('^(?<name>.+)@(?<range>.+)$').exec(req);\nif (!match?.groups) {\nreturn;\n}\nconst depType = 'pre-commit-node';\nconst dep = npmExtractDependency(\ndepType,\nmatch.groups.name,\nmatch.groups.range,\n);\npackageDependencies.push({\ndepType,\ndepName: match.groups.name,\npackageName: match.groups.name,\n...dep,\n});\n});\n} else if (hook.language === 'python') {\nhook.additional_dependencies?.map((req) => {\nconst dep = pep508ToPackageDependency('pre-commit-python', req);\nif (dep) {\npackageDependencies.push(dep);\n}\n});\n}\n});\n}\nif (matchesPrecommitDependencyHeuristic(item)) {\nlogger.trace(item, 'Matched pre-commit dependency spec');\nconst repository = String(item.repo);\nconst tag = String(item.rev);\nconst dep = extractDependency(tag, repository);\npackageDependencies.push(dep);\n} else {\nlogger.trace(item, 'Did not find pre-commit repo spec');\n}\n});\nreturn packageDependencies;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n): PackageFileContent | null {\ntype ParsedContent = Record<string, unknown> | PreCommitConfig;\nlet parsedContent: ParsedContent;\ntry {\nparsedContent = parseSingleYaml(content);\n} catch (err) {\nlogger.debug(\n{ filename: packageFile, err },\n'Failed to parse pre-commit config YAML',\n);\nreturn null;\n}\nif (!isPlainObject<Record<string, unknown>>(parsedContent)) {\nlogger.debug(\n{ packageFile },\n`Parsing of pre-commit config YAML returned invalid result`,\n);\nreturn null;\n}\nif (!matchesPrecommitConfigHeuristic(parsedContent)) {\nlogger.debug(\n{ packageFile },\n`File does not look like a pre-commit config file`,\n);\nreturn null;\n}\ntry {\nconst deps = findDependencies(parsedContent);\nif (deps.length) {\nlogger.trace({ deps }, 'Found dependencies in pre-commit config');\nreturn { deps };\n}\n} catch (err)  {\nlogger.debug(\n{ packageFile, err },\n'Error scanning parsed pre-commit config',\n);\n}\nreturn null;\n}"
"function parseGitDependency(module: PuppetfileModule): PackageDependency {\nconst moduleName = module.name;\nconst git = module.tags?.get('git');\nconst tag = module.tags?.get('tag');\nif (!git || !tag) {\nreturn {\ndepName: moduleName,\nsourceUrl: git,\nskipReason: 'invalid-version',\n};\n}\nconst parsedUrl = parseUrl(git);\nconst githubUrl = isGithubUrl(git, parsedUrl);\nif (githubUrl && parsedUrl && parsedUrl.protocol !== 'https:') {\nlogger.debug(\n`Access to github is only allowed for https, your url was: ${git}`,\n);\nreturn {\ndepName: moduleName,\nsourceUrl: git,\nskipReason: 'invalid-url',\n};\n}\nconst gitOwnerRepo = parseGitOwnerRepo(git, githubUrl);\nif (!gitOwnerRepo) {\nreturn {\ndepName: moduleName,\nsourceUrl: git,\nskipReason: 'invalid-url',\n};\n}\nconst packageDependency: PackageDependency = {\ndepName: moduleName,\npackageName: git,\nsourceUrl: git,\ngitRef: true,\ncurrentValue: tag,\ndatasource: GitTagsDatasource.id,\n};\nif (githubUrl) {\npackageDependency.packageName = gitOwnerRepo;\npackageDependency.datasource = GithubTagsDatasource.id;\n}\nreturn packageDependency;\n}"
"export function parsePuppetfile(content: string): Puppetfile {\nconst puppetfile: Puppetfile = new Puppetfile();\nlet currentForge: string | null = null;\nlet currentPuppetfileModule: PuppetfileModule = {};\nfor (const rawLine of content.split(newlineRegex)) {\nconst line = rawLine.replace(commentRegex, '');\nconst forgeResult = forgeRegex.exec(line);\nif (forgeResult) {\npuppetfile.add(currentForge, currentPuppetfileModule);\ncurrentPuppetfileModule = {};\ncurrentForge = forgeResult[1];\ncontinue;\n}\nconst moduleStart = line.startsWith('mod');\nif (moduleStart) {\npuppetfile.add(currentForge, currentPuppetfileModule);\ncurrentPuppetfileModule = {};\n}\nconst moduleValueRegex = regEx(/(?:\s*:(\w+)\s+=>\s+)?['`]([^'`]+)['`]/g);\nlet moduleValue: RegExpExecArray | null;\nwhile ((moduleValue = moduleValueRegex.exec(line)) !== null) {\nconst key = moduleValue[1];\nconst value = moduleValue[2];\nif (key) {\ncurrentPuppetfileModule.tags =\ncurrentPuppetfileModule.tags ?? new Map();\ncurrentPuppetfileModule.tags.set(key, value);\n} else {\nfillPuppetfileModule(currentPuppetfileModule, value);\n}\n}\n}\npuppetfile.add(currentForge, currentPuppetfileModule);\nreturn puppetfile;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n): PackageFileContent | null {\nlogger.trace(`renovate-config-presets.extractPackageFile(${packageFile})`);\nconst config = RenovateJson.safeParse(content);\nif (!config.success) {\nlogger.debug({ packageFile, err: config.error }, 'Invalid Renovate Config');\nreturn null;\n}\nconst deps: PackageDependency[] = [];\nfor (const preset of config.data.extends ?? []) {\nconst parsedPreset = parsePreset(preset);\nconst datasource = supportedPresetSources[parsedPreset.presetSource];\nif (isNullOrUndefined(datasource)) {\nif (parsedPreset.presetSource !== 'internal') {\ndeps.push({\ndepName: parsedPreset.repo,\nskipReason: 'unsupported-datasource',\n});\n}\ncontinue;\n}\nif (isNullOrUndefined(parsedPreset.tag)) {\ndeps.push({\ndepName: parsedPreset.repo,\nskipReason: 'unspecified-version',\n});\ncontinue;\n}\ndeps.push({\ndepName: parsedPreset.repo,\ndatasource,\ncurrentValue: parsedPreset.tag,\n});\n}\nreturn isNonEmptyArray(deps) ? { deps } : null;\n}"
"function depHandler(ctx: Ctx): Ctx {\nconst {\nscalaVersion,\ngroupId,\nartifactId,\ncurrentValue,\nuseScalaVersion,\ndepType,\nvariableName,\n} = ctx;\ndelete ctx.groupId;\ndelete ctx.artifactId;\ndelete ctx.currentValue;\ndelete ctx.useScalaVersion;\ndelete ctx.depType;\ndelete ctx.variableName;\nconst depName = `${groupId!}:${artifactId!}`;\nconst dep: PackageDependency = {\ndatasource: SbtPackageDatasource.id,\ndepName,\npackageName:\nscalaVersion && useScalaVersion ? `${depName}_${scalaVersion}` : depName,\ncurrentValue,\n};\nif (depType) {\ndep.depType = depType;\n}\nif (depType === 'plugin') {\ndep.datasource = SbtPluginDatasource.id;\n}\nif (variableName) {\ndep.sharedVariableName = variableName;\ndep.variableName = variableName;\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"function extractPackageFileInternal(\ncontent: string,\npackageFile: string,\nctxScalaVersion?: string,\n): PackageFileContent | null {\nif (\npackageFile === 'project/build.properties' ||\npackageFile.endsWith('/project/build.properties')\n) {\nconst regexResult = sbtVersionRegex.exec(content);\nconst sbtVersion = regexResult?.groups?.version;\nconst matchString = regexResult?.[0];\nif (sbtVersion) {\nconst sbtDependency: PackageDependency = {\ndatasource: GithubReleasesDatasource.id,\ndepName: 'sbt/sbt',\npackageName: 'sbt/sbt',\nversioning: semverVersioning.id,\ncurrentValue: sbtVersion,\nreplaceString: matchString,\nextractVersion: '^v(?<version>\\S+)',\nregistryUrls: [],\n};\nreturn {\ndeps: [sbtDependency],\n};\n} else {\nreturn null;\n}\n}\nlet parsedResult: Ctx | null = null;\ntry {\nparsedResult = scala.query(content, query, {\nvars: {},\ndeps: [],\nregistryUrls: [],\nscalaVersion: ctxScalaVersion,\n});\n} catch (err)  {\nlogger.debug({ err, packageFile }, 'Sbt parsing error');\n}\nif (!parsedResult) {\nreturn null;\n}\nconst { deps, scalaVersion, packageFileVersion } = parsedResult;\nif (!deps.length) {\nreturn null;\n}\nreturn { deps, packageFileVersion, managerData: { scalaVersion } };\n}"
"export async function extractAllPackageFiles(\n_config: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile[]> {\nconst packages: PackageFile[] = [];\nconst proxyUrls: string[] = [];\nlet ctxScalaVersion: string | undefined;\nconst sortedPackageFiles = sortPackageFiles(packageFiles);\nfor (const packageFile of sortedPackageFiles) {\nconst content = await readLocalFile(packageFile, 'utf8');\nif (!content) {\nlogger.debug({ packageFile }, 'packageFile has no content');\ncontinue;\n}\nif (packageFile === 'repositories') {\nconst urls = extractProxyUrls(content, packageFile);\nproxyUrls.push(...urls);\n} else {\nconst pkg = extractPackageFileInternal(\ncontent,\npackageFile,\nctxScalaVersion,\n);\nif (pkg) {\npackages.push({ deps: pkg.deps, packageFile });\nif (pkg.managerData?.scalaVersion) {\nctxScalaVersion = pkg.managerData.scalaVersion;\n}\n}\n}\n}\nfor (const pkg of packages) {\nfor (const dep of pkg.deps) {\nif (dep.datasource !== GithubReleasesDatasource.id) {\nif (proxyUrls.length > 0) {\ndep.registryUrls!.unshift(...proxyUrls);\n} else if (dep.depType === 'plugin') {\ndep.registryUrls!.unshift(SBT_PLUGINS_REPO, MAVEN_REPO);\n} else {\ndep.registryUrls!.unshift(MAVEN_REPO);\n}\n}\n}\n}\nreturn packages;\n}"
"function parseDep(\nline: string,\nsection: string | null,\nrecord: string | null,\n): PackageDependency | null {\nconst packagePattern = '[a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9._-]*[a-zA-Z0-9]';\nconst extrasPattern = '(?:\\s*\\[[^\\]]+\\])?';\nconst rangePattern: string = RANGE_PATTERN;\nconst specifierPartPattern = `\\s*${rangePattern.replace(\nregEx(/\?<\w+>/g),\n'?:',\n)}`;\nconst specifierPattern = `${specifierPartPattern}(?:\\s*,${specifierPartPattern})*`;\nconst dependencyPattern = `(${packagePattern})(${extrasPattern})(${specifierPattern})`;\nconst pkgRegex = regEx(`^(${packagePattern})$`);\nconst pkgValRegex = regEx(`^${dependencyPattern}$`);\nconst depType = getDepType(section, record);\nif (!depType) {\nreturn null;\n}\nconst [lineNoEnvMarkers] = line.split(';').map((part) => part.trim());\nconst packageMatches =\npkgValRegex.exec(lineNoEnvMarkers) ?? pkgRegex.exec(lineNoEnvMarkers);\nif (!packageMatches) {\nreturn null;\n}\nconst [, depName, , currVal] = packageMatches;\nconst currentValue = currVal?.trim();\nconst dep: PackageDependency = {\ndepName,\npackageName: normalizePythonDepName(depName),\ncurrentValue,\ndatasource: PypiDatasource.id,\ndepType,\n};\nif (currentValue?.startsWith('==')) {\ndep.currentVersion = currentValue.replace(/^==\s*/, '');\n}\nreturn dep;\n}"
"export function extractPackageFile(\ncontent: string,\n): MaybePromise<PackageFileContent | null> {\nlogger.trace('setup-cfg.extractPackageFile()');\nlet sectionName: string | null = null;\nlet sectionRecord: string | null = null;\nconst deps: PackageDependency[] = [];\ncontent\n.split(newlineRegex)\n.map((line) => line.replace(regEx(/#.*$/), '').trimEnd())\n.forEach((rawLine) => {\nlet line = rawLine;\nconst newSectionName = getSectionName(line);\nconst newSectionRecord = getSectionRecord(line);\nif (newSectionName) {\nsectionName = newSectionName;\n}\nif (newSectionRecord) {\nsectionRecord = newSectionRecord;\nline = rawLine.replace(regEx(/^[^=]*=\s*/), '');\nline.split(';').forEach((part) => {\nconst dep = parseDep(part, sectionName, sectionRecord);\nif (dep) {\ndeps.push(dep);\n}\n});\nreturn;\n}\nconst dep = parseDep(line, sectionName, sectionRecord);\nif (dep) {\ndeps.push(dep);\n}\n});\nreturn deps.length ? { deps } : null;\n}"
"function searchKeysForState(state: string | null): (keyof typeof regExps)[] {\nswitch (state) {\ncase 'dependencies':\nreturn [SPACE, COLON, WILDCARD];\ncase 'dependencies:':\nreturn [SPACE, BEGIN_SECTION, WILDCARD];\ncase 'dependencies: [':\nreturn [SPACE, PACKAGE, END_SECTION];\ncase '.package(':\nreturn [SPACE, URL_KEY, PACKAGE, END_SECTION];\ncase '.package(url':\nreturn [SPACE, COLON, PACKAGE, END_SECTION];\ncase '.package(url:':\nreturn [SPACE, STRING_LITERAL, PACKAGE, END_SECTION];\ncase '.package(url: [depName]':\nreturn [SPACE, COMMA, PACKAGE, END_SECTION];\ncase '.package(url: [depName],':\nreturn [\nSPACE,\nFROM,\nSTRING_LITERAL,\nRANGE_OP,\nEXACT_VERSION,\nEXACT_VERSION_LABEL,\nPACKAGE,\nEND_SECTION,\n];\ncase '.package(url: [depName], .exact(':\nreturn [SPACE, STRING_LITERAL, PACKAGE, END_SECTION];\ncase '.package(url: [depName], exact:':\nreturn [SPACE, STRING_LITERAL, PACKAGE, END_SECTION];\ncase '.package(url: [depName], from':\nreturn [SPACE, COLON, PACKAGE, END_SECTION];\ncase '.package(url: [depName], from:':\nreturn [SPACE, STRING_LITERAL, PACKAGE, END_SECTION];\ncase '.package(url: [depName], [value]':\nreturn [SPACE, RANGE_OP, PACKAGE, END_SECTION];\ncase '.package(url: [depName], [rangeFrom][rangeOp]':\nreturn [SPACE, STRING_LITERAL, PACKAGE, END_SECTION];\ndefault:\nreturn [DEPS];\n}\n}"
"function getDeps(doc: TektonResource): PackageDependency[] {\nconst deps: PackageDependency[] = [];\nif (isFalsy(doc)) {\nreturn deps;\n}\naddDep(doc.spec?.taskRef, deps);\naddStepImageSpec(doc.spec?.taskSpec, deps);\naddStepImageSpec(doc.spec, deps);\naddDep(doc.spec?.pipelineRef, deps);\naddPipelineAsCodeAnnotations(doc.metadata?.annotations, deps);\nconst pipelineSpec = doc.spec?.pipelineSpec;\nif (isTruthy(pipelineSpec)) {\ndeps.push(...getDeps({ spec: pipelineSpec }));\n}\nfor (const task of [\n...coerceArray(doc.spec?.tasks),\n...coerceArray(doc.spec?.finally),\n]) {\naddDep(task.taskRef, deps);\naddStepImageSpec(task.taskSpec, deps);\n}\nfor (const resource of coerceArray(doc.spec?.resourcetemplates)) {\ndeps.push(...getDeps(resource));\n}\nfor (const item of coerceArray(doc.items)) {\ndeps.push(...getDeps(item));\n}\nreturn deps;\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): Promise<PackageFileContent | null> {\nlogger.trace({ content }, `terraform.extractPackageFile(${packageFile})`);\nconst passedExtractors: DependencyExtractor[] = [];\nfor (const extractor of resourceExtractors) {\nif (checkFileContainsDependency(content, extractor.getCheckList())) {\npassedExtractors.push(extractor);\n}\n}\nif (!passedExtractors.length) {\nlogger.debug(\n{ packageFile },\n'preflight content check has not found any relevant content',\n);\nreturn null;\n}\nlogger.trace(\n{ packageFile },\n`preflight content check passed for extractors: [${passedExtractors\n.map((value) => value.constructor.name)\n.toString()}]`,\n);\nconst dependencies: PackageDependency[] = [];\nconst hclMap = await hcl.parseHCL(content, packageFile);\nif (isNullOrUndefined(hclMap)) {\nlogger.debug({ packageFile }, 'failed to parse HCL file');\nreturn null;\n}\nconst locks = await extractLocksForPackageFile(packageFile);\nfor (const extractor of passedExtractors) {\nconst deps = extractor.extract(hclMap, locks, config);\ndependencies.push(...deps);\n}\ndependencies.forEach((value) => delete value.managerData);\nreturn dependencies.length ? { deps: dependencies } : null;\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile?: string,\n): PackageFileContent | null {\nlogger.trace({ content }, `terragrunt.extractPackageFile(${packageFile!})`);\nif (!checkFileContainsDependency(content, contentCheckList)) {\nif (content.match(includeBlockCheck)) {\nreturn { deps: [] };\n}\nreturn null;\n}\nlet deps: PackageDependency<TerraformManagerData>[] = [];\ntry {\nconst lines = content.split(newlineRegex);\nfor (let lineNumber = 0; lineNumber < lines.length; lineNumber += 1) {\nconst line = lines[lineNumber];\nconst terragruntDependency = dependencyBlockExtractionRegex.exec(line);\nif (terragruntDependency?.groups) {\nlogger.trace(\n`Matched ${terragruntDependency.groups.type} on line ${lineNumber}`,\n);\nconst tfDepType = getTerragruntDependencyType(\nterragruntDependency.groups.type,\n);\nlet result: ExtractionResult | null = null;\nswitch (tfDepType) {\ncase 'terraform': {\nresult = extractTerragruntModule(lineNumber, lines);\nbreak;\n}\ndefault:\nlogger.trace(\n`Could not identify TerragruntDependencyType ${terragruntDependency.groups.type} on line ${lineNumber}.`,\n);\nbreak;\n}\nif (result) {\nlineNumber = result.lineNumber;\ndeps = deps.concat(result.dependencies);\nresult = null;\n}\n}\n}\n} catch (err)  {\nlogger.debug({ err, packageFile }, 'Error extracting terragrunt plugins');\n}\ndeps.forEach((dep) => {\nswitch (dep.managerData!.terragruntDependencyType) {\ncase 'terraform':\nanalyseTerragruntModule(dep);\nbreak;\ndefault:\n}\ndelete dep.managerData;\n});\nreturn { deps };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\n_config: ExtractConfig,\n): PackageFileContent | null {\nlogger.trace({ content }, `tflint.extractPackageFile(${packageFile})`);\nif (!checkFileContainsPlugins(content)) {\nlogger.debug(\n{ packageFile },\n'preflight content check has not found any relevant content',\n);\nreturn null;\n}\nlet deps: PackageDependency[] = [];\ntry {\nconst lines = content.split(newlineRegex);\nfor (let lineNumber = 0; lineNumber < lines.length; lineNumber += 1) {\nconst line = lines[lineNumber];\nconst tfLintPlugin = dependencyBlockExtractionRegex.exec(line);\nif (tfLintPlugin?.groups) {\nlogger.trace(`Matched TFLint plugin on line ${lineNumber}`);\nlet result: ExtractionResult | null = null;\nresult = extractTFLintPlugin(\nlineNumber,\nlines,\ntfLintPlugin.groups.pluginName,\n);\nif (result) {\nlineNumber = result.lineNumber;\ndeps = deps.concat(result.dependencies);\nresult = null;\n}\n}\n}\n} catch (err)  {\nlogger.debug({ err, packageFile }, 'Error extracting TFLint plugins');\n}\nreturn deps.length ? { deps } : null;\n}"
"export function extractTFLintPlugin(\nstartingLine: number,\nlines: string[],\npluginName: string,\n): ExtractionResult {\nlet lineNumber = startingLine;\nconst deps: PackageDependency[] = [];\nlet pluginSource: string | null = null;\nlet currentVersion: string | null = null;\nlet braceCounter = 0;\ndo {\nif (lineNumber > lines.length - 1) {\nlogger.debug(`Malformed TFLint configuration file detected.`);\n}\nconst line = lines[lineNumber];\nif (isString(line)) {\nconst openBrackets = (line.match(regEx(/\{/g)) ?? []).length;\nconst closedBrackets = (line.match(regEx(/\}/g)) ?? []).length;\nbraceCounter = braceCounter + openBrackets - closedBrackets;\nif (braceCounter === 1) {\nconst kvMatch = keyValueExtractionRegex.exec(line);\nif (kvMatch?.groups) {\nif (kvMatch.groups.key === 'version') {\ncurrentVersion = kvMatch.groups.value;\n} else if (kvMatch.groups.key === 'source') {\npluginSource = kvMatch.groups.value;\n}\n}\n}\n} else {\nbraceCounter = 0;\n}\nlineNumber += 1;\n} while (braceCounter !== 0);\nconst dep = analyseTFLintPlugin(pluginSource, currentVersion);\ndeps.push(dep);\nlineNumber -= 1;\nreturn { lineNumber, dependencies: deps };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile?: string,\n): PackageFileContent | null {\nlet doc: TravisYaml;\ntry {\ndoc = parseSingleYaml(content);\n} catch (err) {\nlogger.debug({ err, packageFile }, 'Failed to parse .travis.yml file.');\nreturn null;\n}\nlet deps: PackageDependency[] = [];\nif (doc && isArray(doc.node_js)) {\ndeps = doc.node_js.map((currentValue) => ({\ndepName: 'node',\ndatasource: NodeVersionDatasource.id,\ncurrentValue: currentValue.toString(),\n}));\n}\nlet matrix_include: TravisMatrixItem[] | undefined;\nif (doc?.jobs?.include) {\nmatrix_include = doc.jobs.include;\n} else if (doc?.matrix?.include) {\nmatrix_include = doc.matrix.include;\n}\nif (!isArray(matrix_include)) {\nreturn deps.length ? { deps } : null;\n}\nfor (const item of matrix_include) {\nif (item?.node_js) {\nif (isArray(item.node_js)) {\nitem.node_js.forEach((currentValue) => {\ndeps.push({\ndepName: 'node',\ndatasource: NodeVersionDatasource.id,\ncurrentValue: currentValue.toString(),\n});\n});\n} else if (isString(item.node_js)) {\ndeps.push({\ndepName: 'node',\ndatasource: NodeVersionDatasource.id,\ncurrentValue: item.node_js.toString(),\n});\n}\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"export function extractPackageFile(\nfile: string,\npackageFile?: string,\n): PackageFileContent | null {\nlet doc: VelaPipelineConfiguration;\ntry {\ndoc = parseSingleYaml(file);\n} catch (err) {\nlogger.debug({ err, packageFile }, 'Failed to parse Vela file.');\nreturn null;\n}\nconst deps: PackageDependency[] = [];\nfor (const step of coerceArray(doc.steps)) {\nconst dep = getDep(step.image);\ndeps.push(dep);\n}\nfor (const service of coerceArray(doc.services)) {\nconst dep = getDep(service.image);\ndeps.push(dep);\n}\nfor (const stage of Object.values(doc.stages ?? {})) {\nfor (const step of coerceArray(stage.steps)) {\nconst dep = getDep(step.image);\ndeps.push(dep);\n}\n}\nfor (const secret of Object.values(doc.secrets ?? {})) {\nif (secret.origin) {\nconst dep = getDep(secret.origin.image);\ndeps.push(dep);\n}\n}\nif (!deps.length) {\nreturn null;\n}\nreturn { deps };\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nextractConfig: ExtractConfig,\n): PackageFileContent | null {\nlogger.debug('woodpecker.extractPackageFile()');\nlet config: WoodpeckerConfig;\ntry {\nconfig = parseSingleYaml(content);\nif (!config) {\nlogger.debug(\n{ packageFile },\n'Null config when parsing Woodpecker Configuration content',\n);\nreturn null;\n}\nif (typeof config !== 'object') {\nlogger.debug(\n{ packageFile, type: typeof config },\n'Unexpected type for Woodpecker Configuration content',\n);\nreturn null;\n}\n} catch (err) {\nlogger.debug(\n{ packageFile, err },\n'Error parsing Woodpecker Configuration config YAML',\n);\nreturn null;\n}\nconst pipelineKeys = woodpeckerVersionDecider(config);\nif (pipelineKeys.length === 0) {\nlogger.debug({ packageFile }, `Couldn't identify dependencies`);\nreturn null;\n}\nconst deps = pipelineKeys.flatMap((pipelineKey) =>\nObject.values(config[pipelineKey] ?? {})\n.filter((step) => isString(step?.image))\n.map((step) => getDep(step.image, true, extractConfig.registryAliases)),\n);\nlogger.trace({ deps }, 'Woodpecker Configuration image');\nreturn deps.length ? { deps } : null;\n}"
"export async function getFile(\nrepoId: string,\nfilePath: string,\nbranchName: string,\n): Promise<string | null> {\nlogger.trace(`getFile(filePath=${filePath}, branchName=${branchName})`);\nconst azureApiGit = await azureApi.gitApi();\nconst item = await azureApiGit.getItemText(\nrepoId,\nfilePath,\nundefined,\nundefined,\n0,\nfalse,\nfalse,\ntrue,\n{\nversionType: 0,\nversionOptions: 0,\nversion: getBranchNameWithoutRefsheadsPrefix(branchName),\n},\n);\nif (item?.readable) {\nconst fileContent = await streamToString(item);\ntry {\nconst result = WrappedException.safeParse(fileContent);\nif (result.success) {\nif (result.data.typeKey === 'GitItemNotFoundException') {\nlogger.warn({ filePath }, 'Unable to find file');\nreturn null;\n}\nif (result.data.typeKey === 'GitUnresolvableToCommitException') {\nlogger.warn({ branchName }, 'Unable to find branch');\nreturn null;\n}\n}\n} catch  {\n}\nreturn fileContent;\n}\nreturn null;\n}"
"export async function getMergeMethod(\nrepoId: string,\nproject: string,\nbranchRef?: string | null,\ndefaultBranch?: string,\n): Promise<GitPullRequestMergeStrategy> {\nlogger.debug(\n`getMergeMethod(branchRef=${branchRef}, defaultBranch=${defaultBranch})`,\n);\ninterface Scope {\nrepositoryId: string;\nrefName?: string;\nmatchKind: 'Prefix' | 'Exact' | 'DefaultBranch';\n}\nconst isRelevantScope = (scope: Scope): boolean => {\nif (\nscope.matchKind === 'DefaultBranch' &&\n(!branchRef || branchRef === `refs/heads/${defaultBranch!}`)\n) {\nreturn true;\n}\nif (scope.repositoryId !== repoId && scope.repositoryId !== null) {\nreturn false;\n}\nif (!branchRef) {\nreturn true;\n}\nreturn scope.matchKind === 'Exact'\n? scope.refName === branchRef\n: branchRef.startsWith(scope.refName!);\n};\nconst policyConfigurations = (\nawait (\nawait azureApi.policyApi()\n).getPolicyConfigurations(project, undefined, mergePolicyGuid)\n)\n.filter((p) => p.settings.scope.some(isRelevantScope))\n.map((p) => p.settings)[0];\nlogger.debug(\n`getMergeMethod(branchRef=${branchRef!}) determining mergeMethod from matched policy:\n${JSON.stringify(\npolicyConfigurations,\nnull,\n4,\n)}`,\n);\ntry {\nreturn Object.keys(policyConfigurations)\n.map(\n(p) =>\nGitPullRequestMergeStrategy[\np.slice(5) as never\n] as never as GitPullRequestMergeStrategy,\n)\n.find((p) => p)!;\n} catch {\nreturn GitPullRequestMergeStrategy.NoFastForward;\n}\n}"
"export async function getRawFile(\nfileName: string,\nrepoName?: string,\nbranchOrTag?: string,\n): Promise<string | null> {\ntry {\nconst azureApiGit = await azureApi.gitApi();\nlet repoId: string | undefined;\nif (repoName) {\nconst repos = await azureApiGit.getRepositories();\nconst repo = getRepoByName(repoName, repos);\nrepoId = repo?.id;\n} else {\nrepoId = config.repoId;\n}\nif (!repoId) {\nlogger.debug('No repoId so cannot getRawFile');\nreturn null;\n}\nlet item: GitItem | undefined;\nconst versionDescriptor: GitVersionDescriptor = {\nversion: branchOrTag,\n} satisfies GitVersionDescriptor;\nfor (const versionType of [GitVersionType.Tag, GitVersionType.Branch]) {\nversionDescriptor.versionType = versionType;\nitem = await azureApiGit.getItem(\nrepoId,\nfileName,\nundefined,\nundefined,\nundefined,\nundefined,\nundefined,\nundefined,\nbranchOrTag ? versionDescriptor : undefined,\ntrue,\n);\nif (item) {\nbreak;\n} else {\nlogger.debug(\n`File: ${fileName} not found in ${repoName} with ${versionType}: ${branchOrTag}`,\n);\n}\n}\nreturn item?.content ?? null;\n} catch (err)  {\nif (\nerr.message?.includes('<title>Azure DevOps Services Unavailable</title>')\n) {\nlogger.debug(\n'Azure DevOps is currently unavailable when attempting to fetch file - throwing ExternalHostError',\n);\nthrow new ExternalHostError(err, id);\n}\nif (err.code === 'ECONNRESET' || err.code === 'ETIMEDOUT') {\nthrow new ExternalHostError(err, id);\n}\nif (err.statusCode && err.statusCode >= 500 && err.statusCode < 600) {\nthrow new ExternalHostError(err, id);\n}\nthrow err;\n}\n}"
"export async function initRepo({\nrepository,\ncloneSubmodules,\ncloneSubmodulesFilter,\n}: RepoParams): Promise<RepoResult> {\nlogger.debug(`initRepo(`${repository}`)`);\nconfig = { repository } as Config;\nconst azureApiGit = await azureApi.gitApi();\nconst repos = await azureApiGit.getRepositories();\nconst repo = getRepoByName(repository, repos);\nif (!repo) {\nlogger.error({ repos, repo }, 'Could not find repo in repo list');\nthrow new Error(REPOSITORY_NOT_FOUND);\n}\nlogger.debug({ repositoryDetails: repo }, 'Repository details');\nif (repo.isDisabled) {\nlogger.debug('Repository is disabled- throwing error to abort renovation');\nthrow new Error(REPOSITORY_ARCHIVED);\n}\nif (!repo.defaultBranch) {\nlogger.debug('Repo is empty');\nthrow new Error(REPOSITORY_EMPTY);\n}\nconfig.repoId = repo.id!;\nconfig.project = repo.project!.name!;\nconfig.owner = '?owner?';\nlogger.debug(`${repository} owner = ${config.owner}`);\nconst defaultBranch = repo.defaultBranch.replace('refs/heads/', '');\nconfig.defaultBranch = defaultBranch;\nlogger.debug(`${repository} default branch = ${defaultBranch}`);\nconfig.mergeMethods = {};\nconfig.repoForceRebase = false;\nconst [projectName, repoName] = repository.split('/');\nconst opts = hostRules.find({\nhostType: defaults.hostType,\nurl: defaults.endpoint,\n});\nconst manualUrl = `${defaults.endpoint!}${encodeURIComponent(\nprojectName,\n)}/_git/${encodeURIComponent(repoName)}`;\nconst url = repo.remoteUrl ?? manualUrl;\nawait git.initRepo({\n...config,\nurl,\nextraCloneOpts: getStorageExtraCloneOpts(opts),\ncloneSubmodules,\ncloneSubmodulesFilter,\n});\nconst repoConfig: RepoResult = {\ndefaultBranch,\nisFork: false,\nrepoFingerprint: repoFingerprint(repo.id!, defaults.endpoint),\n};\nreturn repoConfig;\n}"
"export async function findPr({\nbranchName,\nprTitle,\nstate = 'all',\ntargetBranch,\n}: FindPRConfig): Promise<Pr | null> {\nlet prsFiltered: Pr[] = [];\ntry {\nconst prs = await getPrList();\nprsFiltered = prs.filter(\n(item) => item.sourceRefName === getNewBranchName(branchName),\n);\nif (prTitle) {\nprsFiltered = prsFiltered.filter(\n(item) => item.title.toUpperCase() === prTitle.toUpperCase(),\n);\n}\nswitch (state) {\ncase 'all':\nbreak;\ncase '!open':\nprsFiltered = prsFiltered.filter((item) => item.state !== 'open');\nbreak;\ndefault:\nprsFiltered = prsFiltered.filter((item) => item.state === state);\nbreak;\n}\n} catch (err) {\nlogger.error({ err }, 'findPr error');\n}\nif (prsFiltered.length === 0) {\nreturn null;\n}\nif (targetBranch && prsFiltered.length > 1) {\nconst pr = prsFiltered.find((item) => item.targetBranch === targetBranch);\nif (pr) {\nreturn pr;\n}\n}\nreturn prsFiltered[0];\n}"
"export async function getBranchStatus(\nbranchName: string,\ninternalChecksAsSuccess: boolean,\n): Promise<BranchStatus> {\nlogger.debug(`getBranchStatus(${branchName})`);\nconst statuses = await getStatusCheck(branchName);\nlogger.debug({ branch: branchName, statuses }, 'branch status check result');\nif (!statuses.length) {\nlogger.debug('empty branch status check result = returning `pending`');\nreturn 'yellow';\n}\nconst noOfFailures = statuses.filter(\n(status) =>\nstatus.state === GitStatusState.Error ||\nstatus.state === GitStatusState.Failed,\n).length;\nif (noOfFailures) {\nreturn 'red';\n}\nconst noOfPending = statuses.filter(\n(status) =>\nstatus.state === GitStatusState.NotSet ||\nstatus.state === GitStatusState.Pending,\n).length;\nif (noOfPending) {\nreturn 'yellow';\n}\nif (\n!internalChecksAsSuccess &&\nstatuses.every(\n(status) =>\nstatus.state === GitStatusState.Succeeded &&\nstatus.context?.genre === 'renovate',\n)\n) {\nlogger.debug(\n'Successful checks are all internal renovate/ checks, so returning `pending` branch status',\n);\nreturn 'yellow';\n}\nreturn 'green';\n}"
"export async function createPr({\nsourceBranch,\ntargetBranch,\nprTitle: title,\nprBody: body,\nlabels,\ndraftPR = false,\nplatformPrOptions,\n}: CreatePRConfig): Promise<Pr> {\nconst sourceRefName = getNewBranchName(sourceBranch);\nconst targetRefName = getNewBranchName(targetBranch);\nconst description = max4000Chars(sanitize(body));\nconst azureApiGit = await azureApi.gitApi();\nconst workItemRefs = [\n{\nid: platformPrOptions?.azureWorkItemId?.toString(),\n},\n];\nlet pr: GitPullRequest = await azureApiGit.createPullRequest(\n{\nsourceRefName,\ntargetRefName,\ntitle,\ndescription,\nworkItemRefs,\nisDraft: draftPR,\n},\nconfig.repoId,\n);\nif (platformPrOptions?.usePlatformAutomerge) {\nconst mergeStrategy =\nplatformPrOptions.automergeStrategy === 'auto'\n? await getMergeStrategy(pr.targetRefName!)\n: mapMergeStrategy(platformPrOptions.automergeStrategy);\npr = await azureApiGit.updatePullRequest(\n{\nautoCompleteSetBy: {\nid: pr.createdBy!.id,\n},\ncompletionOptions: {\nmergeStrategy,\ndeleteSourceBranch: true,\nmergeCommitMessage: title,\n},\n},\nconfig.repoId,\npr.pullRequestId!,\n);\n}\nif (platformPrOptions?.autoApprove) {\nawait azureApiGit.createPullRequestReviewer(\n{\nreviewerUrl: pr.createdBy!.url,\nvote: AzurePrVote.Approved,\nisFlagged: false,\nisRequired: false,\n},\nconfig.repoId,\npr.pullRequestId!,\npr.createdBy!.id!,\n);\n}\nawait Promise.all(\nlabels!.map((label) =>\nazureApiGit.createPullRequestLabel(\n{\nname: label,\n},\nconfig.repoId,\npr.pullRequestId!,\n),\n),\n);\nconst result = getRenovatePRFormat(pr);\nif (config.prList) {\nconfig.prList.push(result);\n}\nreturn result;\n}"
"export async function updatePr({\nnumber: prNo,\nprTitle: title,\nprBody: body,\nstate,\nplatformPrOptions,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlogger.debug(`updatePr(${prNo}, ${title}, body)`);\nconst azureApiGit = await azureApi.gitApi();\nconst objToUpdate: GitPullRequest = {\ntitle,\n};\nif (targetBranch) {\nobjToUpdate.targetRefName = getNewBranchName(targetBranch);\n}\nif (body) {\nobjToUpdate.description = max4000Chars(sanitize(body));\n}\nif (state === 'open') {\nawait azureApiGit.updatePullRequest(\n{\nstatus: PullRequestStatus.Active,\n},\nconfig.repoId,\nprNo,\n);\n} else if (state === 'closed') {\nobjToUpdate.status = PullRequestStatus.Abandoned;\n}\nif (platformPrOptions?.autoApprove) {\nconst pr = await azureApiGit.getPullRequestById(prNo, config.project);\nawait azureApiGit.createPullRequestReviewer(\n{\nreviewerUrl: pr.createdBy!.url,\nvote: AzurePrVote.Approved,\nisFlagged: false,\nisRequired: false,\n},\nconfig.repoId,\npr.pullRequestId!,\npr.createdBy!.id!,\n);\n}\nconst updatedPr = await azureApiGit.updatePullRequest(\nobjToUpdate,\nconfig.repoId,\nprNo,\n);\nif (config.prList) {\nconst prToCache = getRenovatePRFormat(updatedPr);\nconst existingIndex = config.prList.findIndex(\n(item) => item.number === prNo,\n);\nif (existingIndex === -1) {\nlogger.warn({ prNo }, 'PR not found in cache');\nconfig.prList.push(prToCache);\n}  else {\nconfig.prList[existingIndex] = prToCache;\n}\n}\n}"
"export async function ensureComment({\nnumber,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\nlogger.debug(`ensureComment(${number}, ${topic!}, content)`);\nconst header = topic ? `### ${topic}\n\n` : '';\nconst body = `${header}${sanitize(massageMarkdown(content))}`;\nconst azureApiGit = await azureApi.gitApi();\nconst threads = await azureApiGit.getThreads(config.repoId, number);\nlet threadIdFound: number | undefined;\nlet commentIdFound: number | undefined;\nlet commentNeedsUpdating = false;\nthreads.forEach((thread) => {\nconst firstCommentContent = thread.comments?.[0].content;\nif (\n(topic && firstCommentContent?.startsWith(header)) === true ||\n(!topic && firstCommentContent === body)\n) {\nthreadIdFound = thread.id;\ncommentIdFound = thread.comments?.[0].id;\ncommentNeedsUpdating = firstCommentContent !== body;\n}\n});\nif (!threadIdFound) {\nawait azureApiGit.createThread(\n{\ncomments: [{ content: body, commentType: 1, parentCommentId: 0 }],\nstatus: 1,\n},\nconfig.repoId,\nnumber,\n);\nlogger.info(\n{ repository: config.repository, issueNo: number, topic },\n'Comment added',\n);\n} else if (commentNeedsUpdating) {\nawait azureApiGit.updateComment(\n{\ncontent: body,\n},\nconfig.repoId,\nnumber,\nthreadIdFound,\ncommentIdFound!,\n);\nlogger.debug(\n{ repository: config.repository, issueNo: number, topic },\n'Comment updated',\n);\n} else {\nlogger.debug(\n{ repository: config.repository, issueNo: number, topic },\n'Comment is already update-to-date',\n);\n}\nreturn true;\n}"
"export async function ensureCommentRemoval(\nremoveConfig: EnsureCommentRemovalConfig,\n): Promise<void> {\nconst { number: issueNo } = removeConfig;\nconst key =\nremoveConfig.type === 'by-topic'\n? removeConfig.topic\n: removeConfig.content;\nlogger.debug(`Ensuring comment `${key}` in #${issueNo} is removed`);\nconst azureApiGit = await azureApi.gitApi();\nconst threads = await azureApiGit.getThreads(config.repoId, issueNo);\nlet threadIdFound: number | null | undefined = null;\nif (removeConfig.type === 'by-topic') {\nconst thread = threads.find(\n(thread: GitPullRequestCommentThread): boolean =>\n!!thread.comments?.[0].content?.startsWith(\n`### ${removeConfig.topic}\n\n`,\n),\n);\nthreadIdFound = thread?.id;\n} else {\nconst thread = threads.find(\n(thread: GitPullRequestCommentThread): boolean =>\nthread.comments?.[0].content?.trim() === removeConfig.content,\n);\nthreadIdFound = thread?.id;\n}\nif (threadIdFound) {\nawait azureApiGit.updateThread(\n{\nstatus: 4,\n},\nconfig.repoId,\nissueNo,\nthreadIdFound,\n);\n}\n}"
"export async function ensureComment({\nconfig,\nnumber: prNo,\ntopic,\ncontent,\n}: EnsureBitbucketCommentConfig): Promise<boolean> {\ntry {\nconst comments = await getComments(config, prNo);\nlet body: string;\nlet commentId: number | undefined;\nlet commentNeedsUpdating: boolean | undefined;\nif (topic) {\nlogger.debug(`Ensuring comment `${topic}` in #${prNo}`);\nbody = `### ${topic}\n\n${content}`;\ncomments.forEach((comment) => {\nif (comment.content.raw.startsWith(`### ${topic}\n\n`)) {\ncommentId = comment.id;\ncommentNeedsUpdating = comment.content.raw !== body;\n}\n});\n} else {\nlogger.debug(`Ensuring content-only comment in #${prNo}`);\nbody = `${content}`;\ncomments.forEach((comment) => {\nif (comment.content.raw === body) {\ncommentId = comment.id;\ncommentNeedsUpdating = false;\n}\n});\n}\nbody = sanitizeCommentBody(body);\nif (!commentId) {\nawait addComment(config, prNo, body);\nlogger.info(\n{ repository: config.repository, prNo, topic },\n'Comment added',\n);\n} else if (commentNeedsUpdating) {\nawait editComment(config, prNo, commentId, body);\nlogger.debug({ repository: config.repository, prNo }, 'Comment updated');\n} else {\nlogger.debug('Comment is already update-to-date');\n}\nreturn true;\n} catch (err)  {\nlogger.warn({ err }, 'Error ensuring comment');\nreturn false;\n}\n}"
"export async function initPlatform({\nendpoint,\nusername,\npassword,\ntoken,\n}: PlatformParams): Promise<PlatformResult> {\nif (!(username && password) && !token) {\nthrow new Error(\n'Init: You must configure either a Bitbucket token or username and password',\n);\n}\nif (endpoint && endpoint !== BITBUCKET_PROD_ENDPOINT) {\nlogger.warn(\n`Init: Bitbucket Cloud endpoint should generally be ${BITBUCKET_PROD_ENDPOINT} but is being configured to a different value. Did you mean to use Bitbucket Server?`,\n);\ndefaults.endpoint = endpoint;\n}\nsetBaseUrl(defaults.endpoint);\nrenovateUserUuid = null;\nconst options: HttpOptions = { memCache: false };\nif (token) {\noptions.token = token;\n} else {\noptions.username = username;\noptions.password = password;\n}\ntry {\nconst { uuid } = (\nawait bitbucketHttp.getJsonUnchecked<Account>('/2.0/user', options)\n).body;\nrenovateUserUuid = uuid;\n} catch (err) {\nif (\nerr.statusCode === 403 &&\nerr.body?.error?.detail?.required?.includes('account')\n) {\nlogger.warn(`Bitbucket: missing 'account' scope for password`);\n} else {\nlogger.debug({ err }, 'Unknown error fetching Bitbucket user identity');\n}\n}\nconst platformConfig: PlatformResult = {\nendpoint: endpoint ?? BITBUCKET_PROD_ENDPOINT,\n};\nreturn Promise.resolve(platformConfig);\n}"
"export async function findPr({\nbranchName,\nprTitle,\nstate = 'all',\nincludeOtherAuthors,\n}: FindPRConfig): Promise<Pr | null> {\nlogger.debug(`findPr(${branchName}, ${prTitle}, ${state})`);\nif (includeOtherAuthors) {\nconst prs = (\nawait bitbucketHttp.getJsonUnchecked<PagedResult<PrResponse>>(\n`/2.0/repositories/${config.repository}/pullrequests?q=source.branch.name=`${branchName}`&state=open`,\n{ cacheProvider: memCacheProvider },\n)\n).body.values;\nif (prs.length === 0) {\nlogger.debug(`No PR found for branch ${branchName}`);\nreturn null;\n}\nreturn utils.prInfo(prs[0]);\n}\nconst prList = await getPrList();\nconst pr = prList.find(\n(p) =>\np.sourceBranch === branchName &&\n(!prTitle || p.title.toUpperCase() === prTitle.toUpperCase()) &&\nmatchesState(p.state, state),\n);\nif (!pr) {\nreturn null;\n}\nlogger.debug(`Found PR #${pr.number}`);\nif (pr.state === 'closed') {\nconst reopenComments = await comments.reopenComments(config, pr.number);\nif (isNonEmptyArray(reopenComments)) {\nif (config.is_private) {\nlogger.debug(\n`Found '${comments.REOPEN_PR_COMMENT_KEYWORD}' comment from workspace member. Renovate will reopen PR ${pr.number} as a new PR`,\n);\nreturn null;\n}\nfor (const comment of reopenComments) {\nif (await isAccountMemberOfWorkspace(comment.user, config.repository)) {\nlogger.debug(\n`Found '${comments.REOPEN_PR_COMMENT_KEYWORD}' comment from workspace member. Renovate will reopen PR ${pr.number} as a new PR`,\n);\nreturn null;\n}\n}\n}\n}\nreturn pr;\n}"
"export async function ensureIssue({\ntitle,\nreuseTitle,\nbody,\n}: EnsureIssueConfig): Promise<EnsureIssueResult | null> {\nlogger.debug(`ensureIssue()`);\nif (!config.has_issues) {\nlogger.debug('Issues are disabled - cannot ensureIssue');\nlogger.debug(`Failed to ensure Issue with title:${title}`);\nreturn null;\n}\ntry {\nlet issues = await findOpenIssues(title);\nconst description = massageMarkdown(sanitize(body));\nif (!issues.length && reuseTitle) {\nissues = await findOpenIssues(reuseTitle);\n}\nif (issues.length) {\nfor (const issue of issues.slice(1)) {\nawait closeIssue(issue.id);\n}\nconst [issue] = issues;\nif (\nissue.title !== title ||\nString(issue.content?.raw).trim() !== description.trim()\n) {\nlogger.debug('Issue updated');\nawait bitbucketHttp.putJson(\n`/2.0/repositories/${config.repository}/issues/${issue.id}`,\n{\nbody: {\ncontent: {\nraw: readOnlyIssueBody(description),\nmarkup: 'markdown',\n},\n},\n},\n);\nreturn 'updated';\n}\n} else {\nlogger.info('Issue created');\nawait bitbucketHttp.postJson(\n`/2.0/repositories/${config.repository}/issues`,\n{\nbody: {\ntitle,\ncontent: {\nraw: readOnlyIssueBody(description),\nmarkup: 'markdown',\n},\n},\n},\n);\nreturn 'created';\n}\n} catch (err)  {\nif (err.message.startsWith('Repository has no issue tracker.')) {\nlogger.debug(`Issues are disabled, so could not create issue: ${title}`);\n} else {\nlogger.warn({ err }, 'Could not ensure issue');\n}\n}\nreturn null;\n}"
"async function sanitizeReviewers(\nreviewers: Account[],\nerr: any,\n): Promise<Account[] | undefined> {\nif (err.statusCode === 400 && err.body?.error?.fields?.reviewers) {\nconst sanitizedReviewers: Account[] = [];\nconst MSG_AUTHOR_AND_REVIEWER =\n'is the author and cannot be included as a reviewer.';\nconst MSG_MALFORMED_REVIEWERS_LIST = 'Malformed reviewers list';\nconst MSG_NOT_WORKSPACE_MEMBER =\n'is not a member of this workspace and cannot be added to this pull request';\nfor (const msg of err.body.error.fields.reviewers) {\nif (msg === MSG_MALFORMED_REVIEWERS_LIST) {\nlogger.debug(\n{ err },\n'PR contains reviewers that may be either inactive or no longer a member of this workspace. Will try setting only active reviewers',\n);\nfor (const reviewer of reviewers) {\nconst reviewerUser = (\nawait bitbucketHttp.getJsonUnchecked<Account>(\n`/2.0/users/${reviewer.uuid}`,\n{ cacheProvider: aggressiveRepoCacheProvider },\n)\n).body;\nif (reviewerUser.account_status === 'active') {\nif (await isAccountMemberOfWorkspace(reviewer, config.repository)) {\nsanitizedReviewers.push(reviewer);\n}\n}\n}\n} else if (msg.endsWith(MSG_NOT_WORKSPACE_MEMBER)) {\nlogger.debug(\n{ err },\n'PR contains reviewer accounts which are no longer member of this workspace. Will try setting only member reviewers',\n);\nfor (const reviewer of reviewers) {\nif (await isAccountMemberOfWorkspace(reviewer, config.repository)) {\nsanitizedReviewers.push(reviewer);\n}\n}\n} else if (msg.endsWith(MSG_AUTHOR_AND_REVIEWER)) {\nlogger.debug(\n{ err },\n'PR contains reviewer accounts which are also the author. Will try setting only non-author reviewers',\n);\nconst author = msg.replace(MSG_AUTHOR_AND_REVIEWER, '').trim();\nfor (const reviewer of reviewers) {\nif (reviewer.display_name !== author) {\nsanitizedReviewers.push(reviewer);\n}\n}\n} else {\nreturn undefined;\n}\n}\nreturn sanitizedReviewers;\n}\nreturn undefined;\n}"
"async function autoResolvePrTasks(pr: Pr): Promise<void> {\nlogger.debug(`Auto resolve PR tasks in #${pr.number}`);\ntry {\nconst unResolvedTasks = (\nawait bitbucketHttp.getJson(\n`/2.0/repositories/${config.repository}/pullrequests/${pr.number}/tasks`,\n{ paginate: true, pagelen: 100 },\nUnresolvedPrTasks,\n)\n).body;\nlogger.trace(\n{\nprId: pr.number,\nlistTaskRes: unResolvedTasks,\n},\n'List PR tasks',\n);\nfor (const task of unResolvedTasks) {\nconst res = await bitbucketHttp.putJson(\n`/2.0/repositories/${config.repository}/pullrequests/${pr.number}/tasks/${task.id}`,\n{\nbody: {\nstate: 'RESOLVED',\ncontent: {\nraw: task.content.raw,\n},\n},\n},\n);\nlogger.trace(\n{\nprId: pr.number,\nupdateTaskResponse: res,\n},\n'Put PR tasks - mark resolved',\n);\n}\n} catch (err) {\nlogger.warn({ prId: pr.number, err }, 'Error resolving PR tasks');\n}\n}"
"export async function updatePr({\nnumber: prNo,\nprTitle: title,\nprBody: description,\nstate,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlogger.debug(`updatePr(${prNo}, ${title}, body)`);\nconst pr = (\nawait bitbucketHttp.getJsonUnchecked<PrResponse>(\n`/2.0/repositories/${config.repository}/pullrequests/${prNo}`,\n)\n).body;\nlet updatedPrRes: PrResponse;\ntry {\nconst body: any = {\ntitle,\ndescription: sanitize(description),\nreviewers: pr.reviewers,\n};\nif (targetBranch) {\nbody.destination = {\nbranch: {\nname: targetBranch,\n},\n};\n}\nupdatedPrRes = (\nawait bitbucketHttp.putJson<PrResponse>(\n`/2.0/repositories/${config.repository}/pullrequests/${prNo}`,\n{ body },\n)\n).body;\n} catch (err) {\nconst sanitizedReviewers = await sanitizeReviewers(pr.reviewers, err);\nif (sanitizedReviewers === undefined) {\nthrow err;\n} else {\nupdatedPrRes = (\nawait bitbucketHttp.putJson<PrResponse>(\n`/2.0/repositories/${config.repository}/pullrequests/${prNo}`,\n{\nbody: {\ntitle,\ndescription: sanitize(description),\nreviewers: sanitizedReviewers,\n},\n},\n)\n).body;\n}\n}\nif (state === 'closed' && pr) {\nawait bitbucketHttp.postJson(\n`/2.0/repositories/${config.repository}/pullrequests/${prNo}/decline`,\n);\n}\nawait BitbucketPrCache.setPr(\nbitbucketHttp,\nconfig.repository,\nrenovateUserUuid,\nutils.prInfo({ ...updatedPrRes, ...(state && { state }) }),\n);\n}"
"function repoMock(\nendpoint: URL | string,\nprojectKey: string,\nrepositorySlug: string,\noptions: { cloneUrl: { https: boolean; ssh: boolean } } = {\ncloneUrl: { https: true, ssh: true },\n},\n) {\nconst endpointStr = endpoint.toString();\nconst links: {\nself: { href: string }[];\nclone?: { href: string; name: string }[];\n} = {\nself: [\n{\nhref: `${endpointStr}projects/${projectKey}/repos/${repositorySlug}/browse`,\n},\n],\n};\nif (options.cloneUrl.https || options.cloneUrl.ssh) {\nlinks.clone = [\noptions.cloneUrl.https\n? {\nhref: httpLink(endpointStr, projectKey, repositorySlug),\nname: 'http',\n}\n: null,\noptions.cloneUrl.ssh\n? {\nhref: sshLink(projectKey, repositorySlug),\nname: 'ssh',\n}\n: null,\n].filter(isTruthy);\n}\nreturn {\nslug: repositorySlug,\nid: 13076,\nname: repositorySlug,\nscmId: 'git',\nstate: 'AVAILABLE',\nstatusMessage: 'Available',\nforkable: true,\nproject: {\nkey: projectKey,\nid: 2900,\nname: `${repositorySlug}'s name`,\npublic: false,\ntype: 'NORMAL',\nlinks: {\nself: [\n{ href: `https:\n],\n},\n},\npublic: false,\nlinks,\n};\n}"
"export async function initRepo({\nrepository,\ncloneSubmodules,\ncloneSubmodulesFilter,\nignorePrAuthor,\ngitUrl,\n}: RepoParams): Promise<RepoResult> {\nlogger.debug(`initRepo(`${JSON.stringify({ repository }, null, 2)}`)`);\nconst opts = hostRules.find({\nhostType: defaults.hostType,\nurl: defaults.endpoint,\n});\nconst [projectKey, repositorySlug] = repository.split('/');\nconfig = {\nprojectKey,\nrepositorySlug,\nrepository,\nprVersions: new Map<number, number>(),\nusername: opts.username,\nignorePrAuthor,\n} as any;\ntry {\nconst info = (\nawait bitbucketServerHttp.getJsonUnchecked<BbsRestRepo>(\n`./rest/api/1.0/projects/${config.projectKey}/repos/${config.repositorySlug}`,\n)\n).body;\nconfig.owner = info.project.key;\nlogger.debug(`${repository} owner = ${config.owner}`);\nconst branchRes = await bitbucketServerHttp.getJsonUnchecked<BbsRestBranch>(\n`./rest/api/1.0/projects/${config.projectKey}/repos/${config.repositorySlug}/branches/default`,\n);\nif ([204, 404].includes(branchRes.statusCode)) {\nthrow new Error(REPOSITORY_EMPTY);\n}\nconst url = utils.getRepoGitUrl(\nconfig.repositorySlug,\ndefaults.endpoint!,\ngitUrl,\ninfo,\nopts,\n);\nawait git.initRepo({\n...config,\nurl,\nextraCloneOpts: getExtraCloneOpts(opts),\ncloneSubmodules,\ncloneSubmodulesFilter,\nfullClone: semver.lte(defaults.version, '8.0.0'),\n});\nconfig.mergeMethod = 'merge';\nconst repoConfig: RepoResult = {\ndefaultBranch: branchRes.body.displayId,\nisFork: !!info.origin,\nrepoFingerprint: repoFingerprint(info.id, defaults.endpoint),\n};\nreturn repoConfig;\n} catch (err)  {\nif (err.statusCode === 404) {\nthrow new Error(REPOSITORY_NOT_FOUND);\n}\nif (err.message === REPOSITORY_EMPTY) {\nthrow err;\n}\nlogger.debug({ err }, 'Unknown Bitbucket initRepo error');\nthrow err;\n}\n}"
"export async function findPr({\nbranchName,\nprTitle,\nstate = 'all',\nincludeOtherAuthors,\n}: FindPRConfig): Promise<Pr | null> {\nlogger.debug(`findPr(${branchName}, `${prTitle!}`, `${state}`)`);\nif (includeOtherAuthors) {\nconst searchParams: Record<string, string> = {\nstate: 'OPEN',\n};\nsearchParams.direction = 'outgoing';\nsearchParams.at = `refs/heads/${branchName}`;\nconst query = getQueryString(searchParams);\nconst prs = (\nawait bitbucketServerHttp.getJsonUnchecked<BbsRestPr[]>(\n`./rest/api/1.0/projects/${config.projectKey}/repos/${config.repositorySlug}/pull-requests?${query}`,\n{\npaginate: true,\nlimit: 1,\n},\n)\n).body;\nif (!prs.length) {\nlogger.debug(`No PR found for branch ${branchName}`);\nreturn null;\n}\nreturn utils.prInfo(prs[0]);\n}\nconst prList = await getPrList();\nconst pr = prList.find(isRelevantPr(branchName, prTitle, state));\nif (pr) {\nlogger.debug(`Found PR #${pr.number}`);\n} else {\nlogger.debug(`Renovate did not find a PR for branch #${branchName}`);\n}\nreturn pr ?? null;\n}"
"export async function setBranchStatus({\nbranchName,\ncontext,\ndescription,\nstate,\nurl: targetUrl,\n}: BranchStatusConfig): Promise<void> {\nlogger.debug(`setBranchStatus(${branchName})`);\nconst existingStatus = await getBranchStatusCheck(branchName, context);\nif (existingStatus === state) {\nreturn;\n}\nlogger.debug({ branch: branchName, context, state }, 'Setting branch status');\nconst branchCommit = git.getBranchCommit(branchName);\ntry {\nconst body: any = {\nkey: context,\ndescription,\nurl: targetUrl ?? 'https:\n};\nswitch (state) {\ncase 'green':\nbody.state = 'SUCCESSFUL';\nbreak;\ncase 'yellow':\nbody.state = 'INPROGRESS';\nbreak;\ncase 'red':\ndefault:\nbody.state = 'FAILED';\nbreak;\n}\nawait bitbucketServerHttp.postJson(\n`./rest/build-status/1.0/commits/${branchCommit!}`,\n{ body },\n);\nawait getStatus(branchName, false);\nawait getStatusCheck(branchName, false);\n} catch (err) {\nlogger.warn({ err }, `Failed to set branch status`);\n}\n}"
"async function updatePRAndAddReviewers(\nprNo: number,\nreviewers: string[],\n): Promise<void> {\ntry {\nconst pr = await getPr(prNo);\nif (!pr) {\nthrow new Error(REPOSITORY_NOT_FOUND);\n}\nconst reviewersSet = new Set([...pr.reviewers!, ...reviewers]);\nawait bitbucketServerHttp.putJson(\n`./rest/api/1.0/projects/${config.projectKey}/repos/${config.repositorySlug}/pull-requests/${prNo}`,\n{\nbody: {\ntitle: pr.title,\nversion: pr.version,\nreviewers: Array.from(reviewersSet).map((name) => ({\nuser: { name },\n})),\n},\n},\n);\nawait getPr(prNo, true);\n} catch (err) {\nlogger.warn({ err, reviewers, prNo }, `Failed to add reviewers`);\nif (err.statusCode === 404) {\nthrow new Error(REPOSITORY_NOT_FOUND);\n} else if (err.statusCode === 409) {\nif (utils.isInvalidReviewersResponse(err)) {\nconst invalidReviewers = utils.getInvalidReviewers(err);\nconst filteredReviewers = reviewers.filter(\n(name) => !invalidReviewers.includes(name),\n);\nawait updatePRAndAddReviewers(prNo, filteredReviewers);\n} else {\nlogger.debug(\n'409 response to adding reviewers - has repository changed?',\n);\nthrow new Error(REPOSITORY_CHANGED);\n}\n} else {\nthrow err;\n}\n}\n}"
"export async function ensureComment({\nnumber,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\nconst sanitizedContent = sanitize(content);\ntry {\nconst comments = await getComments(number);\nlet body: string;\nlet commentId: number | undefined;\nlet commentNeedsUpdating: boolean | undefined;\nif (topic) {\nlogger.debug(`Ensuring comment `${topic}` in #${number}`);\nbody = `### ${topic}\n\n${sanitizedContent}`;\ncomments.forEach((comment) => {\nif (comment.text.startsWith(`### ${topic}\n\n`)) {\ncommentId = comment.id;\ncommentNeedsUpdating = comment.text !== body;\n}\n});\n} else {\nlogger.debug(`Ensuring content-only comment in #${number}`);\nbody = `${sanitizedContent}`;\ncomments.forEach((comment) => {\nif (comment.text === body) {\ncommentId = comment.id;\ncommentNeedsUpdating = false;\n}\n});\n}\nif (!commentId) {\nawait addComment(number, body);\nlogger.info(\n{ repository: config.repository, prNo: number, topic },\n'Comment added',\n);\n} else if (commentNeedsUpdating) {\nawait editComment(number, commentId, body);\nlogger.debug(\n{ repository: config.repository, prNo: number },\n'Comment updated',\n);\n} else {\nlogger.debug('Comment is already update-to-date');\n}\nreturn true;\n} catch (err)  {\nlogger.warn({ err }, 'Error ensuring comment');\nreturn false;\n}\n}"
"async function getUsersFromReviewerGroup(groupName: string): Promise<string[]> {\nconst allGroups = [];\ntry {\nconst reviewerGroups = await bitbucketServerHttp.getJson(\n`./rest/api/1.0/projects/${config.projectKey}/repos/${config.repositorySlug}/settings/reviewer-groups`,\n{ paginate: true },\nReviewerGroups,\n);\nallGroups.push(...reviewerGroups.body);\n} catch (err) {\nlogger.debug({ err, groupName }, 'Failed to get reviewer groups for repo');\nreturn [];\n}\nconst repoGroup = allGroups.find(\n(group) => group.name === groupName && group.scope?.type === 'REPOSITORY',\n);\nif (repoGroup) {\nreturn repoGroup.users\n.filter((user) => user.active)\n.map((user) => user.slug);\n}\nconst projectGroup = allGroups.find(\n(group) => group.name === groupName && group.scope?.type === 'PROJECT',\n);\nif (projectGroup) {\nreturn projectGroup.users\n.filter((user) => user.active)\n.map((user) => user.slug);\n}\nlogger.warn(\n{ groupName },\n'Reviewer group not found at repo or project level',\n);\nreturn [];\n}"
"function infoMock(\nendpoint: URL | string,\nprojectKey: string,\nrepositorySlug: string,\noptions: { cloneUrl: { https: boolean; ssh: boolean } } = {\ncloneUrl: { https: true, ssh: true },\n},\n): BbsRestRepo {\nconst endpointStr = endpoint.toString();\nconst links: {\nself: { href: string }[];\nclone?: { href: string; name: string }[];\n} = {\nself: [\n{\nhref: `${endpointStr}projects/${projectKey}/repos/${repositorySlug}/browse`,\n},\n],\n};\nif (options.cloneUrl.https || options.cloneUrl.ssh) {\nlinks.clone = [];\nif (options.cloneUrl.https) {\nlinks.clone.push({\nhref: httpLink(endpointStr, projectKey, repositorySlug),\nname: 'http',\n});\n}\nif (options.cloneUrl.ssh) {\nlinks.clone.push({\nhref: sshLink(projectKey, repositorySlug),\nname: 'ssh',\n});\n}\nreturn {\nid: 123,\nslug: repositorySlug,\nproject: { key: projectKey },\norigin: { name: repositorySlug, slug: repositorySlug },\nlinks,\n};\n} else {\nreturn {\nid: 1,\nslug: repositorySlug,\nproject: { key: projectKey },\norigin: { name: repositorySlug, slug: repositorySlug },\nlinks: { clone: undefined },\n};\n}\n}"
"export function getCodeCommitUrl(\nrepoMetadata: RepositoryMetadata,\nrepoName: string,\n): string {\nlogger.debug('get code commit url');\nconst env = getEnv();\nif (!env.AWS_ACCESS_KEY_ID || !env.AWS_SECRET_ACCESS_KEY) {\nif (repoMetadata.cloneUrlHttp) {\nreturn repoMetadata.cloneUrlHttp;\n}\nreturn `https:\nenv.AWS_REGION ?? 'us-east-1'\n}.amazonaws.com/v1/repos/${repoName}`;\n}\nconst signer = new aws4.RequestSigner({\nservice: 'codecommit',\nhost: `git-codecommit.${env.AWS_REGION ?? 'us-east-1'}.amazonaws.com`,\nmethod: 'GIT',\npath: `v1/repos/${repoName}`,\n});\nconst dateTime = signer.getDateTime();\nif (!isString(dateTime)) {\nthrow new Error(REPOSITORY_UNINITIATED);\n}\nconst token = `${dateTime}Z${signer.signature()}`;\nlet username = `${env.AWS_ACCESS_KEY_ID}${\nenv.AWS_SESSION_TOKEN ? `%${env.AWS_SESSION_TOKEN}` : ''\n}`;\nif (username.includes('/')) {\nusername = username.replace(/\\n}\nreturn `https:\nenv.AWS_REGION ?? 'us-east-1'\n}.amazonaws.com/v1/repos/${repoName}`;\n}"
"export async function initPlatform({\nendpoint,\nusername,\npassword,\ntoken: awsToken,\n}: PlatformParams): Promise<PlatformResult> {\nconst accessKeyId = username;\nconst secretAccessKey = password;\nconst env = getEnv();\nlet region: string | undefined;\nif (accessKeyId) {\nenv.AWS_ACCESS_KEY_ID = accessKeyId;\n}\nif (secretAccessKey) {\nenv.AWS_SECRET_ACCESS_KEY = secretAccessKey;\n}\nif (awsToken) {\nenv.AWS_SESSION_TOKEN = awsToken;\n}\nif (endpoint) {\nconst regionReg = regEx(/.*codecommit\.(?<region>.+)\.amazonaws\.com/);\nconst codeCommitMatch = regionReg.exec(endpoint);\nregion = codeCommitMatch?.groups?.region;\nif (region) {\nenv.AWS_REGION = region;\n} else {\nlogger.warn(`Can't parse region, make sure your endpoint is correct`);\n}\n}\nclient.buildCodeCommitClient();\nawait client.listRepositories();\nconst platformConfig: PlatformResult = {\nendpoint:\nendpoint ??\n`https:\n};\nreturn Promise.resolve(platformConfig);\n}"
"export async function initRepo({\nrepository,\nendpoint,\n}: RepoParams): Promise<RepoResult> {\nlogger.debug(`initRepo(`${repository}`)`);\nconfig = { repository } as Config;\nlet repo;\ntry {\nrepo = await client.getRepositoryInfo(repository);\n} catch (err) {\nlogger.error({ err }, 'Could not find repository');\nthrow new Error(REPOSITORY_NOT_FOUND);\n}\nif (!repo?.repositoryMetadata) {\nlogger.error({ repository }, 'Could not find repository');\nthrow new Error(REPOSITORY_NOT_FOUND);\n}\nlogger.debug({ repositoryDetails: repo }, 'Repository details');\nconst metadata = repo.repositoryMetadata;\nconst url = client.getCodeCommitUrl(metadata, repository);\ntry {\nawait git.initRepo({\nurl,\n});\n} catch (err) {\nlogger.debug({ err }, 'Failed to git init');\nthrow new Error(PLATFORM_BAD_CREDENTIALS);\n}\nif (!metadata.defaultBranch || !metadata.repositoryId) {\nlogger.debug('Repo is empty');\nthrow new Error(REPOSITORY_EMPTY);\n}\nconst defaultBranch = metadata.defaultBranch;\nconfig.defaultBranch = defaultBranch;\nlogger.debug(`${repository} default branch = ${defaultBranch}`);\nreturn {\nrepoFingerprint: repoFingerprint(metadata.repositoryId, endpoint),\ndefaultBranch,\nisFork: false,\n};\n}"
"export async function getPrList(): Promise<CodeCommitPr[]> {\nlogger.debug('getPrList()');\nif (config.prList) {\nreturn config.prList;\n}\nconst listPrsResponse = await client.listPullRequests(config.repository!);\nconst fetchedPrs: CodeCommitPr[] = [];\nif (listPrsResponse && !listPrsResponse.pullRequestIds) {\nreturn fetchedPrs;\n}\nconst prIds = coerceArray(listPrsResponse.pullRequestIds);\nfor (const prId of prIds) {\nconst prRes = await client.getPr(prId);\nif (!prRes?.pullRequest) {\ncontinue;\n}\nconst prInfo = prRes.pullRequest;\nconst pr: CodeCommitPr = {\ntargetBranch: prInfo.pullRequestTargets![0].destinationReference!,\nsourceBranch: prInfo.pullRequestTargets![0].sourceReference!,\ndestinationCommit: prInfo.pullRequestTargets![0].destinationCommit!,\nsourceCommit: prInfo.pullRequestTargets![0].sourceCommit!,\nstate:\nprInfo.pullRequestStatus === PullRequestStatusEnum.OPEN\n? 'open'\n: 'closed',\nnumber: Number.parseInt(prId),\ntitle: prInfo.title!,\nbody: prInfo.description!,\n};\nfetchedPrs.push(pr);\n}\nconfig.prList = fetchedPrs;\nlogger.debug(`Retrieved Pull Requests, count: ${fetchedPrs.length}`);\nreturn fetchedPrs;\n}"
"export async function mergePr({\nbranchName,\nid: prNo,\nstrategy,\n}: MergePRConfig): Promise<boolean> {\nlogger.debug(`mergePr(${prNo}, ${branchName!})`);\nawait client.getPr(`${prNo}`);\nreturn Promise.resolve(false);\n}"
"export async function ensureComment({\nnumber,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\nlogger.debug(`ensureComment(${number}, ${topic!}, content)`);\nconst header = topic ? `### ${topic}\n\n` : '';\nconst body = `${header}${sanitize(content)}`;\nlet prCommentsResponse: GetCommentsForPullRequestOutput;\ntry {\nprCommentsResponse = await client.getPrComments(`${number}`);\n} catch (err) {\nlogger.debug({ err }, 'Unable to retrieve pr comments');\nreturn false;\n}\nlet commentId: string | undefined = undefined;\nlet commentNeedsUpdating = false;\nif (!prCommentsResponse?.commentsForPullRequestData) {\nreturn false;\n}\nfor (const commentObj of prCommentsResponse.commentsForPullRequestData) {\nif (!commentObj?.comments) {\ncontinue;\n}\nconst firstCommentContent = commentObj.comments[0].content;\nif (\n(topic && firstCommentContent?.startsWith(header)) === true ||\n(!topic && firstCommentContent === body)\n) {\ncommentId = commentObj.comments[0].commentId;\ncommentNeedsUpdating = firstCommentContent !== body;\nbreak;\n}\n}\nif (!commentId) {\nconst prs = await getPrList();\nconst thisPr = prs.filter((item) => item.number === number);\nif (!thisPr[0].sourceCommit || !thisPr[0].destinationCommit) {\nreturn false;\n}\nawait client.createPrComment(\n`${number}`,\nconfig.repository,\nbody,\nthisPr[0].destinationCommit,\nthisPr[0].sourceCommit,\n);\nlogger.info(\n{ repository: config.repository, prNo: number, topic },\n'Comment added',\n);\n} else if (commentNeedsUpdating && commentId) {\nawait client.updateComment(commentId, body);\nlogger.debug(\n{ repository: config.repository, prNo: number, topic },\n'Comment updated',\n);\n} else {\nlogger.debug(\n{ repository: config.repository, prNo: number, topic },\n'Comment is already update-to-date',\n);\n}\nreturn true;\n}"
"export async function ensureCommentRemoval(\nremoveConfig: EnsureCommentRemovalConfig,\n): Promise<void> {\nconst { number: prNo } = removeConfig;\nconst key =\nremoveConfig.type === 'by-topic'\n? removeConfig.topic\n: removeConfig.content;\nlogger.debug(`Ensuring comment `${key}` in #${prNo} is removed`);\nlet prCommentsResponse: GetCommentsForPullRequestOutput;\ntry {\nprCommentsResponse = await client.getPrComments(`${prNo}`);\n} catch (err) {\nlogger.debug({ err }, 'Unable to retrieve pr comments');\nreturn;\n}\nif (!prCommentsResponse?.commentsForPullRequestData) {\nlogger.debug('commentsForPullRequestData not found');\nreturn;\n}\nlet commentIdToRemove: string | undefined;\nfor (const commentObj of prCommentsResponse.commentsForPullRequestData) {\nif (!commentObj?.comments) {\nlogger.debug(\n'comments object not found under commentsForPullRequestData',\n);\ncontinue;\n}\nfor (const comment of commentObj.comments) {\nif (\n(removeConfig.type === 'by-topic' &&\ncomment.content?.startsWith(`### ${removeConfig.topic}\n\n`)) ===\ntrue ||\n(removeConfig.type === 'by-content' &&\nremoveConfig.content === comment.content?.trim())\n) {\ncommentIdToRemove = comment.commentId;\nbreak;\n}\n}\nif (commentIdToRemove) {\nawait client.deleteComment(commentIdToRemove);\nlogger.debug(`comment `${key}` in PR #${prNo} was removed`);\nbreak;\n}\n}\n}"
"async initPlatform({\nendpoint,\ntoken,\n}: PlatformParams): Promise<PlatformResult> {\nif (!token) {\nthrow new Error(\n'Init: You must configure a Forgejo personal access token',\n);\n}\nif (endpoint) {\nlet baseEndpoint = trimTrailingApiPath(endpoint);\nbaseEndpoint = ensureTrailingSlash(baseEndpoint);\ndefaults.endpoint = baseEndpoint;\n} else {\nlogger.debug('Using default Forgejo endpoint: ' + defaults.endpoint);\n}\nsetBaseUrl(defaults.endpoint);\nlet gitAuthor: string;\ntry {\nconst user = await helper.getCurrentUser({ token });\ngitAuthor = `${user.full_name ?? user.username} <${user.email}>`;\nbotUserID = user.id;\nbotUserName = user.username;\nconst env = getEnv();\nif (semver.valid(env.RENOVATE_X_PLATFORM_VERSION)) {\ndefaults.version = env.RENOVATE_X_PLATFORM_VERSION!;\n}  else {\ndefaults.version = await helper.getVersion({ token });\n}\nlogger.debug(`Forgejo version: ${defaults.version}`);\n} catch (err) {\nlogger.debug(\n{ err },\n'Error authenticating with Forgejo. Check your token',\n);\nthrow new Error('Init: Authentication failure');\n}\nreturn {\nendpoint: defaults.endpoint,\ngitAuthor,\n};\n},"
"async getRepos(config?: AutodiscoverConfig): Promise<string[]> {\nlogger.debug('Auto-discovering Forgejo repositories');\ntry {\nif (config?.topics) {\nlogger.debug({ topics: config.topics }, 'Auto-discovering by topics');\nconst fetchRepoArgs: FetchRepositoriesArgs[] = config.topics.map(\n(topic) => {\nreturn {\ntopic,\nsort: config.sort,\norder: config.order,\n};\n},\n);\nconst repos = await map(fetchRepoArgs, fetchRepositories);\nreturn deduplicateArray(repos.flat());\n} else if (config?.namespaces) {\nlogger.debug(\n{ namespaces: config.namespaces },\n'Auto-discovering by organization',\n);\nconst repos = await map(\nconfig.namespaces,\nasync (organization: string) => {\nconst orgRepos = await helper.orgListRepos(organization);\nreturn orgRepos\n.filter((r) => !r.mirror && !r.archived)\n.map((r) => r.full_name);\n},\n);\nreturn deduplicateArray(repos.flat());\n} else {\nreturn await fetchRepositories({\nsort: config?.sort,\norder: config?.order,\n});\n}\n} catch (err) {\nlogger.error({ err }, 'Forgejo getRepos() error');\nthrow err;\n}\n},"
"async updatePr({\nnumber,\nprTitle,\nprBody: body,\nlabels,\nstate,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlet title = prTitle;\nif ((await getPrList()).find((pr) => pr.number === number)?.isDraft) {\ntitle = DRAFT_PREFIX + title;\n}\nconst prUpdateParams: PRUpdateParams = {\ntitle,\n...(body && { body }),\n...(state && { state }),\n};\nif (targetBranch) {\nprUpdateParams.base = targetBranch;\n}\nif (Array.isArray(labels)) {\nprUpdateParams.labels = (await map(labels, lookupLabelByName)).filter(\nisNumber,\n);\nif (labels.length !== prUpdateParams.labels.length) {\nlogger.warn(\n'Some labels could not be looked up. Renovate may halt label updates assuming changes by others.',\n);\n}\n}\nconst gpr = await helper.updatePR(\nconfig.repository,\nnumber,\nprUpdateParams,\n);\nconst pr = toRenovatePR(gpr, botUserName);\nif (pr) {\nawait ForgejoPrCache.setPr(\nforgejoHttp,\nconfig.repository,\nconfig.ignorePrAuthor,\nbotUserName,\npr,\n);\n}\n},"
"async ensureComment({\nnumber: issue,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\ntry {\nlet body = sanitize(content);\nconst commentList = await helper.getComments(config.repository, issue);\nlet comment: Comment | null = null;\nif (topic) {\ncomment = findCommentByTopic(commentList, topic);\nbody = `### ${topic}\n\n${body}`;\n} else {\ncomment = findCommentByContent(commentList, body);\n}\nif (!comment) {\ncomment = await helper.createComment(config.repository, issue, body);\nlogger.info(\n{ repository: config.repository, issue, comment: comment.id },\n'Comment added',\n);\n} else if (comment.body === body) {\nlogger.debug(`Comment #${comment.id} is already up-to-date`);\n} else {\nawait helper.updateComment(config.repository, comment.id, body);\nlogger.debug(\n{ repository: config.repository, issue, comment: comment.id },\n'Comment updated',\n);\n}\nreturn true;\n} catch (err) {\nlogger.warn({ err, issue, subject: topic }, 'Error ensuring comment');\nreturn false;\n}\n},"
"export function getRepoUrl(\nrepo: Repo,\ngitUrl: GitUrlOption | undefined,\nendpoint: string,\n): string {\nif (gitUrl === 'ssh') {\nif (!repo.ssh_url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nlogger.debug(`Using SSH URL: ${repo.ssh_url}`);\nreturn repo.ssh_url;\n}\nconst opts = hostRules.find({\nhostType: 'forgejo',\nurl: endpoint,\n});\nif (gitUrl === 'endpoint') {\nconst url = parseUrl(endpoint);\nif (!url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nurl.username = opts.token ?? '';\nurl.pathname = `${url.pathname}${repo.full_name}.git`;\nlogger.debug(\n{ url: url.toString() },\n'using URL based on configured endpoint',\n);\nreturn url.toString();\n}\nif (!repo.clone_url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nlogger.debug(`Using HTTP URL: ${repo.clone_url}`);\nconst repoUrl = parseUrl(repo.clone_url);\nif (!repoUrl) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nrepoUrl.username = opts.token ?? '';\nreturn repoUrl.toString();\n}"
"export function toRenovatePR(data: PR, author: string | null): Pr | null {\nif (!data) {\nreturn null;\n}\nif (\n!data.base?.ref ||\n!data.head?.label ||\n!data.head?.sha ||\n!data.head?.repo?.full_name\n) {\nlogger.trace(\n`Skipping Pull Request #${data.number} due to missing base and/or head branch`,\n);\nreturn null;\n}\nconst createdBy = data.user?.username;\nif (\ncreatedBy &&\nauthor &&\n!reconfigurePrRegex.test(data.head.label) &&\ncreatedBy !== author\n) {\nreturn null;\n}\nlet title = data.title;\nlet isDraft = false;\nif (title.startsWith(DRAFT_PREFIX)) {\ntitle = title.substring(DRAFT_PREFIX.length);\nisDraft = true;\n}\nconst labels = (data?.labels ?? []).map((l) => l.name);\nreturn {\nlabels,\nnumber: data.number,\nstate: data.merged ? 'merged' : data.state,\ntitle,\nisDraft,\nbodyStruct: getPrBodyStruct(data.body),\nsha: data.head.sha,\nsourceBranch: data.head.label,\ntargetBranch: data.base.ref,\nsourceRepo: data.head.repo.full_name,\ncreatedAt: data.created_at,\ncannotMergeReason: data.mergeable\n? undefined\n: `pr.mergeable=`${data.mergeable}``,\nhasAssignees: !!(data.assignee?.login ?? isNonEmptyArray(data.assignees)),\n};\n}"
"async findChanges(\nrepository: string,\nfindPRConfig: GerritFindPRConfig,\n): Promise<GerritChange[]> {\nconst startOffset = findPRConfig.startOffset ?? 0;\nconst pageLimit = findPRConfig.singleChange\n? 1\n: (findPRConfig.pageLimit ?? 50);\nconst query: Record<string, any> = {\nn: pageLimit,\n};\nif (findPRConfig.requestDetails) {\nquery.o = findPRConfig.requestDetails;\n}\nconst filters = GerritClient.buildSearchFilters(repository, findPRConfig);\nconst allChanges: GerritChange[] = [];\nwhile (true) {\nquery.S = allChanges.length + startOffset;\nconst queryString = `q=${filters.join('+')}&${getQueryString(query)}`;\nconst changes = await this.gerritHttp.getJsonUnchecked<GerritChange[]>(\n`a/changes/?${queryString}`,\n);\nlogger.trace(\n`findChanges(${queryString},start=${query.S},limit=${query.n}) => ${changes.body.length}`,\n);\nconst lastChange = changes.body.at(-1);\nlet hasMoreChanges = false;\nif (lastChange?._more_changes) {\nhasMoreChanges = true;\ndelete lastChange._more_changes;\n}\nallChanges.push(...changes.body);\nif (\nfindPRConfig.singleChange ||\nfindPRConfig.noPagination ||\n!hasMoreChanges\n) {\nbreak;\n}\n}\nreturn allChanges;\n}"
"export async function initRepo({\nrepository,\ngitUrl,\n}: RepoParams): Promise<RepoResult> {\nlogger.debug(`initRepo(${repository}, ${gitUrl})`);\nconst projectInfo = await client.getProjectInfo(repository);\nconst branchInfo = await client.getBranchInfo(repository);\nconfig = {\n...config,\nrepository,\nhead: branchInfo.revision,\nconfig: projectInfo,\nlabels: projectInfo.labels ?? {},\n};\nconst baseUrl = defaults.endpoint!;\nconst url = getGerritRepoUrl(repository, baseUrl);\nconfigureScm(repository, config.gerritUsername!);\nawait git.initRepo({ url });\nconst rejectedChanges = await client.findChanges(config.repository!, {\nbranchName: '',\nstate: 'open',\nlabel: '-2',\n});\nfor (const change of rejectedChanges) {\nawait client.abandonChange(\nchange._number,\n'This change has been abandoned as it was voted with Code-Review -2.',\n);\nlogger.info(\n`Abandoned change ${change._number} with Code-Review -2 in repository ${repository}`,\n);\n}\nconst repoConfig: RepoResult = {\ndefaultBranch: config.head!,\nisFork: false,\nrepoFingerprint: repoFingerprint(repository, baseUrl),\n};\nreturn repoConfig;\n}"
"override async commitAndPush(\ncommit: CommitFilesConfig,\n): Promise<LongCommitSha | null> {\nlogger.debug(`commitAndPush(${commit.branchName})`);\nconst searchConfig: GerritFindPRConfig = {\nstate: 'open',\nbranchName: commit.branchName,\ntargetBranch: commit.baseBranch,\nsingleChange: true,\nrequestDetails: ['CURRENT_REVISION'],\n};\nconst existingChange = (\nawait client.findChanges(repository, searchConfig)\n).pop();\nlet hasChanges = true;\nconst message =\ntypeof commit.message === 'string' ? [commit.message] : commit.message;\nif (commit.prTitle) {\nconst firstMessageLines = message[0].split('\n');\nfirstMessageLines[0] = commit.prTitle;\nmessage[0] = firstMessageLines.join('\n');\n}\nconst changeId = existingChange?.change_id ?? generateChangeId();\ncommit.message = [\n...message,\n`Renovate-Branch: ${commit.branchName}\nChange-Id: ${changeId}`,\n];\nconst commitResult = await git.prepareCommit({ ...commit, force: true });\nif (commitResult) {\nconst { commitSha } = commitResult;\nif (existingChange) {\nconst currentRevision =\nexistingChange.revisions![existingChange.current_revision!];\nconst fetchRefSpec = currentRevision.ref;\nawait git.fetchRevSpec(fetchRefSpec);\nhasChanges = await git.hasDiff('HEAD', 'FETCH_HEAD');\n}\nif (hasChanges || commit.force) {\nconst pushOptions = ['notify=NONE'];\nif (commit.autoApprove) {\npushOptions.push('label=Code-Review+2');\n}\nif (commit.labels) {\nfor (const label of commit.labels) {\npushOptions.push(`hashtag=${label}`);\n}\n}\nconst pushResult = await git.pushCommit({\nsourceRef: commit.branchName,\ntargetRef: `refs/for/${commit.baseBranch!}`,\nfiles: commit.files,\npushOptions,\n});\nif (pushResult) {\nreturn commitSha;\n}\n}\n}\nreturn null;\n}"
"async initPlatform({\nendpoint,\ntoken,\n}: PlatformParams): Promise<PlatformResult> {\nif (!token) {\nthrow new Error('Init: You must configure a Gitea personal access token');\n}\nif (endpoint) {\nlet baseEndpoint = trimTrailingApiPath(endpoint);\nbaseEndpoint = ensureTrailingSlash(baseEndpoint);\ndefaults.endpoint = baseEndpoint;\n} else {\nlogger.debug('Using default Gitea endpoint: ' + defaults.endpoint);\n}\nsetBaseUrl(defaults.endpoint);\nlet gitAuthor: string;\ntry {\nconst user = await helper.getCurrentUser({ token });\ngitAuthor = `${user.full_name ?? user.username} <${user.email}>`;\nbotUserID = user.id;\nbotUserName = user.username;\nconst env = getEnv();\nif (semver.valid(env.RENOVATE_X_PLATFORM_VERSION)) {\ndefaults.version = env.RENOVATE_X_PLATFORM_VERSION!;\n}  else {\ndefaults.version = await helper.getVersion({ token });\n}\nif (defaults.version?.includes('gitea-')) {\ndefaults.isForgejo = true;\nlogger.info(\n`Detected Forgejo instance, please use 'forgejo' platform instead`,\n);\n}\nlogger.debug(\n`${defaults.isForgejo ? 'Forgejo' : 'Gitea'} version: ${defaults.version}`,\n);\n} catch (err) {\nlogger.debug(\n{ err },\n'Error authenticating with Gitea. Check your token',\n);\nthrow new Error('Init: Authentication failure');\n}\nreturn {\nendpoint: defaults.endpoint,\ngitAuthor,\n};\n},"
"async getRepos(config?: AutodiscoverConfig): Promise<string[]> {\nlogger.debug('Auto-discovering Gitea repositories');\ntry {\nif (config?.topics) {\nlogger.debug({ topics: config.topics }, 'Auto-discovering by topics');\nconst fetchRepoArgs: FetchRepositoriesArgs[] = config.topics.map(\n(topic) => {\nreturn {\ntopic,\nsort: config.sort,\norder: config.order,\n};\n},\n);\nconst repos = await map(fetchRepoArgs, fetchRepositories);\nreturn deduplicateArray(repos.flat());\n} else if (config?.namespaces) {\nlogger.debug(\n{ namespaces: config.namespaces },\n'Auto-discovering by organization',\n);\nconst repos = await map(\nconfig.namespaces,\nasync (organization: string) => {\nconst orgRepos = await helper.orgListRepos(organization);\nreturn orgRepos\n.filter((r) => !r.mirror && !r.archived)\n.map((r) => r.full_name);\n},\n);\nreturn deduplicateArray(repos.flat());\n} else {\nreturn await fetchRepositories({\nsort: config?.sort,\norder: config?.order,\n});\n}\n} catch (err) {\nlogger.error({ err }, 'Gitea getRepos() error');\nthrow err;\n}\n},"
"async updatePr({\nnumber,\nprTitle,\nprBody: body,\nlabels,\nstate,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlet title = prTitle;\nif ((await getPrList()).find((pr) => pr.number === number)?.isDraft) {\ntitle = DRAFT_PREFIX + title;\n}\nconst prUpdateParams: PRUpdateParams = {\ntitle,\n...(body && { body }),\n...(state && { state }),\n};\nif (targetBranch) {\nprUpdateParams.base = targetBranch;\n}\nif (Array.isArray(labels)) {\nprUpdateParams.labels = (await map(labels, lookupLabelByName)).filter(\nisNumber,\n);\nif (labels.length !== prUpdateParams.labels.length) {\nlogger.warn(\n'Some labels could not be looked up. Renovate may halt label updates assuming changes by others.',\n);\n}\n}\nconst gpr = await helper.updatePR(\nconfig.repository,\nnumber,\nprUpdateParams,\n);\nconst pr = toRenovatePR(gpr, botUserName);\nif (pr) {\nawait GiteaPrCache.setPr(\ngiteaHttp,\nconfig.repository,\nconfig.ignorePrAuthor,\nbotUserName,\npr,\n);\n}\n},"
"async ensureComment({\nnumber: issue,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\ntry {\nlet body = sanitize(content);\nconst commentList = await helper.getComments(config.repository, issue);\nlet comment: Comment | null = null;\nif (topic) {\ncomment = findCommentByTopic(commentList, topic);\nbody = `### ${topic}\n\n${body}`;\n} else {\ncomment = findCommentByContent(commentList, body);\n}\nif (!comment) {\ncomment = await helper.createComment(config.repository, issue, body);\nlogger.info(\n{ repository: config.repository, issue, comment: comment.id },\n'Comment added',\n);\n} else if (comment.body === body) {\nlogger.debug(`Comment #${comment.id} is already up-to-date`);\n} else {\nawait helper.updateComment(config.repository, comment.id, body);\nlogger.debug(\n{ repository: config.repository, issue, comment: comment.id },\n'Comment updated',\n);\n}\nreturn true;\n} catch (err) {\nlogger.warn({ err, issue, subject: topic }, 'Error ensuring comment');\nreturn false;\n}\n},"
"export function getRepoUrl(\nrepo: Repo,\ngitUrl: GitUrlOption | undefined,\nendpoint: string,\n): string {\nif (gitUrl === 'ssh') {\nif (!repo.ssh_url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nlogger.debug(`Using SSH URL: ${repo.ssh_url}`);\nreturn repo.ssh_url;\n}\nconst opts = hostRules.find({\nhostType: 'gitea',\nurl: endpoint,\n});\nif (gitUrl === 'endpoint') {\nconst url = parseUrl(endpoint);\nif (!url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nurl.username = opts.token ?? '';\nurl.pathname = `${url.pathname}${repo.full_name}.git`;\nlogger.debug(\n{ url: url.toString() },\n'using URL based on configured endpoint',\n);\nreturn url.toString();\n}\nif (!repo.clone_url) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nlogger.debug(`Using HTTP URL: ${repo.clone_url}`);\nconst repoUrl = parseUrl(repo.clone_url);\nif (!repoUrl) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nrepoUrl.username = opts.token ?? '';\nreturn repoUrl.toString();\n}"
"export function toRenovatePR(data: PR, author: string | null): Pr | null {\nif (!data) {\nreturn null;\n}\nif (\n!data.base?.ref ||\n!data.head?.label ||\n!data.head?.sha ||\n!data.head?.repo?.full_name\n) {\nlogger.trace(\n`Skipping Pull Request #${data.number} due to missing base and/or head branch`,\n);\nreturn null;\n}\nconst createdBy = data.user?.username;\nif (\ncreatedBy &&\nauthor &&\n!reconfigurePrRegex.test(data.head.label) &&\ncreatedBy !== author\n) {\nreturn null;\n}\nlet title = data.title;\nlet isDraft = false;\nif (title.startsWith(DRAFT_PREFIX)) {\ntitle = title.substring(DRAFT_PREFIX.length);\nisDraft = true;\n}\nconst labels = (data?.labels ?? []).map((l) => l.name);\nreturn {\nlabels,\nnumber: data.number,\nstate: data.merged ? 'merged' : data.state,\ntitle,\nisDraft,\nbodyStruct: getPrBodyStruct(data.body),\nsha: data.head.sha,\nsourceBranch: data.head.label,\ntargetBranch: data.base.ref,\nsourceRepo: data.head.repo.full_name,\ncreatedAt: data.created_at,\ncannotMergeReason: data.mergeable\n? undefined\n: `pr.mergeable=`${data.mergeable}``,\nhasAssignees: !!(data.assignee?.login ?? isNonEmptyArray(data.assignees)),\n};\n}"
"export function coerceRestPr(pr: GhRestPr): GhPr {\nconst bodyStruct = pr.bodyStruct ?? getPrBodyStruct(pr.body);\nconst result: GhPr = {\nnumber: pr.number,\nsourceBranch: pr.head?.ref,\ntitle: pr.title,\nstate:\npr.state === 'closed' && isString(pr.merged_at) ? 'merged' : pr.state,\nbodyStruct,\nupdated_at: pr.updated_at,\nnode_id: pr.node_id,\n};\nif (pr.head?.sha) {\nresult.sha = pr.head.sha;\n}\nif (pr.head?.repo?.full_name) {\nresult.sourceRepo = pr.head.repo.full_name;\n}\nif (pr.labels) {\nresult.labels = pr.labels.map(({ name }) => name);\n}\nif (!!pr.assignee || isNonEmptyArray(pr.assignees)) {\nresult.hasAssignees = true;\n}\nif (pr.requested_reviewers) {\nresult.reviewers = pr.requested_reviewers\n.map(({ login }) => login)\n.filter(isNonEmptyString);\n}\nif (pr.created_at) {\nresult.createdAt = pr.created_at;\n}\nif (pr.closed_at) {\nresult.closedAt = pr.closed_at;\n}\nif (pr.base?.ref) {\nresult.targetBranch = pr.base.ref;\n}\nreturn result;\n}"
"export async function findPr({\nbranchName,\nprTitle,\nstate = 'all',\nincludeOtherAuthors,\n}: FindPRConfig): Promise<GhPr | null> {\nlogger.debug(`findPr(${branchName}, ${prTitle}, ${state})`);\nif (includeOtherAuthors) {\nconst repo = config.parentRepo ?? config.repository;\nconst org = repo?.split('/')[0];\nconst { body: prList } = await githubApi.getJsonUnchecked<GhRestPr[]>(\n`repos/${repo}/pulls?head=${org}:${branchName}&state=open`,\n{ cacheProvider: repoCacheProvider },\n);\nif (!prList.length) {\nlogger.debug(`No PR found for branch ${branchName}`);\nreturn null;\n}\nreturn coerceRestPr(prList[0]);\n}\nconst prList = await getPrList();\nconst pr = prList.find((p) => {\nif (p.sourceBranch !== branchName) {\nreturn false;\n}\nif (prTitle && prTitle.toUpperCase() !== p.title.toUpperCase()) {\nreturn false;\n}\nif (!matchesState(p.state, state)) {\nreturn false;\n}\nif (!config.forkToken && !looseEquals(config.repository, p.sourceRepo)) {\nreturn false;\n}\nreturn true;\n});\nif (pr) {\nlogger.debug(`Found PR #${pr.number}`);\n}\nreturn pr ?? null;\n}"
"export async function tryReuseAutoclosedPr(\nautoclosedPr: Pr,\nnewTitle: string,\n): Promise<Pr | null> {\nconst { sha, number, sourceBranch: branchName } = autoclosedPr;\ntry {\nawait ensureBranchSha(branchName, sha!);\nlogger.debug(`Recreated autoclosed branch ${branchName} with sha ${sha}`);\n} catch (err) {\nlogger.debug(\n{ err, branchName, sha, autoclosedPr },\n'Could not recreate autoclosed branch - skipping reopen',\n);\nreturn null;\n}\ntry {\nconst { body: ghPr } = await githubApi.patchJson<GhRestPr>(\n`repos/${config.repository}/pulls/${number}`,\n{\nbody: {\nstate: 'open',\ntitle: newTitle,\n},\n},\n);\nlogger.info(\n{ branchName, oldTitle: autoclosedPr.title, newTitle, number },\n'Successfully reopened autoclosed PR',\n);\nconst result = coerceRestPr(ghPr);\nconst localSha = git.getBranchCommit(branchName);\nif (localSha && localSha !== sha) {\nawait git.forcePushToRemote(branchName, 'origin');\nresult.sha = localSha;\n}\ncachePr(result);\nreturn result;\n} catch {\nlogger.debug('Could not reopen autoclosed PR');\nreturn null;\n}\n}"
"export async function setBranchStatus({\nbranchName,\ncontext,\ndescription,\nstate,\nurl: targetUrl,\n}: BranchStatusConfig): Promise<void> {\nif (config.parentRepo) {\nlogger.debug('Cannot set branch status when in forking mode');\nreturn;\n}\nconst existingStatus = await getBranchStatusCheck(branchName, context);\nif (existingStatus === state) {\nreturn;\n}\nlogger.debug({ branch: branchName, context, state }, 'Setting branch status');\nlet url: string | undefined;\ntry {\nconst branchCommit = git.getBranchCommit(branchName);\nurl = `repos/${config.repository}/statuses/${branchCommit}`;\nconst renovateToGitHubStateMapping = {\ngreen: 'success',\nyellow: 'pending',\nred: 'failure',\n};\nconst options: any = {\nstate: renovateToGitHubStateMapping[state],\ndescription,\ncontext,\n};\nif (targetUrl) {\noptions.target_url = targetUrl;\n}\nawait githubApi.postJson(url, { body: options });\nawait getStatus(branchName, false);\nawait getStatusCheck(branchName, false);\n} catch (err)  {\nlogger.debug({ err, url }, 'Caught error setting branch status - aborting');\nthrow new Error(REPOSITORY_CHANGED);\n}\n}"
"export async function ensureComment({\nnumber,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\nconst sanitizedContent = sanitize(content);\ntry {\nconst comments = await getComments(number);\nlet body: string;\nlet commentId: number | null = null;\nlet commentNeedsUpdating = false;\nif (topic) {\nlogger.debug(`Ensuring comment `${topic}` in #${number}`);\nbody = `### ${topic}\n\n${sanitizedContent}`;\ncomments.forEach((comment) => {\nif (comment.body.startsWith(`### ${topic}\n\n`)) {\ncommentId = comment.id;\ncommentNeedsUpdating = comment.body !== body;\n}\n});\n} else {\nlogger.debug(`Ensuring content-only comment in #${number}`);\nbody = `${sanitizedContent}`;\ncomments.forEach((comment) => {\nif (comment.body === body) {\ncommentId = comment.id;\ncommentNeedsUpdating = false;\n}\n});\n}\nif (!commentId) {\nawait addComment(number, body);\nlogger.info(\n{ repository: config.repository, issueNo: number, topic },\n'Comment added',\n);\n} else if (commentNeedsUpdating) {\nawait editComment(commentId, body);\nlogger.debug(\n{ repository: config.repository, issueNo: number },\n'Comment updated',\n);\n} else {\nlogger.debug('Comment is already update-to-date');\n}\nreturn true;\n} catch (err)  {\nif (err instanceof ExternalHostError) {\nthrow err;\n}\nif (err.body?.message?.includes('is locked')) {\nlogger.debug('Issue is locked - cannot add comment');\n} else {\nlogger.warn({ err }, 'Error ensuring comment');\n}\nreturn false;\n}\n}"
"async function tryPrAutomerge(\nprNumber: number,\nprNodeId: string,\nplatformPrOptions: PlatformPrOptions | undefined,\n): Promise<void> {\nif (!platformPrOptions?.usePlatformAutomerge) {\nreturn;\n}\nif (platformConfig.isGhe) {\nif (semver.satisfies(platformConfig.gheVersion!, '<3.3.0')) {\nlogger.debug(\n{ prNumber },\n'GitHub-native automerge: not supported on this version of GHE. Use 3.3.0 or newer.',\n);\nreturn;\n}\n}\nif (!config.autoMergeAllowed) {\nlogger.debug(\n{ prNumber },\n'GitHub-native automerge: not enabled in repo settings',\n);\nreturn;\n}\ntry {\nconst mergeMethod = config.mergeMethod?.toUpperCase() || 'MERGE';\nconst variables = { pullRequestId: prNodeId, mergeMethod };\nconst queryOptions = { variables };\nconst res = await githubApi.requestGraphql<GhAutomergeResponse>(\nenableAutoMergeMutation,\nqueryOptions,\n);\nif (res?.errors) {\nlogger.debug(\n{ prNumber, errors: res.errors },\n'GitHub-native automerge: fail',\n);\nreturn;\n}\nlogger.debug(`GitHub-native automerge: success...PrNo: ${prNumber}`);\n} catch (err)  {\nlogger.warn({ prNumber, err }, 'GitHub-native automerge: REST API error');\n}\n}"
"export async function createPr({\nsourceBranch,\ntargetBranch,\nprTitle: title,\nprBody: rawBody,\nlabels,\ndraftPR = false,\nplatformPrOptions,\nmilestone,\n}: CreatePRConfig): Promise<GhPr | null> {\nconst body = sanitize(rawBody);\nconst base = targetBranch;\nconst head = `${config.repository!.split('/')[0]}:${sourceBranch}`;\nconst options: any = {\nbody: {\ntitle,\nhead,\nbase,\nbody,\ndraft: draftPR,\n},\n};\nif (config.forkToken) {\noptions.token = config.forkToken;\noptions.body.maintainer_can_modify =\n!config.forkOrg &&\nplatformPrOptions?.forkModeDisallowMaintainerEdits !== true;\n}\nlogger.debug({ title, head, base, draft: draftPR }, 'Creating PR');\nconst ghPr = (\nawait githubApi.postJson<GhRestPr>(\n`repos/${config.parentRepo ?? config.repository}/pulls`,\noptions,\n)\n).body;\nlogger.debug(\n{ branch: sourceBranch, pr: ghPr.number, draft: draftPR },\n'PR created',\n);\nconst result = coerceRestPr(ghPr);\nconst { number, node_id } = result;\nawait addLabels(number, labels);\nawait tryAddMilestone(number, milestone);\nawait tryPrAutomerge(number, node_id, platformPrOptions);\ncachePr(result);\nreturn result;\n}"
"export async function updatePr({\nnumber: prNo,\nprTitle: title,\nprBody: rawBody,\naddLabels: labelsToAdd,\nremoveLabels,\nstate,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlogger.debug(`updatePr(${prNo}, ${title}, body)`);\nconst body = sanitize(rawBody);\nconst patchBody: any = { title };\nif (body) {\npatchBody.body = body;\n}\nif (targetBranch) {\npatchBody.base = targetBranch;\n}\nif (state) {\npatchBody.state = state;\n}\nconst options: any = {\nbody: patchBody,\n};\nif (config.forkToken) {\noptions.token = config.forkToken;\n}\ntry {\nif (labelsToAdd) {\nawait addLabels(prNo, labelsToAdd);\n}\nif (removeLabels) {\nfor (const label of removeLabels) {\nawait deleteLabel(prNo, label);\n}\n}\nconst { body: ghPr } = await githubApi.patchJson<GhRestPr>(\n`repos/${config.parentRepo ?? config.repository}/pulls/${prNo}`,\noptions,\n);\nconst result = coerceRestPr(ghPr);\ncachePr(result);\nlogger.debug(`PR updated...prNo: ${prNo}`);\n} catch (err)  {\nif (err instanceof ExternalHostError) {\nthrow err;\n}\nlogger.warn({ err }, 'Error updating PR');\n}\n}"
"export async function getVulnerabilityAlerts(): Promise<VulnerabilityAlert[]> {\nif (config.hasVulnerabilityAlertsEnabled === false) {\nlogger.debug('No vulnerability alerts enabled for repo');\nreturn [];\n}\nlet vulnerabilityAlerts: VulnerabilityAlert[] | undefined;\ntry {\nvulnerabilityAlerts = (\nawait githubApi.getJson(\n`/repos/${config.repositoryOwner}/${config.repositoryName}/dependabot/alerts?state=open&direction=asc&per_page=100`,\n{\npaginate: true,\nheaders: { accept: 'application/vnd.github+json' },\ncacheProvider: repoCacheProvider,\n},\nGithubVulnerabilityAlert,\n)\n).body;\n} catch (err)  {\nlogger.debug({ err }, 'Error retrieving vulnerability alerts');\nlogger.warn(\n{\nurl: 'https:\n},\n'Cannot access vulnerability alerts. Please ensure permissions have been granted.',\n);\n}\ntry {\nif (vulnerabilityAlerts?.length) {\nconst shortAlerts: AggregatedVulnerabilities = {};\nlogger.trace(\n{ alerts: vulnerabilityAlerts },\n'GitHub vulnerability details',\n);\nfor (const alert of vulnerabilityAlerts) {\nif (alert.security_vulnerability === null) {\ncontinue;\n}\nconst {\npackage: { name, ecosystem },\nvulnerable_version_range: vulnerableVersionRange,\nfirst_patched_version: firstPatchedVersion,\n} = alert.security_vulnerability;\nconst patch = firstPatchedVersion?.identifier;\nconst normalizedName = normalizeNamePerEcosystem({ name, ecosystem });\nalert.security_vulnerability.package.name = normalizedName;\nconst key = `${ecosystem.toLowerCase()}/${normalizedName}`;\nconst range = vulnerableVersionRange;\nconst elem = shortAlerts[key] || {};\nelem[range] = coerceToNull(patch);\nshortAlerts[key] = elem;\n}\nlogger.debug({ alerts: shortAlerts }, 'GitHub vulnerability details');\n} else {\nlogger.debug('No vulnerability alerts found');\n}\n} catch (err)  {\nlogger.error({ err }, 'Error processing vulnerabity alerts');\n}\nreturn vulnerabilityAlerts ?? [];\n}"
"private static reconcile(cacheData: CacheData): CacheData | null {\nconst issuesToReconcile = memCache.get<GithubIssue[]>(\n'github-issues-reconcile-queue',\n);\nif (!issuesToReconcile) {\nreturn cacheData;\n}\nlet isReconciled = false;\nfor (const issue of issuesToReconcile) {\nconst cachedIssue = cacheData[issue.number];\nif (\ncachedIssue &&\ncachedIssue.number === issue.number &&\ncachedIssue.lastModified === issue.lastModified\n) {\nisReconciled = true;\nlogger.debug(`Issues cache: Done reconciling at issue ${issue.number}`);\nbreak;\n}\ncacheData[issue.number] = issue;\n}\nif (issuesToReconcile.length >= Object.keys(cacheData).length) {\nlogger.debug(\n`Issues cache: Done reconciling by iterating over all items`,\n);\nisReconciled = true;\n}\nif (!isReconciled) {\nlogger.debug('Issues cache: reset');\nthis.reset(null);\nreturn null;\n}\nlogger.debug('Issues cache: synced');\nthis.reset(cacheData);\nreturn cacheData;\n}"
"export async function initPlatform({\nendpoint,\nusername,\ntoken,\ngitAuthor,\n}: PlatformParams): Promise<PlatformResult> {\nif (!token) {\nthrow new Error('Init: You must configure a GitLab personal access token');\n}\nif (endpoint) {\ndefaults.endpoint = ensureTrailingSlash(endpoint);\nsetBaseUrl(defaults.endpoint);\n} else {\nlogger.debug('Using default GitLab endpoint: ' + defaults.endpoint);\n}\nconst platformConfig: PlatformResult = {\nendpoint: defaults.endpoint,\n};\nlet gitlabVersion: string;\ntry {\nif (!gitAuthor) {\nconst user = (\nawait gitlabApi.getJsonUnchecked<{\nemail: EmailAddress;\nname: string;\nid: number;\ncommit_email?: EmailAddress;\n}>(`user`, { token })\n).body;\nplatformConfig.gitAuthor = `${user.name} <${\nuser.commit_email ?? user.email\n}>`;\nbotUserName = user.name;\n}\nconst env = getEnv();\nif (env.RENOVATE_X_PLATFORM_VERSION) {\ngitlabVersion = env.RENOVATE_X_PLATFORM_VERSION;\n}  else {\nconst version = (\nawait gitlabApi.getJsonUnchecked<{ version: string }>('version', {\ntoken,\n})\n).body;\ngitlabVersion = version.version;\n}\nlogger.debug('GitLab version is: ' + gitlabVersion);\n[gitlabVersion] = gitlabVersion.split('-');\ndefaults.version = gitlabVersion;\n} catch (err) {\nlogger.debug(\n{ err },\n'Error authenticating with GitLab. Check that your token includes `api` permissions',\n);\nthrow new Error('Init: Authentication failure');\n}\ndraftPrefix = semver.lt(defaults.version, '13.2.0')\n? DRAFT_PREFIX_DEPRECATED\n: DRAFT_PREFIX;\nbotUserName ??= username!;\nreturn platformConfig;\n}"
"export async function getRepos(config?: AutodiscoverConfig): Promise<string[]> {\nlogger.debug('Autodiscovering GitLab repositories');\nconst queryParams: Record<string, any> = {\nmembership: true,\nper_page: 100,\nwith_merge_requests_enabled: true,\nmin_access_level: 30,\narchived: false,\n};\nif (config?.topics?.length) {\nqueryParams.topic = config.topics.join(',');\n}\nconst urls = [];\nif (config?.namespaces?.length) {\nqueryParams.with_shared = false;\nqueryParams.include_subgroups = true;\nurls.push(\n...config.namespaces.map(\n(namespace) =>\n`groups/${urlEscape(namespace)}/projects?${getQueryString(\nqueryParams,\n)}`,\n),\n);\n} else {\nurls.push('projects?' + getQueryString(queryParams));\n}\ntry {\nconst repos = (\nawait pMap(\nurls,\n(url) =>\ngitlabApi.getJsonUnchecked<RepoResponse[]>(url, {\npaginate: true,\n}),\n{\nconcurrency: 2,\n},\n)\n).flatMap((response) => response.body);\nlogger.debug(`Discovered ${repos.length} project(s)`);\nreturn repos\n.filter((repo) => !repo.mirror || config?.includeMirrors)\n.map((repo) => repo.path_with_namespace);\n} catch (err) {\nlogger.error({ err }, `GitLab getRepos error`);\nthrow err;\n}\n}"
"export async function getBranchStatus(\nbranchName: string,\ninternalChecksAsSuccess: boolean,\n): Promise<BranchStatus> {\nlogger.debug(`getBranchStatus(${branchName})`);\nif (!git.branchExists(branchName)) {\nthrow new Error(REPOSITORY_CHANGED);\n}\nconst branchStatuses = await getStatus(branchName);\nif (!isArray(branchStatuses)) {\nlogger.warn(\n{ branchName, branchStatuses },\n'Empty or unexpected branch statuses',\n);\nreturn 'yellow';\n}\nlogger.debug(`Got res with ${branchStatuses.length} results`);\nconst mr = await getBranchPr(branchName);\nif (mr && mr.sha !== mr.headPipelineSha && mr.headPipelineStatus) {\nlogger.debug(\n'Merge request head pipeline has different sha to commit, assuming merged results pipeline',\n);\nbranchStatuses.push({\nstatus: mr.headPipelineStatus as BranchState,\nname: 'head_pipeline',\n});\n}\nconst res = branchStatuses.filter((check) => check.status !== 'skipped');\nif (res.length === 0) {\nreturn 'yellow';\n}\nif (\n!internalChecksAsSuccess &&\nbranchStatuses.every(\n(check) =>\ncheck.name?.startsWith('renovate/') &&\ngitlabToRenovateStatusMapping[check.status] === 'green',\n)\n) {\nlogger.debug(\n'Successful checks are all internal renovate/ checks, so returning `pending` branch status',\n);\nreturn 'yellow';\n}\nlet status: BranchStatus = 'green';\nres\n.filter((check) => !check.allow_failure)\n.forEach((check) => {\nif (status !== 'red') {\nlet mappedStatus: BranchStatus =\ngitlabToRenovateStatusMapping[check.status];\nif (!mappedStatus) {\nlogger.warn(\n{ check },\n'Could not map GitLab check.status to Renovate status',\n);\nmappedStatus = 'yellow';\n}\nif (mappedStatus !== 'green') {\nlogger.trace({ check }, 'Found non-green check');\nstatus = mappedStatus;\n}\n}\n});\nreturn status;\n}"
"async function ignoreApprovals(pr: number): Promise<void> {\ntry {\nconst url = `projects/${config.repository}/merge_requests/${pr}/approval_rules`;\nconst { body: rules } = await gitlabApi.getJsonUnchecked<\n{\nname: string;\nrule_type: string;\nid: number;\n}[]\n>(url);\nconst ruleName = 'renovateIgnoreApprovals';\nconst existingAnyApproverRule = rules?.find(\n({ rule_type }) => rule_type === 'any_approver',\n);\nconst existingRegularApproverRules = rules?.filter(\n({ rule_type, name }) =>\nrule_type !== 'any_approver' &&\nname !== ruleName &&\nrule_type !== 'report_approver' &&\nrule_type !== 'code_owner',\n);\nif (existingRegularApproverRules?.length) {\nawait p.all(\nexistingRegularApproverRules.map((rule) => async (): Promise<void> => {\nawait gitlabApi.deleteJson(`${url}/${rule.id}`);\n}),\n);\n}\nif (existingAnyApproverRule) {\nawait gitlabApi.putJson(`${url}/${existingAnyApproverRule.id}`, {\nbody: { ...existingAnyApproverRule, approvals_required: 0 },\n});\nreturn;\n}\nconst zeroApproversRule = rules?.find(({ name }) => name === ruleName);\nif (!zeroApproversRule) {\nawait gitlabApi.postJson(url, {\nbody: {\nname: ruleName,\napprovals_required: 0,\n},\n});\n}\n} catch (err) {\nlogger.warn({ err }, 'GitLab: Error adding approval rule');\n}\n}"
"export async function createPr({\nsourceBranch,\ntargetBranch,\nprTitle,\nprBody: rawDescription,\ndraftPR,\nlabels,\nplatformPrOptions,\n}: CreatePRConfig): Promise<Pr> {\nlet title = prTitle;\nif (draftPR) {\ntitle = draftPrefix + title;\n}\nconst description = sanitize(rawDescription);\nlogger.debug(`Creating Merge Request: ${title}`);\nconst res = await gitlabApi.postJson<GitLabMergeRequest>(\n`projects/${config.repository}/merge_requests`,\n{\nbody: {\nsource_branch: sourceBranch,\ntarget_branch: targetBranch,\nremove_source_branch: true,\ntitle,\ndescription,\nlabels: (labels ?? []).join(','),\nsquash: config.squash,\n},\n},\n);\nconst pr = prInfo(res.body);\nawait GitlabPrCache.setPr(\ngitlabApi,\nconfig.repository,\nbotUserName,\npr,\n!!config.ignorePrAuthor,\n);\nif (platformPrOptions?.autoApprove) {\nawait approveMr(pr.number);\n}\nawait tryPrAutomerge(pr.number, platformPrOptions);\nreturn pr;\n}"
"export async function updatePr({\nnumber: iid,\nprTitle,\nprBody: description,\naddLabels,\nremoveLabels,\nstate,\nplatformPrOptions,\ntargetBranch,\n}: UpdatePrConfig): Promise<void> {\nlet title = prTitle;\nif ((await getPrList()).find((pr) => pr.number === iid)?.isDraft) {\ntitle = draftPrefix + title;\n}\nconst newState = {\n['closed']: 'close',\n['open']: 'reopen',\n}[state!];\nconst body: any = {\ntitle,\ndescription: sanitize(description),\n...(newState && { state_event: newState }),\n};\nif (targetBranch) {\nbody.target_branch = targetBranch;\n}\nif (addLabels) {\nbody.add_labels = addLabels;\n}\nif (removeLabels) {\nbody.remove_labels = removeLabels;\n}\nconst updatedPrInfo = (\nawait gitlabApi.putJson<GitLabMergeRequest>(\n`projects/${config.repository}/merge_requests/${iid}`,\n{ body },\n)\n).body;\nconst updatedPr = prInfo(updatedPrInfo);\nawait GitlabPrCache.setPr(\ngitlabApi,\nconfig.repository,\nbotUserName,\nupdatedPr,\n!!config.ignorePrAuthor,\n);\nif (platformPrOptions?.autoApprove) {\nawait approveMr(iid);\n}\n}"
"export async function ensureIssue({\ntitle,\nreuseTitle,\nbody,\nlabels,\nconfidential,\n}: EnsureIssueConfig): Promise<'updated' | 'created' | null> {\nlogger.debug(`ensureIssue()`);\nconst description = massageMarkdown(sanitize(body));\ntry {\nconst issueList = await getIssueList();\nlet issue = issueList.find((i) => i.title === title);\nissue ??= issueList.find((i) => i.title === reuseTitle);\nif (issue) {\nconst existingDescription = (\nawait gitlabApi.getJsonUnchecked<{ description: string }>(\n`projects/${config.repository}/issues/${issue.iid}`,\n)\n).body.description;\nif (issue.title !== title || existingDescription !== description) {\nlogger.debug('Updating issue');\nawait gitlabApi.putJson(\n`projects/${config.repository}/issues/${issue.iid}`,\n{\nbody: {\ntitle,\ndescription,\nlabels: (labels ?? issue.labels ?? []).join(','),\nconfidential: confidential ?? false,\n},\n},\n);\nreturn 'updated';\n}\n} else {\nawait gitlabApi.postJson(`projects/${config.repository}/issues`, {\nbody: {\ntitle,\ndescription,\nlabels: (labels ?? []).join(','),\nconfidential: confidential ?? false,\n},\n});\nlogger.info('Issue created');\ndelete config.issueList;\nreturn 'created';\n}\n} catch (err)  {\nif (err.message.startsWith('Issues are disabled for this repo')) {\nlogger.debug(`Could not create issue: ${(err as Error).message}`);\n} else {\nlogger.warn({ err }, 'Could not ensure issue');\n}\n}\nreturn null;\n}"
"export async function addReviewers(\niid: number,\nreviewers: string[],\n): Promise<void> {\nlogger.debug(`Adding reviewers '${reviewers.join(', ')}' to #${iid}`);\nif (semver.lt(defaults.version, '13.9.0')) {\nlogger.warn(\n{ version: defaults.version },\n'Adding reviewers is only available in GitLab 13.9 and onwards',\n);\nreturn;\n}\nlet mr: GitLabMergeRequest;\ntry {\nmr = await getMR(config.repository, iid);\n} catch (err) {\nlogger.warn({ err }, 'Failed to get existing reviewers');\nreturn;\n}\nmr.reviewers = coerceArray(mr.reviewers);\nconst existingReviewers = mr.reviewers.map((r) => r.username);\nconst existingReviewerIDs = mr.reviewers.map((r) => r.id);\nconst newReviewers = reviewers.filter((r) => !existingReviewers.includes(r));\nlet newReviewerIDs: number[];\ntry {\nnewReviewerIDs = (\nawait p.all(\nnewReviewers.map((r) => async () => {\ntry {\nreturn [await getUserID(r)];\n} catch {\nreturn getMemberUserIDs(r);\n}\n}),\n)\n).flat();\n} catch (err) {\nlogger.warn({ err }, 'Failed to get IDs of the new reviewers');\nreturn;\n}\nnewReviewerIDs = [...new Set(newReviewerIDs)];\ntry {\nawait updateMR(config.repository, iid, {\nreviewer_ids: [...existingReviewerIDs, ...newReviewerIDs],\n});\n} catch (err) {\nlogger.warn({ err }, 'Failed to add reviewers');\n}\n}"
"export async function ensureComment({\nnumber,\ntopic,\ncontent,\n}: EnsureCommentConfig): Promise<boolean> {\nconst sanitizedContent = sanitize(content);\nconst massagedTopic = topic\n? topic\n.replace(regEx(/Pull Request/g), 'Merge Request')\n.replace(regEx(/PR/g), 'MR')\n: topic;\nconst comments = await getComments(number);\nlet body: string;\nlet commentId: number | undefined;\nlet commentNeedsUpdating: boolean | undefined;\nif (topic) {\nlogger.debug(`Ensuring comment `${massagedTopic!}` in #${number}`);\nbody = `### ${topic}\n\n${sanitizedContent}`;\nbody = smartTruncate(\nbody\n.replace(regEx(/Pull Request/g), 'Merge Request')\n.replace(regEx(/PR/g), 'MR'),\nmaxBodyLength(),\n);\ncomments.forEach((comment: { body: string; id: number }) => {\nif (comment.body.startsWith(`### ${massagedTopic!}\n\n`)) {\ncommentId = comment.id;\ncommentNeedsUpdating = comment.body !== body;\n}\n});\n} else {\nlogger.debug(`Ensuring content-only comment in #${number}`);\nbody = smartTruncate(`${sanitizedContent}`, maxBodyLength());\ncomments.forEach((comment: { body: string; id: number }) => {\nif (comment.body === body) {\ncommentId = comment.id;\ncommentNeedsUpdating = false;\n}\n});\n}\nif (!commentId) {\nawait addComment(number, body);\nlogger.debug(\n{ repository: config.repository, issueNo: number },\n'Added comment',\n);\n} else if (commentNeedsUpdating) {\nawait editComment(number, commentId, body);\nlogger.debug(\n{ repository: config.repository, issueNo: number },\n'Updated comment',\n);\n} else {\nlogger.debug('Comment is already update-to-date');\n}\nreturn true;\n}"
"private async sync(http: GitlabHttp): Promise<GitlabPrCache> {\nlogger.debug('Syncing PR list');\nconst searchParams: Record<string, string> = {\nper_page: '100',\norder_by: 'updated_at',\nsort: 'desc',\n};\nconst opts: GitlabHttpOptions = { paginate: true };\nconst updated_after = this.cache.updated_at;\nif (updated_after) {\nopts.cacheProvider = repoCacheProvider;\nsearchParams.updated_after = updated_after;\n}\nif (!this.ignorePrAuthor) {\nsearchParams.scope = 'created_by_me';\n}\nconst query: string | null = getQueryString(searchParams);\nconst { body: items } = await http.getJsonUnchecked<GitLabMergeRequest[]>(\n`/projects/${this.repo}/merge_requests?${query}`,\nopts,\n);\nif (items.length) {\nfor (const item of items) {\nconst id = item.iid;\nthis.cache.items[id] = prInfo(item);\n}\nconst [{ updated_at }] = items;\nthis.cache.updated_at = updated_at.replace(regEx(/\.\d\d\dZ$/), 'Z');\n}\nthis.updateItems();\nreturn this;\n}"
"export function getRepoUrl(\nrepository: string,\ngitUrl: GitUrlOption | undefined,\nres: HttpResponse<RepoResponse>,\n): string {\nif (gitUrl === 'ssh') {\nif (!res.body.ssh_url_to_repo) {\nthrow new Error(CONFIG_GIT_URL_UNAVAILABLE);\n}\nlogger.debug(`Using ssh URL: ${res.body.ssh_url_to_repo}`);\nreturn res.body.ssh_url_to_repo;\n}\nconst opts = hostRules.find({\nhostType: defaults.hostType,\nurl: defaults.endpoint,\n});\nconst env = getEnv();\nif (\ngitUrl === 'endpoint' ||\nisNonEmptyString(env.GITLAB_IGNORE_REPO_URL) ||\nres.body.http_url_to_repo === null\n) {\nif (res.body.http_url_to_repo === null) {\nlogger.debug('no http_url_to_repo found. Falling back to old behavior.');\n}\nif (env.GITLAB_IGNORE_REPO_URL) {\nlogger.warn(\n'GITLAB_IGNORE_REPO_URL environment variable is deprecated. Please use `gitUrl` option.',\n);\n}\nconst { protocol, host, pathname } = parseUrl(defaults.endpoint)!;\nconst newPathname = pathname.slice(0, pathname.indexOf('/api'));\nconst uri = url.format({\nprotocol:\nprotocol.slice(0, -1) || 'https',\nauth: `oauth2:${opts.token!}`,\nhost,\npathname: `${newPathname}/${repository}.git`,\n});\nlogger.debug(`Using URL based on configured endpoint, url:${uri}`);\nreturn uri;\n}\nlogger.debug(`Using http URL: ${res.body.http_url_to_repo}`);\nconst repoUrl = parseUrl(res.body.http_url_to_repo);\nif (!repoUrl) {\nreturn '';\n}\nrepoUrl.username = 'oauth2';\nrepoUrl.password = opts.token!;\nreturn repoUrl.toString();\n}"
"function getNewValue({\ncurrentValue,\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n}: NewValueConfig): string {\nif (!currentValue || currentValue === '*') {\nreturn currentValue;\n}\nif (rangeStrategy === 'bump' && regEx(/^\d+(?:\.\d+)*$/).test(currentValue)) {\nreturn newVersion;\n}\nif (isSingleVersion(currentValue)) {\nlet res = '=';\nif (currentValue.startsWith('= ')) {\nres += ' ';\n}\nres += newVersion;\nreturn res;\n}\nif (rangeStrategy === 'replace' && matches(newVersion, currentValue)) {\nreturn currentValue;\n}\nconst newSemver = npm.getNewValue({\ncurrentValue: cargo2npm(currentValue),\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n});\nlet newCargo = newSemver\n? npm2cargo(newSemver)\n:  null;\nif (!newCargo) {\nlogger.info(\n{ currentValue, newSemver },\n'Could not get cargo version from semver',\n);\nreturn currentValue;\n}\nif (\n(currentValue.startsWith('~') || currentValue.startsWith('^')) &&\nrangeStrategy === 'replace' &&\nnewCargo.split('.').length > currentValue.split('.').length\n) {\nnewCargo = newCargo\n.split('.')\n.slice(0, currentValue.split('.').length)\n.join('.');\n}\nif (newCargo.startsWith('^') && !currentValue.startsWith('^')) {\nconst withoutCaret = newCargo.substring(1);\nconst components = currentValue.split('.').length;\nnewCargo = withoutCaret.split('.').slice(0, components).join('.');\n}\nreturn newCargo;\n}"
"export function fixParsedRange(range: string): any {\nconst ordValues = [];\nconst originalSplit = range.split(' ');\nfor (let i = 0; i < originalSplit.length; i += 1) {\nif (\n!containsOperators(originalSplit[i]) &&\n!originalSplit[i].includes('||')\n) {\nif (i !== 0 && originalSplit[i - 1].includes('||')) {\nordValues.push(`|| ${originalSplit[i]}`);\n} else if (i !== originalSplit.length && originalSplit[i + 1] === '||') {\nordValues.push(`${originalSplit[i]} ||`);\n}\n} else {\nordValues.push(originalSplit[i]);\n}\n}\nconst parsedRange = parseRange(range);\nconst cleanRange = range.replace(/([<=>^~])( )?/g, '');\nconst splitRange = cleanRange.split(' ');\nconst semverRange: SemVer[] = [];\nfor (let i = 0; i < splitRange.length; i += 1) {\nif (!splitRange[i].includes('||')) {\nconst splitVersion = splitRange[i].split('.');\nconst major = splitVersion[0];\nconst minor = splitVersion[1];\nconst patch = splitVersion[2];\nconst operator = ordValues[i].includes('||')\n? '||'\n: parsedRange[i].operator;\nconst NewSemVer: SemVer = {\nmajor,\n};\nlet full = `${coerceString(operator)}${major}`;\nif (minor) {\nNewSemVer.minor = minor;\nfull = `${full}.${minor}`;\nif (patch) {\nNewSemVer.patch = patch;\nfull = `${full}.${patch}`;\n}\n}\nif (operator) {\nNewSemVer.operator = operator;\nfull = range.includes(`${operator} `)\n? `${operator} ${full.replace(operator, '')}`\n: `${operator}${full.replace(operator, '')}`;\n}\nfull = ordValues[i].includes('||') ? ordValues[i] : full;\nNewSemVer.semver = full;\nsemverRange.push(NewSemVer);\n}\n}\nreturn semverRange;\n}"
"protected _compare_string(a: string, b: string): number {\nlet charPos = 0;\nwhile (charPos < a.length || charPos < b.length) {\nconst aChar = a.charAt(charPos);\nconst bChar = b.charAt(charPos);\nif (numericChars.includes(aChar) && numericChars.includes(bChar)) {\nlet aNumericEnd = charPos + 1;\nwhile (numericChars.includes(a.charAt(aNumericEnd))) {\naNumericEnd += 1;\n}\nlet bNumericEnd = charPos + 1;\nwhile (numericChars.includes(b.charAt(bNumericEnd))) {\nbNumericEnd += 1;\n}\nconst numericCmp = a\n.substring(charPos, aNumericEnd)\n.localeCompare(b.substring(charPos, bNumericEnd), undefined, {\nnumeric: true,\n});\nif (numericCmp !== 0) {\nreturn numericCmp;\n}\ncharPos = aNumericEnd;\ncontinue;\n}\nif (aChar !== bChar) {\nconst aPriority = characterOrder.indexOf(\nnumericChars.includes(aChar) || aChar === '' ? ' ' : aChar,\n);\nconst bPriority = characterOrder.indexOf(\nnumericChars.includes(bChar) || bChar === '' ? ' ' : bChar,\n);\nreturn Math.sign(aPriority - bPriority);\n}\ncharPos += 1;\n}\nreturn 0;\n}"
"protected override _compare(version: string, other: string): number {\nconst parsed1 = this._parse(version);\nconst parsed2 = this._parse(other);\nif (!(parsed1 && parsed2)) {\nreturn 1;\n}\nconst length = Math.max(parsed1.release.length, parsed2.release.length);\nfor (let i = 0; i < length; i += 1) {\nconst part1 = parsed1.release[i];\nconst part2 = parsed2.release[i];\nif (part1 === undefined) {\nreturn 1;\n}\nif (part2 === undefined) {\nreturn -1;\n}\nif (part1 !== part2) {\nreturn part1 - part2;\n}\n}\nif (parsed1.prerelease !== parsed2.prerelease) {\nif (!parsed1.prerelease && parsed2.prerelease) {\nreturn 1;\n}\nif (parsed1.prerelease && !parsed2.prerelease) {\nreturn -1;\n}\nif (parsed1.prerelease && parsed2.prerelease) {\nreturn parsed1.prerelease.localeCompare(parsed2.prerelease);\n}\n}\nconst suffix1 = coerceString(parsed1.suffix);\nconst suffix2 = coerceString(parsed2.suffix);\nreturn suffix2.localeCompare(suffix1);\n}"
"export function tokenize(versionStr: string): Token[] | null {\nlet result: Token[] | null = [];\nlet currentVal = '';\nfunction yieldToken(): void {\nif (result) {\nconst val = currentVal;\nif (regEx(/^\d+$/).test(val)) {\nresult.push({\ntype: TokenType.Number,\nval: parseInt(val),\n});\n} else {\nresult.push({\ntype: TokenType.String,\nval,\n});\n}\n}\n}\niterateChars(versionStr, (prevChar, nextChar) => {\nif (nextChar === null) {\nyieldToken();\n} else if (isSeparator(nextChar)) {\nif (prevChar && !isSeparator(prevChar)) {\nyieldToken();\ncurrentVal = '';\n} else {\nresult = null;\n}\n} else if (prevChar !== null && isTransition(prevChar, nextChar)) {\nyieldToken();\ncurrentVal = nextChar;\n} else {\ncurrentVal = currentVal.concat(nextChar);\n}\n});\nreturn result;\n}"
"export function parseMavenBasedRange(input: string): MavenBasedRange | null {\nif (!input) {\nreturn null;\n}\nconst matchGroups = mavenBasedRangeRegex.exec(input)?.groups;\nif (matchGroups) {\nconst { leftBoundStr, separator, rightBoundStr } = matchGroups;\nlet leftVal: string | null = matchGroups.leftVal;\nlet rightVal: string | null = matchGroups.rightVal;\nif (!leftVal) {\nleftVal = null;\n}\nif (!rightVal) {\nrightVal = null;\n}\nconst isVersionLeft = isString(leftVal) && isVersion(leftVal);\nconst isVersionRight = isString(rightVal) && isVersion(rightVal);\nif (\n(leftVal === null || isVersionLeft) &&\n(rightVal === null || isVersionRight)\n) {\nif (\nisVersionLeft &&\nisVersionRight &&\nleftVal &&\nrightVal &&\ncompare(leftVal, rightVal) === 1\n) {\nreturn null;\n}\nconst leftBound = leftBoundStr.trim() === '[' ? 'inclusive' : 'exclusive';\nconst rightBound =\nrightBoundStr.trim() === ']' ? 'inclusive' : 'exclusive';\nreturn {\nleftBound,\nleftBoundStr,\nleftVal,\nseparator,\nrightBound,\nrightBoundStr,\nrightVal,\n};\n}\n}\nreturn null;\n}"
"export function hashicorp2npm(input: string): string {\nif (!input) {\nreturn input;\n}\nreturn input\n.split(',')\n.map((single) => {\nconst r = single.match(\nregEx(\n`^\\s*(?<operator>(|=|!=|>|<|>=|<=|~>))\\s*v?(?<version>${semverRegex.source})\\s*$`,\n),\n);\nif (!r) {\nlogger.warn(\n{ constraint: input, element: single },\n'Invalid hashicorp constraint',\n);\nthrow new Error('Invalid hashicorp constraint');\n}\nif (r.groups!.operator === '!=') {\nlogger.warn(\n{ constraint: input, element: single },\n'Unsupported hashicorp constraint',\n);\nthrow new Error('Unsupported hashicorp constraint');\n}\nreturn {\noperator: r.groups!.operator,\nversion: r.groups!.version,\n};\n})\n.map(({ operator, version }) => {\nswitch (operator) {\ncase '=':\nreturn version;\ncase '~>':\nif (version.match(regEx(/^\d+$/))) {\nreturn `>=${version}`;\n}\nif (version.match(regEx(/^\d+\.\d+$/))) {\nreturn `^${version}`;\n}\nreturn `~${version}`;\ndefault:\nreturn `${operator}${version}`;\n}\n})\n.join(' ');\n}"
"export function npm2hashicorp(input: string): string {\nif (!input) {\nreturn input;\n}\nreturn input\n.split(' ')\n.map((single) => {\nconst r = single.match(\nregEx(\n`^(?<operator>(|>|<|>=|<=|~|\\^))v?(?<version>${semverRegex.source})$`,\n),\n);\nif (!r) {\nthrow new Error('invalid npm constraint');\n}\nreturn {\noperator: r.groups!.operator,\nversion: r.groups!.version,\n};\n})\n.map(({ operator, version }) => {\nswitch (operator) {\ncase '^': {\nif (version.match(regEx(/^\d+$/))) {\nreturn `~> ${version}.0`;\n}\nconst withZero = version.match(regEx(/^(\d+\.\d+)\.0$/));\nif (withZero) {\nreturn `~> ${withZero[1]}`;\n}\nconst nonZero = version.match(regEx(/^(\d+\.\d+)\.\d+$/));\nif (nonZero) {\nreturn `~> ${nonZero[1]}`;\n}\nreturn `~> ${version}`;\n}\ncase '~':\nif (version.match(regEx(/^\d+$/))) {\nreturn `~> ${version}.0`;\n}\nif (version.match(regEx(/^\d+\.\d+$/))) {\nreturn `~> ${version}.0`;\n}\nreturn `~> ${version}`;\ncase '':\nreturn `${version}`;\ndefault:\nreturn `${operator} ${version}`;\n}\n})\n.join(', ');\n}"
"protected override _parse(version: string): RegExpVersion | null {\nconst parsed = this._parseHermitVersioning(version);\nif (parsed) {\nreturn parsed;\n}\nconst channelVer = HermitVersioning._getChannel(version);\nconst groups = this._config?.exec(channelVer)?.groups;\nif (!groups) {\nreturn null;\n}\nconst {\nmajor,\nminor,\npatch,\nsupplement,\nbuild,\nprerelease,\ncompatibility,\n} = groups;\nconst release = [];\nif (major) {\nrelease.push(Number.parseInt(major));\n}\nif (minor) {\nrelease.push(Number.parseInt(minor));\n}\nif (patch) {\nrelease.push(Number.parseInt(patch));\n}\nif (supplement) {\nrelease.push(Number.parseInt(supplement));\n}\nif (build) {\nrelease.push(Number.parseInt(build));\n}\nreturn {\nrelease,\nprerelease,\ncompatibility,\n};\n}"
"protected override _compare(version: string, other: string): number {\nif (this._isValid(version) && this._isValid(other)) {\nreturn super._compare(version, other);\n}\nconst parsedVersion = this._parse(version);\nconst parsedOther = this._parse(other);\nif (parsedVersion === null || parsedOther === null) {\nif (parsedVersion === null && parsedOther === null) {\nreturn version.localeCompare(other);\n}\nreturn parsedVersion === null ? -1 : 1;\n}\nconst versionReleases = parsedVersion.release;\nconst otherReleases = parsedOther.release;\nconst maxLength =\nversionReleases.length > otherReleases.length\n? versionReleases.length\n: otherReleases.length;\nfor (let i = 0; i < maxLength; i++) {\nconst verVal = versionReleases[i];\nconst otherVal = otherReleases[i];\nif (\nverVal !== undefined &&\notherVal !== undefined &&\nverVal !== otherVal\n) {\nreturn verVal - otherVal;\n} else if (verVal === undefined) {\nreturn 1;\n} else if (otherVal === undefined) {\nreturn -1;\n}\n}\nreturn 0;\n}"
"function iterateTokens(versionStr: string, cb: (token: Token) => void): void {\nlet currentPrefix = PREFIX_HYPHEN;\nlet currentVal = '';\nfunction yieldToken(transition = false): void {\nconst val = currentVal || '0';\nif (regEx(/^\d+$/).test(val)) {\ncb({\nprefix: currentPrefix,\ntype: TYPE_NUMBER,\nval: parseInt(val),\nisTransition: transition,\n});\n} else {\ncb({\nprefix: currentPrefix,\ntype: TYPE_QUALIFIER,\nval,\nisTransition: transition,\n});\n}\n}\niterateChars(versionStr, (prevChar, nextChar) => {\nif (nextChar === null) {\nyieldToken();\n} else if (nextChar === '-') {\nyieldToken();\ncurrentPrefix = PREFIX_HYPHEN;\ncurrentVal = '';\n} else if (nextChar === '.') {\nyieldToken();\ncurrentPrefix = PREFIX_DOT;\ncurrentVal = '';\n} else if (prevChar !== null && isTransition(prevChar, nextChar)) {\nyieldToken(true);\ncurrentPrefix = PREFIX_HYPHEN;\ncurrentVal = nextChar;\n} else {\ncurrentVal = currentVal.concat(nextChar);\n}\n});\n}"
"function autoExtendMavenRange(\ncurrentRepresentation: string,\nnewValue: string,\n): string | null {\nconst range = parseRange(currentRepresentation);\nif (!range) {\nreturn currentRepresentation;\n}\nconst isPoint = (vals: Range[]): boolean => {\nif (vals.length !== 1) {\nreturn false;\n}\nconst { leftType, leftValue, rightType, rightValue } = vals[0];\nreturn (\nleftType === 'INCLUDING_POINT' &&\nleftType === rightType &&\nleftValue === rightValue\n);\n};\nif (isPoint(range)) {\nreturn `[${newValue}]`;\n}\nconst interval = [...range].reverse().find((elem) => {\nconst { rightType, rightValue } = elem;\nreturn (\nrightValue === null ||\n(rightType === INCLUDING_POINT && compare(rightValue, newValue) === -1) ||\n(rightType === EXCLUDING_POINT && compare(rightValue, newValue) !== 1)\n);\n});\nif (!interval) {\nreturn currentRepresentation;\n}\nconst { leftValue, rightValue } = interval;\nif (\nleftValue !== null &&\nrightValue !== null &&\nincrementRangeValue(leftValue) === rightValue\n) {\nif (compare(newValue, leftValue) !== -1) {\ninterval.leftValue = coerceRangeValue(leftValue, newValue);\ninterval.rightValue = incrementRangeValue(interval.leftValue);\n}\n} else if (rightValue !== null) {\nif (interval.rightType === INCLUDING_POINT) {\nconst tokens = tokenize(rightValue);\nconst lastToken = tokens[tokens.length - 1];\nif (typeof lastToken.val === 'number') {\ninterval.rightValue = coerceRangeValue(rightValue, newValue);\n} else {\ninterval.rightValue = newValue;\n}\n} else {\ninterval.rightValue = incrementRangeValue(\ncoerceRangeValue(rightValue, newValue),\n);\n}\n} else if (leftValue !== null) {\ninterval.leftValue = coerceRangeValue(leftValue, newValue);\n}\nreturn rangeToStr(range);\n}"
"getSatisfyingVersion(versions: string[], range: string): string | null {\nconst r = parseRange(range);\nif (r) {\nlet result: string | null = null;\nlet vMax: NugetVersion | undefined;\nfor (const version of versions) {\nconst v = parseVersion(version);\nif (!v) {\ncontinue;\n}\nif (!matches(v, r)) {\ncontinue;\n}\nif (!vMax || compare(v, vMax) > 0) {\nvMax = v;\nresult = version;\n}\n}\nreturn result;\n}\nconst u = parseVersion(range);\nif (u) {\nlet result: string | null = null;\nlet vMax: NugetVersion | undefined;\nfor (const version of versions) {\nconst v = parseVersion(version);\nif (!v) {\ncontinue;\n}\nif (compare(v, u) < 0) {\ncontinue;\n}\nif (!vMax || compare(v, vMax) > 0) {\nvMax = v;\nresult = version;\n}\n}\nreturn result;\n}\nreturn null;\n}"
"minSatisfyingVersion(versions: string[], range: string): string | null {\nconst r = parseRange(range);\nif (r) {\nlet result: string | null = null;\nlet vMin: NugetVersion | undefined;\nfor (const version of versions) {\nconst v = parseVersion(version);\nif (!v) {\ncontinue;\n}\nif (!matches(v, r)) {\ncontinue;\n}\nif (!vMin || compare(v, vMin) < 0) {\nresult = version;\nvMin = v;\n}\n}\nreturn result;\n}\nconst u = parseVersion(range);\nif (u) {\nlet result: string | null = null;\nlet vMin: NugetVersion | undefined;\nfor (const version of versions) {\nconst v = parseVersion(version);\nif (!v) {\ncontinue;\n}\nif (compare(v, u) < 0) {\ncontinue;\n}\nif (!vMin || compare(v, vMin) < 0) {\nresult = version;\nvMin = v;\n}\n}\nreturn result;\n}\nreturn null;\n}"
"getNewValue({\ncurrentValue,\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n}: NewValueConfig): string | null {\nconst v = parseVersion(newVersion);\nif (!v) {\nreturn null;\n}\nif (this.isVersion(currentValue)) {\nreturn newVersion;\n}\nconst r = parseRange(currentValue);\nif (!r) {\nreturn null;\n}\nif (this.isLessThanRange(newVersion, currentValue)) {\nreturn currentValue;\n}\nif (r.type === 'nuget-exact-range') {\nreturn rangeToString({ type: 'nuget-exact-range', version: v });\n}\nif (r.type === 'nuget-floating-range') {\nconst floating = r.floating;\nif (!floating) {\nreturn versionToString(v);\n}\nconst res: NugetFloatingRange = { ...r };\nif (floating === 'major') {\nres.major = coerceFloatingComponent(v.major);\nreturn tryBump(res, v, currentValue);\n}\nres.major = v.major;\nif (floating === 'minor') {\nres.minor = coerceFloatingComponent(v.minor);\nreturn tryBump(res, v, currentValue);\n}\nres.minor = v.minor ?? 0;\nif (floating === 'patch') {\nres.patch = coerceFloatingComponent(v.patch);\nreturn tryBump(res, v, currentValue);\n}\nres.patch = v.patch ?? 0;\nres.revision = coerceFloatingComponent(v.revision);\nreturn tryBump(res, v, currentValue);\n}\nconst res: NugetBracketRange = { ...r };\nif (!r.max) {\nres.min = v;\nres.minInclusive = true;\nreturn rangeToString(res);\n}\nif (matches(v, r)) {\nreturn currentValue;\n}\nif (!r.min) {\nres.max = v;\nres.maxInclusive = true;\nreturn rangeToString(res);\n}\nres.max = v;\nres.maxInclusive = true;\nreturn rangeToString(res);\n}"
"export function parseFloatingRange(input: string): NugetFloatingRange | null {\nconst groups = floatingRangeRegex.exec(input)?.groups;\nif (!groups) {\nreturn null;\n}\nlet res: NugetFloatingRange = {\ntype: 'nuget-floating-range',\nmajor: 0,\n};\nconst {\nmajor,\nfloating_major,\nminor,\nfloating_minor,\npatch,\nfloating_patch,\nrevision,\nfloating_revision,\nfloating_prerelease,\n} = groups;\nif (floating_prerelease) {\nres.prerelease = groups.floating_prerelease as `${string}*`;\n}\nif (floating_major) {\nreturn {\n...res,\nmajor: parseFloatingComponent(floating_major),\nfloating: 'major',\n};\n}\nconst majorNum = Number.parseInt(major);\nif (!Number.isNaN(majorNum)) {\nres = { ...res, major: majorNum };\n}\nif (floating_minor) {\nreturn {\n...res,\nminor: parseFloatingComponent(floating_minor),\nfloating: 'minor',\n};\n}\nconst minorNum = Number.parseInt(minor);\nif (!Number.isNaN(minorNum)) {\nres = { ...res, minor: minorNum };\n}\nif (floating_patch) {\nreturn {\n...res,\npatch: parseFloatingComponent(floating_patch),\nfloating: 'patch',\n};\n}\nconst patchNum = Number.parseInt(patch);\nif (!Number.isNaN(patchNum)) {\nres = { ...res, patch: patchNum };\n}\nif (floating_revision) {\nreturn {\n...res,\nrevision: parseFloatingComponent(floating_revision),\nfloating: 'revision',\n};\n}\nconst revisionNum = Number.parseInt(revision);\nif (!Number.isNaN(revisionNum)) {\nres = { ...res, revision: revisionNum };\n}\nif (res.prerelease) {\nreturn res;\n}\nreturn null;\n}"
"export function parseBracketRange(input: string): NugetBracketRange | null {\nconst maxGroups = maxBracketRangeRegex.exec(input)?.groups;\nif (maxGroups) {\nconst { max_version, left_bracket, right_bracket } = maxGroups;\nconst max = parseVersion(max_version);\nif (!max) {\nreturn null;\n}\nreturn {\ntype: 'nuget-bracket-range',\nmax,\nminInclusive: left_bracket === '[',\nmaxInclusive: right_bracket === ']',\n};\n}\nconst minGroups = minBracketRangeRegex.exec(input)?.groups;\nif (minGroups) {\nconst { min_version, left_bracket, right_bracket } = minGroups;\nconst min = parseVersion(min_version) ?? parseFloatingRange(min_version);\nif (!min) {\nreturn null;\n}\nreturn {\ntype: 'nuget-bracket-range',\nmin,\nminInclusive: left_bracket === '[',\nmaxInclusive: right_bracket === ']',\n};\n}\nconst groups = bracketRangeRegex.exec(input)?.groups;\nif (groups) {\nconst { min_version, max_version, left_bracket, right_bracket } = groups;\nconst min = parseVersion(min_version) ?? parseFloatingRange(min_version);\nif (!min) {\nreturn null;\n}\nconst max = parseVersion(max_version);\nif (!max) {\nreturn null;\n}\nreturn {\ntype: 'nuget-bracket-range',\nmin,\nmax,\nminInclusive: left_bracket === '[',\nmaxInclusive: right_bracket === ']',\n};\n}\nreturn null;\n}"
"export function rangeToString(range: NugetRange): string {\nif (range.type === 'nuget-exact-range') {\nreturn `[${versionToString(range.version)}]`;\n}\nif (range.type === 'nuget-floating-range') {\nconst { major, minor, patch, revision, floating, prerelease } = range;\nlet res = '';\nif (prerelease) {\nres = `-${prerelease}`;\n}\nif (revision !== undefined) {\nconst revisionPart =\nfloating === 'revision'\n? floatingComponentToString(revision)\n: `${revision}`;\nres = `.${revisionPart}${res}`;\n}\nif (patch !== undefined) {\nconst patchPart =\nfloating === 'patch' ? floatingComponentToString(patch) : `${patch}`;\nres = `.${patchPart}${res}`;\n}\nif (minor !== undefined) {\nconst minorPart =\nfloating === 'minor' ? floatingComponentToString(minor) : `${minor}`;\nres = `.${minorPart}${res}`;\n}\nif (major !== undefined) {\nconst majorPart =\nfloating === 'major' ? floatingComponentToString(major) : `${major}`;\nres = `${majorPart}${res}`;\n}\nreturn res;\n}\nconst { min, max, minInclusive, maxInclusive } = range;\nconst leftBracket = minInclusive ? '[' : '(';\nconst rightBracket = maxInclusive ? ']' : ')';\nif (min && max) {\nconst minStr =\nmin.type === 'nuget-version' ? versionToString(min) : rangeToString(min);\nconst maxStr = versionToString(max);\nreturn `${leftBracket}${minStr},${maxStr}${rightBracket}`;\n}\nif (min) {\nconst minStr =\nmin.type === 'nuget-version' ? versionToString(min) : rangeToString(min);\nreturn `${leftBracket}${minStr},${rightBracket}`;\n}\nconst maxStr = versionToString(max);\nreturn `${leftBracket},${maxStr}${rightBracket}`;\n}"
"function updateRangeValue(\n{ currentValue, rangeStrategy, currentVersion, newVersion }: NewValueConfig,\nrange: Range,\n): string | null {\nif (range.operator === '!=') {\nreturn range.operator + range.version;\n}\nif (range.prefix) {\nconst futureVersion = getFutureVersion(\nUserPolicyPrecisionMap.None,\nnewVersion,\nrange.version,\n).join('.');\nreturn range.operator + futureVersion + '.*';\n}\nif (range.operator === '~=') {\nconst baseVersion = coerceArray(parseVersion(range.version)?.release);\nconst futureVersion = coerceArray(parseVersion(newVersion)?.release);\nconst baseLen = baseVersion.length;\nconst newVerLen = futureVersion.length;\nif (baseLen < newVerLen) {\nreturn (\nrange.operator + futureVersion.slice(0, baseVersion.length).join('.')\n);\n}\nif (baseLen > newVerLen) {\nfor (let i = baseLen - newVerLen - 1; i >= 0; i--) {\nfutureVersion.push(0);\n}\nreturn range.operator + futureVersion.join('.');\n}\nreturn range.operator + newVersion;\n}\nif (['==', '<='].includes(range.operator)) {\nif (lte(newVersion, range.version)) {\nreturn range.operator + range.version;\n}\nreturn range.operator + newVersion;\n}\nlet output = handleUpperBound(range, newVersion);\nif (output) {\nreturn output;\n}\noutput = handleLowerBound(range, newVersion);\nif (output) {\nreturn output;\n}\nlogger.error(\n{ newVersion, currentValue, range },\n'pep440: failed to process range',\n);\nreturn null;\n}"
"function handleWidenStrategy(\n{ currentValue, rangeStrategy, currentVersion, newVersion }: NewValueConfig,\nranges: Range[],\n): (string | null)[] {\nif (satisfies(newVersion, currentValue)) {\nreturn [currentValue];\n}\nlet rangePrecision = getRangePrecision(ranges);\nconst trimZeros = hasZeroSpecifier(ranges);\nlet newRanges: Range[] = [];\nif (ranges.length === 1 && ranges[0].operator === '~=') {\nnewRanges = divideCompatibleReleaseRange(ranges[0]);\n} else {\nnewRanges = ranges;\n}\nreturn newRanges.map((range) => {\nif (range.operator === '<' && gte(newVersion, range.version)) {\nconst upperBound = coerceArray(parseVersion(range.version)?.release);\nconst len = upperBound.length;\nif (upperBound[len - 1] !== 0) {\nconst key =\nPrecisionUserPolicyMap[\n(len - 1) as keyof typeof PrecisionUserPolicyMap\n];\nrangePrecision =\nUserPolicyPrecisionMap[key as keyof typeof UserPolicyPrecisionMap];\n}\nlet futureVersion = getFutureVersion(\nrangePrecision,\nnewVersion,\nrange.version,\n);\nif (trimZeros) {\nfutureVersion = trimTrailingZeros(futureVersion);\n}\nreturn range.operator + futureVersion.join('.');\n}\nreturn updateRangeValue(\n{\ncurrentValue,\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n},\nrange,\n);\n});\n}"
"function handleReplaceStrategy(\n{ currentValue, rangeStrategy, currentVersion, newVersion }: NewValueConfig,\nranges: Range[],\n): (string | null)[] {\nif (satisfies(newVersion, currentValue)) {\nreturn [currentValue];\n}\nconst trimZeros = hasZeroSpecifier(ranges);\nreturn ranges.map((range) => {\nif (range.operator === '<' && gte(newVersion, range.version)) {\nconst rangePrecision = getRangePrecision(ranges);\nlet futureVersion = getFutureVersion(\nrangePrecision,\nnewVersion,\nrange.version,\n);\nif (trimZeros) {\nfutureVersion = trimTrailingZeros(futureVersion);\n}\nreturn range.operator + futureVersion.join('.');\n}\nif (['>', '>='].includes(range.operator)) {\nif (lte(newVersion, range.version)) {\nreturn '>=' + newVersion;\n}\nconst lowerBound = coerceArray(parseVersion(range.version)?.release);\nconst rangePrecision = lowerBound.length - 1;\nlet newBase = getFutureVersion(rangePrecision, newVersion);\nif (trimZeros) {\nnewBase = trimTrailingZeros(newBase);\n}\nif (range.operator === '>') {\nif (newVersion === newBase.join('.') && newBase.length > 1) {\nnewBase.pop();\n}\n}\nreturn range.operator + newBase.join('.');\n}\nreturn updateRangeValue(\n{\ncurrentValue,\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n},\nrange,\n);\n});\n}"
"function getNewValue({\ncurrentValue,\nrangeStrategy,\ncurrentVersion,\nnewVersion,\n}: NewValueConfig): string {\nif (rangeStrategy === 'replace') {\nconst npmCurrentValue = poetry2npm(currentValue);\ntry {\nconst massagedNewVersion = poetry2semver(newVersion);\nif (\nmassagedNewVersion &&\nisVersion(massagedNewVersion) &&\nnpm.matches(massagedNewVersion, npmCurrentValue)\n) {\nreturn currentValue;\n}\n} catch (err)  {\nlogger.info(\n{ err },\n'Poetry versioning: Error caught checking if newVersion satisfies currentValue',\n);\n}\nconst parsedRange = parseRange(npmCurrentValue);\nconst element = parsedRange[parsedRange.length - 1];\nif (parsedRange.length === 1 && element.operator) {\nif (element.operator === '^') {\nconst version = handleShort('^', npmCurrentValue, newVersion);\nif (version) {\nreturn npm2poetry(version);\n}\n}\nif (element.operator === '~') {\nconst version = handleShort('~', npmCurrentValue, newVersion);\nif (version) {\nreturn npm2poetry(version);\n}\n}\n}\n}\nif (\n(VERSION_PATTERN.exec(newVersion)?.groups?.release ?? '').split('.')\n.length !== 3\n) {\nlogger.debug(\n'Cannot massage python version to npm - returning currentValue',\n);\nreturn currentValue;\n}\ntry {\nconst currentSemverVersion =\ncurrentVersion && poetry2semver(currentVersion);\nconst newSemverVersion = poetry2semver(newVersion);\nif (currentSemverVersion && newSemverVersion) {\nconst newSemver = npm.getNewValue({\ncurrentValue: poetry2npm(currentValue),\nrangeStrategy,\ncurrentVersion: currentSemverVersion,\nnewVersion: newSemverVersion,\n});\nconst newPoetry = newSemver && npm2poetry(newSemver);\nif (newPoetry) {\nreturn newPoetry;\n}\n}\n} catch (err)  {\nlogger.debug(\n{ currentValue, rangeStrategy, currentVersion, newVersion, err },\n'Could not generate new value using npm.getNewValue()',\n);\n}\nreturn currentValue;\n}"
"function getNewValue({\ncurrentValue,\nnewVersion,\nrangeStrategy,\n}: NewValueConfig): string | null {\nif (rangeStrategy !== 'widen') {\nlogger.info(\n{ rangeStrategy, currentValue, newVersion },\n`PVP can't handle this range strategy.`,\n);\nreturn null;\n}\nconst parsed = parseRange(currentValue);\nif (parsed === null) {\nlogger.info(\n{ currentValue, newVersion },\n'could not parse PVP version range',\n);\nreturn null;\n}\nif (isLessThanRange(newVersion, currentValue)) {\nreturn null;\n}\nif (matches(newVersion, currentValue)) {\nreturn null;\n}\nconst compos = getParts(newVersion);\nif (compos === null) {\nreturn null;\n}\nconst majorPlusOne = plusOne(compos.major);\nif (!matches(newVersion, `>=${parsed.lower} && <${majorPlusOne}`)) {\nlogger.warn(\n{ newVersion },\n`Even though the major bound was bumped, the newVersion still isn't accepted.`,\n);\nreturn null;\n}\nreturn `>=${parsed.lower} && <${majorPlusOne}`;\n}"
"protected _parse(version: string): RpmVersion | null {\nlet remainingVersion = version;\nlet epoch = 0;\nconst epochIndex = remainingVersion.indexOf(':');\nif (epochIndex !== -1) {\nconst epochStr = remainingVersion.slice(0, epochIndex);\nif (epochPattern.test(epochStr)) {\nepoch = parseInt(epochStr);\n} else {\nreturn null;\n}\nremainingVersion = remainingVersion.slice(epochIndex + 1);\n}\nlet upstreamVersion: string;\nlet rpmRelease = '';\nlet rpmPreRelease = '';\nlet snapshot = '';\nconst releaseIndex = remainingVersion.indexOf('-');\nconst prereleaseIndex = remainingVersion.indexOf('~');\nconst snapshotIndex = remainingVersion.indexOf('^');\nif (releaseIndex >= 0) {\nupstreamVersion = remainingVersion.slice(0, releaseIndex);\nif (prereleaseIndex >= 0) {\nrpmRelease = remainingVersion.slice(releaseIndex, prereleaseIndex);\nif (snapshotIndex >= 0) {\nrpmPreRelease = remainingVersion.slice(\nprereleaseIndex,\nsnapshotIndex,\n);\nsnapshot = remainingVersion.slice(snapshotIndex + 1);\n} else {\nrpmPreRelease = remainingVersion.slice(prereleaseIndex);\n}\n} else {\nrpmRelease = remainingVersion.slice(releaseIndex + 1);\n}\n} else {\nupstreamVersion = remainingVersion;\n}\nconst release = [...remainingVersion.matchAll(regEx(/\d+/g))].map((m) =>\nparseInt(m[0]),\n);\nreturn {\nepoch,\nupstreamVersion,\nrpmRelease,\nrelease,\nrpmPreRelease,\nsnapshot,\n};\n}"
"protected _compare_glob(v1: string, v2: string): number {\nif (v1 === v2) {\nreturn 0;\n}\nconst matchesv1 = v1.match(alphaNumPattern) ?? [];\nconst matchesv2 = v2.match(alphaNumPattern) ?? [];\nconst matches = Math.min(matchesv1.length, matchesv2.length);\nfor (let i = 0; i < matches; i++) {\nconst matchv1 = matchesv1[i];\nconst matchv2 = matchesv2[i];\nif (matchv1?.startsWith('~') || matchv2?.startsWith('~')) {\nif (!matchv1?.startsWith('~')) {\nreturn 1;\n}\nif (!matchv2?.startsWith('~')) {\nreturn -1;\n}\n}\nif (isNumericString(matchv1?.[0])) {\nif (!isNumericString(matchv2?.[0])) {\nreturn 1;\n}\nconst result = matchv1.localeCompare(matchv2, undefined, {\nnumeric: true,\n});\nif (result === 0) {\ncontinue;\n}\nreturn Math.sign(result);\n} else if (isNumericString(matchv2?.[0])) {\nreturn -1;\n}\nconst compared_value = this._compare_string(matchv1, matchv2);\nif (compared_value !== 0) {\nreturn compared_value;\n}\n}\nif (matchesv1.length === matchesv2.length) {\nreturn 0;\n}\nif (matchesv1.length > matches && matchesv1[matches].startsWith('~')) {\nreturn -1;\n}\nif (matchesv2.length > matches && matchesv2[matches].startsWith('~')) {\nreturn 1;\n}\nreturn matchesv1.length > matchesv2.length ? 1 : -1;\n}"
"protected override _compare(version: string, other: string): number {\nconst parsed1 = this._parse(version);\nconst parsed2 = this._parse(other);\nif (!(parsed1 && parsed2)) {\nreturn 1;\n}\nif (parsed1.epoch !== parsed2.epoch) {\nreturn Math.sign(parsed1.epoch - parsed2.epoch);\n}\nconst upstreamVersionDifference = this._compare_glob(\nparsed1.upstreamVersion,\nparsed2.upstreamVersion,\n);\nif (upstreamVersionDifference !== 0) {\nreturn upstreamVersionDifference;\n}\nconst releaseVersionDifference = this._compare_glob(\nparsed1.rpmRelease,\nparsed2.rpmRelease,\n);\nif (releaseVersionDifference !== 0) {\nreturn releaseVersionDifference;\n}\nif (parsed1.rpmPreRelease === '' && parsed2.rpmPreRelease !== '') {\nreturn 1;\n} else if (parsed1.rpmPreRelease !== '' && parsed2.rpmPreRelease === '') {\nreturn -1;\n}\nconst preReleaseDifference = this._compare_glob(\nparsed1.rpmPreRelease,\nparsed2.rpmPreRelease,\n);\nif (preReleaseDifference !== 0) {\nreturn releaseVersionDifference;\n}\nreturn this._compare_glob(parsed1.snapshot, parsed2.snapshot);\n}"
"function isGreaterThan(version: string, other: string): boolean {\nconst xMajor = getMajor(version) ?? 0;\nconst yMajor = getMajor(other) ?? 0;\nif (xMajor > yMajor) {\nreturn true;\n}\nif (xMajor < yMajor) {\nreturn false;\n}\nconst xMinor = getMinor(version) ?? 0;\nconst yMinor = getMinor(other) ?? 0;\nif (xMinor > yMinor) {\nreturn true;\n}\nif (xMinor < yMinor) {\nreturn false;\n}\nconst xImageVersion = getDatedContainerImageVersion(version) ?? 0;\nconst yImageVersion = getDatedContainerImageVersion(other) ?? 0;\nif (xImageVersion > yImageVersion) {\nreturn true;\n}\nif (xImageVersion < yImageVersion) {\nreturn false;\n}\nconst xSuffixVersion = getDatedContainerImageSuffix(version) ?? 0;\nconst ySuffixVersion = getDatedContainerImageSuffix(other) ?? 0;\nif (xSuffixVersion > ySuffixVersion) {\nreturn true;\n}\nif (xSuffixVersion < ySuffixVersion) {\nreturn false;\n}\nconst xPatch = getPatch(version) ?? 0;\nconst yPatch = getPatch(other) ?? 0;\nreturn xPatch > yPatch;\n}"
"export async function init(\nurl: string,\nprefix: string | undefined,\n): Promise<void> {\nif (!url) {\nreturn;\n}\nrprefix = prefix ?? '';\nlogger.debug('Redis cache init');\nconst rewrittenUrl = normalizeRedisUrl(url);\nconst clusteredMode = rewrittenUrl.length !== url.length;\nconst config = {\nurl: rewrittenUrl,\nsocket: {\nreconnectStrategy: (retries: number) => {\nreturn Math.min(retries * 100, 3000);\n},\n},\npingInterval: 30000,\n};\nif (clusteredMode) {\nconst clusterConfig: RedisClusterOptions = { rootNodes: [config] };\nconst parsedUrl = new URL(rewrittenUrl);\nif (parsedUrl.username) {\nclusterConfig.defaults = {\nusername: parsedUrl.username,\n};\n}\nif (parsedUrl.password) {\nclusterConfig.defaults ??= {};\nclusterConfig.defaults.password = parsedUrl.password;\n}\nclient = createCluster(clusterConfig);\n} else {\nclient = createClient(config);\n}\nawait client.connect();\nlogger.debug('Redis cache connected');\n}"
"export async function getDockerTag(\npackageName: string,\nconstraint: string,\nversioning: string,\n): Promise<string> {\nconst versioningApi = allVersioning.get(versioning);\nif (!versioningApi.isValid(constraint)) {\nlogger.warn(\n{ versioning, constraint },\n`Invalid Docker image version constraint`,\n);\nreturn 'latest';\n}\nlogger.debug(\n{ packageName, versioning, constraint },\n`Found version constraint - checking for a compatible image to use`,\n);\nconst imageReleases = await getPkgReleases({\ndatasource: 'docker',\npackageName,\nversioning,\n});\nif (imageReleases?.releases) {\nlet versions = imageReleases.releases.map((release) => release.version);\nversions = versions.filter(\n(version) =>\nversioningApi.isVersion(version) &&\nversioningApi.matches(version, constraint),\n);\nif (!versions.every((version) => versioningApi.isStable(version))) {\nlogger.debug('Filtering out unstable versions');\nversions = versions.filter((version) => versioningApi.isStable(version));\n}\nconst version = versions\n.sort(versioningApi.sortVersions.bind(versioningApi))\n.pop();\nif (version) {\nlogger.debug(\n{ packageName, versioning, constraint, version },\n`Found compatible image version`,\n);\nreturn version;\n}\n} else {\nlogger.error({ packageName }, `Docker exec: no releases found`);\nreturn 'latest';\n}\nlogger.warn(\n{ packageName, constraint, versioning },\n'Failed to find a tag satisfying constraint, using `latest` tag instead',\n);\nreturn 'latest';\n}"
"export async function removeDanglingContainers(): Promise<void> {\nif (GlobalConfig.get('binarySource') !== 'docker') {\nreturn;\n}\ntry {\nconst containerLabel = getContainerLabel(\nGlobalConfig.get('dockerChildPrefix'),\n);\nlogger.debug(\n`Removing dangling child containers with label ${containerLabel}`,\n);\nconst res = await rawExec(\n`docker ps --filter label=${containerLabel} -aq`,\n{\nencoding: 'utf-8',\n},\n);\nif (res?.stdout?.trim().length) {\nconst containerIds = res.stdout\n.trim()\n.split(newlineRegex)\n.map((container) => container.trim())\n.filter(Boolean);\nlogger.debug({ containerIds }, 'Removing dangling child containers');\nawait rawExec(`docker rm -f ${containerIds.join(' ')}`, {\nencoding: 'utf-8',\n});\n} else {\nlogger.debug('No dangling containers to remove');\n}\n} catch (err) {\nif (err.errno === 'ENOMEM') {\nthrow new Error(SYSTEM_INSUFFICIENT_MEMORY);\n}\nif (err.stderr?.includes('Cannot connect to the Docker daemon')) {\nlogger.info('No docker daemon found');\n} else {\nlogger.warn({ err }, 'Error removing dangling containers');\n}\n}\n}"
"export async function generateDockerCommand(\ncommands: string[],\npreCommands: string[],\noptions: DockerOptions,\n): Promise<string> {\nconst { envVars, cwd } = options;\nlet image = sideCarImage;\nconst volumes = options.volumes ?? [];\nconst {\nlocalDir,\ncacheDir,\ncontainerbaseDir,\ndockerUser,\ndockerChildPrefix,\ndockerCliOptions,\ndockerSidecarImage,\n} = GlobalConfig.get();\nconst result = ['docker run --rm'];\nconst containerName = getContainerName(image, dockerChildPrefix);\nconst containerLabel = getContainerLabel(dockerChildPrefix);\nresult.push(`--name=${containerName}`);\nresult.push(`--label=${containerLabel}`);\nif (dockerUser) {\nresult.push(`--user=${dockerUser}`);\n}\nif (dockerCliOptions) {\nresult.push(dockerCliOptions);\n}\nconst volumeDirs: VolumeOption[] = [localDir, cacheDir];\nif (containerbaseDir) {\nif (cacheDir && containerbaseDir.startsWith(cacheDir)) {\nlogger.debug('containerbaseDir is inside cacheDir');\n} else {\nlogger.debug('containerbaseDir is separate from cacheDir');\nvolumeDirs.push(containerbaseDir);\n}\n} else {\nlogger.debug('containerbaseDir is missing');\n}\nvolumeDirs.push(...volumes);\nresult.push(...prepareVolumes(volumeDirs));\nif (envVars) {\nresult.push(\n...uniq(envVars)\n.filter(isString)\n.map((e) => `-e ${e}`),\n);\n}\nif (cwd) {\nresult.push(`-w `${cwd}``);\n}\nimage = dockerSidecarImage!;\nlogger.debug(\n{ image  },\n'Resolved tag constraint',\n);\nconst taggedImage = image;\nawait prefetchDockerImage(taggedImage);\nresult.push(taggedImage);\nconst bashCommand = [...prepareCommands(preCommands), ...commands].join(\n' && ',\n);\nresult.push(`bash -l -c `${bashCommand.replace(regEx(/`/g), '\\`')}``);\nreturn result.join(' ');\n}"
"private async doRawQuery(): Promise<\nRawQueryResponse<GithubGraphqlPayload<GraphqlItem>>\n> {\nconst requestOptions = this.getRawQueryOptions();\ntype GraphqlData = GithubGraphqlRepoResponse<GraphqlItem>;\ntype HttpBody = GithubGraphqlResponse<GraphqlData>;\nlet httpRes: HttpResponse<HttpBody>;\ntry {\nhttpRes = await this.http.postJson<HttpBody>('/graphql', requestOptions);\n} catch (err) {\nreturn [null, err];\n}\nconst { body } = httpRes;\nconst { data, errors } = body;\nif (errors?.length) {\nif (errors.length === 1) {\nconst { message } = errors[0];\nconst err = new Error(message);\nreturn [null, err];\n} else {\nconst errorInstances = errors.map(({ message }) => new Error(message));\nconst err = new AggregateError(errorInstances);\nreturn [null, err];\n}\n}\nif (!data) {\nconst msg = 'GitHub GraphQL datasource: failed to obtain data';\nconst err = new Error(msg);\nreturn [null, err];\n}\nif (!data.repository) {\nconst msg = 'GitHub GraphQL datasource: failed to obtain repository data';\nconst err = new Error(msg);\nreturn [null, err];\n}\nif (!data.repository.payload) {\nconst msg =\n'GitHub GraphQL datasource: failed to obtain repository payload data';\nconst err = new Error(msg);\nreturn [null, err];\n}\nthis.queryCount += 1;\nthis.isPersistent ??= data.repository.isRepoPrivate === false;\nconst res = data.repository.payload;\nreturn [res, null];\n}"
"private async doPaginatedFetch(): Promise<void> {\nlet hasNextPage = true;\nlet isPaginationDone = false;\nlet nextCursor: string | undefined;\nwhile (hasNextPage && !isPaginationDone && !this.hasReachedQueryLimit()) {\nconst queryResult = await this.doShrinkableQuery();\nconst resultItems: ResultItem[] = [];\nfor (const node of queryResult.nodes) {\nconst item = this.datasourceAdapter.transform(node);\nif (!item) {\nlogger.once.info(\n{\npackageName: `${this.repoOwner}/${this.repoName}`,\nbaseUrl: this.baseUrl,\n},\n`GitHub GraphQL datasource: skipping empty item`,\n);\ncontinue;\n}\nresultItems.push(item);\n}\nisPaginationDone = await this.cacheStrategy().reconcile(resultItems);\nhasNextPage = !!queryResult?.pageInfo?.hasNextPage;\nnextCursor = queryResult?.pageInfo?.endCursor;\nif (hasNextPage && nextCursor) {\nthis.cursor = nextCursor;\n}\n}\nif (this.isPersistent) {\nawait this.storePersistenceFlag(30);\n}\n}"
"async wrapServerResponse<T>(\nmethod: string,\nurl: string,\nresp: HttpResponse<T>,\n): Promise<HttpResponse<T>> {\nif (resp.statusCode === 200) {\nconst etag = resp.headers?.etag;\nconst lastModified = resp.headers?.['last-modified'];\nHttpCacheStats.incRemoteMisses(url);\nconst httpResponse = copyResponse(resp, true);\nconst timestamp = new Date().toISOString();\nconst newHttpCache = HttpCache.parse({\netag,\nlastModified,\nhttpResponse,\ntimestamp,\n});\nif (!newHttpCache) {\nlogger.debug(`http cache: failed to persist cache for ${url}`);\nreturn resp;\n}\nlogger.debug(\n`http cache: saving ${url} (etag=${etag}, lastModified=${lastModified})`,\n);\nawait this.persist(method, url, newHttpCache as HttpCache);\nreturn resp;\n}\nif (resp.statusCode === 304) {\nconst httpCache = await this.get(method, url);\nif (!httpCache) {\nreturn resp;\n}\nconst timestamp = httpCache.timestamp;\nlogger.debug(\n`http cache: Using cached response: ${url} from ${timestamp}`,\n);\nhttpCache.timestamp = new Date().toISOString();\nawait this.persist(method, url, httpCache);\nHttpCacheStats.incRemoteHits(url);\nconst cachedResp = copyResponse(\nhttpCache.httpResponse as HttpResponse<T>,\ntrue,\n);\ncachedResp.authorization = resp.authorization;\nreturn cachedResp;\n}\nreturn resp;\n}"
"export async function configMigration(\nconfig: RenovateConfig,\nbranchList: string[],\n): Promise<ConfigMigrationResult> {\nif (config.mode === 'silent') {\nlogger.debug(\n'Config migration issues are not created, updated or closed when mode=silent',\n);\nreturn { result: 'no-migration' };\n}\nconst migratedConfigData = await MigratedDataFactory.getAsync();\nif (!migratedConfigData) {\nlogger.debug('Config does not need migration');\nMigratedDataFactory.reset();\nreturn { result: 'no-migration' };\n}\nconst res = await checkConfigMigrationBranch(config, migratedConfigData);\nif (res.result === 'no-migration-branch') {\nMigratedDataFactory.reset();\nreturn { result: 'add-checkbox' };\n}\nbranchList.push(res.migrationBranch);\nconst pr = await ensureConfigMigrationPr(config, migratedConfigData);\nif (!pr) {\nMigratedDataFactory.reset();\nreturn { result: 'add-checkbox' };\n}\nMigratedDataFactory.reset();\nreturn {\nresult:\nres.result === 'migration-branch-exists' ? 'pr-exists' : 'pr-modified',\nprNumber: pr.number,\n};\n}"
"export async function getManagerPackageFiles(\nconfig: WorkerExtractConfig,\n): Promise<PackageFile[] | null> {\nconst { enabled, manager, fileList } = config;\nlogger.trace(`getPackageFiles(${manager})`);\nif (!enabled) {\nlogger.debug(`${manager} is disabled`);\nreturn [];\n}\nif (isNonEmptyArray(fileList)) {\nlogger.debug(\n`Matched ${\nfileList.length\n} file(s) for manager ${manager}: ${fileList.join(', ')}`,\n);\n} else {\nreturn [];\n}\nif (get(manager, 'extractAllPackageFiles')) {\nconst allPackageFiles = await extractAllPackageFiles(\nmanager,\nconfig,\nfileList,\n);\nmassageDepNames(allPackageFiles);\nreturn allPackageFiles;\n}\nconst packageFiles: PackageFile[] = [];\nfor (const packageFile of fileList) {\nconst content = await readLocalFile(packageFile, 'utf8');\nif (content) {\nconst res = await extractPackageFile(\nmanager,\ncontent,\npackageFile,\nconfig,\n);\nif (res) {\npackageFiles.push({\n...res,\npackageFile,\n});\n}\n} else {\nlogger.debug(`${packageFile} has no content`);\n}\n}\nmassageDepNames(packageFiles);\nreturn packageFiles;\n}"
"export function processSupersedesManagers(extracts: ExtractResults[]): void {\nconst rejected: Record<string, string[]> = {};\nfor (const primaryExtract of extracts) {\nconst primaryManager = primaryExtract.manager;\nconst secondaryManagers = get(primaryExtract.manager, 'supersedesManagers');\nif (!isNonEmptyArray(secondaryManagers)) {\ncontinue;\n}\nif (!primaryExtract.packageFiles) {\ncontinue;\n}\nconst primaryPackageFiles = primaryExtract.packageFiles.map(\n({ packageFile }) => packageFile,\n);\nfor (const secondaryManager of secondaryManagers) {\nconst secondaryExtract = extracts.find(\n({ manager }) => manager === secondaryManager,\n);\nif (!secondaryExtract?.packageFiles) {\ncontinue;\n}\nfor (const { packageFile, lockFiles } of secondaryExtract.packageFiles) {\nif (isNonEmptyArray(lockFiles)) {\nrejected[primaryManager] ??= [];\nrejected[primaryManager].push(packageFile);\ncontinue;\n}\nif (primaryPackageFiles.includes(packageFile)) {\nrejected[secondaryManager] ??= [];\nrejected[secondaryManager].push(packageFile);\n}\n}\n}\n}\nfor (const extract of extracts) {\nconst rejectedFiles = rejected[extract.manager];\nif (!isNonEmptyArray(rejectedFiles) || !extract.packageFiles) {\ncontinue;\n}\nextract.packageFiles = extract.packageFiles.filter(\n({ packageFile }) => !rejectedFiles.includes(packageFile),\n);\n}\n}"
"export async function pruneStaleBranches(\nconfig: RenovateConfig,\nbranchList: string[] | null | undefined,\n): Promise<void> {\nlogger.debug('Removing any stale branches');\nlogger.trace({ config }, `pruneStaleBranches`);\nlogger.debug(`config.repoIsOnboarded=${config.repoIsOnboarded!}`);\nif (!branchList) {\nlogger.debug('No branchList');\nreturn;\n}\nlet renovateBranches = getBranchList().filter(\n(branchName) =>\nbranchName.startsWith(config.branchPrefix!) &&\nbranchName !== getReconfigureBranchName(config.branchPrefix!),\n);\nif (!renovateBranches?.length) {\nlogger.debug('No renovate branches found');\nreturn;\n}\nlogger.debug(\n{\nbranchList: branchList?.sort(),\nrenovateBranches: renovateBranches?.sort(),\n},\n'Branch lists',\n);\nconst lockFileBranch = `${config.branchPrefix!}lock-file-maintenance`;\nrenovateBranches = renovateBranches.filter(\n(branch) => branch !== lockFileBranch,\n);\nconst remainingBranches = renovateBranches.filter(\n(branch) => !branchList.includes(branch),\n);\nlogger.debug(`remainingBranches=${String(remainingBranches)}`);\nif (remainingBranches.length === 0) {\nlogger.debug('No branches to clean up');\nreturn;\n}\nawait cleanUpBranches(config, remainingBranches);\n}"
"function filterDependencyDashboardData(\nbranches: BranchCache[],\n): Partial<BranchCache>[] {\nconst branchesFiltered: Partial<BranchCache>[] = [];\nfor (const branch of branches) {\nconst upgradesFiltered: Partial<BranchUpgradeCache>[] = [];\nconst { branchName, prNo, prTitle, result, upgrades, prBlockedBy } = branch;\nfor (const upgrade of upgrades ?? []) {\nconst {\ndatasource,\ndepName,\ndisplayPending,\nfixedVersion,\ncurrentVersion,\ncurrentValue,\ncurrentDigest,\nnewValue,\nnewVersion,\nnewDigest,\npackageFile,\nupdateType,\npackageName,\n} = upgrade;\nconst filteredUpgrade: Partial<BranchUpgradeCache> = {\ndatasource,\ndepName,\ndisplayPending,\nfixedVersion,\ncurrentVersion,\ncurrentValue,\ncurrentDigest,\nnewValue,\nnewVersion,\nnewDigest,\npackageFile,\nupdateType,\npackageName,\n};\nupgradesFiltered.push(filteredUpgrade);\n}\nconst filteredBranch: Partial<BranchCache> = {\nbranchName,\nprNo,\nprTitle,\nresult,\nprBlockedBy,\nupgrades: upgradesFiltered,\n};\nbranchesFiltered.push(filteredBranch);\n}\nreturn branchesFiltered;\n}"
"export function isCacheExtractValid(\nbaseBranchSha: string,\nconfigHash: string,\ncachedExtract?: BaseBranchCache,\n): boolean {\nif (!cachedExtract) {\nreturn false;\n}\nif (!cachedExtract.revision) {\nlogger.debug('Cached extract is missing revision, so cannot be used');\nreturn false;\n}\nif (cachedExtract.revision !== EXTRACT_CACHE_REVISION) {\nlogger.debug(\n`Extract cache revision has changed (old=${cachedExtract.revision}, new=${EXTRACT_CACHE_REVISION})`,\n);\nreturn false;\n}\nif (!(cachedExtract.sha && cachedExtract.configHash)) {\nreturn false;\n}\nif (cachedExtract.sha !== baseBranchSha) {\nlogger.debug(\n`Cached extract result cannot be used due to base branch SHA change (old=${cachedExtract.sha}, new=${baseBranchSha})`,\n);\nreturn false;\n}\nif (cachedExtract.configHash !== configHash) {\nlogger.debug('Cached extract result cannot be used due to config change');\nreturn false;\n}\nif (!cachedExtract.extractionFingerprints) {\nlogger.debug(\n'Cached extract is missing extractionFingerprints, so cannot be used',\n);\nreturn false;\n}\nconst changedManagers = new Set();\nfor (const [manager, fingerprint] of Object.entries(\ncachedExtract.extractionFingerprints,\n)) {\nif (fingerprint !== hashMap.get(manager)) {\nchangedManagers.add(manager);\n}\n}\nif (changedManagers.size > 0) {\nlogger.debug(\n{ changedManagers: [...changedManagers] },\n'Manager fingerprint(s) have changed, extract cache cannot be reused',\n);\nreturn false;\n}\nlogger.debug(\n`Cached extract for sha=${baseBranchSha} is valid and can be used`,\n);\nreturn true;\n}"
"export async function extract(\nconfig: RenovateConfig,\noverwriteCache = true,\n): Promise<Record<string, PackageFile[]>> {\nlogger.debug('extract()');\nconst { baseBranch } = config;\nconst baseBranchSha = await scm.getBranchCommit(baseBranch!);\nlet packageFiles: Record<string, PackageFile[]>;\nconst cache = getCache();\ncache.scan ??= {};\nconst cachedExtract = cache.scan[baseBranch!];\nconst configHash = fingerprint(generateFingerprintConfig(config));\nif (\noverwriteCache &&\nisCacheExtractValid(baseBranchSha!, configHash, cachedExtract)\n) {\npackageFiles = cachedExtract.packageFiles;\ntry {\nfor (const files of Object.values(packageFiles)) {\nfor (const file of files) {\nfor (const dep of file.deps) {\ndelete dep.updates;\n}\n}\n}\nlogger.debug('Deleted cached dep updates');\n} catch (err) {\nlogger.info({ err }, 'Error deleting cached dep updates');\n}\n} else {\nawait scm.checkoutBranch(baseBranch!);\nconst extractResult = (await extractAllDependencies(config)) || {};\npackageFiles = extractResult.packageFiles;\nconst { extractionFingerprints } = extractResult;\nif (overwriteCache) {\ncache.scan[baseBranch!] = {\nrevision: EXTRACT_CACHE_REVISION,\nsha: baseBranchSha!,\nconfigHash,\nextractionFingerprints,\npackageFiles,\n};\n}\nconst baseBranches = isNonEmptyArray(config.baseBranches)\n? config.baseBranches\n: [baseBranch];\nObject.keys(cache.scan).forEach((branchName) => {\nif (!baseBranches.includes(branchName)) {\ndelete cache.scan![branchName];\n}\n});\n}\nconst stats = extractStats(packageFiles);\nlogger.info(\n{ baseBranch: config.baseBranch, stats },\n`Dependency extraction complete`,\n);\nlogger.trace({ config: packageFiles }, 'packageFiles');\nensureGithubToken(packageFiles);\nreturn packageFiles;\n}"
"export function calculateLibYears(\nconfig: RenovateConfig,\npackageFiles?: Record<string, PackageFile[]>,\n): void {\nif (!packageFiles) {\nreturn;\n}\nconst allDeps: DepInfo[] = [];\nfor (const [manager, files] of Object.entries(packageFiles)) {\nfor (const file of files) {\nfor (const dep of file.deps) {\nconst depInfo: DepInfo = {\ndepName: dep.depName!,\nmanager,\nfile: file.packageFile,\ndatasource: dep.datasource!,\nversion: (dep.currentVersion ?? dep.currentValue)!,\n};\nif (!dep.updates?.length) {\nallDeps.push(depInfo);\ncontinue;\n}\ndepInfo.outdated = true;\nif (!dep.currentVersionTimestamp) {\nlogger.once.debug(`No currentVersionTimestamp for ${dep.depName}`);\nallDeps.push(depInfo);\ncontinue;\n}\nconst currentVersionDate = DateTime.fromISO(\ndep.currentVersionTimestamp,\n);\nfor (const update of dep.updates) {\nif (!update.releaseTimestamp) {\nlogger.once.debug(\n`No releaseTimestamp for ${dep.depName} update to ${update.newVersion}`,\n);\ncontinue;\n}\nconst releaseDate = DateTime.fromISO(update.releaseTimestamp);\nconst libYears = releaseDate.diff(currentVersionDate, 'years').years;\nif (libYears >= 0) {\nupdate.libYears = libYears;\n}\n}\nconst depLibYears = Math.max(\n...dep.updates.map((update) => update.libYears ?? 0),\n0,\n);\ndepInfo.libYear = depLibYears;\nallDeps.push(depInfo);\n}\n}\n}\nconst libYearsWithStatus = getLibYears(allDeps);\nlogger.debug(libYearsWithStatus, 'Repository libYears');\naddLibYears(config, libYearsWithStatus);\n}"
"private getFixedVersion(\necosystem: Ecosystem,\ndepVersion: string,\naffected: Osv.Affected,\nversioningApi: VersioningApi,\n): string | null {\nconst fixedVersions: string[] = [];\nconst lastAffectedVersions: string[] = [];\nfor (const range of affected.ranges ?? []) {\nif (range.type === 'GIT') {\ncontinue;\n}\nfor (const event of range.events) {\nif (\nisNonEmptyString(event.fixed) &&\nversioningApi.isVersion(event.fixed)\n) {\nfixedVersions.push(event.fixed);\n} else if (\nisNonEmptyString(event.last_affected) &&\nversioningApi.isVersion(event.last_affected)\n) {\nlastAffectedVersions.push(event.last_affected);\n}\n}\n}\nfixedVersions.sort((a, b) => versioningApi.sortVersions(a, b));\nconst fixedVersion = fixedVersions.find((version) =>\nthis.isVersionGt(version, depVersion, versioningApi),\n);\nif (fixedVersion) {\nreturn this.getFixedVersionByEcosystem(fixedVersion, ecosystem);\n}\nlastAffectedVersions.sort((a, b) => versioningApi.sortVersions(a, b));\nconst lastAffected = lastAffectedVersions.find((version) =>\nthis.isVersionGtOrEq(version, depVersion, versioningApi),\n);\nif (lastAffected) {\nreturn this.getLastAffectedByEcosystem(lastAffected, ecosystem);\n}\nreturn null;\n}"
"export async function syncBranchState(\nbranchName: string,\nbaseBranch: string,\n): Promise<BranchCache> {\nlogger.debug('syncBranchState()');\nconst branchSha = await scm.getBranchCommit(branchName);\nconst baseBranchSha = await scm.getBranchCommit(baseBranch);\nconst cache = getCache();\ncache.branches ??= [];\nconst { branches: cachedBranches } = cache;\nlet branchState = cachedBranches.find((br) => br.branchName === branchName);\nif (!branchState) {\nlogger.debug(\n'syncBranchState(): Branch cache not found, creating minimal branchState',\n);\nbranchState = {\nbranchName,\nsha: branchSha,\nbaseBranch,\nbaseBranchSha,\n} as BranchCache;\ncachedBranches.push(branchState);\n}\nif (baseBranch !== branchState.baseBranch) {\nlogger.debug('syncBranchState(): update baseBranch name');\nbranchState.baseBranch = baseBranch;\ndelete branchState.isModified;\nbranchState.pristine = false;\n}\nif (baseBranchSha !== branchState.baseBranchSha) {\nlogger.debug('syncBranchState(): update baseBranchSha');\ndelete branchState.isBehindBase;\ndelete branchState.isConflicted;\nbranchState.baseBranchSha = baseBranchSha;\nbranchState.pristine = false;\n}\nif (branchSha !== branchState.sha) {\nlogger.debug('syncBranchState(): update branchSha');\ndelete branchState.isBehindBase;\ndelete branchState.isConflicted;\ndelete branchState.isModified;\ndelete branchState.commitFingerprint;\nbranchState.sha = branchSha;\nbranchState.pristine = false;\n}\nreturn branchState;\n}"
"export async function getReconfigureConfig(\nbranchName: string,\n): Promise<GetReconfigureConfigResult> {\nawait scm.checkoutBranch(branchName);\nconst configFileName = await detectConfigFile();\nif (configFileName === null) {\nlogger.debug('No config file found in reconfigure branch');\nreturn {\nok: false,\nerrMessage: 'Validation Failed - No config file found',\n};\n}\nconst configFileRaw = await readLocalFile(configFileName, 'utf8');\nif (configFileRaw === null) {\nreturn {\nok: false,\nerrMessage: 'Validation Failed - Invalid config file',\nconfigFileName,\n};\n}\nlet configFileParsed: any;\ntry {\nconfigFileParsed = parseJson(configFileRaw, configFileName);\nif (configFileName === 'package.json') {\nconfigFileParsed = configFileParsed.renovate;\n}\n} catch (err) {\nlogger.debug({ err }, 'Error while parsing config file');\nreturn {\nok: false,\nerrMessage: 'Validation Failed - Unparsable config file',\nconfigFileName,\n};\n}\nreturn { ok: true, config: configFileParsed, configFileName };\n}"
"export async function validateReconfigureBranch(\nconfig: RenovateConfig,\nreconfigureConfig: RenovateConfig,\nconfigFileName: string,\nreconfigurePr: Pr | null,\n): Promise<boolean> {\nlogger.debug('validateReconfigureBranch()');\nconst context = config.statusCheckNames?.configValidation;\nconst branchName = getReconfigureBranchName(config.branchPrefix!);\nconst branchSha = getBranchCommit(branchName)!;\nif (context) {\nconst validationStatus = await platform.getBranchStatusCheck(\nbranchName,\ncontext,\n);\nif (isNonEmptyString(validationStatus)) {\nlogger.debug(\n'Skipping validation check because status check already exists.',\n);\nreturn validationStatus === 'green';\n}\n} else {\nlogger.debug(\n'Status check is null or an empty string, skipping status check addition.',\n);\n}\nconst massagedConfig = massageConfig(reconfigureConfig);\nconst validationResult = await validateConfig('repo', massagedConfig);\nif (validationResult.errors.length > 0) {\nlogger.debug(\n{ errors: validationResult.errors.map((err) => err.message).join(', ') },\n'Validation Errors',\n);\nif (reconfigurePr) {\nlet body = `There is an error with this repository's Renovate configuration that needs to be fixed.\n\n`;\nbody += `Location: \`${configFileName}\`\n`;\nbody += `Message: \`${validationResult.errors\n.map((e) => e.message)\n.join(', ')\n.replace(regEx(/`/g), `'`)}\`\n`;\nawait ensureComment({\nnumber: reconfigurePr.number,\ntopic: 'Action Required: Fix Renovate Configuration',\ncontent: body,\n});\n}\nawait setBranchStatus(branchName, 'Validation Failed', 'red', context);\nsetReconfigureBranchCache(branchSha, false);\nreturn false;\n}\nawait setBranchStatus(branchName, 'Validation Successful', 'green', context);\nreturn true;\n}"
"function compileCommitMessage(upgrade: BranchUpgradeConfig): string {\nif (upgrade.semanticCommits === 'enabled' && !upgrade.commitMessagePrefix) {\nlogger.trace('Upgrade has semantic commits enabled');\nlet semanticPrefix = upgrade.semanticCommitType;\nif (upgrade.semanticCommitScope) {\nsemanticPrefix += `(${template.compile(\nupgrade.semanticCommitScope,\nupgrade,\n)})`;\n}\nupgrade.commitMessagePrefix = CommitMessage.formatPrefix(semanticPrefix!);\nupgrade.toLowerCase =\nregEx(/[A-Z]/).exec(upgrade.semanticCommitType!) === null &&\n!upgrade.semanticCommitType!.startsWith(':');\n}\nupgrade.commitMessage = template.compile(\nupgrade.commitMessage ?? '',\nupgrade,\n);\nupgrade.commitMessage = template.compile(upgrade.commitMessage, upgrade);\nupgrade.commitMessage = template.compile(upgrade.commitMessage, upgrade);\nif (upgrade.commitMessage !== sanitize(upgrade.commitMessage)) {\nlogger.debug(\n{ branchName: upgrade.branchName },\n'Secrets exposed in commit message',\n);\nthrow new Error(CONFIG_SECRETS_EXPOSED);\n}\nupgrade.commitMessage = upgrade.commitMessage.trim();\nupgrade.commitMessage = upgrade.commitMessage.replace(regEx(/\s+/g), ' ');\nupgrade.commitMessage = upgrade.commitMessage.replace(\nregEx(/to vv(\d)/),\n'to v$1',\n);\nif (upgrade.toLowerCase && upgrade.commitMessageLowerCase !== 'never') {\nconst splitMessage = upgrade.commitMessage.split(newlineRegex);\nsplitMessage[0] = splitMessage[0].toLowerCase();\nupgrade.commitMessage = splitMessage.join('\n');\n}\nlogger.trace(`commitMessage: ` + JSON.stringify(upgrade.commitMessage));\nreturn upgrade.commitMessage;\n}"
"function compilePrTitle(\nupgrade: BranchUpgradeConfig,\ncommitMessage: string,\n): void {\nif (upgrade.prTitle) {\nupgrade.prTitle = template.compile(upgrade.prTitle, upgrade);\nupgrade.prTitle = template.compile(upgrade.prTitle, upgrade);\nupgrade.prTitle = template\n.compile(upgrade.prTitle, upgrade)\n.trim()\n.replace(regEx(/\s+/g), ' ');\nif (upgrade.prTitle !== sanitize(upgrade.prTitle)) {\nlogger.debug(\n{ branchName: upgrade.branchName },\n'Secrets were exposed in PR title',\n);\nthrow new Error(CONFIG_SECRETS_EXPOSED);\n}\nif (upgrade.toLowerCase && upgrade.commitMessageLowerCase !== 'never') {\nupgrade.prTitle = upgrade.prTitle.toLowerCase();\n}\n} else {\n[upgrade.prTitle] = commitMessage.split(newlineRegex);\n}\nif (!upgrade.prTitleStrict) {\nupgrade.prTitle += upgrade.hasBaseBranches ? ' ({{baseBranch}})' : '';\nif (upgrade.isGroup) {\nupgrade.prTitle +=\nupgrade.updateType === 'major' && upgrade.separateMajorMinor\n? ' (major)'\n: '';\nupgrade.prTitle +=\nupgrade.updateType === 'minor' && upgrade.separateMinorPatch\n? ' (minor)'\n: '';\nupgrade.prTitle +=\nupgrade.updateType === 'patch' && upgrade.separateMinorPatch\n? ' (patch)'\n: '';\n}\n}\nupgrade.prTitle = template.compile(upgrade.prTitle, upgrade);\nlogger.trace(`prTitle: ` + JSON.stringify(upgrade.prTitle));\n}"
"decode(input: _m0.Reader | Uint8Array, length?: number): Release {\nconst reader =\ninput instanceof _m0.Reader ? input : _m0.Reader.create(input);\nlet end = length === undefined ? reader.len : reader.pos + length;\nconst message = createBaseRelease();\nwhile (reader.pos < end) {\nconst tag = reader.uint32();\nswitch (tag >>> 3) {\ncase 1:\nif (tag !== 10) {\nbreak;\n}\nmessage.version = reader.string();\ncontinue;\ncase 2:\nif (tag !== 18) {\nbreak;\n}\nmessage.innerChecksum = reader.bytes();\ncontinue;\ncase 3:\nif (tag !== 26) {\nbreak;\n}\nmessage.dependencies.push(Dependency.decode(reader, reader.uint32()));\ncontinue;\ncase 4:\nif (tag !== 34) {\nbreak;\n}\nmessage.retired = RetirementStatus.decode(reader, reader.uint32());\ncontinue;\ncase 5:\nif (tag !== 42) {\nbreak;\n}\nmessage.outerChecksum = reader.bytes();\ncontinue;\n}\nif ((tag & 7) === 4 || tag === 0) {\nbreak;\n}\nreader.skipType(tag & 7);\n}\nreturn message;\n},"
"decode(input: _m0.Reader | Uint8Array, length?: number): Dependency {\nconst reader =\ninput instanceof _m0.Reader ? input : _m0.Reader.create(input);\nlet end = length === undefined ? reader.len : reader.pos + length;\nconst message = createBaseDependency();\nwhile (reader.pos < end) {\nconst tag = reader.uint32();\nswitch (tag >>> 3) {\ncase 1:\nif (tag !== 10) {\nbreak;\n}\nmessage.package = reader.string();\ncontinue;\ncase 2:\nif (tag !== 18) {\nbreak;\n}\nmessage.requirement = reader.string();\ncontinue;\ncase 3:\nif (tag !== 24) {\nbreak;\n}\nmessage.optional = reader.bool();\ncontinue;\ncase 4:\nif (tag !== 34) {\nbreak;\n}\nmessage.app = reader.string();\ncontinue;\ncase 5:\nif (tag !== 42) {\nbreak;\n}\nmessage.repository = reader.string();\ncontinue;\n}\nif ((tag & 7) === 4 || tag === 0) {\nbreak;\n}\nreader.skipType(tag & 7);\n}\nreturn message;\n},"
"private popStack(): boolean {\nconst current = this.stack.pop();\nif (!current) {\nreturn false;\n}\nif (!current.isComplete) {\nthis.stack.push(current);\nreturn false;\n}\nconst parent = this.safeCurrent;\nif (parent) {\nif (parent.type === 'attribute' && fragments.isValue(current)) {\nparent.value = current;\nparent.isComplete = true;\nreturn true;\n}\nif (parent.type === 'array' && fragments.isPrimitive(current)) {\nparent.items.push(current);\nreturn true;\n}\nif (\n(parent.type === 'rule' ||\nparent.type === 'extensionTag' ||\nparent.type === 'repoRuleCall') &&\ncurrent.type === 'attribute' &&\ncurrent.value !== undefined\n) {\nparent.children[current.name] = current.value;\nreturn true;\n}\n} else if (\ncurrent.type === 'rule' ||\ncurrent.type === 'extensionTag' ||\ncurrent.type === 'useRepoRule' ||\ncurrent.type === 'repoRuleCall'\n) {\nthis.results.push(current);\nreturn true;\n}\nthrow new CtxProcessingError(current, parent);\n}"
"export async function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: JsonataExtractConfig,\n): Promise<PackageFileContent | null> {\nlet json: unknown;\ntry {\nswitch (config.fileFormat) {\ncase 'json':\njson = parseJson(content, packageFile);\nbreak;\ncase 'yaml':\njson = parseYaml(content);\nbreak;\ncase 'toml':\njson = parseToml(content);\nbreak;\n}\n} catch (err) {\nlogger.debug(\n{ err, fileName: packageFile, fileFormat: config.fileFormat },\n'Error while parsing file',\n);\nreturn null;\n}\nif (isNullOrUndefined(json)) {\nreturn null;\n}\nconst deps = await handleMatching(json, packageFile, config);\nif (!deps.length) {\nreturn null;\n}\nconst res: PackageFileContent & JSONataManagerTemplates = {\ndeps,\nmatchStrings: config.matchStrings,\nfileFormat: config.fileFormat,\n};\nfor (const field of validMatchFields.map(\n(f) => `${f}Template` as keyof JSONataManagerTemplates,\n)) {\nif (config[field]) {\nres[field] = config[field];\n}\n}\nreturn res;\n}"
"export async function handleMatching(\njson: unknown,\npackageFile: string,\nconfig: JsonataExtractConfig,\n): Promise<PackageDependency[]> {\nlet results: Record<string, string>[] = [];\nconst { matchStrings: jsonataQueries } = config;\nfor (const query of jsonataQueries) {\nconst jsonataExpression = jsonata(query);\nconst queryResult = await jsonataExpression.evaluate(json);\nif (!queryResult || isEmptyArray(queryResult)) {\nlogger.debug(\n{\njsonataQuery: query,\npackageFile,\n},\n'The jsonata query returned no matches. Possible error, please check your query. Skipping',\n);\ncontinue;\n}\nconst parsed = QueryResultZod.safeParse(queryResult);\nif (parsed.success) {\nresults = results.concat(parsed.data);\n} else {\nlogger.warn(\n{ err: parsed.error, jsonataQuery: query, packageFile, queryResult },\n'Query results failed schema validation',\n);\ncontinue;\n}\n}\nreturn results\n.map((dep) => createDependency(dep, config))\n.filter(isTruthy)\n.filter((dep) =>\ncheckIsValidDependency(dep, packageFile, 'custom.jsonata'),\n);\n}"
"export function extractPackageFile(\ncontent: string,\npackageFile: string,\nconfig: ExtractConfig,\n): MaybePromise<PackageFileContent | null> {\nlet deps: PackageDependency[];\nswitch (config.matchStringsStrategy) {\ndefault:\ncase 'any':\ndeps = handleAny(content, packageFile, config as RegexManagerConfig);\nbreak;\ncase 'combination':\ndeps = handleCombination(\ncontent,\npackageFile,\nconfig as RegexManagerConfig,\n);\nbreak;\ncase 'recursive':\ndeps = handleRecursive(\ncontent,\npackageFile,\nconfig as RegexManagerConfig,\n);\nbreak;\n}\ndeps = deps.filter(isTruthy);\nif (deps.length) {\nconst res: PackageFileContent & RegexManagerTemplates = {\ndeps,\nmatchStrings: config.matchStrings,\n};\nif (config.matchStringsStrategy) {\nres.matchStringsStrategy = config.matchStringsStrategy;\n}\nfor (const field of validMatchFields.map(\n(f) => `${f}Template` as keyof RegexManagerTemplates,\n)) {\nif (config[field]) {\nres[field] = config[field];\n}\n}\nif (config.autoReplaceStringTemplate) {\nres.autoReplaceStringTemplate = config.autoReplaceStringTemplate;\n}\nreturn res;\n}\nlogger.debug(\n{ packageFile },\n'No dependencies found in file for custom regex manager',\n);\nreturn null;\n}"
"function extractLiteralVersion({\nversion,\ndepStartIndex,\ndepSubContent,\nsectionKey,\n}: {\nversion: GradleVersionPointerTarget | undefined;\ndepStartIndex: number;\ndepSubContent: string;\nsectionKey: string;\n}): VersionExtract {\nif (!version) {\nreturn { skipReason: 'unspecified-version' };\n} else if (isString(version)) {\nconst fileReplacePosition =\ndepStartIndex + findVersionIndex(depSubContent, sectionKey, version);\nreturn { currentValue: version, fileReplacePosition };\n} else if (isPlainObject(version)) {\nconst versionKeys = ['require', 'prefer', 'strictly'];\nlet found = false;\nlet currentValue: string | undefined;\nlet fileReplacePosition: number | undefined;\nif (version.reject || version.rejectAll) {\nreturn { skipReason: 'unsupported-version' };\n}\nfor (const key of versionKeys) {\nif (key in version) {\nif (found) {\nreturn { skipReason: 'multiple-constraint-dep' };\n}\nfound = true;\ncurrentValue = version[key] as string;\nfileReplacePosition =\ndepStartIndex +\nfindIndexAfter(depSubContent, sectionKey, currentValue);\n}\n}\nif (found) {\nreturn { currentValue, fileReplacePosition };\n}\n}\nreturn { skipReason: 'unspecified-version' };\n}"
"function extractDependency({\ndescriptor,\nversions,\ndepStartIndex,\ndepSubContent,\ndepName,\nversionStartIndex,\nversionSubContent,\n}: {\ndescriptor:\n| string\n| GradleCatalogModuleDescriptor\n| GradleCatalogArtifactDescriptor;\nversions: Record<string, GradleVersionPointerTarget>;\ndepStartIndex: number;\ndepSubContent: string;\ndepName: string;\nversionStartIndex: number;\nversionSubContent: string;\n}): PackageDependency<GradleManagerData> {\nif (isString(descriptor)) {\nconst [group, name, currentValue] = descriptor.split(':');\nif (!currentValue) {\nreturn {\ndepName,\nskipReason: 'unspecified-version',\n};\n}\nreturn {\ndepName: `${group}:${name}`,\ncurrentValue,\nmanagerData: {\nfileReplacePosition:\ndepStartIndex + findIndexAfter(depSubContent, depName, currentValue),\n},\n};\n}\nconst { currentValue, fileReplacePosition, skipReason } = extractVersion({\nversion: descriptor.version,\nversions,\ndepStartIndex,\ndepSubContent,\ndepName,\nversionStartIndex,\nversionSubContent,\n});\nif (skipReason) {\nreturn {\ndepName,\nskipReason,\n};\n}\nconst dependency: PackageDependency<GradleManagerData> = {\ncurrentValue,\nmanagerData: { fileReplacePosition },\n};\nif (isArtifactDescriptor(descriptor)) {\nconst { group, name } = descriptor;\ndependency.depName = `${group}:${name}`;\n} else {\nconst [depGroupName, name] = descriptor.module.split(':');\ndependency.depName = `${depGroupName}:${name}`;\n}\nif (isVersionPointer(descriptor.version)) {\ndependency.sharedVariableName = normalizeAlias(descriptor.version.ref);\n}\nreturn dependency;\n}"
"export function parseGcv(\npropsFileName: string,\nfileContents: Record<string, string | null>,\n): PackageDependency<GradleManagerData>[] {\nconst propsFileContent = coerceString(fileContents[propsFileName]);\nconst lockFileName = fs.getSiblingFileName(propsFileName, VERSIONS_LOCK);\nconst lockFileContent = coerceString(fileContents[lockFileName]);\nconst lockFileMap = parseLockFile(lockFileContent);\nconst [propsFileExactMap, propsFileRegexMap] =\nparsePropsFile(propsFileContent);\nconst extractedDeps: PackageDependency<GradleManagerData>[] = [];\nfor (const [propDep, versionAndPosition] of propsFileExactMap) {\nif (lockFileMap.has(propDep)) {\nconst newDep: Record<string, any> = {\nmanagerData: {\npackageFile: propsFileName,\nfileReplacePosition: versionAndPosition.filePos,\n},\ndepName: propDep,\ncurrentValue: versionAndPosition.version,\nlockedVersion: lockFileMap.get(propDep)?.version,\ndepType: lockFileMap.get(propDep)?.depType,\n} satisfies PackageDependency<GradleManagerData>;\nextractedDeps.push(newDep);\nlockFileMap.delete(propDep);\n}\n}\nfor (const [propDepGlob, propVerAndPos] of propsFileRegexMap) {\nconst globRegex = globToRegex(propDepGlob);\nfor (const [exactDep, lockVersionAndDepType] of lockFileMap) {\nif (globRegex.test(exactDep)) {\nconst newDep: Record<string, any> = {\nmanagerData: {\npackageFile: propsFileName,\nfileReplacePosition: propVerAndPos.filePos,\n},\ndepName: exactDep,\ncurrentValue: propVerAndPos.version,\nlockedVersion: lockVersionAndDepType.version,\ndepType: lockVersionAndDepType.depType,\nsharedVariableName: propDepGlob,\n} satisfies PackageDependency<GradleManagerData>;\nextractedDeps.push(newDep);\nlockFileMap.delete(exactDep);\n}\n}\n}\nreturn extractedDeps;\n}"
"export function parsePropsFile(\ninput: string,\n): [Map<string, VersionWithPosition>, Map<string, VersionWithPosition>] {\nconst propsLineRegex = regEx(\n`^(?<depName>[^:]+:[^=]+?) *= *(?<propsVersion>.*)$`,\n);\nconst depVerExactMap = new Map<string, VersionWithPosition>();\nconst depVerRegexMap = new Map<string, VersionWithPosition>();\nlet startOfLineIdx = 0;\nconst isCrLf = input.indexOf('\r\n') > 0;\nconst validGlob = /^[a-zA-Z][-_a-zA-Z0-9.:*]+$/;\nfor (const line of input.split(newlineRegex)) {\nconst lineMatch = propsLineRegex.exec(line);\nif (lineMatch?.groups) {\nconst { depName, propsVersion } = lineMatch.groups;\nif (\nvalidGlob.test(depName) &&\nversionLikeSubstring(propsVersion) !== null\n) {\nconst startPosInLine = line.lastIndexOf(propsVersion);\nconst propVersionPos = startOfLineIdx + startPosInLine;\nif (depName.includes('*')) {\ndepVerRegexMap.set(depName, {\nversion: propsVersion,\nfilePos: propVersionPos,\n});\n} else {\ndepVerExactMap.set(depName, {\nversion: propsVersion,\nfilePos: propVersionPos,\n});\n}\n}\n}\nstartOfLineIdx += line.length + (isCrLf ? 2 : 1);\n}\nlogger.trace(\n`Found ${depVerExactMap.size} dependencies and ${depVerRegexMap.size} wildcard dependencies in ${VERSIONS_PROPS}.`,\n);\nreturn [depVerExactMap, new Map([...depVerRegexMap].sort().reverse())];\n}"
"export function handleDepString(ctx: Ctx): Ctx {\nconst stringTokens = loadFromTokenMap(ctx, 'templateStringTokens');\nconst templateString = interpolateString(stringTokens, ctx);\nif (!templateString) {\nreturn ctx;\n}\nconst dep = parseDependencyString(templateString);\nif (!dep) {\nreturn ctx;\n}\nlet packageFile: string | undefined;\nlet fileReplacePosition: number | undefined;\nfor (const token of stringTokens) {\nif (token.type === 'symbol') {\nconst varData = findVariable(token.value, ctx);\nif (varData) {\npackageFile = varData.packageFile;\nfileReplacePosition = varData.fileReplacePosition;\nif (varData.value === dep.currentValue) {\ndep.managerData = { fileReplacePosition, packageFile };\ndep.sharedVariableName = varData.key;\n}\n}\n}\n}\nif (!dep.managerData) {\nconst lastToken = stringTokens[stringTokens.length - 1];\nif (\nlastToken?.type === 'string-value' &&\ndep.currentValue &&\nlastToken.value.includes(dep.currentValue)\n) {\npackageFile = ctx.packageFile;\nif (stringTokens.length === 1) {\nfileReplacePosition = lastToken.offset + dep.depName!.length + 1;\n} else {\nfileReplacePosition =\nlastToken.offset + lastToken.value.lastIndexOf(dep.currentValue);\n}\ndelete dep.sharedVariableName;\n} else {\ndep.skipReason = 'contains-variable';\n}\ndep.managerData = { fileReplacePosition, packageFile };\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"export function handleKotlinShortNotationDep(ctx: Ctx): Ctx {\nconst moduleNameTokens = loadFromTokenMap(ctx, 'artifactId');\nconst versionTokens = loadFromTokenMap(ctx, 'version');\nconst moduleName = interpolateString(moduleNameTokens, ctx);\nconst versionValue = interpolateString(versionTokens, ctx);\nif (!moduleName || !versionValue) {\nreturn ctx;\n}\nconst groupIdArtifactId = `org.jetbrains.kotlin:kotlin-${moduleName}`;\nconst dep = parseDependencyString(`${groupIdArtifactId}:${versionValue}`);\nif (!dep) {\nreturn ctx;\n}\ndep.depName = moduleName;\ndep.packageName = groupIdArtifactId;\ndep.managerData = {\nfileReplacePosition: versionTokens[0].offset,\npackageFile: ctx.packageFile,\n};\nif (versionTokens.length > 1) {\ndep.skipReason = 'unspecified-version';\n} else if (versionTokens[0].type === 'symbol') {\nconst varData = findVariable(versionTokens[0].value, ctx);\nif (varData) {\ndep.sharedVariableName = varData.key;\ndep.currentValue = varData.value;\ndep.managerData = {\nfileReplacePosition: varData.fileReplacePosition,\npackageFile: varData.packageFile,\n};\n}\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"export function handleLongFormDep(ctx: Ctx): Ctx {\nconst groupIdTokens = loadFromTokenMap(ctx, 'groupId');\nconst artifactIdTokens = loadFromTokenMap(ctx, 'artifactId');\nconst versionTokens = loadFromTokenMap(ctx, 'version');\nconst groupId = interpolateString(groupIdTokens, ctx);\nconst artifactId = interpolateString(artifactIdTokens, ctx);\nconst version = interpolateString(versionTokens, ctx);\nif (!groupId || !artifactId || !version) {\nreturn ctx;\n}\nif (\nisDependencyString(groupId) &&\nisDependencyString(artifactId) &&\nisDependencyString(version)\n) {\nctx.tokenMap.templateStringTokens = groupIdTokens;\nhandleDepString(ctx);\nctx.tokenMap.templateStringTokens = artifactIdTokens;\nhandleDepString(ctx);\nctx.tokenMap.templateStringTokens = versionTokens;\nhandleDepString(ctx);\nreturn ctx;\n}\nconst dep = parseDependencyString([groupId, artifactId, version].join(':'));\nif (!dep) {\nreturn ctx;\n}\nconst methodName = ctx.tokenMap.methodName ?? null;\nif (versionTokens.length > 1) {\ndep.skipReason = 'unspecified-version';\n} else if (versionTokens[0].type === 'symbol') {\nconst varData = findVariable(versionTokens[0].value, ctx);\nif (varData) {\ndep.sharedVariableName = varData.key;\ndep.managerData = {\nfileReplacePosition: varData.fileReplacePosition,\npackageFile: varData.packageFile,\n};\n}\n} else {\nif (methodName?.[0]?.value === 'dependencySet') {\ndep.sharedVariableName = `${groupId}:${version}`;\n}\ndep.managerData = {\nfileReplacePosition: versionTokens[0].offset,\npackageFile: ctx.packageFile,\n};\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"export function handlePlugin(ctx: Ctx): Ctx {\nconst methodName = loadFromTokenMap(ctx, 'methodName')[0];\nconst pluginNameTokens = loadFromTokenMap(ctx, 'pluginName');\nconst pluginVersion = loadFromTokenMap(ctx, 'version');\nconst plugin = interpolateString(pluginNameTokens, ctx);\nif (!plugin) {\nreturn ctx;\n}\nconst depName =\nmethodName.value === 'kotlin' ? `org.jetbrains.kotlin.${plugin}` : plugin;\nconst packageName = `${depName}:${depName}.gradle.plugin`;\nconst dep: PackageDependency<GradleManagerData> = {\ndepType: 'plugin',\ndepName,\npackageName,\ncommitMessageTopic: `plugin ${depName}`,\ncurrentValue: pluginVersion[0].value,\nmanagerData: {\nfileReplacePosition: pluginVersion[0].offset,\npackageFile: ctx.packageFile,\n},\n};\nif (pluginVersion.length > 1) {\ndep.skipReason = 'unspecified-version';\n} else if (pluginVersion[0].type === 'symbol') {\nconst varData = findVariable(pluginVersion[0].value, ctx);\nif (varData) {\ndep.sharedVariableName = varData.key;\ndep.currentValue = varData.value;\ndep.managerData = {\nfileReplacePosition: varData.fileReplacePosition,\npackageFile: varData.packageFile,\n};\n} else {\ndep.skipReason = 'unspecified-version';\n}\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"export function handleRegistryContent(ctx: Ctx): Ctx {\nconst methodName = loadFromTokenMap(ctx, 'methodName')[0].value;\nlet groupId = loadFromTokenMap(ctx, 'groupId')[0].value;\nlet matcher: ContentDescriptorMatcher = 'simple';\nif (methodName.includes('Regex')) {\nmatcher = 'regex';\ngroupId = `^${groupId}$`.replaceAll('\\\\', '\\');\nif (!isValidContentDescriptorRegex('group', groupId)) {\nreturn ctx;\n}\n} else if (methodName.includes('AndSubgroups')) {\nmatcher = 'subgroup';\n}\nconst mode = methodName.startsWith('include') ? 'include' : 'exclude';\nconst spec: ContentDescriptorSpec = { mode, matcher, groupId };\nif (methodName.includes('Module') || methodName.includes('Version')) {\nspec.artifactId = loadFromTokenMap(ctx, 'artifactId')[0].value;\nif (matcher === 'regex') {\nspec.artifactId = `^${spec.artifactId}$`.replaceAll('\\\\', '\\');\nif (!isValidContentDescriptorRegex('module', spec.artifactId)) {\nreturn ctx;\n}\n}\n}\nif (methodName.includes('Version')) {\nspec.version = loadFromTokenMap(ctx, 'version')[0].value;\nif (matcher === 'regex') {\nspec.version = `^${spec.version}$`.replaceAll('\\\\', '\\');\nif (!isValidContentDescriptorRegex('version', spec.version)) {\nreturn ctx;\n}\n}\n}\nctx.tmpRegistryContent.push(spec);\nreturn ctx;\n}"
"export function handleApplyFrom(ctx: Ctx): Ctx {\nlet scriptFile = interpolateString(loadFromTokenMap(ctx, 'scriptFile'), ctx);\nif (!scriptFile) {\nreturn ctx;\n}\nif (ctx.tokenMap.parentPath) {\nconst parentPath = interpolateString(\nloadFromTokenMap(ctx, 'parentPath'),\nctx,\n);\nif (parentPath && scriptFile) {\nscriptFile = upath.join(parentPath, scriptFile);\n}\n}\nif (ctx.recursionDepth > 2) {\nlogger.debug(`Max recursion depth reached in script file: ${scriptFile}`);\nreturn ctx;\n}\nif (!regEx(/\.gradle(\.kts)?$/).test(scriptFile)) {\nlogger.debug({ scriptFile }, `Only Gradle files can be included`);\nreturn ctx;\n}\nconst scriptFilePath = getSiblingFileName(ctx.packageFile, scriptFile);\nif (!ctx.fileContents[scriptFilePath]) {\nlogger.debug(`Failed to process included Gradle file ${scriptFilePath}`);\nreturn ctx;\n}\nconst matchResult = parseGradle(\nctx.fileContents[scriptFilePath],\nctx.globalVars,\nscriptFilePath,\nctx.fileContents,\nctx.recursionDepth + 1,\n);\nctx.deps.push(...matchResult.deps);\nctx.globalVars = { ...ctx.globalVars, ...matchResult.vars };\nctx.registryUrls.push(...matchResult.urls);\nreturn ctx;\n}"
"export function handleImplicitDep(ctx: Ctx): Ctx {\nconst implicitDepName = loadFromTokenMap(ctx, 'implicitDepName')[0].value;\nconst versionTokens = loadFromTokenMap(ctx, 'version');\nconst versionValue = interpolateString(versionTokens, ctx);\nif (!versionValue) {\nreturn ctx;\n}\nconst isImplicitGradlePlugin = implicitDepName in GRADLE_PLUGINS;\nconst groupIdArtifactId = isImplicitGradlePlugin\n? GRADLE_PLUGINS[implicitDepName as keyof typeof GRADLE_PLUGINS][1]\n: GRADLE_TEST_SUITES[implicitDepName as keyof typeof GRADLE_TEST_SUITES];\nconst dep = parseDependencyString(`${groupIdArtifactId}:${versionValue}`);\nif (!dep) {\nreturn ctx;\n}\ndep.depName = implicitDepName;\ndep.packageName = groupIdArtifactId;\ndep.managerData = {\nfileReplacePosition: versionTokens[0].offset,\npackageFile: ctx.packageFile,\n};\nif (versionTokens.length > 1) {\ndep.skipReason = 'unspecified-version';\n} else if (versionTokens[0].type === 'symbol') {\nconst varData = findVariable(versionTokens[0].value, ctx);\nif (varData) {\ndep.sharedVariableName = varData.key;\ndep.currentValue = varData.value;\ndep.managerData = {\nfileReplacePosition: varData.fileReplacePosition,\npackageFile: varData.packageFile,\n};\n}\n}\nctx.deps.push(dep);\nreturn ctx;\n}"
"export async function extractAllPackageFiles(\nconfig: ExtractConfig,\npackageFiles: string[],\n): Promise<PackageFile<NpmManagerData>[]> {\nconst npmFiles: PackageFile<NpmManagerData>[] = [];\nfor (const packageFile of packageFiles) {\nconst content = await readLocalFile(packageFile, 'utf8');\nif (content) {\nconst parsedPnpmWorkspaceYaml = tryParsePnpmWorkspaceYaml(content);\nif (parsedPnpmWorkspaceYaml.success) {\nlogger.trace(\n{ packageFile },\n`Extracting file as a pnpm workspace YAML file`,\n);\nconst deps = await extractPnpmWorkspaceFile(\nparsedPnpmWorkspaceYaml.data,\npackageFile,\n);\nif (deps) {\nnpmFiles.push({\n...deps,\npackageFile,\n});\n}\n} else {\nif (packageFile.endsWith('json')) {\nlogger.trace({ packageFile }, `Extracting as a package.json file`);\nconst deps = await extractPackageFile(content, packageFile, config);\nif (deps) {\nnpmFiles.push({\n...deps,\npackageFile,\n});\n}\n} else {\nlogger.trace({ packageFile }, `Extracting as a .yarnrc.yml file`);\nconst yarnConfig = loadConfigFromYarnrcYml(content);\nif (yarnConfig?.catalogs || yarnConfig?.catalog) {\nconst hasPackageManagerResult = await hasPackageManager(\nupath.dirname(packageFile),\n);\nconst catalogsDeps = await extractYarnCatalogs(\n{ catalog: yarnConfig.catalog, catalogs: yarnConfig.catalogs },\npackageFile,\nhasPackageManagerResult,\n);\nif (catalogsDeps) {\nnpmFiles.push({\n...catalogsDeps,\npackageFile,\n});\n}\n}\n}\n}\n} else {\nlogger.debug({ packageFile }, `No content found`);\n}\n}\nawait postExtract(npmFiles);\nreturn npmFiles;\n}"
"export async function detectPnpmWorkspaces(\npackageFiles: Partial<PackageFile<NpmManagerData>>[],\n): Promise<void> {\nlogger.debug(`Detecting pnpm Workspaces`);\nconst packagePathCache = new Map<string, string[] | null>();\nfor (const p of packageFiles) {\nconst { packageFile, managerData } = p;\nconst pnpmShrinkwrap = managerData?.pnpmShrinkwrap;\nif (pnpmShrinkwrap) {\nlogger.trace(\n{ packageFile, pnpmShrinkwrap },\n'Found an existing pnpm shrinkwrap file; skipping pnpm monorepo check.',\n);\ncontinue;\n}\nconst pnpmWorkspace = await findPnpmWorkspace(packageFile!);\nif (pnpmWorkspace === null) {\ncontinue;\n}\nconst { workspaceYamlPath, lockFilePath } = pnpmWorkspace;\nif (!packagePathCache.has(workspaceYamlPath)) {\nconst filters = await extractPnpmFilters(workspaceYamlPath);\nconst localDir = GlobalConfig.get('localDir');\nconst packages = await findPackages(\nupath.dirname(upath.join(localDir, workspaceYamlPath)),\n{\npatterns: filters,\nignore: ['**/node_modulesbower_components/**'],\n},\n);\nconst packagePaths = packages.map((pkg) =>\nupath.join(pkg.dir, 'package.json'),\n);\npackagePathCache.set(workspaceYamlPath, packagePaths);\n}\nconst packagePaths = packagePathCache.get(workspaceYamlPath);\nconst isPackageInWorkspace = packagePaths?.some((p) =>\np.endsWith(packageFile!),\n);\nif (isPackageInWorkspace) {\np.managerData ??= {};\np.managerData.pnpmShrinkwrap = lockFilePath;\n} else {\nlogger.trace(\n{ packageFile, workspaceYamlPath },\n`Didn't find the package in the pnpm workspace`,\n);\n}\n}\n}"
"export async function getYarnLock(filePath: string): Promise<LockFile> {\nconst yarnLockRaw = (await readLocalFile(filePath, 'utf8'))!;\ntry {\nconst parsed = parseSyml(yarnLockRaw);\nconst lockedVersions: Record<string, string> = {};\nlet lockfileVersion: number | undefined;\nfor (const [key, val] of Object.entries(parsed)) {\nif (key === '__metadata') {\nlockfileVersion = parseInt(val.cacheKey);\nlogger.once.debug(\n`yarn.lock ${filePath} has __metadata.cacheKey=${lockfileVersion}`,\n);\n} else {\nfor (const entry of key.split(', ')) {\ntry {\nconst { scope, name, range } = structUtils.parseDescriptor(entry);\nconst packageName = scope ? `@${scope}/${name}` : name;\nconst { selector } = structUtils.parseRange(range);\nlogger.trace({ entry, version: val.version });\nlockedVersions[packageName + '@' + selector] = parsed[key].version;\n} catch (err) {\nlogger.debug(\n{ entry, err },\n'Invalid descriptor or range found in yarn.lock',\n);\n}\n}\n}\n}\nconst isYarn1 = !('__metadata' in parsed);\nif (isYarn1) {\nlogger.once.debug(\n`yarn.lock ${filePath} is has no __metadata so is yarn 1`,\n);\n} else {\nlogger.once.debug(\n`yarn.lock ${filePath} is has __metadata so is yarn 2+`,\n);\n}\nreturn {\nisYarn1,\nlockfileVersion,\nlockedVersions,\n};\n} catch (err) {\nlogger.debug({ filePath, err }, 'Warning: Exception parsing yarn.lock');\nreturn { isYarn1: true, lockedVersions: {} };\n}\n}"
"export function determineLockFileDirs(\nconfig: PostUpdateConfig,\npackageFiles: AdditionalPackageFiles,\n): DetermineLockFileDirsResult {\nconst npmLockDirs: (string | undefined)[] = [];\nconst yarnLockDirs: (string | undefined)[] = [];\nconst pnpmShrinkwrapDirs: (string | undefined)[] = [];\nfor (const upgrade of config.upgrades) {\nif (\nupgrade.updateType === 'lockFileMaintenance' ||\nupgrade.isRemediation === true ||\nupgrade.isLockfileUpdate === true\n) {\nyarnLockDirs.push(upgrade.managerData?.yarnLock);\nnpmLockDirs.push(upgrade.managerData?.npmLock);\npnpmShrinkwrapDirs.push(upgrade.managerData?.pnpmShrinkwrap);\n}\n}\nif (\nconfig.upgrades.every(\n(upgrade: Upgrade) =>\nupgrade.updateType === 'lockFileMaintenance' ||\nupgrade.isLockfileUpdate,\n)\n) {\nreturn {\nyarnLockDirs: getDirs(yarnLockDirs),\nnpmLockDirs: getDirs(npmLockDirs),\npnpmShrinkwrapDirs: getDirs(pnpmShrinkwrapDirs),\n};\n}\nfunction getPackageFile(\nfileName: string,\n): Partial<PackageFile<NpmManagerData>> {\nlogger.trace('Looking for packageFile: ' + fileName);\nfor (const packageFile of packageFiles.npm!) {\nif (packageFile.packageFile === fileName) {\nlogger.trace({ packageFile }, 'Found packageFile');\nreturn packageFile;\n}\nlogger.trace('No match');\n}\nreturn {};\n}\nfor (const p of config.updatedPackageFiles!) {\nlogger.trace(`Checking ${String(p.path)} for lock files`);\nconst packageFile = getPackageFile(p.path);\nif (!packageFile.managerData) {\ncontinue;\n}\nyarnLockDirs.push(packageFile.managerData.yarnLock);\nnpmLockDirs.push(packageFile.managerData.npmLock);\npnpmShrinkwrapDirs.push(packageFile.managerData.pnpmShrinkwrap);\n}\nreturn {\nyarnLockDirs: getDirs(yarnLockDirs),\nnpmLockDirs: getDirs(npmLockDirs),\npnpmShrinkwrapDirs: getDirs(pnpmShrinkwrapDirs),\n};\n}"
"async function updateYarnOffline(\nlockFileDir: string,\nupdatedArtifacts: FileChange[],\n): Promise<void> {\ntry {\nconst resolvedPaths: string[] = [];\nconst yarnrcYml = await getFile(upath.join(lockFileDir, '.yarnrc.yml'));\nconst yarnrc = await getFile(upath.join(lockFileDir, '.yarnrc'));\nif (yarnrcYml) {\nconst paths = getZeroInstallPaths(yarnrcYml);\nresolvedPaths.push(...paths.map((p) => upath.join(lockFileDir, p)));\n} else if (yarnrc) {\nconst mirrorLine = yarnrc\n.split(newlineRegex)\n.find((line) => line.startsWith('yarn-offline-mirror '));\nif (mirrorLine) {\nconst mirrorPath = ensureTrailingSlash(\nmirrorLine.split(' ')[1].replace(regEx(/`/g), ''),\n);\nresolvedPaths.push(upath.join(lockFileDir, mirrorPath));\n}\n}\nlogger.debug({ resolvedPaths }, 'updateYarnOffline resolvedPaths');\nif (resolvedPaths.length) {\nconst status = await getRepoStatus();\nfor (const f of status.modified.concat(status.not_added)) {\nif (resolvedPaths.some((p) => f.startsWith(p))) {\nupdatedArtifacts.push({\ntype: 'addition',\npath: f,\ncontents: await readLocalFile(f),\n});\n}\n}\nfor (const f of status.deleted || []) {\nif (resolvedPaths.some((p) => f.startsWith(p))) {\nupdatedArtifacts.push({ type: 'deletion', path: f });\n}\n}\n}\n} catch (err) {\nlogger.error({ err }, 'Error updating yarn offline packages');\n}\n}"
"export async function updateYarnBinary(\nlockFileDir: string,\nupdatedArtifacts: FileChange[],\nexistingYarnrcYmlContent: string | undefined | null,\n): Promise<string | undefined | null> {\nlet yarnrcYml = existingYarnrcYmlContent;\ntry {\nconst yarnrcYmlFilename = upath.join(lockFileDir, '.yarnrc.yml');\nyarnrcYml ??= (await getFile(yarnrcYmlFilename)) ?? undefined;\nconst newYarnrcYml = await readLocalFile(yarnrcYmlFilename, 'utf8');\nif (!isString(yarnrcYml) || !isString(newYarnrcYml)) {\nreturn existingYarnrcYmlContent;\n}\nconst oldYarnPath = parseSingleYaml<YarnRcYmlFile>(yarnrcYml)?.yarnPath;\nconst newYarnPath = parseSingleYaml<YarnRcYmlFile>(newYarnrcYml)?.yarnPath;\nif (\n!isNonEmptyStringAndNotWhitespace(oldYarnPath) ||\n!isNonEmptyStringAndNotWhitespace(newYarnPath)\n) {\nreturn existingYarnrcYmlContent;\n}\nconst oldYarnFullPath = upath.join(lockFileDir, oldYarnPath);\nconst newYarnFullPath = upath.join(lockFileDir, newYarnPath);\nlogger.debug({ oldYarnPath, newYarnPath }, 'Found updated Yarn binary');\nyarnrcYml = yarnrcYml.replace(oldYarnPath, newYarnPath);\nupdatedArtifacts.push(\n{\ntype: 'addition',\npath: yarnrcYmlFilename,\ncontents: yarnrcYml,\n},\n{\ntype: 'deletion',\npath: oldYarnFullPath,\n},\n{\ntype: 'addition',\npath: newYarnFullPath,\ncontents: await readLocalFile(newYarnFullPath, 'utf8'),\nisExecutable: true,\n},\n);\n} catch (err) {\nlogger.error({ err }, 'Error updating Yarn binary');\n}\nreturn existingYarnrcYmlContent && yarnrcYml;\n}"
"export function divideWorkspaceAndRootDeps(\nlockFileDir: string,\nlockUpdates: Upgrade[],\n): {\nlockRootUpdates: Upgrade[];\nlockWorkspacesUpdates: Upgrade[];\nworkspaces: Set<string>;\nrootDeps: Set<string>;\n} {\nconst lockRootUpdates: Upgrade[] = [];\nconst lockWorkspacesUpdates: Upgrade[] = [];\nconst workspaces = new Set<string>();\nconst rootDeps = new Set<string>();\nfor (const upgrade of lockUpdates) {\nupgrade.managerData ??= {};\nupgrade.managerData.packageKey = generatePackageKey(\nupgrade.packageName!,\nupgrade.newVersion!,\n);\nif (\nupgrade.managerData.workspacesPackages?.length &&\nisString(upgrade.packageFile)\n) {\nconst workspacePatterns = upgrade.managerData.workspacesPackages;\nconst packageFileDir = trimSlashes(\nupgrade.packageFile.replace('package.json', ''),\n);\nconst workspaceDir = trimSlashes(\npackageFileDir.startsWith(lockFileDir)\n? packageFileDir.slice(lockFileDir.length)\n: packageFileDir,\n);\nif (isNonEmptyString(workspaceDir)) {\nlet workspaceName: string | undefined;\nfor (const workspacePattern of workspacePatterns) {\nconst massagedPattern = (workspacePattern as string).replace(\n/^\.\\n'',\n);\nif (minimatch(massagedPattern).match(workspaceDir)) {\nworkspaceName = workspaceDir;\nbreak;\n}\n}\nif (workspaceName) {\nif (\n!rootDeps.has(upgrade.managerData.packageKey)\n) {\nworkspaces.add(workspaceName);\nupgrade.workspace = workspaceName;\nlockWorkspacesUpdates.push(upgrade);\n}\n} else {\nlogger.warn(\n{ workspacePatterns, workspaceDir },\n'workspaceDir not found',\n);\n}\ncontinue;\n}\n}\nlockRootUpdates.push(upgrade);\nrootDeps.add(upgrade.managerData.packageKey);\n}\nreturn { lockRootUpdates, lockWorkspacesUpdates, workspaces, rootDeps };\n}"
"export function getPackageManagerVersion(\nname: string,\npkg: PackageJson,\n): string | null {\nif (pkg.volta?.[name]) {\nconst version = pkg.volta[name];\nlogger.debug(`Found ${name} constraint in package.json volta: ${version}`);\nreturn version;\n}\nif (pkg.devEngines?.packageManager) {\nconst packageManagers = isArray(pkg.devEngines.packageManager)\n? pkg.devEngines.packageManager\n: [pkg.devEngines.packageManager];\nconst packageMgr = packageManagers.find((pm) => pm.name === name);\nconst version = packageMgr?.version;\nif (version) {\nlogger.debug(\n`Found ${name} constraint in package.json devEngines: ${version}`,\n);\nreturn version;\n}\n}\nif (pkg.packageManager?.name === name) {\nconst version = pkg.packageManager.version;\nlogger.debug(\n`Found ${name} constraint in package.json packageManager: ${version}`,\n);\nif (semver.valid(version)) {\nreturn version;\n}\nreturn null;\n}\nif (pkg.engines?.[name]) {\nconst version = pkg.engines[name];\nlogger.debug(\n`Found ${name} constraint in package.json engines: ${version}`,\n);\nreturn version;\n}\nreturn null;\n}"
"export async function checkYarnrc(\nlockFileDir: string,\n): Promise<{ offlineMirror: boolean; yarnPath: string | null }> {\nlet offlineMirror = false;\nlet yarnPath: string | null = null;\ntry {\nconst yarnrc = await readLocalFile(\nupath.join(lockFileDir, '.yarnrc'),\n'utf8',\n);\nif (isString(yarnrc)) {\nconst mirrorLine = yarnrc\n.split(newlineRegex)\n.find((line) => line.startsWith('yarn-offline-mirror '));\nofflineMirror = !!mirrorLine;\nconst pathLine = yarnrc\n.split(newlineRegex)\n.find((line) => line.startsWith('yarn-path '));\nif (pathLine) {\nyarnPath = pathLine.replace(regEx(/^yarn-path\s+`?(.+?)`?$/), '$1');\n}\nif (yarnPath) {\nyarnPath = upath.join(lockFileDir, yarnPath);\n}\nconst yarnBinaryExists = yarnPath\n? await localPathIsFile(yarnPath)\n: false;\nlet scrubbedYarnrc = yarnrc\n.replace('--install.pure-lockfile true', '')\n.replace('--install.frozen-lockfile true', '');\nif (!yarnBinaryExists) {\nscrubbedYarnrc = scrubbedYarnrc.replace(\nregEx(/^yarn-path\s+`?.+?`?$/gm),\n'',\n);\nyarnPath = null;\n}\nif (yarnrc !== scrubbedYarnrc) {\nlogger.debug(`Writing scrubbed .yarnrc to ${lockFileDir}`);\nawait writeLocalFile(\nupath.join(lockFileDir, '.yarnrc'),\nscrubbedYarnrc,\n);\n}\n}\n} catch {\n}\nreturn { offlineMirror, yarnPath };\n}"
"export function extractMsbuildGlobalManifest(\ncontent: string,\npackageFile: string,\nregistries: Registry[] | undefined,\n): PackageFileContent | null {\nconst deps: PackageDependency[] = [];\nlet manifest: GlobalJson;\nlet extractedConstraints: Record<string, string> | undefined;\ntry {\nmanifest = GlobalJson.parse(content);\n} catch {\nlogger.debug({ packageFile }, `Invalid JSON`);\nreturn null;\n}\nif (!manifest['msbuild-sdks'] && !manifest.sdk?.version) {\nlogger.debug({ packageFile }, 'This global.json is not a Nuget file');\nreturn null;\n}\nif (manifest.sdk?.version) {\ndeps.push({\ndepType: 'dotnet-sdk',\ndepName: 'dotnet-sdk',\ncurrentValue: manifest.sdk?.version,\ndatasource: DotnetVersionDatasource.id,\n});\nextractedConstraints = { 'dotnet-sdk': manifest.sdk?.version };\n}\nif (manifest['msbuild-sdks']) {\nfor (const depName of Object.keys(manifest['msbuild-sdks'])) {\nconst currentValue = manifest['msbuild-sdks'][depName];\nconst dep: NugetPackageDependency = {\ndepType: 'msbuild-sdk',\ndepName,\ncurrentValue,\ndatasource: NugetDatasource.id,\n};\napplyRegistries(dep, registries);\ndeps.push(dep);\n}\n}\nreturn { deps, ...(extractedConstraints && { extractedConstraints }) };\n}"
"function generateCMDs(updatedDeps: Upgrade<Pep621ManagerData>[]): string[] {\nconst cmds: string[] = [];\nconst packagesByCMD: Record<string, string[]> = {};\nfor (const dep of updatedDeps) {\nswitch (dep.depType) {\ncase depTypes.optionalDependencies: {\nif (!dep.managerData?.depGroup) {\nlogger.once.warn(\n{ dep: dep.depName },\n'Unexpected optional dependency without group',\n);\ncontinue;\n}\naddPackageToCMDRecord(\npackagesByCMD,\n`${pdmUpdateCMD} -G ${quote(dep.managerData.depGroup)}`,\ndep.packageName!,\n);\nbreak;\n}\ncase depTypes.dependencyGroups:\ncase depTypes.pdmDevDependencies: {\nif (!dep.managerData?.depGroup) {\nlogger.once.warn(\n{ dep: dep.depName },\n'Unexpected dev dependency without group',\n);\ncontinue;\n}\naddPackageToCMDRecord(\npackagesByCMD,\n`${pdmUpdateCMD} -dG ${quote(dep.managerData.depGroup)}`,\ndep.packageName!,\n);\nbreak;\n}\ncase depTypes.buildSystemRequires:\nbreak;\ndefault: {\naddPackageToCMDRecord(packagesByCMD, pdmUpdateCMD, dep.packageName!);\n}\n}\n}\nfor (const commandPrefix in packagesByCMD) {\nconst packageList = packagesByCMD[commandPrefix].map(quote).join(' ');\nconst cmd = `${commandPrefix} ${packageList}`;\ncmds.push(cmd);\n}\nreturn cmds;\n}"
"async updateArtifacts(\nupdateArtifact: UpdateArtifact,\nproject: PyProject,\n): Promise<UpdateArtifactsResult[] | null> {\nconst { config, updatedDeps, packageFileName } = updateArtifact;\nconst { isLockFileMaintenance } = config;\nconst lockFileName = getSiblingFileName(packageFileName, this.lockfileName);\ntry {\nconst existingLockFileContent = await readLocalFile(lockFileName, 'utf8');\nif (!existingLockFileContent) {\nlogger.debug('No pdm.lock found');\nreturn null;\n}\nconst pythonConstraint: ToolConstraint = {\ntoolName: 'python',\nconstraint:\nconfig.constraints?.python ?? project.project?.['requires-python'],\n};\nconst pdmConstraint: ToolConstraint = {\ntoolName: 'pdm',\nconstraint: config.constraints?.pdm,\n};\nconst extraEnv = {\n...getGitEnvironmentVariables(['pep621']),\n};\nconst execOptions: ExecOptions = {\ncwdFile: packageFileName,\nextraEnv,\ndocker: {},\ntoolConstraints: [pythonConstraint, pdmConstraint],\n};\nconst cmds: string[] = [];\nif (isLockFileMaintenance) {\ncmds.push(pdmUpdateCMD);\n} else {\ncmds.push(...generateCMDs(updatedDeps));\n}\nawait exec(cmds, execOptions);\nconst fileChanges: UpdateArtifactsResult[] = [];\nconst newLockContent = await readLocalFile(lockFileName, 'utf8');\nconst isLockFileChanged = existingLockFileContent !== newLockContent;\nif (isLockFileChanged) {\nfileChanges.push({\nfile: {\ntype: 'addition',\npath: lockFileName,\ncontents: newLockContent,\n},\n});\n} else {\nlogger.debug('pdm.lock is unchanged');\n}\nreturn fileChanges.length ? fileChanges : null;\n} catch (err) {\nif (err.message === TEMPORARY_ERROR) {\nthrow err;\n}\nlogger.debug({ err }, 'Failed to update PDM lock file');\nreturn [\n{\nartifactError: {\nlockFile: lockFileName,\nstderr: err.message,\n},\n},\n];\n}\n}"
"async function getUvExtraIndexUrl(\nproject: PyProject,\ndeps: Upgrade[],\n): Promise<NodeJS.ProcessEnv> {\nconst pyPiRegistryUrls = deps\n.filter((dep) => dep.datasource === PypiDatasource.id)\n.filter((dep) => {\nconst sources = project.tool?.uv?.sources;\nconst packageName = dep.packageName!;\nreturn !sources || !(packageName in sources);\n})\n.flatMap((dep) => dep.registryUrls)\n.filter(isString)\n.filter((registryUrl) => {\nconst configuredIndexUrls =\nproject.tool?.uv?.index?.map(({ url }) => url) ?? [];\nreturn (\nregistryUrl !== PypiDatasource.defaultURL &&\n!configuredIndexUrls.includes(registryUrl)\n);\n});\nconst registryUrls = new Set(pyPiRegistryUrls);\nconst extraIndexUrls: string[] = [];\nfor (const registryUrl of registryUrls) {\nconst parsedUrl = parseUrl(registryUrl);\nif (!parsedUrl) {\ncontinue;\n}\nconst { username, password } = await getUsernamePassword(parsedUrl);\nif (username || password) {\nif (username) {\nparsedUrl.username = username;\n}\nif (password) {\nparsedUrl.password = password;\n}\n}\nextraIndexUrls.push(parsedUrl.toString());\n}\nreturn {\nUV_EXTRA_INDEX_URL: extraIndexUrls.join(' '),\n};\n}"
"process(project: PyProject, deps: PackageDependency[]): PackageDependency[] {\nconst uv = project.tool?.uv;\nif (!uv) {\nreturn deps;\n}\nconst hasExplicitDefault = uv.index?.some(\n(index) => index.default && index.explicit,\n);\nconst defaultIndex = uv.index?.find(\n(index) => index.default && !index.explicit,\n);\nconst implicitIndexUrls = uv.index\n?.filter((index) => !index.explicit && index.name !== defaultIndex?.name)\n?.map(({ url }) => url);\nconst devDependencies = uv['dev-dependencies'];\nif (devDependencies) {\ndeps.push(...devDependencies);\n}\nif (uv.sources || defaultIndex || implicitIndexUrls) {\nfor (const dep of deps) {\nif (!dep.packageName) {\ncontinue;\n}\nif (dep.depType === 'requires-python') {\ncontinue;\n}\nconst depSource = uv.sources?.[dep.packageName];\nif (depSource) {\ndep.depType = depTypes.uvSources;\nif ('index' in depSource) {\nconst index = uv.index?.find(\n({ name }) => name === depSource.index,\n);\nif (index) {\ndep.registryUrls = [index.url];\n}\n} else if ('git' in depSource) {\napplyGitSource(\ndep,\ndepSource.git,\ndepSource.rev,\ndepSource.tag,\ndepSource.branch,\n);\n} else if ('url' in depSource) {\ndep.skipReason = 'unsupported-url';\n} else if ('path' in depSource) {\ndep.skipReason = 'path-dependency';\n} else if ('workspace' in depSource) {\ndep.skipReason = 'inherited-dependency';\n} else {\ndep.skipReason = 'unknown-registry';\n}\n} else {\nif (hasExplicitDefault) {\ndep.registryUrls = [];\n} else if (defaultIndex) {\ndep.registryUrls = [defaultIndex.url];\n}\nif (implicitIndexUrls?.length) {\ndep.registryUrls = implicitIndexUrls.concat(\ndep.registryUrls ?? PypiDatasource.defaultURL,\n);\n}\n}\n}\n}\nreturn deps;\n}"
"static async createHashes(\nregistryURL: string,\nrepository: string,\nversion: string,\n): Promise<string[] | null> {\nlogger.debug(\n`Creating hashes for ${repository}@${version} (${registryURL})`,\n);\nconst builds = await TerraformProviderHash.terraformDatasource.getBuilds(\nregistryURL,\nrepository,\nversion,\n);\nif (!builds) {\nreturn null;\n}\nconst shaUrls = deduplicateArray(\nbuilds.map((build) => build.shasums_url).filter(isNotNullOrUndefined),\n);\nlogger.debug(\n`Getting zip hashes for ${shaUrls.length} shasum URL(s) for ${repository}@${version}`,\n);\nconst zhHashes: string[] = [];\nfor (const shaUrl of shaUrls) {\nconst hashes =\nawait TerraformProviderHash.terraformDatasource.getZipHashes(shaUrl);\nzhHashes.push(...coerceArray(hashes));\n}\nlogger.debug(\n`Got ${zhHashes.length} zip hashes for ${repository}@${version}`,\n);\nconst h1Hashes =\nawait TerraformProviderHash.calculateHashScheme1Hashes(builds);\nconst hashes = [];\nhashes.push(...h1Hashes.map((hash) => `h1:${hash}`));\nhashes.push(...zhHashes.map((hash) => `zh:${hash}`));\nreturn hashes.sort();\n}"
"async function updateAllLocks(\nlocks: ProviderLock[],\n): Promise<ProviderLockUpdate[]> {\nconst updates = await p.map(\nlocks,\nasync (lock) => {\nconst updateConfig: GetPkgReleasesConfig = {\nversioning: 'hashicorp',\ndatasource: 'terraform-provider',\npackageName: lock.packageName,\n};\nconst { releases } = (await getPkgReleases(updateConfig)) ?? {};\nif (!releases) {\nreturn null;\n}\nconst versioning = getVersioning(updateConfig.versioning);\nconst versionsList = releases.map((release) => release.version);\nconst newVersion = versioning.getSatisfyingVersion(\nversionsList,\nlock.constraints,\n);\nif (!newVersion || newVersion === lock.version) {\nreturn null;\n}\nconst update: ProviderLockUpdate = {\nnewVersion,\nnewConstraint: lock.constraints,\nnewHashes:\n(await TerraformProviderHash.createHashes(\nlock.registryUrl,\nlock.packageName,\nnewVersion,\n)) ?? [],\n...lock,\n};\nreturn update;\n},\n{ concurrency: 4 },\n);\nreturn updates.filter(isTruthy);\n}"
"export function getNewConstraint(\ndep: Upgrade<Record<string, unknown>>,\noldConstraint: string | undefined,\n): string | undefined {\nconst {\ncurrentValue,\ncurrentVersion,\nnewValue: rawNewValue,\nnewVersion,\npackageName,\n} = dep;\nconst newValue = massageNewValue(rawNewValue);\nif (oldConstraint && currentValue && newValue && currentValue === newValue) {\nlogger.debug(\n`Leaving constraints `${oldConstraint}` unchanged for `${packageName}` as current and new values are the same`,\n);\nreturn oldConstraint;\n}\nif (\noldConstraint &&\ncurrentValue &&\nnewValue &&\noldConstraint.includes(currentValue)\n) {\nlogger.debug(\n`Updating constraint `${oldConstraint}` to replace `${currentValue}` with `${newValue}` for `${packageName}``,\n);\nreturn oldConstraint.replace(\nregEx(`(,\\s|^)${escapeRegExp(currentValue)}(\\.0)*`),\n`$1${newValue}`,\n);\n}\nif (\noldConstraint &&\ncurrentVersion &&\nnewVersion &&\noldConstraint.includes(currentVersion)\n) {\nlogger.debug(\n`Updating constraint `${oldConstraint}` to replace `${currentVersion}` with `${newVersion}` for `${packageName}``,\n);\nreturn oldConstraint.replace(currentVersion, newVersion);\n}\nif (isPinnedVersion(newValue)) {\nlogger.debug(`Pinning constraint for `${packageName}` to `${newVersion}``);\nreturn newVersion;\n}\nlogger.debug(\n`Could not detect constraint to update for `${packageName}` so setting to newValue `${newValue}``,\n);\nreturn newValue;\n}"
"function transform(item: GithubGraphqlRelease): GithubReleaseItem | null {\nconst releaseItem = GithubGraphqlRelease.safeParse(item);\nif (!releaseItem.success) {\nreturn null;\n}\nconst {\nversion,\nreleaseTimestamp,\nisDraft,\nisPrerelease,\nurl,\nid,\nname,\ndescription,\n} = releaseItem.data;\nif (isDraft) {\nreturn null;\n}\nconst result: GithubReleaseItem = {\nversion,\nreleaseTimestamp,\nurl,\n};\nif (id) {\nresult.id = id;\n}\nif (name) {\nresult.name = name;\n}\nif (description) {\nresult.description = description;\n}\nif (isPrerelease) {\nresult.isStable = false;\n}\nreturn result;\n}"
"export async function getConfig(env: NodeJS.ProcessEnv): Promise<AllConfig> {\nlet config: AllConfig = {};\nconst configFile = env.RENOVATE_ADDITIONAL_CONFIG_FILE;\nif (!configFile) {\nlogger.debug('No additional config file found specified - skipping');\nreturn config;\n}\nconst configFileExists = await fs.pathExists(configFile);\nif (!configFileExists) {\nlogger.fatal(\n{ configFile },\n`Custom additional config file specified in RENOVATE_ADDITIONAL_CONFIG_FILE must exist`,\n);\nprocess.exit(1);\n}\nlogger.debug('Checking for additional config file in ' + configFile);\ntry {\nconfig = await getParsedContent(configFile);\n} catch (err) {\nif (err instanceof SyntaxError || err instanceof TypeError) {\nlogger.fatal(\n{ error: err.stack },\n'Could not parse additional config file',\n);\nprocess.exit(1);\n} else if (err instanceof ReferenceError) {\nlogger.fatal(\n`Error parsing additional config file due to unresolved variable(s): ${err.message}`,\n);\nprocess.exit(1);\n} else if (err.message === 'Unsupported file type') {\nlogger.fatal(err.message);\nprocess.exit(1);\n} else if (env.RENOVATE_ADDITIONAL_CONFIG_FILE) {\nlogger.debug({ err }, 'Parse error');\nlogger.fatal('Error parsing additional config file');\nprocess.exit(1);\n}\nlogger.debug('Error reading or parsing additional config file - skipping');\n}\nif (isNonEmptyObject(config.processEnv)) {\nconst exportedKeys = [];\nfor (const [key, value] of Object.entries(config.processEnv)) {\nif (!isNonEmptyString(value)) {\nlogger.error({ key }, 'processEnv value is not a string.');\ncontinue;\n}\nexportedKeys.push(key);\nprocess.env[key] = value;\n}\nlogger.debug(\n{ keys: exportedKeys },\n'processEnv keys were exported to env',\n);\ndelete config.processEnv;\n}\nreturn migrateAndValidateConfig(config, configFile);\n}"
"export async function getConfig(env: NodeJS.ProcessEnv): Promise<AllConfig> {\nconst configFile = env.RENOVATE_CONFIG_FILE ?? 'config.js';\nconst configFileExists = await fs.pathExists(configFile);\nif (env.RENOVATE_CONFIG_FILE && !configFileExists) {\nlogger.fatal(\n{ configFile },\n`Custom config file specified in RENOVATE_CONFIG_FILE must exist`,\n);\nprocess.exit(1);\n}\nlet config: AllConfig = {};\nif (!configFileExists) {\nlogger.debug('No config file found on disk - skipping');\nreturn config;\n}\nlogger.debug('Checking for config file in ' + configFile);\ntry {\nconfig = await getParsedContent(configFile);\n} catch (err) {\nif (err instanceof SyntaxError || err instanceof TypeError) {\nlogger.fatal({ error: err.stack }, 'Could not parse config file');\nprocess.exit(1);\n} else if (err instanceof ReferenceError) {\nlogger.fatal(\n`Error parsing config file due to unresolved variable(s): ${err.message}`,\n);\nprocess.exit(1);\n} else if (err.message === 'Unsupported file type') {\nlogger.fatal(err.message);\nprocess.exit(1);\n} else if (env.RENOVATE_CONFIG_FILE) {\nlogger.debug({ err }, 'Parse error');\nlogger.fatal('Error parsing config file');\nprocess.exit(1);\n}\nlogger.debug('Error reading or parsing file - skipping');\n}\nif (isNonEmptyObject(config.processEnv)) {\nconst exportedKeys = [];\nfor (const [key, value] of Object.entries(config.processEnv)) {\nif (!isNonEmptyString(value)) {\nlogger.error({ key }, 'processEnv value is not a string.');\ncontinue;\n}\nexportedKeys.push(key);\nprocess.env[key] = value;\n}\nlogger.debug(\n{ keys: exportedKeys },\n'processEnv keys were exported to env',\n);\ndelete config.processEnv;\n}\nreturn migrateAndValidateConfig(config, configFile);\n}"
"export function hostRulesFromEnv(env: NodeJS.ProcessEnv): HostRule[] {\nconst datasources = new Set(getDatasourceList());\nconst platforms = new Set(['github']);\nconst hostRules: HostRule[] = [];\nconst npmEnvPrefixes = ['npm_config_', 'npm_lifecycle_', 'npm_package_'];\nfor (const envName of Object.keys(env).sort()) {\nif (['GITHUB_COM_TOKEN', 'RENOVATE_GITHUB_COM_TOKEN'].includes(envName)) {\ncontinue;\n}\nif (npmEnvPrefixes.some((prefix) => envName.startsWith(prefix))) {\nlogger.trace('Ignoring npm env: ' + envName);\ncontinue;\n}\nconst splitEnv = envName\n.replace(/^RENOVATE_/, '')\n.toLowerCase()\n.replace(/__/g, '-')\n.split('_');\nconst hostType = splitEnv.shift()!;\nif (\ndatasources.has(hostType) ||\n(platforms.has(hostType) && splitEnv.length > 1)\n) {\nlet suffix = splitEnv.pop()!;\nif (isAuthField(suffix) || isHttpsAuthField(suffix)) {\nsuffix = restoreHttpsAuthField(suffix);\nlet matchHost: string | undefined = undefined;\nconst rule: HostRule = {};\nsetHostRuleValue(rule, suffix, env[envName]);\nif (splitEnv.length === 0) {\n} else if (splitEnv.length === 1) {\nlogger.warn({ env: envName }, 'Cannot parse env');\ncontinue;\n} else {\nmatchHost = splitEnv.join('.');\n}\nconst existingRule = hostRules.find(\n(hr) => hr.hostType === hostType && hr.matchHost === matchHost,\n);\nlogger.debug(`Converting ${envName} into a global host rule`);\nif (existingRule) {\nsetHostRuleValue(existingRule, suffix, env[envName]);\n} else {\nconst newRule: HostRule = {\nhostType,\n};\nif (matchHost) {\nnewRule.matchHost = matchHost;\n}\nsetHostRuleValue(newRule, suffix, env[envName]);\nhostRules.push(newRule);\n}\n}\n}\n}\nreturn hostRules;\n}"
"export async function createConfigMigrationBranch(\nconfig: Partial<RenovateConfig>,\nmigratedConfigData: MigratedData,\n): Promise<string | null> {\nlogger.debug('createConfigMigrationBranch()');\nconst pJsonMigration = migratedConfigData.filename === 'package.json';\nconst configFileName = pJsonMigration\n? 'renovate.json'\n: migratedConfigData.filename;\nlogger.debug('Creating config migration branch');\nconst commitMessageFactory = new ConfigMigrationCommitMessageFactory(\nconfig,\nconfigFileName,\n);\nconst commitMessage = commitMessageFactory.getCommitMessage();\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would commit files to config migration branch');\nreturn Promise.resolve(null);\n}\nawait scm.checkoutBranch(config.defaultBranch!);\nconst contents =\nawait MigratedDataFactory.applyPrettierFormatting(migratedConfigData);\nconst files: FileChange[] = [\n{\ntype: 'addition',\npath: configFileName,\ncontents,\n},\n];\nif (pJsonMigration) {\nconst pJson = parseJson(\nawait readLocalFile('package.json', 'utf8'),\n'package.json',\n) as Record<string, unknown>;\nif (pJson?.renovate) {\ndelete pJson.renovate;\n}\nconst pJsonContent = await applyPrettierFormatting(\n'package.json',\nJSON.stringify(pJson, undefined, migratedConfigData.indent.indent),\n'json',\nmigratedConfigData.indent,\n);\nfiles.push({\ntype: 'addition',\npath: 'package.json',\ncontents: pJsonContent,\n});\n}\nreturn scm.commitAndPush({\nbaseBranch: config.baseBranch,\nbranchName: getMigrationBranchName(config),\nfiles,\nmessage: commitMessage.toString(),\nplatformCommit: config.platformCommit,\nforce: true,\nlabels: config.labels,\n});\n}"
"export async function applyPrettierFormatting(\nfilename: string,\ncontent: string,\nparser: PrettierParser,\nindent?: Indent,\n): Promise<string> {\ntry {\nlogger.trace('applyPrettierFormatting - START');\nconst fileList = await scm.getFileList();\nlet prettierExists = fileList.some((file) =>\nprettierConfigFilenames.has(file),\n);\nconst editorconfigExists = fileList.some(\n(file) => file === '.editorconfig',\n);\nif (!prettierExists) {\ntry {\nconst packageJsonContent = await readLocalFile('package.json', 'utf8');\nprettierExists =\npackageJsonContent && JSON.parse(packageJsonContent).prettier;\n} catch {\nlogger.warn(\n'applyPrettierFormatting - Error processing package.json file',\n);\n}\n}\nif (!prettierExists || !parser) {\nreturn content;\n}\nconst options: Options = {\nparser,\ntabWidth: indent?.amount === 0 ? 2 : indent?.amount,\nuseTabs: indent?.type === 'tab',\n};\nif (editorconfigExists) {\nconst editorconf = await EditorConfig.getCodeFormat(filename);\nif (editorconf.maxLineLength) {\noptions.printWidth = isNumber(editorconf.maxLineLength)\n? editorconf.maxLineLength\n: Number.POSITIVE_INFINITY;\n}\n}\nreturn prettier().format(content, options);\n} finally {\nlogger.trace('applyPrettierFormatting - END');\n}\n}"
"private static async build(): Promise<MigratedData | null> {\nlet res: MigratedData | null = null;\ntry {\nconst { configFileName, configFileParsed = {} } =\nawait detectRepoFileConfig();\nconst { isMigrated, migratedConfig } = migrateConfig(configFileParsed);\nif (!isMigrated) {\nreturn null;\n}\ndelete migratedConfig.errors;\ndelete migratedConfig.warnings;\nconst raw = await platform.getRawFile(configFileName!);\nconst indent = detectIndent(raw ?? '');\nconst indentSpace = indent.indent ?? '  ';\nconst filename = configFileName!;\nlet content: string;\nif (filename.endsWith('.json5')) {\ncontent = JSON5.stringify(migratedConfig, undefined, indentSpace);\n} else {\ncontent = JSON.stringify(migratedConfig, undefined, indentSpace);\n}\nif (!content.endsWith('\n')) {\ncontent += '\n';\n}\nres = { content, filename, indent };\n} catch (err) {\nlogger.debug(\n{ err },\n'MigratedDataFactory.getAsync() Error initializing renovate MigratedData',\n);\n}\nreturn res;\n}"
"export async function rebaseMigrationBranch(\nconfig: RenovateConfig,\nmigratedConfigData: MigratedData,\n): Promise<string | null> {\nlogger.debug('Checking if migration branch needs rebasing');\nconst baseBranch = config.defaultBranch!;\nconst branchName = getMigrationBranchName(config);\nconst configFileName = migratedConfigData.filename;\nlet contents = migratedConfigData.content;\nconst existingContents = await getFile(configFileName, branchName);\nif (\njsonStripWhitespaces(contents) === jsonStripWhitespaces(existingContents)\n) {\nlogger.debug('Migration branch is up to date');\nreturn null;\n}\nlogger.debug('Rebasing migration branch');\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would rebase files in migration branch');\nreturn null;\n}\nconst commitMessageFactory = new ConfigMigrationCommitMessageFactory(\nconfig,\nconfigFileName,\n);\nconst commitMessage = commitMessageFactory.getCommitMessage();\nawait scm.checkoutBranch(baseBranch);\ncontents =\nawait MigratedDataFactory.applyPrettierFormatting(migratedConfigData);\nreturn scm.commitAndPush({\nbaseBranch: config.baseBranch,\nbranchName,\nfiles: [\n{\ntype: 'addition',\npath: configFileName,\ncontents,\n},\n],\nmessage: commitMessage.toString(),\nplatformCommit: config.platformCommit,\nlabels: config.labels,\n});\n}"
"async function searchDefaultOnboardingPreset(\nrepository: string,\n): Promise<string | undefined> {\nlet foundPreset: string | undefined;\nlogger.debug('Checking for a default Renovate preset which can be used.');\nconst repoPathParts = repository.split('/');\nfor (\nlet index = repoPathParts.length - 1;\nindex >= 1 && !foundPreset;\nindex--\n) {\nconst groupName = repoPathParts.slice(0, index).join('/');\ntry {\nconst repo = `${groupName}/renovate-config`;\nconst preset = `local>${repo}`;\nlogger.debug(`Checking for preset: ${preset}`);\nif (await getPreset({ repo })) {\nfoundPreset = preset;\n}\n} catch (err) {\nif (\nerr.message !== PRESET_DEP_NOT_FOUND &&\n!err.message.startsWith('Unsupported platform')\n) {\nlogger.warn({ err }, 'Unknown error fetching default owner preset');\n}\n}\n}\nif (!foundPreset) {\nconst orgName = repoPathParts[0];\nconst platform = GlobalConfig.get('platform')!;\ntry {\nconst repo = `${orgName}/.${platform}`;\nconst presetName = 'renovate-config';\nconst orgPresetName = `local>${repo}:${presetName}`;\nlogger.debug(`Checking for preset: ${orgPresetName}`);\nif (\nawait getPreset({\nrepo,\npresetName,\n})\n) {\nfoundPreset = orgPresetName;\n}\n} catch (err) {\nif (\nerr.message !== PRESET_DEP_NOT_FOUND &&\n!err.message.startsWith('Unsupported platform')\n) {\nlogger.warn({ err }, 'Unknown error fetching default owner preset');\n}\n}\n}\nreturn foundPreset;\n}"
"export async function createOnboardingBranch(\nconfig: Partial<RenovateConfig>,\n): Promise<string | null> {\nlogger.debug('createOnboardingBranch()');\nconst configFile = getDefaultConfigFileName(config);\nconst contents = await getOnboardingConfigContents(config, configFile);\nlogger.debug('Creating onboarding branch');\nconst commitMessageFactory = new OnboardingCommitMessageFactory(\nconfig,\nconfigFile,\n);\nlet commitMessage = commitMessageFactory.create().toString();\nif (config.commitBody) {\ncommitMessage = `${commitMessage}\n\n${compile(\nconfig.commitBody,\n{ gitAuthor: config.gitAuthor },\n)}`;\nlogger.trace(`commitMessage: ${commitMessage}`);\n}\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would commit files to onboarding branch');\nreturn null;\n}\nreturn scm.commitAndPush({\nbaseBranch: config.baseBranch,\nbranchName: config.onboardingBranch!,\nfiles: [\n{\ntype: 'addition',\npath: configFile,\ncontents,\n},\n],\nmessage: commitMessage,\nplatformCommit: config.platformCommit,\nforce: true,\nlabels: config.labels,\n});\n}"
"export async function rebaseOnboardingBranch(\nconfig: RenovateConfig,\npreviousConfigHash: string | undefined,\n): Promise<string | null> {\nlogger.debug('Checking if onboarding branch needs rebasing');\nconst platform = GlobalConfig.get('platform')!;\nif (!['github', 'gitea', 'gitlab'].includes(platform)) {\nlogger.debug(\n`Skipping rebase as ${platform} does not support html comments`,\n);\nreturn null;\n}\nconst configFile = getDefaultConfigFileName(config);\nconst contents = await getOnboardingConfigContents(config, configFile);\nconst currentConfigHash = toSha256(contents);\nif (previousConfigHash === currentConfigHash) {\nlogger.debug('No rebase needed');\nreturn null;\n}\nlogger.debug(\n{ previousConfigHash, currentConfigHash },\n'Rebasing onboarding branch',\n);\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would rebase files in onboarding branch');\nreturn null;\n}\nconst commitMessageFactory = new OnboardingCommitMessageFactory(\nconfig,\nconfigFile,\n);\nconst commitMessage = commitMessageFactory.create();\nreturn scm.commitAndPush({\nbaseBranch: config.baseBranch,\nbranchName: config.onboardingBranch!,\nfiles: [\n{\ntype: 'addition',\npath: configFile,\ncontents,\n},\n],\nmessage: commitMessage.toString(),\nplatformCommit: config.platformCommit,\nlabels: config.labels,\n});\n}"
"export function calculateAbandonment(\nreleaseResult: ReleaseResult,\nconfig: LookupUpdateConfig,\n): ReleaseResult {\nconst { lookupName } = releaseResult;\nconst { abandonmentThreshold } = config;\nif (!abandonmentThreshold) {\nlogger.trace(\n{ lookupName },\n'No abandonmentThreshold defined, skipping abandonment check',\n);\nreturn releaseResult;\n}\nconst abandonmentThresholdMs = toMs(abandonmentThreshold);\nif (!abandonmentThresholdMs) {\nlogger.trace(\n{ lookupName, abandonmentThreshold },\n'Could not parse abandonmentThreshold to milliseconds, skipping abandonment check',\n);\nreturn releaseResult;\n}\nconst { mostRecentTimestamp } = releaseResult;\nif (!mostRecentTimestamp) {\nlogger.trace(\n{ lookupName },\n'No mostRecentTimestamp value found, skipping abandonment check',\n);\nreturn releaseResult;\n}\nconst mostRecentTimestampDate = DateTime.fromISO(mostRecentTimestamp);\nconst abandonmentDate = mostRecentTimestampDate.plus({\nmilliseconds: abandonmentThresholdMs,\n});\nconst now = DateTime.local();\nconst isAbandoned = abandonmentDate < now;\nreleaseResult.isAbandoned = isAbandoned;\nif (isAbandoned) {\nlogger.debug(\n`Package abandonment detected: ${config.packageName} (${config.datasource}) - most recent release: ${mostRecentTimestamp}`,\n);\n}\nlogger.trace(\n{\nlookupName,\nmostRecentTimestamp,\nabandonmentThreshold,\nabandonmentThresholdMs,\nabandonmentDate: abandonmentDate.toISO(),\nnow: now.toISO(),\nisAbandoned,\n},\n'Calculated abandonment status',\n);\nif (isAbandoned) {\nconst { datasource, packageName } = config;\nAbandonedPackageStats.write(datasource, packageName, mostRecentTimestamp);\n}\nreturn releaseResult;\n}"
"export function getBucket(\nconfig: BucketConfig,\ncurrentVersion: string,\nnewVersion: string,\nversioningApi: VersioningApi,\n): string | null {\nconst {\nseparateMajorMinor,\nseparateMultipleMajor,\nseparateMultipleMinor,\nseparateMinorPatch,\n} = config;\nif (!separateMajorMinor) {\nreturn 'latest';\n}\nconst fromMajor = versioningApi.getMajor(currentVersion);\nconst toMajor = versioningApi.getMajor(newVersion);\nif (toMajor === null) {\nreturn null;\n}\nif (fromMajor !== toMajor) {\nif (separateMultipleMajor) {\nreturn `v${toMajor}`;\n}\nreturn 'major';\n}\nconst fromMinor = versioningApi.getMinor(currentVersion);\nconst toMinor = versioningApi.getMinor(newVersion);\nif (fromMinor === null || toMinor === null) {\nreturn 'non-major';\n}\nif (fromMinor !== toMinor) {\nif (separateMultipleMinor) {\nreturn `v${toMajor}.${toMinor}`;\n}\nif (separateMinorPatch) {\nreturn 'minor';\n}\nreturn 'non-major';\n}\nif (separateMinorPatch) {\nreturn 'patch';\n}\nreturn 'non-major';\n}"
"export function getCurrentVersion(\ncurrentValue: string,\nlockedVersion: string,\nversioningApi: VersioningApi,\nrangeStrategy: string,\nlatestVersion: string,\nallVersions: string[],\n): string | null {\nif (!isString(currentValue)) {\nreturn null;\n}\nlet useVersions = allVersions.filter((v) =>\nversioningApi.matches(v, currentValue),\n);\nif (useVersions.length === 1) {\nreturn useVersions[0];\n}\nif (latestVersion && versioningApi.matches(latestVersion, currentValue)) {\nuseVersions = useVersions.filter(\n(v) => !versioningApi.isGreaterThan(v, latestVersion),\n);\n}\nif (rangeStrategy === 'pin') {\nreturn (\nlockedVersion ||\nversioningApi.getSatisfyingVersion(useVersions, currentValue)\n);\n}\nif (rangeStrategy === 'bump') {\nreturn versioningApi.minSatisfyingVersion(useVersions, currentValue);\n}\nconst satisfyingVersion = versioningApi.getSatisfyingVersion(\nuseVersions,\ncurrentValue,\n);\nif (satisfyingVersion) {\nreturn satisfyingVersion;\n}\nif (versioningApi.isVersion(currentValue)) {\nreturn currentValue;\n}\nif (versioningApi.isSingleVersion(currentValue)) {\nreturn currentValue.replace(regEx(/=/g), '').trim();\n}\nreturn null;\n}"
"export function getRollbackUpdate(\nconfig: RollbackConfig,\nversions: Release[],\nversioningApi: VersioningApi,\n): LookupUpdate | null {\nconst { packageFile, versioning, depName, currentValue } = config;\nif (!('isLessThanRange' in versioningApi)) {\nlogger.debug(\n{ versioning },\n'Current versioning does not support isLessThanRange()',\n);\nreturn null;\n}\nconst lessThanVersions = versions.filter((v) => {\ntry {\nreturn versioningApi.isLessThanRange!(v.version, currentValue!);\n} catch  {\nreturn false;\n}\n});\nif (!lessThanVersions.length) {\nlogger.debug(\n{ packageFile, depName, currentValue },\n'Missing version has nothing to roll back to',\n);\nreturn null;\n}\nlogger.debug(\n{ packageFile, depName, currentValue },\n`Current version not found - rolling back`,\n);\nlogger.debug(\n{ dependency: depName, versions },\n'Versions found before rolling back',\n);\nlessThanVersions.sort((a, b) =>\nversioningApi.sortVersions(a.version, b.version),\n);\nlet newRelease;\nif (currentValue && versioningApi.isStable(currentValue)) {\nnewRelease = lessThanVersions\n.filter((v) => versioningApi.isStable(v.version))\n.pop();\n}\nlet newVersion = newRelease?.version;\nlet registryUrl = newRelease?.registryUrl;\nif (!newVersion) {\nnewRelease = lessThanVersions.pop();\nnewVersion = newRelease?.version;\nregistryUrl = newRelease?.registryUrl;\n}\nif (!newVersion) {\nlogger.debug('No newVersion to roll back to');\nreturn null;\n}\nconst newValue = versioningApi.getNewValue({\ncurrentValue: currentValue!,\nrangeStrategy: 'replace',\nnewVersion,\n});\nreturn {\nbucket: 'rollback',\nnewMajor: versioningApi.getMajor(newVersion)!,\nnewValue: newValue!,\nnewVersion,\nregistryUrl,\nupdateType: 'rollback',\n};\n}"
"export function calculateMostRecentTimestamp(\nversioningApi: VersioningApi,\nreleaseResult: ReleaseResult,\n): ReleaseResult {\nconst { lookupName } = releaseResult;\nlet highestRelease: Release | undefined;\nfor (const release of releaseResult.releases) {\nif (!highestRelease) {\nif (versioningApi.isVersion(release.version)) {\nhighestRelease = release;\n}\ncontinue;\n}\ntry {\nif (\nversioningApi.isGreaterThan(release.version, highestRelease.version)\n) {\nhighestRelease = release;\ncontinue;\n}\n} catch {\nlogger.trace(\n{ lookupName },\n'Error calculating `mostRecentTimestamp` value',\n);\n}\n}\nif (!highestRelease) {\nlogger.trace(\n{ lookupName },\n'Could not determine the highest release to calculate `mostRecentTimestamp` value',\n);\nreturn releaseResult;\n}\nif (highestRelease.isDeprecated) {\nlogger.trace(\n{ lookupName },\n'Highest release is deprecated, skip calculating `mostRecentTimestamp` value',\n);\nreturn releaseResult;\n}\nconst highestReleaseTimestamp = asTimestamp(highestRelease.releaseTimestamp);\nif (highestReleaseTimestamp) {\nconst highestReleaseDatetime = DateTime.fromISO(highestReleaseTimestamp);\nconst higherTimestampExists = releaseResult.releases.some((release) => {\nconst releaseTimestamp = asTimestamp(release.releaseTimestamp);\nif (!releaseTimestamp) {\nreturn false;\n}\nreturn DateTime.fromISO(releaseTimestamp) > highestReleaseDatetime;\n});\nif (!higherTimestampExists) {\nlogger.trace(\n{ lookupName },\n'Using `mostRecentTimestamp` value because it is the highest timestamp of the highest release version',\n);\nreleaseResult.mostRecentTimestamp = highestReleaseTimestamp;\nreturn releaseResult;\n}\n}\nlogger.trace(\n{ lookupName },\n'Skip using `mostRecentTimestamp` value because the higher timestamp exists for lower version',\n);\nreturn releaseResult;\n}"
"export async function prAlreadyExisted(\nconfig: BranchConfig,\n): Promise<Pr | null> {\nlogger.trace({ config }, 'prAlreadyExisted');\nif (config.recreateClosed) {\nlogger.debug('recreateClosed is true. No need to check for closed PR.');\nreturn null;\n}\nlogger.debug(\n'Check for closed PR because recreating closed PRs is disabled.',\n);\nlet pr = await platform.findPr({\nbranchName: config.branchName,\nprTitle: config.prTitle,\nstate: '!open',\ntargetBranch: config.baseBranch,\n});\nif (!pr && config.branchPrefix !== config.branchPrefixOld) {\npr = await platform.findPr({\nbranchName: config.branchName.replace(\nconfig.branchPrefix!,\nconfig.branchPrefixOld!,\n),\nprTitle: config.prTitle,\nstate: '!open',\ntargetBranch: config.baseBranch,\n});\nif (pr) {\nlogger.debug('Found closed PR with branchPrefixOld');\n}\n}\nif (pr) {\nlogger.debug('Found closed PR with current title');\nconst prDetails = await platform.getPr(pr.number);\nif (prDetails!.state === 'open') {\nlogger.debug('PR reopened - aborting run');\nthrow new Error(REPOSITORY_CHANGED);\n}\nreturn pr;\n}\nlogger.debug('prAlreadyExisted=false');\nreturn null;\n}"
"export function commitFilesToBranch(\nconfig: BranchConfig,\n): Promise<LongCommitSha | null> {\nlet updatedFiles = config.updatedPackageFiles!.concat(\nconfig.updatedArtifacts!,\n);\nif (isNonEmptyArray(config.excludeCommitPaths)) {\nupdatedFiles = updatedFiles.filter(({ path: filePath }) => {\nconst matchesExcludePaths = config.excludeCommitPaths!.some(\n(excludedPath) =>\nminimatch(excludedPath, { dot: true }).match(filePath),\n);\nif (matchesExcludePaths) {\nlogger.debug(`Excluding ${filePath} from commit`);\nreturn false;\n}\nreturn true;\n});\n}\nif (!isNonEmptyArray(updatedFiles)) {\nlogger.debug(`No files to commit`);\nreturn Promise.resolve(null);\n}\nconst fileLength = [...new Set(updatedFiles.map((file) => file.path))].length;\nlogger.debug(`${fileLength} file(s) to commit`);\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would commit files to branch ' + config.branchName);\nreturn Promise.resolve(null);\n}\nif (\nconfig.branchName !== sanitize(config.branchName) ||\nconfig.commitMessage !== sanitize(config.commitMessage)\n) {\nlogger.debug(\n{ branchName: config.branchName },\n'Secrets exposed in branchName or commitMessage',\n);\nthrow new Error(CONFIG_SECRETS_EXPOSED);\n}\nreturn scm.commitAndPush({\nbaseBranch: config.baseBranch,\nbranchName: config.branchName,\nfiles: updatedFiles,\nmessage: config.commitMessage!,\nforce: !!config.forceCommit,\nplatformCommit: config.platformCommit,\nprTitle: config.prTitle,\nautoApprove: config.autoApprove,\nlabels: config.labels,\n});\n}"
"export default async function executePostUpgradeCommands(\nconfig: BranchConfig,\n): Promise<PostUpgradeCommandsExecutionResult | null> {\nconst hasChangedFiles =\n(isArray(config.updatedPackageFiles) &&\nconfig.updatedPackageFiles.length > 0) ||\n(isArray(config.updatedArtifacts) && config.updatedArtifacts.length > 0);\nif (!hasChangedFiles) {\nlogger.debug('No changes to package files, skipping post-upgrade tasks');\nreturn null;\n}\nconst branchUpgradeCommands: BranchUpgradeConfig[] = [\n{\nmanager: config.manager,\ndepName: config.upgrades.map(({ depName }) => depName).join(' '),\nbranchName: config.branchName,\npostUpgradeTasks:\nconfig.postUpgradeTasks!.executionMode === 'branch'\n? config.postUpgradeTasks\n: undefined,\nfileFilters: config.fileFilters,\n},\n];\nconst updateUpgradeCommands: BranchUpgradeConfig[] = config.upgrades.filter(\n({ postUpgradeTasks }) =>\n!postUpgradeTasks?.executionMode ||\npostUpgradeTasks.executionMode === 'update',\n);\nconst { updatedArtifacts, artifactErrors } =\nawait postUpgradeCommandsExecutor(updateUpgradeCommands, config);\nreturn postUpgradeCommandsExecutor(branchUpgradeCommands, {\n...config,\nupdatedArtifacts,\nartifactErrors,\n});\n}"
"export async function handleModifiedPr(\nconfig: BranchConfig,\npr: Pr,\n): Promise<void> {\nif (config.suppressNotifications!.includes('prEditedNotification')) {\nreturn;\n}\nconst editedPrCommentTopic = 'Edited/Blocked Notification';\nconst content =\n'Renovate will not automatically rebase this PR, because it does not recognize the last commit author and assumes somebody else may have edited the PR.\n\n' +\n'You can manually request rebase by checking the rebase/retry box above.\n\n' +\nemojify(' :warning: **Warning**: custom changes will be lost.');\nconst dependencyDashboardCheck =\nconfig.dependencyDashboardChecks?.[config.branchName];\nif (!!dependencyDashboardCheck || config.rebaseRequested) {\nlogger.debug('Manual rebase has been requested for PR');\nif (GlobalConfig.get('dryRun')) {\nlogger.info(\n`DRY-RUN: Would remove edited/blocked PR comment in PR #${pr.number}`,\n);\nreturn;\n}\nlogger.debug(`Removing edited/blocked PR comment in PR #${pr.number}`);\nawait ensureCommentRemoval({\ntype: 'by-topic',\nnumber: pr.number,\ntopic: editedPrCommentTopic,\n});\n} else {\nif (GlobalConfig.get('dryRun')) {\nlogger.info(\n`DRY-RUN: Would ensure edited/blocked PR comment in PR #${pr.number}`,\n);\nreturn;\n}\nlogger.debug('Ensuring comment to indicate that rebasing is not possible');\nawait ensureComment({\nnumber: pr.number,\ntopic: editedPrCommentTopic,\ncontent,\n});\n}\n}"
"export function hasValidSchedule(\nschedule: string[] | null | 'at any time',\n): [true] | [false, string] {\nlet message = '';\nif (\n!schedule ||\nschedule === 'at any time' ||\nschedule[0] === 'at any time'\n) {\nreturn [true];\n}\nconst hasFailedSchedules = schedule.some((scheduleText) => {\nconst parsedCron = parseCron(scheduleText);\nif (parsedCron !== undefined) {\nif (\nparsedCron.minute.filter((v) => v !== 1).length !== 0 ||\n!scheduleText.startsWith(minutesChar)\n) {\nmessage = `Invalid schedule: `${scheduleText}` has cron syntax, but doesn't have * as minutes`;\nreturn true;\n}\nreturn false;\n}\nconst massagedText = fixShortHours(\nscheduleMappings[scheduleText] || scheduleText,\n);\nconst parsedSchedule = later.parse.text(massagedText);\nif (parsedSchedule.error !== -1) {\nmessage = `Invalid schedule: Failed to parse `${scheduleText}``;\nreturn true;\n}\nif (parsedSchedule.schedules.some((s) => s.m)) {\nmessage = `Invalid schedule: `${scheduleText}` should not specify minutes`;\nreturn true;\n}\nif (\n!parsedSchedule.schedules.some(\n(s) =>\n!!s.M || s.d !== undefined || !!s.D || s.t_a !== undefined || !!s.t_b,\n)\n) {\nmessage = `Invalid schedule: `${scheduleText}` has no months, days of week or time of day`;\nreturn true;\n}\nreturn false;\n});\nif (hasFailedSchedules) {\nreturn [false, message];\n}\nreturn [true];\n}"
"export async function tryReuseAutoclosedPr(\nbranchName: string,\nnewTitle: string,\n): Promise<Pr | null> {\nif (!platform.tryReuseAutoclosedPr) {\nreturn null;\n}\nconst autoclosedPr = await platform.findPr({ branchName, state: 'closed' });\nif (!autoclosedPr) {\nreturn null;\n}\nif (!autoclosedPr.title.endsWith(' - autoclosed')) {\nreturn null;\n}\nconst closedAt = autoclosedPr.closedAt;\nif (!closedAt) {\nreturn null;\n}\nconst closedMillisAgo = DateTime.fromISO(closedAt)\n.diffNow()\n.negate()\n.toMillis();\nif (closedMillisAgo > REOPEN_THRESHOLD_MILLIS) {\nlogger.debug(\n`Found autoclosed PR ${autoclosedPr.number} but it is too old to reopen`,\n);\nreturn null;\n}\nlogger.debug(\n{ number: autoclosedPr.number },\n'Found autoclosed PR for branch',\n);\nif (GlobalConfig.get('dryRun')) {\nlogger.info('DRY-RUN: Would try to reopen autoclosed PR');\nreturn null;\n}\ntry {\nconst pr = await platform.tryReuseAutoclosedPr(autoclosedPr, newTitle);\nreturn pr;\n} catch (err) {\nlogger.debug(\n{ err },\n`Error trying to reuse existing PR with branch=${branchName}`,\n);\nreturn null;\n}\n}"
"export async function detectMonorepos(\npackageFiles: Partial<PackageFile<NpmManagerData>>[],\n): Promise<void> {\nawait detectPnpmWorkspaces(packageFiles);\nlogger.debug('Detecting workspaces');\nfor (const p of packageFiles) {\nconst { packageFile, npmrc, managerData = {}, skipInstalls } = p;\nconst {\nnpmLock,\nyarnZeroInstall,\nhasPackageManager,\nworkspacesPackages,\nyarnLock,\n} = managerData;\nconst packages = workspacesPackages as string[] | undefined;\nif (packages?.length) {\nconst internalPackagePatterns = (\nisArray(packages) ? packages : [packages]\n).map((pattern) => getSiblingFileName(packageFile!, pattern));\nconst internalPackageFiles = packageFiles.filter((sp) =>\nmatchesAnyPattern(\ngetParentDir(sp.packageFile!),\ninternalPackagePatterns,\n),\n);\nconst internalPackageNames = internalPackageFiles\n.map((sp) => sp.managerData?.packageJsonName)\n.filter(Boolean);\np.deps?.forEach((dep) => {\nif (\nisString(dep.depName) &&\ninternalPackageNames.includes(dep.depName)\n) {\ndep.isInternal = true;\n}\n});\nfor (const subPackage of internalPackageFiles) {\nsubPackage.managerData = subPackage.managerData ?? {};\nsubPackage.managerData.yarnZeroInstall = yarnZeroInstall;\nsubPackage.managerData.hasPackageManager = hasPackageManager;\nsubPackage.managerData.yarnLock ??= yarnLock;\nsubPackage.managerData.npmLock ??= npmLock;\nsubPackage.skipInstalls = skipInstalls && subPackage.skipInstalls;\nsubPackage.managerData.workspacesPackages = workspacesPackages;\nsubPackage.npmrc ??= npmrc;\nif (p.extractedConstraints) {\nsubPackage.extractedConstraints = {\n...p.extractedConstraints,\n...subPackage.extractedConstraints,\n};\n}\nsubPackage.deps?.forEach((dep) => {\nif (internalPackageNames.includes(dep.depName)) {\ndep.isInternal = true;\n}\n});\n}\n}\n}\n}"
"export function updatePnpmCatalogDependency({\nfileContent,\nupgrade,\n}: UpdateDependencyConfig): string | null {\nconst { depType, managerData, depName } = upgrade;\nconst catalogName = depType?.split('.').at(-1);\nif (!isString(catalogName)) {\nlogger.error(\n'No catalogName was found; this is likely an extraction error.',\n);\nreturn null;\n}\nlet { newValue } = upgrade;\nnewValue = getNewGitValue(upgrade) ?? newValue;\nnewValue = getNewNpmAliasValue(newValue, upgrade) ?? newValue;\nlogger.trace(\n`npm.updatePnpmCatalogDependency(): ${depType}:${ managerData?.catalogName}.${depName} = ${newValue}`,\n);\nlet document;\nlet parsedContents;\ntry {\ndocument = parseDocument(fileContent, { keepSourceTokens: true });\nparsedContents = PnpmCatalogs.parse(document.toJS());\n} catch (err) {\nlogger.debug({ err }, 'Could not parse pnpm-workspace YAML file.');\nreturn null;\n}\nconst usesImplicitDefaultCatalog = parsedContents.catalog !== undefined;\nconst oldVersion =\ncatalogName === 'default' && usesImplicitDefaultCatalog\n? parsedContents.catalog?.[depName!]\n: parsedContents.catalogs?.[catalogName]?.[depName!];\nif (oldVersion === newValue) {\nlogger.trace('Version is already updated');\nreturn fileContent;\n}\nconst path = getDepPath({\ndepName: depName!,\ncatalogName,\nusesImplicitDefaultCatalog,\n});\nconst modifiedDocument = changeDependencyIn(document, path, {\nnewValue,\nnewName: upgrade.newName,\n});\nif (!modifiedDocument) {\nreturn null;\n}\nif (!modifiedDocument.contents?.srcToken) {\nreturn null;\n}\nreturn CST.stringify(modifiedDocument.contents.srcToken);\n}"
"function changeDependencyIn(\ndocument: Document,\npath: string[],\n{ newName, newValue }: { newName?: string; newValue?: string },\n): Document | null {\nconst parentPath = path.slice(0, -1);\nconst relevantItemKey = path.at(-1);\nconst parentNode = document.getIn(parentPath);\nif (!parentNode || !isCollection(parentNode)) {\nreturn null;\n}\nconst relevantNode = parentNode.items.find(\n(item) =>\nisPair(item) && isScalar(item.key) && item.key.value === relevantItemKey,\n);\nif (!relevantNode || !isPair(relevantNode)) {\nreturn null;\n}\nif (newName) {\nif (!CST.isScalar(relevantNode.srcToken?.key)) {\nreturn null;\n}\nCST.setScalarValue(relevantNode.srcToken.key, newName);\n}\nif (newValue) {\nif (!CST.isScalar(relevantNode.srcToken?.value)) {\nreturn null;\n}\nCST.setScalarValue(relevantNode.srcToken.value, newValue);\n}\nreturn document;\n}"
"export function updateYarnrcCatalogDependency({\nfileContent,\nupgrade,\n}: UpdateDependencyConfig): string | null {\nconst { depType, depName } = upgrade;\nconst catalogName = depType?.split('.').at(-1);\nif (!isString(catalogName)) {\nlogger.error(\n'No catalogName was found; this is likely an extraction error.',\n);\nreturn null;\n}\nlet { newValue } = upgrade;\nnewValue = getNewGitValue(upgrade) ?? newValue;\nnewValue = getNewNpmAliasValue(newValue, upgrade) ?? newValue;\nlogger.trace(\n`npm.updateYarnrcCatalogDependency(): ${depType}::${catalogName}.${depName} = ${newValue}`,\n);\nlet document: ReturnType<typeof parseDocument>;\nlet parsedContents: YarnConfig;\ntry {\ndocument = parseDocument(fileContent, { keepSourceTokens: true });\nparsedContents = YarnConfig.parse(document.toString());\n} catch (err) {\nlogger.debug({ err }, 'Could not parse yarnrc YAML file.');\nreturn null;\n}\nconst oldVersion =\ncatalogName === 'default'\n? parsedContents.catalog?.[depName!]\n: isObject(parsedContents.catalogs?.[catalogName]) && isString(depName)\n? parsedContents.catalogs?.[catalogName][depName]\n: undefined;\nif (oldVersion === newValue) {\nlogger.trace('Version is already updated');\nreturn fileContent;\n}\nconst path = getDepPath({\ndepName: depName!,\ncatalogName,\n});\nconst modifiedDocument = changeDependencyIn(document, path, {\nnewValue,\nnewName: upgrade.newName,\n});\nif (!modifiedDocument) {\nreturn null;\n}\nreturn CST.stringify(modifiedDocument.contents!.srcToken!);\n}"
"function changeDependencyIn(\ndocument: Document,\npath: string[],\n{ newName, newValue }: { newName?: string; newValue?: string },\n): Document | null {\nconst parentPath = path.slice(0, -1);\nconst relevantItemKey = path.at(-1);\nconst parentNode = document.getIn(parentPath);\nif (!parentNode || !isCollection(parentNode)) {\nreturn null;\n}\nconst relevantNode = parentNode.items.find(\n(item) =>\nisPair(item) && isScalar(item.key) && item.key.value === relevantItemKey,\n);\nif (!relevantNode || !isPair(relevantNode)) {\nreturn null;\n}\nif (newName) {\nCST.setScalarValue(relevantNode.srcToken!.key!, newName);\n}\nif (newValue) {\nif (!CST.isScalar(relevantNode.srcToken?.value)) {\nreturn null;\n}\nCST.setScalarValue(relevantNode.srcToken.value, newValue);\n}\nreturn document;\n}"
"export function bumpPackageVersion(\ncontent: string,\ncurrentValue: string,\nbumpVersion: ReleaseType | `mirror:${string}`,\n): BumpPackageVersionResult {\nlogger.debug(\n{ bumpVersion, currentValue },\n'Checking if we should bump package.json version',\n);\nlet newPjVersion: string | null;\nlet bumpedContent = content;\ntry {\nif (isMirrorBumpVersion(bumpVersion)) {\nconst mirrorPackage = bumpVersion.replace('mirror:', '');\nconst parsedContent = JSON.parse(content);\nnewPjVersion =\nparsedContent.dependencies?.[mirrorPackage] ??\nparsedContent.devDependencies?.[mirrorPackage] ??\nparsedContent.optionalDependencies?.[mirrorPackage] ??\nparsedContent.peerDependencies?.[mirrorPackage];\nif (!newPjVersion) {\nlogger.warn({ mirrorPackage }, 'bumpVersion mirror package not found');\nreturn { bumpedContent };\n}\n} else {\nnewPjVersion = semver.inc(currentValue, bumpVersion);\n}\nlogger.debug(`newPjVersion: ${newPjVersion!}`);\nbumpedContent = content.replace(\nregEx(`(?<version>`version`:\\s*`)[^`]*`),\n`$<version>${newPjVersion!}`,\n);\nif (bumpedContent === content) {\nlogger.debug('Version was already bumped');\n} else {\nlogger.debug('Bumped package.json version');\n}\n} catch {\nlogger.warn(\n{\ncontent,\ncurrentValue,\nbumpVersion,\n},\n'Failed to bumpVersion',\n);\n}\nreturn { bumpedContent };\n}"
"private walkPath(\nabstractDep: PackageDependency,\nparentElement: unknown,\nleftPath: string[],\nconfig: ExtractConfig,\n): PackageDependency[] {\nconst dependencies: PackageDependency[] = [];\nif (leftPath.length === 0) {\nif (!isNonEmptyString(parentElement)) {\nreturn [\n{\n...abstractDep,\nskipReason: 'invalid-dependency-specification',\n},\n];\n}\nconst test = getDep(parentElement, true, config.registryAliases);\nconst dep: PackageDependency = {\n...abstractDep,\n...test,\n};\nreturn [dep];\n}\nconst pathElement = leftPath[0];\nconst element = isNonEmptyObject(parentElement)\n? parentElement[pathElement]\n: null;\nif (isNullOrUndefined(element)) {\nreturn leftPath.length === 1\n? [\n{\n...abstractDep,\nskipReason: 'invalid-dependency-specification',\n},\n]\n: [];\n}\nif (isArray(element)) {\nfor (const arrayElement of element) {\ndependencies.push(\n...this.walkPath(\nabstractDep,\narrayElement,\nleftPath.slice(1),\nconfig,\n),\n);\n}\nreturn dependencies;\n}\nreturn this.walkPath(abstractDep, element, leftPath.slice(1), config);\n}"
"override extract(\nhclMap: TerraformDefinitionFile,\n_locks: ProviderLock[],\nconfig: ExtractConfig,\n): PackageDependency[] {\nconst dependencies = [];\nconst helmReleases = hclMap?.resource?.helm_release;\nif (isNullOrUndefined(helmReleases)) {\nreturn [];\n}\nif (!isPlainObject(helmReleases)) {\nlogger.debug(\n{ helmReleases },\n'Terraform: unexpected `helmReleases` value',\n);\nreturn [];\n}\nfor (const helmRelease of Object.values(helmReleases).flat()) {\nconst dep: PackageDependency = {\ncurrentValue: helmRelease.version,\ndepType: 'helm_release',\ndepName: helmRelease.chart,\ndatasource: HelmDatasource.id,\n};\ndependencies.push(dep);\nif (!isNonEmptyString(helmRelease.chart)) {\ndep.skipReason = 'invalid-name';\n} else if (isOCIRegistry(helmRelease.chart)) {\ndep.depName = removeOCIPrefix(helmRelease.chart);\nthis.processOCI(dep.depName, config, dep);\n} else if (checkIfStringIsPath(helmRelease.chart)) {\ndep.skipReason = 'local-chart';\n} else if (isNonEmptyString(helmRelease.repository)) {\nif (isOCIRegistry(helmRelease.repository)) {\nthis.processOCI(\njoinUrlParts(\nremoveOCIPrefix(helmRelease.repository),\nhelmRelease.chart,\n),\nconfig,\ndep,\n);\n} else {\ndep.registryUrls = [helmRelease.repository];\n}\n}\n}\nreturn dependencies;\n}"
"extract(\nhclRoot: TerraformDefinitionFile,\nlocks: ProviderLock[],\n): PackageDependency[] {\nconst terraformBlocks = hclRoot?.terraform;\nif (isNullOrUndefined(terraformBlocks)) {\nreturn [];\n}\nconst dependencies: PackageDependency[] = [];\nfor (const terraformBlock of terraformBlocks) {\nconst requiredProviders = terraformBlock.required_providers;\nif (isNullOrUndefined(requiredProviders)) {\ncontinue;\n}\nconst entries: [string, TerraformRequiredProvider | string][] =\nrequiredProviders.flatMap(Object.entries);\nfor (const [requiredProviderName, value] of entries) {\nlet dep: PackageDependency;\nif (isString(value)) {\ndep = {\ncurrentValue: value,\nmanagerData: {\nmoduleName: requiredProviderName,\n},\n};\n} else {\ndep = {\ncurrentValue: value.version,\nmanagerData: {\nmoduleName: requiredProviderName,\nsource: value.source,\n},\n};\n}\ndependencies.push(\nthis.analyzeTerraformProvider(dep, locks, 'required_provider'),\n);\n}\n}\nreturn dependencies;\n}"
"export function getPrConfigDescription(config: BranchConfig): string {\nlet prBody = `\n\n---\n\n### Configuration\n\n`;\nprBody += emojify(`:date: **Schedule**: `);\nprBody +=\n'Branch creation - ' + scheduleToString(config.schedule, config.timezone);\nprBody +=\n', Automerge - ' +\nscheduleToString(config.automergeSchedule, config.timezone) +\n'.';\nprBody += '\n\n';\nprBody += emojify(':vertical_traffic_light: **Automerge**: ');\nif (config.automerge) {\nprBody += 'Enabled.';\n} else if (config.automergedPreviously) {\nprBody += 'Disabled because a matching PR was automerged previously.';\n} else {\nprBody +=\n'Disabled by config. Please merge this manually once you are satisfied.';\n}\nprBody += '\n\n';\nprBody += emojify(':recycle: **Rebasing**: ');\nif (config.rebaseWhen === 'behind-base-branch') {\nprBody += 'Whenever PR is behind base branch';\n} else if (config.rebaseWhen === 'never' || config.stopUpdating) {\nprBody += 'Never';\n} else {\nprBody += 'Whenever PR becomes conflicted';\n}\nprBody += `, or you tick the rebase/retry checkbox.\n\n`;\nif (config.recreateClosed) {\nprBody += emojify(\n`:ghost: **Immortal**: This PR will be recreated if closed unmerged. Get [config help](${config.productLinks?.help}) if that's undesired.\n\n`,\n);\n} else {\nprBody += emojify(\n`:no_bell: **Ignore**: Close this PR and you won't be reminded about ${\nconfig.upgrades.length === 1 ? 'this update' : 'these updates'\n} again.\n\n`,\n);\n}\nreturn prBody;\n}"
"function massageUpdateMetadata(config: BranchConfig): void {\nconfig.upgrades.forEach((upgrade) => {\nconst {\nhomepage,\nsourceUrl,\nsourceDirectory,\nchangelogUrl,\ndependencyUrl,\n} = upgrade;\nlet depNameLinked = upgrade.depName!;\nlet newNameLinked = upgrade.newName!;\nconst primaryLink = homepage ?? sourceUrl ?? dependencyUrl;\nif (primaryLink) {\ndepNameLinked = `[${depNameLinked}](${primaryLink})`;\nnewNameLinked = `[${newNameLinked}](${primaryLink})`;\n}\nlet sourceRootPath = 'tree/HEAD';\nif (sourceUrl) {\nconst sourcePlatform = detectPlatform(sourceUrl);\nif (sourcePlatform === 'bitbucket') {\nsourceRootPath = 'src/HEAD';\n} else if (sourcePlatform === 'bitbucket-server') {\nsourceRootPath = 'browse';\n}\n}\nconst otherLinks = [];\nif (sourceUrl && (!!sourceDirectory || homepage)) {\notherLinks.push(\n`[source](${getFullSourceUrl(sourceUrl, sourceRootPath, sourceDirectory)})`,\n);\n}\nconst templatedChangelogUrl = changelogUrl\n? template.compile(changelogUrl, upgrade, true)\n: undefined;\nif (templatedChangelogUrl) {\notherLinks.push(`[changelog](${templatedChangelogUrl})`);\n}\nif (otherLinks.length) {\ndepNameLinked += ` (${otherLinks.join(', ')})`;\n}\nupgrade.depNameLinked = depNameLinked;\nupgrade.newNameLinked = newNameLinked;\nconst references: string[] = [];\nif (homepage) {\nreferences.push(`[homepage](${homepage})`);\n}\nif (sourceUrl) {\nreferences.push(\n`[source](${getFullSourceUrl(sourceUrl, sourceRootPath, sourceDirectory)})`,\n);\n}\nif (templatedChangelogUrl) {\nreferences.push(`[changelog](${templatedChangelogUrl})`);\n}\nupgrade.references = references.join(', ');\n});\n}"
"export function getPrBody(\nbranchConfig: BranchConfig,\nprBodyConfig: PrBodyConfig,\nconfig: RenovateConfig,\n): string {\nmassageUpdateMetadata(branchConfig);\nlet warnings = '';\nwarnings += getWarnings(branchConfig);\nif (branchConfig.packageFiles) {\nwarnings += getDepWarningsPR(\nbranchConfig.packageFiles,\nconfig,\nbranchConfig.dependencyDashboard,\n);\n}\nconst content = {\nheader: getPrHeader(branchConfig),\ntable: getPrUpdatesTable(branchConfig),\nwarnings,\nnotes: getPrNotes(branchConfig) + getPrExtraNotes(branchConfig),\nchangelogs: getChangelogs(branchConfig),\nconfigDescription: getPrConfigDescription(branchConfig),\ncontrols: getControls(),\nfooter: getPrFooter(branchConfig),\n};\nlet prBody = '';\nif (branchConfig.prBodyTemplate) {\nconst prBodyTemplate = branchConfig.prBodyTemplate;\nprBody = template.compile(prBodyTemplate, content, false);\nprBody = prBody.trim();\nprBody = prBody.replace(regEx(/\n\n\n+/g), '\n\n');\nconst prDebugData64 = toBase64(JSON.stringify(prBodyConfig.debugData));\nprBody += `\n<!--renovate-debug:${prDebugData64}-->\n`;\nprBody = platform.massageMarkdown(prBody, config.rebaseLabel);\nif (prBodyConfig?.rebasingNotice) {\nprBody = prBody.replace(\nrebasingRegex,\n`**Rebasing**: ${prBodyConfig.rebasingNotice}`,\n);\n}\n}\nreturn prBody;\n}"
"export async function getChangeLogJSON(\nconfig: BranchUpgradeConfig,\n): Promise<ChangeLogResult | null> {\nconst { sourceUrl, versioning, currentVersion, newVersion } = config;\ntry {\nif (!(sourceUrl && currentVersion && newVersion)) {\nreturn null;\n}\nconst versioningApi = allVersioning.get(versioning);\nif (versioningApi.equals(currentVersion, newVersion)) {\nreturn null;\n}\nlogger.debug(\n`Fetching changelog: ${sourceUrl} (${currentVersion} -> ${newVersion})`,\n);\nconst platform = detectPlatform(sourceUrl);\nif (isNullOrUndefined(platform)) {\nlogger.info(\n{ sourceUrl, hostType: platform },\n'Unknown platform, skipping changelog fetching.',\n);\nreturn null;\n}\nconst changeLogSource = getChangeLogSourceFor(platform);\nif (isNullOrUndefined(changeLogSource)) {\nlogger.info(\n{ sourceUrl, hostType: platform },\n'Unknown changelog source, skipping changelog fetching.',\n);\nreturn null;\n}\nreturn await changeLogSource.getChangeLogJSON(config);\n} catch (err)  {\nlogger.error({ config, err }, 'getChangeLogJSON error');\nreturn null;\n}\n}"
"export async function getReleaseNotes(\nproject: ChangeLogProject,\nrelease: ChangeLogRelease,\nconfig: BranchUpgradeConfig,\n): Promise<ChangeLogNotes | null> {\nconst { packageName, depName, repository } = project;\nconst { version, gitRef } = release;\nlogger.trace(\n`getReleaseNotes(${repository}, ${version}, ${packageName!}, ${depName!})`,\n);\nconst releases = await getCachedReleaseList(project, release);\nlogger.trace({ releases }, 'Release list from getReleaseList');\nlet releaseNotes: ChangeLogNotes | null = null;\nlet matchedRelease = getExactReleaseMatch(\npackageName!,\ndepName!,\nversion,\nreleases,\n);\nif (isUndefined(matchedRelease)) {\nmatchedRelease = releases.find(\n(r) =>\nr.tag === version ||\nr.tag === `v${version}` ||\nr.tag === gitRef ||\nr.tag === `v${gitRef}`,\n);\n}\nif (isUndefined(matchedRelease) && config.extractVersion) {\nconst extractVersionRegEx = regEx(config.extractVersion);\nmatchedRelease = releases.find((r) => {\nconst extractedVersion = extractVersionRegEx.exec(r.tag!)?.groups\n?.version;\nreturn version === extractedVersion;\n});\n}\nreleaseNotes = await releaseNotesResult(matchedRelease, project);\nlogger.trace({ releaseNotes });\nreturn releaseNotes;\n}"
"export async function getReleaseNotesMdFileInner(\nproject: ChangeLogProject,\n): Promise<ChangeLogFile | null> {\nconst { repository, type } = project;\nconst apiBaseUrl = project.apiBaseUrl;\nconst sourceDirectory = project.sourceDirectory!;\ntry {\nswitch (type) {\ncase 'bitbucket':\nreturn await bitbucket.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ncase 'bitbucket-server':\nreturn await bitbucketServer.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ncase 'forgejo':\nreturn await forgejo.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ncase 'gitea':\nreturn await gitea.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ncase 'github':\nreturn await github.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ncase 'gitlab':\nreturn await gitlab.getReleaseNotesMd(\nrepository,\napiBaseUrl,\nsourceDirectory,\n);\ndefault:\nlogger.warn({ apiBaseUrl, repository, type }, 'Invalid project type');\nreturn null;\n}\n} catch (err)  {\nif (err.statusCode === 404) {\nlogger.debug(\n{ repository, type, apiBaseUrl },\n'Error 404 getting changelog md',\n);\n} else {\nlogger.debug(\n{ err, repository, type, apiBaseUrl },\n'Error getting changelog md',\n);\n}\n}\nreturn null;\n}"
"export async function addReleaseNotes(\ninput: ChangeLogResult | null | undefined,\nconfig: BranchUpgradeConfig,\n): Promise<ChangeLogResult | null> {\nif (!input?.versions || !input.project?.type) {\nlogger.debug('Missing project or versions');\nreturn input ?? null;\n}\nconst output: ChangeLogResult = {\n...input,\nversions: [],\nhasReleaseNotes: false,\n};\nconst { repository, sourceDirectory, type: projectType } = input.project;\nconst cacheNamespace: PackageCacheNamespace = `changelog-${projectType}-notes@v2`;\nconst cacheKeyPrefix = sourceDirectory\n? `${repository}:${sourceDirectory}`\n: `${repository}`;\nfor (const v of input.versions) {\nlet releaseNotes: ChangeLogNotes | null | undefined;\nconst cacheKey = `${cacheKeyPrefix}:${v.version}`;\nreleaseNotes = await packageCache.get(cacheNamespace, cacheKey);\nreleaseNotes ??= await getReleaseNotesMd(input.project, v);\nreleaseNotes ??= await getReleaseNotes(input.project, v, config);\nif (!releaseNotes && v.compare.url) {\nreleaseNotes = { url: v.compare.url, notesSourceUrl: '' };\n}\nconst cacheMinutes = releaseNotesCacheMinutes(v.date);\nawait packageCache.set(\ncacheNamespace,\ncacheKey,\nreleaseNotes,\ncacheMinutes,\n);\noutput.versions!.push({\n...v,\nreleaseNotes: releaseNotes!,\n});\nif (releaseNotes) {\noutput.hasReleaseNotes = true;\n}\n}\nreturn output;\n}"
"export async function getInRangeReleases(\nconfig: BranchUpgradeConfig,\n): Promise<Release[] | null> {\nconst versioning = config.versioning!;\nconst currentVersion = config.currentVersion!;\nconst newVersion = config.newVersion!;\nconst depName = config.depName!;\nconst datasource = config.datasource!;\nif (!isGetPkgReleasesConfig(config)) {\nreturn null;\n}\ntry {\nconst pkgReleases = (await getPkgReleases(config))!.releases;\nconst version = get(versioning);\nconst previousReleases = pkgReleases\n.filter((release) =>\nversion.isCompatible(release.version, currentVersion),\n)\n.filter((release) => !version.isGreaterThan(release.version, newVersion))\n.filter(\n(release) =>\nversion.isStable(release.version) ||\nmatchesUnstable(version, currentVersion, release.version) ||\nmatchesUnstable(version, newVersion, release.version),\n);\nconst releases = previousReleases.filter(\n(release) =>\nversion.equals(release.version, currentVersion) ||\nversion.isGreaterThan(release.version, currentVersion),\n);\nif (releases.length === 1) {\nconst newRelease = releases[0];\nconst closestPreviousRelease = previousReleases\n.filter((release) => !version.equals(release.version, newVersion))\n.sort((b, a) => version.sortVersions(a.version, b.version))\n.shift();\nif (\nclosestPreviousRelease &&\nclosestPreviousRelease.version !== newRelease.version\n) {\nreleases.unshift(closestPreviousRelease);\n}\n}\nif (version.valueToVersion) {\nfor (const release of coerceArray(releases)) {\nrelease.version = version.valueToVersion(release.version);\n}\n}\nreturn releases;\n} catch (err)  {\nlogger.debug({ err }, 'getInRangeReleases err');\nlogger.debug(`Error getting releases for ${depName} from ${datasource}`);\nreturn null;\n}\n}"
"export function findDepConstraints(\npackageJson: PackageJson,\nlockEntry: PackageLockOrEntry,\ndepName: string,\ncurrentVersion: string,\nnewVersion: string,\nparentDepName?: string,\n): ParentDependency[] {\nlet parents: ParentDependency[] = [];\nlet packageJsonConstraint = packageJson.dependencies?.[depName];\nif (\npackageJsonConstraint &&\nsemver.matches(currentVersion, packageJsonConstraint)\n) {\nparents.push({\ndepType: 'dependencies',\nconstraint: packageJsonConstraint,\n});\n}\npackageJsonConstraint = packageJson.devDependencies?.[depName];\nif (\npackageJsonConstraint &&\nsemver.matches(currentVersion, packageJsonConstraint)\n) {\nparents.push({\ndepType: 'devDependencies',\nconstraint: packageJsonConstraint,\n});\n}\nconst { dependencies, requires, version } = lockEntry;\nif (parentDepName && requires) {\nlet constraint = requires[depName];\nif (constraint) {\nconstraint = constraint.replace(regEx(/(\d)rc$/), '$1-rc');\nif (semver.isValid(constraint)) {\nif (semver.matches(currentVersion, constraint)) {\nif (constraint === currentVersion) {\nrequires[depName] = newVersion;\n}\nparents.push({\nparentDepName,\nparentVersion: version,\nconstraint,\n});\n}\n}  else {\nlogger.warn(\n{ parentDepName, depName, currentVersion, constraint },\n'Parent constraint is invalid',\n);\n}\n}\n}\nif (dependencies) {\nfor (const [packageName, dependency] of Object.entries(dependencies)) {\nparents = parents.concat(\nfindDepConstraints(\npackageJson,\ndependency,\ndepName,\ncurrentVersion,\nnewVersion,\npackageName,\n),\n);\n}\n}\nconst res: ParentDependency[] = [];\nfor (const req of parents) {\nconst reqStringified = JSON.stringify(req);\nif (!res.find((i) => JSON.stringify(i) === reqStringified)) {\nres.push(req);\n}\n}\nreturn res;\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory?: string,\n): Promise<ChangeLogFile | null> {\nlogger.trace('bitbucket.getReleaseNotesMd()');\nconst repositorySourceURl = joinUrlParts(\napiBaseUrl,\n'2.0/repositories',\nrepository,\n'src/HEAD',\nsourceDirectory ?? '',\n);\nconst rootFiles = (\nawait bitbucketHttp.getJson(\nrepositorySourceURl,\n{\npaginate: true,\n},\nPagedSourceResults,\n)\n).body.values;\nconst allFiles = rootFiles.filter((f) => f.type === 'commit_file');\nconst files = allFiles.filter((f) =>\nchangelogFilenameRegex.test(path.basename(f.path)),\n);\nconst changelogFile = files\n.sort((a, b) => compareChangelogFilePath(a.path, b.path))\n.shift();\nif (isNullOrUndefined(changelogFile)) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nif (files.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile.path}`,\n);\n}\nconst fileRes = await bitbucketHttp.getText(\njoinUrlParts(\napiBaseUrl,\n'2.0/repositories',\nrepository,\n'src',\nchangelogFile.commit.hash,\nchangelogFile.path,\n),\n);\nconst changelogMd = `${fileRes.body}\n#\n##`;\nreturn { changelogFile: changelogFile.path, changelogMd };\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory?: string,\n): Promise<ChangeLogFile | null> {\nlogger.info('bitbucketServer.getReleaseNotesMd()');\nconst [projectKey, repositorySlug] = repository.split('/');\nconst apiRepoBaseUrl = joinUrlParts(\napiBaseUrl,\n`projects`,\nprojectKey,\n'repos',\nrepositorySlug,\n);\nconst repositorySourceURl = joinUrlParts(\napiRepoBaseUrl,\n'files',\nsourceDirectory ?? '',\n);\nconst allFiles = (\nawait http.getJson(\nrepositorySourceURl,\n{\npaginate: true,\n},\nFiles,\n)\n).body;\nconst changelogFiles = allFiles.filter((f) =>\nchangelogFilenameRegex.test(path.basename(f)),\n);\nlet changelogFile = changelogFiles\n.sort((a, b) => compareChangelogFilePath(a, b))\n.shift();\nif (!changelogFile) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nchangelogFile = `${sourceDirectory ? ensureTrailingSlash(sourceDirectory) : ''}${changelogFile}`;\nif (changelogFiles.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile}`,\n);\n}\nconst fileRes = await http.getText(\njoinUrlParts(apiRepoBaseUrl, 'raw', changelogFile),\n);\nconst changelogMd = `${fileRes.body}\n#\n##`;\nreturn { changelogFile, changelogMd };\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory?: string,\n): Promise<ChangeLogFile | null> {\nlogger.trace('forgejo.getReleaseNotesMd()');\nconst apiPrefix = `${apiBaseUrl}repos/${repository}/contents`;\nconst sourceDir = sourceDirectory ? `/${sourceDirectory}` : '';\nconst tree = (\nawait http.getJson(\n`${apiPrefix}${sourceDir}`,\n{\npaginate: false,\n},\nContentsListResponse,\n)\n).body;\nconst allFiles = tree.filter((f) => f.type === 'file');\nlet files: ContentsResponse[] = [];\nif (!files.length) {\nfiles = allFiles.filter((f) => changelogFilenameRegex.test(f.name));\n}\nif (!files.length) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nconst { path: changelogFile } = files\n.sort((a, b) => compareChangelogFilePath(a.path, b.path))\n.shift()!;\nif (files.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile}`,\n);\n}\nconst fileRes = await http.getJson(\n`${apiPrefix}/${changelogFile}`,\nContentsResponse,\n);\nif (!fileRes.body.content) {\nlogger.debug(`Missing content for changelog file, using ${changelogFile}`);\nreturn null;\n}\nconst changelogMd = fromBase64(fileRes.body.content) + '\n#\n##';\nreturn { changelogFile, changelogMd };\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory?: string,\n): Promise<ChangeLogFile | null> {\nlogger.trace('gitea.getReleaseNotesMd()');\nconst apiPrefix = `${apiBaseUrl}repos/${repository}/contents`;\nconst sourceDir = sourceDirectory ? `/${sourceDirectory}` : '';\nconst tree = (\nawait http.getJson(\n`${apiPrefix}${sourceDir}`,\n{\npaginate: false,\n},\nContentsListResponse,\n)\n).body;\nconst allFiles = tree.filter((f) => f.type === 'file');\nlet files: ContentsResponse[] = [];\nif (!files.length) {\nfiles = allFiles.filter((f) => changelogFilenameRegex.test(f.name));\n}\nif (!files.length) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nconst { path: changelogFile } = files\n.sort((a, b) => compareChangelogFilePath(a.path, b.path))\n.shift()!;\nif (files.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile}`,\n);\n}\nconst fileRes = await http.getJson(\n`${apiPrefix}/${changelogFile}`,\nContentsResponse,\n);\nif (!fileRes.body.content) {\nlogger.debug(`Missing content for changelog file, using ${changelogFile}`);\nreturn null;\n}\nconst changelogMd = fromBase64(fileRes.body.content) + '\n#\n##';\nreturn { changelogFile, changelogMd };\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory: string,\n): Promise<ChangeLogFile | null> {\nlogger.trace('github.getReleaseNotesMd()');\nconst apiPrefix = `${ensureTrailingSlash(apiBaseUrl)}repos/${repository}`;\nconst { default_branch: defaultBranch = 'HEAD' } = (\nawait http.getJsonUnchecked<{ default_branch: string }>(apiPrefix, {\ncacheProvider: memCacheProvider,\n})\n).body;\nconst res = await http.getJsonUnchecked<GithubGitTree>(\n`${apiPrefix}/git/trees/${defaultBranch}${\nsourceDirectory ? '?recursive=1' : ''\n}`,\n{ cacheProvider: memCacheProvider },\n);\nif (res.body.truncated) {\nlogger.debug(`Git tree truncated repository:${repository}`);\n}\nconst allFiles = res.body.tree.filter((f) => f.type === 'blob');\nlet files: GithubGitTreeNode[] = [];\nif (sourceDirectory?.length) {\nfiles = allFiles\n.filter((f) => f.path.startsWith(sourceDirectory))\n.filter((f) =>\nchangelogFilenameRegex.test(\nf.path.replace(ensureTrailingSlash(sourceDirectory), ''),\n),\n);\n}\nif (!files.length) {\nfiles = allFiles.filter((f) => changelogFilenameRegex.test(f.path));\n}\nif (!files.length) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nconst { path: changelogFile, sha } = files\n.sort((a, b) => compareChangelogFilePath(a.path, b.path))\n.shift()!;\nif (files.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile}`,\n);\n}\nconst fileRes = await http.getJsonUnchecked<GithubGitBlob>(\n`${apiPrefix}/git/blobs/${sha}`,\n{ cacheProvider: memCacheProvider },\n);\nconst changelogMd = fromBase64(fileRes.body.content) + '\n#\n##';\nreturn { changelogFile, changelogMd };\n}"
"protected override hasValidToken(config: BranchUpgradeConfig): {\nisValid: boolean;\nerror?: ChangeLogError;\n} {\nconst sourceUrl = config.sourceUrl!;\nconst parsedUrl = URL.parse(sourceUrl);\nconst host = parsedUrl.host;\nconst manager = config.manager;\nconst packageName = config.packageName;\nconst url = sourceUrl.startsWith('https:\n? 'https:\n: sourceUrl;\nconst { token } = hostRules.find({\nhostType: 'github',\nurl,\nreadOnly: true,\n});\nif (host && !token) {\nif (host.endsWith('.github.com') || host === 'github.com') {\nif (!GlobalConfig.get('githubTokenWarn')) {\nlogger.debug(\n{ manager, packageName, sourceUrl },\n'GitHub token warning has been suppressed. Skipping release notes retrieval',\n);\nreturn { isValid: false };\n}\nlogger.warn(\n{ manager, packageName, sourceUrl },\n'No github.com token has been configured. Skipping release notes retrieval',\n);\nreturn { isValid: false, error: 'MissingGithubToken' };\n}\nlogger.debug(\n{ manager, packageName, sourceUrl },\n'Repository URL does not match any known github hosts - skipping changelog retrieval',\n);\nreturn { isValid: false };\n}\nreturn { isValid: true };\n}"
"export async function getReleaseNotesMd(\nrepository: string,\napiBaseUrl: string,\nsourceDirectory?: string,\n): Promise<ChangeLogFile | null> {\nlogger.trace('gitlab.getReleaseNotesMd()');\nconst urlEncodedRepo = encodeURIComponent(repository);\nconst apiPrefix = `${apiBaseUrl}projects/${urlEncodedRepo}/repository/`;\nconst tree = (\nawait http.getJsonUnchecked<GitlabTreeNode[]>(\n`${apiPrefix}tree?per_page=100${\nsourceDirectory ? `&path=${sourceDirectory}` : ''\n}`,\n{\npaginate: true,\n},\n)\n).body;\nconst allFiles = tree.filter((f) => f.type === 'blob');\nlet files: GitlabTreeNode[] = [];\nif (!files.length) {\nfiles = allFiles.filter((f) => changelogFilenameRegex.test(f.name));\n}\nif (!files.length) {\nlogger.trace('no changelog file found');\nreturn null;\n}\nconst { path: changelogFile, id } = files\n.sort((a, b) => compareChangelogFilePath(a.name, b.name))\n.shift()!;\nif (files.length !== 0) {\nlogger.debug(\n`Multiple candidates for changelog file, using ${changelogFile}`,\n);\n}\nconst fileRes = await http.getText(`${apiPrefix}blobs/${id}/raw`);\nconst changelogMd = fileRes.body + '\n#\n##';\nreturn { changelogFile, changelogMd };\n}"
"export function Features() {\nconst features = [\n{\ntitle: 'Multi-LLM Support',\ndescription: 'Connect to any LLM provider including OpenAI, Anthropic, and more',\nicon: <IconCloud />,\n},\n{\ntitle: 'API Deployment',\ndescription: 'Deploy your workflows as secure, scalable APIs',\nicon: <IconTerminal2 />,\n},\n{\ntitle: 'Webhook Integration',\ndescription: 'Trigger workflows via webhooks from external services',\nicon: <IconRouteAltLeft />,\n},\n{\ntitle: 'Scheduled Execution',\ndescription: 'Schedule workflows to run at specific times or intervals',\nicon: <IconEaseInOut />,\n},\n{\ntitle: '40+ Integrations',\ndescription: 'Connect to hundreds of external services and data sources',\nicon: <IconAdjustmentsBolt />,\n},\n{\ntitle: 'Visual Debugging',\ndescription: 'Debug workflows visually with detailed execution logs',\nicon: <IconHelp />,\n},\n{\ntitle: 'Version Control',\ndescription: 'Track changes and roll back to previous versions',\nicon: <IconHistory />,\n},\n{\ntitle: 'Team Collaboration',\ndescription: 'Collaborate with team members on workflow development',\nicon: <IconHeart />,\n},\n]\nreturn (\n<div className='relative z-20 mx-auto grid max-w-7xl grid-cols-1 py-10 md:grid-cols-2 lg:grid-cols-4'>\n{features.map((feature, index) => (\n<Feature key={feature.title} {...feature} index={index} />\n))}\n</div>\n)\n}"
"export function WorkflowIcon(props: SVGProps<SVGSVGElement>) {\nreturn (\n<svg\n{...props}\nwidth='30'\nheight='30'\nviewBox='0 0 24 24'\nfill='none'\nxmlns='http:\n>\n<circle\nclassName='a'\ncx='12'\ncy='6'\nr='3'\nstroke='currentColor'\nstrokeWidth='1.5'\nstrokeLinecap='round'\nstrokeLinejoin='round'\n/>\n<rect\nclassName='a'\nheight='5'\nrx='2'\nwidth='8'\nx='2'\ny='16'\nstroke='currentColor'\nstrokeWidth='1.5'\nstrokeLinecap='round'\nstrokeLinejoin='round'\n/>\n<rect\nclassName='a'\nheight='5'\nrx='2'\nwidth='8'\nx='14'\ny='16'\nstroke='currentColor'\nstrokeWidth='1.5'\nstrokeLinecap='round'\nstrokeLinejoin='round'\n/>\n<path\nclassName='a'\nd='M6,16V14a2,2,0,0,1,2-2h8a2,2,0,0,1,2,2v2'\nstroke='currentColor'\nstrokeWidth='1.5'\nstrokeLinecap='round'\nstrokeLinejoin='round'\n/>\n<line\nclassName='a'\nx1='12'\nx2='12'\ny1='9'\ny2='12'\nstroke='currentColor'\nstrokeWidth='1.5'\nstrokeLinecap='round'\nstrokeLinejoin='round'\n/>\n</svg>\n)\n}"
"async continueExecution(blockIds: string[], context: ExecutionContext): Promise<ExecutionResult> {\nconst { setPendingBlocks } = useExecutionStore.getState()\nlet finalOutput: NormalizedBlockOutput = {}\nif (this.isCancelled) {\nreturn {\nsuccess: false,\noutput: finalOutput,\nerror: 'Workflow execution was cancelled',\nlogs: context.blockLogs,\n}\n}\ntry {\nconst outputs = await this.executeLayer(blockIds, context)\nif (outputs.length > 0) {\nconst nonStreamingOutputs = outputs.filter(\n(o) => !(o && typeof o === 'object' && 'stream' in o)\n) as NormalizedBlockOutput[]\nif (nonStreamingOutputs.length > 0) {\nfinalOutput = nonStreamingOutputs[nonStreamingOutputs.length - 1]\n}\n}\nawait this.loopManager.processLoopIterations(context)\nawait this.parallelManager.processParallelIterations(context)\nconst nextLayer = this.getNextExecutionLayer(context)\nsetPendingBlocks(nextLayer)\nconst isComplete = nextLayer.length === 0\nif (isComplete) {\nconst endTime = new Date()\ncontext.metadata.endTime = endTime.toISOString()\nreturn {\nsuccess: true,\noutput: finalOutput,\nmetadata: {\nduration: endTime.getTime() - new Date(context.metadata.startTime!).getTime(),\nstartTime: context.metadata.startTime!,\nendTime: context.metadata.endTime!,\npendingBlocks: [],\nisDebugSession: false,\nworkflowConnections: this.actualWorkflow.connections.map((conn) => ({\nsource: conn.source,\ntarget: conn.target,\n})),\n},\nlogs: context.blockLogs,\n}\n}\nreturn {\nsuccess: true,\noutput: finalOutput,\nmetadata: {\nduration: Date.now() - new Date(context.metadata.startTime!).getTime(),\nstartTime: context.metadata.startTime!,\npendingBlocks: nextLayer,\nisDebugSession: true,\ncontext: context,\n},\nlogs: context.blockLogs,\n}\n} catch (error: any) {\nlogger.error('Debug step execution failed:', this.sanitizeError(error))\nreturn {\nsuccess: false,\noutput: finalOutput,\nerror: this.extractErrorMessage(error),\nlogs: context.blockLogs,\n}\n}\n}"
"private async executeLayer(\nblockIds: string[],\ncontext: ExecutionContext\n): Promise<(NormalizedBlockOutput | StreamingExecution)[]> {\nconst { setActiveBlocks } = useExecutionStore.getState()\ntry {\nconst activeBlockIds = new Set(blockIds)\nblockIds.forEach((blockId) => {\nif (context.parallelBlockMapping?.has(blockId)) {\nconst parallelInfo = context.parallelBlockMapping.get(blockId)\nif (parallelInfo) {\nactiveBlockIds.add(parallelInfo.originalBlockId)\n}\n}\n})\nsetActiveBlocks(activeBlockIds)\nconst settledResults = await Promise.allSettled(\nblockIds.map((blockId) => this.executeBlock(blockId, context))\n)\nconst results: (NormalizedBlockOutput | StreamingExecution)[] = []\nconst errors: Error[] = []\nsettledResults.forEach((result, index) => {\nif (result.status === 'fulfilled') {\nresults.push(result.value)\n} else {\nerrors.push(result.reason)\nresults.push({\nerror: result.reason?.message || 'Block execution failed',\nstatus: 500,\n})\n}\n})\nif (errors.length > 0) {\nlogger.warn(\n`Layer execution completed with ${errors.length} failed blocks out of ${blockIds.length} total`\n)\nif (errors.length === blockIds.length) {\nthrow errors[0]\n}\n}\nblockIds.forEach((blockId) => {\ncontext.executedBlocks.add(blockId)\n})\nthis.pathTracker.updateExecutionPaths(blockIds, context)\nreturn results\n} catch (error) {\nsetActiveBlocks(new Set())\nthrow error\n}\n}"
"private createProcessedStream(\noriginalStream: ReadableStream,\nselectedFields: string[],\nblockId: string\n): ReadableStream {\nlet buffer = ''\nlet hasProcessedComplete = false\nconst self = this\nreturn new ReadableStream({\nasync start(controller) {\nconst reader = originalStream.getReader()\nconst decoder = new TextDecoder()\ntry {\nwhile (true) {\nconst { done, value } = await reader.read()\nif (done) {\nif (buffer.trim() && !hasProcessedComplete) {\nself.processCompleteJson(buffer, selectedFields, controller)\n}\ncontroller.close()\nbreak\n}\nconst chunk = decoder.decode(value, { stream: true })\nbuffer += chunk\nif (!hasProcessedComplete) {\nconst processedChunk = self.processStreamingChunk(buffer, selectedFields)\nif (processedChunk) {\ncontroller.enqueue(new TextEncoder().encode(processedChunk))\nhasProcessedComplete = true\n}\n}\n}\n} catch (error) {\nlogger.error('Error processing streaming response format:', { error, blockId })\ncontroller.error(error)\n} finally {\nreader.releaseLock()\n}\n},\n})\n}"
"private processStreamingChunk(buffer: string, selectedFields: string[]): string | null {\ntry {\nconst parsed = JSON.parse(buffer.trim())\nif (typeof parsed === 'object' && parsed !== null) {\nconst results: string[] = []\nfor (const field of selectedFields) {\nif (field in parsed) {\nconst value = parsed[field]\nconst formattedValue = typeof value === 'string' ? value : JSON.stringify(value)\nresults.push(formattedValue)\n}\n}\nif (results.length > 0) {\nconst result = results.join('\n')\nreturn result\n}\nreturn null\n}\n} catch (e) {\n}\nconst openBraces = (buffer.match(/\{/g) || []).length\nconst closeBraces = (buffer.match(/\}/g) || []).length\nif (openBraces > 0 && openBraces === closeBraces) {\ntry {\nconst parsed = JSON.parse(buffer.trim())\nif (typeof parsed === 'object' && parsed !== null) {\nconst results: string[] = []\nfor (const field of selectedFields) {\nif (field in parsed) {\nconst value = parsed[field]\nconst formattedValue = typeof value === 'string' ? value : JSON.stringify(value)\nresults.push(formattedValue)\n}\n}\nif (results.length > 0) {\nconst result = results.join('\n')\nreturn result\n}\nreturn null\n}\n} catch (e) {\n}\n}\nreturn null\n}"
"export function useKnowledgeBaseTagDefinitions(knowledgeBaseId: string | null) {\nconst [tagDefinitions, setTagDefinitions] = useState<TagDefinition[]>([])\nconst [isLoading, setIsLoading] = useState(false)\nconst [error, setError] = useState<string | null>(null)\nconst fetchTagDefinitions = useCallback(async () => {\nif (!knowledgeBaseId) {\nsetTagDefinitions([])\nreturn\n}\nsetIsLoading(true)\nsetError(null)\ntry {\nconst response = await fetch(`/api/knowledge/${knowledgeBaseId}/tag-definitions`)\nif (!response.ok) {\nthrow new Error(`Failed to fetch tag definitions: ${response.statusText}`)\n}\nconst data = await response.json()\nif (data.success && Array.isArray(data.data)) {\nsetTagDefinitions(data.data)\n} else {\nthrow new Error('Invalid response format')\n}\n} catch (err) {\nconst errorMessage = err instanceof Error ? err.message : 'Unknown error occurred'\nlogger.error('Error fetching tag definitions:', err)\nsetError(errorMessage)\nsetTagDefinitions([])\n} finally {\nsetIsLoading(false)\n}\n}, [knowledgeBaseId])\nconst getTagLabel = useCallback(\n(tagSlot: string): string => {\nconst definition = tagDefinitions.find((def) => def.tagSlot === tagSlot)\nreturn definition?.displayName || tagSlot\n},\n[tagDefinitions]\n)\nconst getTagDefinition = useCallback(\n(tagSlot: string): TagDefinition | undefined => {\nreturn tagDefinitions.find((def) => def.tagSlot === tagSlot)\n},\n[tagDefinitions]\n)\nuseEffect(() => {\nfetchTagDefinitions()\n}, [fetchTagDefinitions])\nreturn {\ntagDefinitions,\nisLoading,\nerror,\nfetchTagDefinitions,\ngetTagLabel,\ngetTagDefinition,\n}\n}"
"export function useUsageLimit() {\nconst [data, setData] = useState<any>(null)\nconst [isLoading, setIsLoading] = useState(true)\nconst [error, setError] = useState<Error | null>(null)\nconst fetchUsageLimit = useCallback(async () => {\ntry {\nsetIsLoading(true)\nsetError(null)\nconst response = await fetch('/api/usage-limits?context=user')\nif (!response.ok) {\nthrow new Error(`HTTP error! status: ${response.status}`)\n}\nconst limitData = await response.json()\nsetData(limitData)\n} catch (error) {\nconst err = error instanceof Error ? error : new Error('Failed to fetch usage limit')\nlogger.error('Failed to fetch usage limit', { error })\nsetError(err)\n} finally {\nsetIsLoading(false)\n}\n}, [])\nuseEffect(() => {\nfetchUsageLimit()\n}, [fetchUsageLimit])\nconst refetch = useCallback(() => {\nreturn fetchUsageLimit()\n}, [fetchUsageLimit])\nconst updateLimit = async (newLimit: number) => {\ntry {\nconst response = await fetch('/api/usage-limits?context=user', {\nmethod: 'PUT',\nheaders: {\n'Content-Type': 'application/json',\n},\nbody: JSON.stringify({ limit: newLimit }),\n})\nif (!response.ok) {\nconst errorData = await response.json()\nthrow new Error(errorData.error || 'Failed to update usage limit')\n}\nawait refetch()\nreturn { success: true }\n} catch (error) {\nlogger.error('Failed to update usage limit', { error, newLimit })\nthrow error\n}\n}\nreturn {\ncurrentLimit: data?.currentLimit ?? DEFAULT_FREE_CREDITS,\ncanEdit: data?.canEdit ?? false,\nminimumLimit: data?.minimumLimit ?? DEFAULT_FREE_CREDITS,\nplan: data?.plan ?? 'free',\nsetBy: data?.setBy,\nupdatedAt: data?.updatedAt ? new Date(data.updatedAt) : null,\nupdateLimit,\nisLoading,\nerror,\nrefetch,\n}\n}"
"export function useUserPermissions(\nworkspacePermissions: WorkspacePermissions | null,\npermissionsLoading = false,\npermissionsError: string | null = null\n): WorkspaceUserPermissions {\nconst { data: session } = useSession()\nconst userPermissions = useMemo((): WorkspaceUserPermissions => {\nif (permissionsLoading || !session?.user?.email) {\nreturn {\ncanRead: false,\ncanEdit: false,\ncanAdmin: false,\nuserPermissions: 'read',\nisLoading: permissionsLoading,\nerror: permissionsError,\n}\n}\nconst currentUser = workspacePermissions?.users?.find(\n(user) => user.email.toLowerCase() === session.user.email.toLowerCase()\n)\nif (!currentUser) {\nlogger.warn('User not found in workspace permissions', {\nuserEmail: session.user.email,\nhasPermissions: !!workspacePermissions,\nuserCount: workspacePermissions?.users?.length || 0,\n})\nreturn {\ncanRead: false,\ncanEdit: false,\ncanAdmin: false,\nuserPermissions: 'read',\nisLoading: false,\nerror: permissionsError || 'User not found in workspace',\n}\n}\nconst userPerms = currentUser.permissionType || 'read'\nconst canAdmin = userPerms === 'admin'\nconst canEdit = userPerms === 'write' || userPerms === 'admin'\nconst canRead = true\nreturn {\ncanRead,\ncanEdit,\ncanAdmin,\nuserPermissions: userPerms,\nisLoading: false,\nerror: permissionsError,\n}\n}, [session, workspacePermissions, permissionsLoading, permissionsError])\nreturn userPermissions\n}"
"export function useWorkspacePermissions(workspaceId: string | null): UseWorkspacePermissionsReturn {\nconst [permissions, setPermissions] = useState<WorkspacePermissions | null>(null)\nconst [loading, setLoading] = useState(false)\nconst [error, setError] = useState<string | null>(null)\nconst fetchPermissions = async (id: string): Promise<void> => {\ntry {\nsetLoading(true)\nsetError(null)\nconst response = await fetch(API_ENDPOINTS.WORKSPACE_PERMISSIONS(id))\nif (!response.ok) {\nif (response.status === 404) {\nthrow new Error('Workspace not found or access denied')\n}\nif (response.status === 401) {\nthrow new Error('Authentication required')\n}\nthrow new Error(`Failed to fetch permissions: ${response.statusText}`)\n}\nconst data: WorkspacePermissions = await response.json()\nsetPermissions(data)\nlogger.info('Workspace permissions loaded', {\nworkspaceId: id,\nuserCount: data.total,\nusers: data.users.map((u) => ({ email: u.email, permissions: u.permissionType })),\n})\n} catch (err) {\nconst errorMessage = err instanceof Error ? err.message : 'Unknown error occurred'\nsetError(errorMessage)\nlogger.error('Failed to fetch workspace permissions', {\nworkspaceId: id,\nerror: errorMessage,\n})\n} finally {\nsetLoading(false)\n}\n}\nconst updatePermissions = (newPermissions: WorkspacePermissions): void => {\nsetPermissions(newPermissions)\n}\nuseEffect(() => {\nif (workspaceId) {\nfetchPermissions(workspaceId)\n} else {\nsetPermissions(null)\nsetError(null)\nsetLoading(false)\n}\n}, [workspaceId])\nreturn {\npermissions,\nloading,\nerror,\nupdatePermissions,\n}\n}"
"static findAllPathNodes(\nedges: Array<{ source: string; target: string }>,\ntargetNodeId: string\n): string[] {\nconst nodeDistances = new Map<string, number>()\nconst visited = new Set<string>()\nconst queue: [string, number][] = [[targetNodeId, 0]]\nconst pathNodes = new Set<string>()\nconst reverseAdjList: Record<string, string[]> = {}\nfor (const edge of edges) {\nif (!reverseAdjList[edge.target]) {\nreverseAdjList[edge.target] = []\n}\nreverseAdjList[edge.target].push(edge.source)\n}\nwhile (queue.length > 0) {\nconst [currentNodeId, distance] = queue.shift()!\nif (visited.has(currentNodeId)) {\nconst currentDistance = nodeDistances.get(currentNodeId) || Number.POSITIVE_INFINITY\nif (distance < currentDistance) {\nnodeDistances.set(currentNodeId, distance)\n}\ncontinue\n}\nvisited.add(currentNodeId)\nnodeDistances.set(currentNodeId, distance)\nif (currentNodeId !== targetNodeId) {\npathNodes.add(currentNodeId)\n}\nconst incomingNodeIds = reverseAdjList[currentNodeId] || []\nfor (const sourceId of incomingNodeIds) {\nqueue.push([sourceId, distance + 1])\n}\n}\nreturn Array.from(pathNodes)\n}"
"export function getRedisClient(): Redis | null {\nif (typeof window !== 'undefined') return null\nif (globalRedisClient) return globalRedisClient\ntry {\nglobalRedisClient = new Redis(redisUrl, {\nkeepAlive: 1000,\nconnectTimeout: 5000,\nmaxRetriesPerRequest: 3,\nretryStrategy: (times) => {\nif (times > 5) {\nlogger.warn('Redis connection failed after 5 attempts, using fallback')\nreturn null\n}\nreturn Math.min(times * 200, 2000)\n},\n})\nglobalRedisClient.on('error', (err: any) => {\nlogger.error('Redis connection error:', { err })\nif (err.code === 'ECONNREFUSED' || err.code === 'ETIMEDOUT') {\nglobalRedisClient = null\n}\n})\nglobalRedisClient.on('connect', () => {})\nreturn globalRedisClient\n} catch (error) {\nlogger.error('Failed to initialize Redis client:', { error })\nreturn null\n}\n}"
"export async function markMessageAsProcessed(\nkey: string,\nexpirySeconds: number = MESSAGE_ID_EXPIRY\n): Promise<void> {\ntry {\nconst redis = getRedisClient()\nconst fullKey = `${MESSAGE_ID_PREFIX}${key}`\nif (redis) {\nawait redis.set(fullKey, '1', 'EX', expirySeconds)\n} else {\nconst expiry = expirySeconds ? Date.now() + expirySeconds * 1000 : null\ninMemoryCache.set(fullKey, { value: '1', expiry })\nif (inMemoryCache.size > MAX_CACHE_SIZE) {\nconst now = Date.now()\nfor (const [cacheKey, entry] of inMemoryCache.entries()) {\nif (entry.expiry && entry.expiry < now) {\ninMemoryCache.delete(cacheKey)\n}\n}\nif (inMemoryCache.size > MAX_CACHE_SIZE) {\nconst keysToDelete = Array.from(inMemoryCache.keys()).slice(\n0,\ninMemoryCache.size - MAX_CACHE_SIZE\n)\nfor (const keyToDelete of keysToDelete) {\ninMemoryCache.delete(keyToDelete)\n}\n}\n}\n}\n} catch (error) {\nlogger.error(`Error marking key ${key} as processed:`, { error })\nconst fullKey = `${MESSAGE_ID_PREFIX}${key}`\nconst expiry = expirySeconds ? Date.now() + expirySeconds * 1000 : null\ninMemoryCache.set(fullKey, { value: '1', expiry })\n}\n}"
"export function convertScheduleOptionsToCron(\nscheduleType: string,\noptions: Record<string, string>\n): string {\nswitch (scheduleType) {\ncase 'minutes': {\nconst interval = options.minutesInterval || '15'\nreturn `*/${interval} * * * *`\n}\ncase 'hourly': {\nreturn `${options.hourlyMinute || '00'} * * * *`\n}\ncase 'daily': {\nconst [minute, hour] = (options.dailyTime || '00:09').split(':')\nreturn `${minute || '00'} ${hour || '09'} * * *`\n}\ncase 'weekly': {\nconst dayMap: Record<string, number> = {\nMON: 1,\nTUE: 2,\nWED: 3,\nTHU: 4,\nFRI: 5,\nSAT: 6,\nSUN: 0,\n}\nconst day = dayMap[options.weeklyDay || 'MON']\nconst [minute, hour] = (options.weeklyDayTime || '00:09').split(':')\nreturn `${minute || '00'} ${hour || '09'} * * ${day}`\n}\ncase 'monthly': {\nconst day = options.monthlyDay || '1'\nconst [minute, hour] = (options.monthlyTime || '00:09').split(':')\nreturn `${minute || '00'} ${hour || '09'} ${day} * *`\n}\ncase 'custom': {\nreturn options.cronExpression\n}\ndefault:\nthrow new Error('Unsupported schedule type')\n}\n}"
"export function getTimezoneAbbreviation(timezone: string, date: Date = new Date()): string {\nif (timezone === 'UTC') return 'UTC'\nconst timezoneMap: Record<string, { standard: string; daylight: string }> = {\n'America/Los_Angeles': { standard: 'PST', daylight: 'PDT' },\n'America/Denver': { standard: 'MST', daylight: 'MDT' },\n'America/Chicago': { standard: 'CST', daylight: 'CDT' },\n'America/New_York': { standard: 'EST', daylight: 'EDT' },\n'Europe/London': { standard: 'GMT', daylight: 'BST' },\n'Europe/Paris': { standard: 'CET', daylight: 'CEST' },\n'Asia/Tokyo': { standard: 'JST', daylight: 'JST' },\n'Australia/Sydney': { standard: 'AEST', daylight: 'AEDT' },\n'Asia/Singapore': { standard: 'SGT', daylight: 'SGT' },\n}\nif (timezone in timezoneMap) {\nconst januaryDate = new Date(date.getFullYear(), 0, 1)\nconst julyDate = new Date(date.getFullYear(), 6, 1)\nconst januaryFormatter = new Intl.DateTimeFormat('en-US', {\ntimeZone: timezone,\ntimeZoneName: 'short',\n})\nconst julyFormatter = new Intl.DateTimeFormat('en-US', {\ntimeZone: timezone,\ntimeZoneName: 'short',\n})\nconst isDSTObserved = januaryFormatter.format(januaryDate) !== julyFormatter.format(julyDate)\nif (isDSTObserved) {\nconst currentFormatter = new Intl.DateTimeFormat('en-US', {\ntimeZone: timezone,\ntimeZoneName: 'short',\n})\nconst isDST = currentFormatter.format(date) !== januaryFormatter.format(januaryDate)\nreturn isDST ? timezoneMap[timezone].daylight : timezoneMap[timezone].standard\n}\nreturn timezoneMap[timezone].standard\n}\nreturn timezone\n}"
"export async function executeProviderRequest(\nproviderId: string,\nrequest: ProviderRequest\n): Promise<ProviderResponse | ReadableStream | StreamingExecution> {\nlogger.info(`Executing request with provider: ${providerId}`, {\nhasResponseFormat: !!request.responseFormat,\nmodel: request.model,\n})\nconst provider = getProvider(providerId)\nif (!provider) {\nthrow new Error(`Provider not found: ${providerId}`)\n}\nif (!provider.executeRequest) {\nthrow new Error(`Provider ${providerId} does not implement executeRequest`)\n}\nconst sanitizedRequest = sanitizeRequest(request)\nif (sanitizedRequest.responseFormat) {\nif (\ntypeof sanitizedRequest.responseFormat === 'string' &&\nsanitizedRequest.responseFormat === ''\n) {\nlogger.info('Empty response format provided, ignoring it')\nsanitizedRequest.responseFormat = undefined\n} else {\nconst structuredOutputInstructions = generateStructuredOutputInstructions(\nsanitizedRequest.responseFormat\n)\nif (structuredOutputInstructions.trim()) {\nconst originalPrompt = sanitizedRequest.systemPrompt || ''\nsanitizedRequest.systemPrompt =\n`${originalPrompt}\n\n${structuredOutputInstructions}`.trim()\nlogger.info('Added structured output instructions to system prompt')\n}\n}\n}\nconst response = await provider.executeRequest(sanitizedRequest)\nif (isStreamingExecution(response)) {\nlogger.info('Provider returned StreamingExecution')\nreturn response\n}\nif (isReadableStream(response)) {\nlogger.info('Provider returned ReadableStream')\nreturn response\n}\nlogger.info('Provider response received', {\ncontentLength: response.content ? response.content.length : 0,\nmodel: response.model,\nhasTokens: !!response.tokens,\nhasToolCalls: !!response.toolCalls,\ntoolCallsCount: response.toolCalls?.length || 0,\n})\nif (response.tokens) {\nconst { prompt: promptTokens = 0, completion: completionTokens = 0 } = response.tokens\nconst useCachedInput = !!request.context && request.context.length > 0\nresponse.cost = calculateCost(response.model, promptTokens, completionTokens, useCachedInput)\n}\nreturn response\n}"
"export function generateStructuredOutputInstructions(responseFormat: any): string {\nif (!responseFormat) return ''\nif (responseFormat.schema || (responseFormat.type === 'object' && responseFormat.properties)) {\nreturn ''\n}\nif (!responseFormat.fields) return ''\nfunction generateFieldStructure(field: any): string {\nif (field.type === 'object' && field.properties) {\nreturn `{\n${Object.entries(field.properties)\n.map(([key, prop]: [string, any]) => ``${key}`: ${prop.type === 'number' ? '0' : '`value`'}`)\n.join(',\n    ')}\n}`\n}\nreturn field.type === 'string'\n? '`value`'\n: field.type === 'number'\n? '0'\n: field.type === 'boolean'\n? 'true/false'\n: '[]'\n}\nconst exampleFormat = responseFormat.fields\n.map((field: any) => `  `${field.name}`: ${generateFieldStructure(field)}`)\n.join(',\n')\nconst fieldDescriptions = responseFormat.fields\n.map((field: any) => {\nlet desc = `${field.name} (${field.type})`\nif (field.description) desc += `: ${field.description}`\nif (field.type === 'object' && field.properties) {\ndesc += '\nProperties:'\nObject.entries(field.properties).forEach(([key, prop]: [string, any]) => {\ndesc += `\n  - ${key} (${(prop as any).type}): ${(prop as any).description || ''}`\n})\n}\nreturn desc\n})\n.join('\n')\nlogger.info(`Generated structured output instructions for ${responseFormat.fields.length} fields`)\nreturn `\nPlease provide your response in the following JSON format:\n{\n${exampleFormat}\n}\nField descriptions:\n${fieldDescriptions}\nYour response MUST be valid JSON and include all the specified fields with their correct types.\nEach metric should be an object containing 'score' (number) and 'reasoning' (string).`\n}"
"export async function transformBlockTool(\nblock: any,\noptions: {\nselectedOperation?: string\ngetAllBlocks: () => any[]\ngetTool: (toolId: string) => any\ngetToolAsync?: (toolId: string) => Promise<any>\n}\n): Promise<ProviderToolConfig | null> {\nconst { selectedOperation, getAllBlocks, getTool, getToolAsync } = options\nconst blockDef = getAllBlocks().find((b: any) => b.type === block.type)\nif (!blockDef) {\nlogger.warn(`Block definition not found for type: ${block.type}`)\nreturn null\n}\nlet toolId: string | null = null\nif ((blockDef.tools?.access?.length || 0) > 1) {\nif (selectedOperation && blockDef.tools?.config?.tool) {\ntry {\ntoolId = blockDef.tools.config.tool({\n...block.params,\noperation: selectedOperation,\n})\n} catch (error) {\nlogger.error('Error selecting tool for block', {\nblockType: block.type,\noperation: selectedOperation,\nerror,\n})\nreturn null\n}\n} else {\ntoolId = blockDef.tools.access[0]\n}\n} else {\ntoolId = blockDef.tools?.access?.[0] || null\n}\nif (!toolId) {\nlogger.warn(`No tool ID found for block: ${block.type}`)\nreturn null\n}\nlet toolConfig: any\nif (toolId.startsWith('custom_') && getToolAsync) {\ntoolConfig = await getToolAsync(toolId)\n} else {\ntoolConfig = getTool(toolId)\n}\nif (!toolConfig) {\nlogger.warn(`Tool config not found for ID: ${toolId}`)\nreturn null\n}\nconst { createLLMToolSchema } = await import('@/tools/params')\nconst userProvidedParams = block.params || {}\nconst llmSchema = createLLMToolSchema(toolConfig, userProvidedParams)\nreturn {\nid: toolConfig.id,\nname: toolConfig.name,\ndescription: toolConfig.description,\nparams: userProvidedParams,\nparameters: llmSchema,\n}\n}"
"export function calculateCost(\nmodel: string,\npromptTokens = 0,\ncompletionTokens = 0,\nuseCachedInput = false,\ncustomMultiplier?: number\n) {\nlet pricing = getEmbeddingModelPricing(model)\nif (!pricing) {\npricing = getModelPricingFromDefinitions(model)\n}\nif (!pricing) {\nconst defaultPricing = {\ninput: 1.0,\ncachedInput: 0.5,\noutput: 5.0,\nupdatedAt: '2025-03-21',\n}\nreturn {\ninput: 0,\noutput: 0,\ntotal: 0,\npricing: defaultPricing,\n}\n}\nconst inputCost =\npromptTokens *\n(useCachedInput && pricing.cachedInput\n? pricing.cachedInput / 1_000_000\n: pricing.input / 1_000_000)\nconst outputCost = completionTokens * (pricing.output / 1_000_000)\nconst totalCost = inputCost + outputCost\nconst costMultiplier = customMultiplier ?? getCostMultiplier()\nconst finalInputCost = inputCost * costMultiplier\nconst finalOutputCost = outputCost * costMultiplier\nconst finalTotalCost = totalCost * costMultiplier\nreturn {\ninput: Number.parseFloat(finalInputCost.toFixed(8)),\noutput: Number.parseFloat(finalOutputCost.toFixed(8)),\ntotal: Number.parseFloat(finalTotalCost.toFixed(8)),\npricing,\n}\n}"
"async function insertTestWorkflow() {\ntry {\nconsole.log('🔍 Finding first workspace and user...')\nconst workspaces = await db.select().from(workspace).limit(1)\nif (workspaces.length === 0) {\nthrow new Error('No workspaces found. Please create a workspace first.')\n}\nconst users = await db.select().from(user).limit(1)\nif (users.length === 0) {\nthrow new Error('No users found. Please create a user first.')\n}\nconst workspaceId = workspaces[0].id\nconst userId = users[0].id\nconsole.log(`✅ Using workspace: ${workspaceId}`)\nconsole.log(`✅ Using user: ${userId}`)\nconst testWorkflowId = `test-migration-workflow-${Date.now()}`\nconst now = new Date()\nawait db.insert(workflow).values({\nid: testWorkflowId,\nname: 'Test Migration Workflow (Old JSON Format)',\nworkspaceId: workspaceId,\nuserId: userId,\nstate: testWorkflowState,\nlastSynced: now,\ncreatedAt: now,\nupdatedAt: now,\nisDeployed: false,\nisPublished: false,\n})\nconsole.log(`✅ Inserted test workflow with old JSON format: ${testWorkflowId}`)\nconsole.log(`🌐 Access it at: http:\nconsole.log('')\nconsole.log('📋 Test steps:')\nconsole.log('1. Open the workflow in your browser')\nconsole.log('2. Verify it renders correctly with all blocks and connections')\nconsole.log('3. Try editing some subblock values')\nconsole.log('4. Run the migration script')\nconsole.log('5. Verify it still works after migration')\n} catch (error) {\nconsole.error('❌ Error inserting test workflow:', error)\nprocess.exit(1)\n}\n}"
"private parseResponseFormatSafely(responseFormat: any): any {\nif (!responseFormat) {\nreturn undefined\n}\nif (typeof responseFormat === 'object' && responseFormat !== null) {\nreturn responseFormat\n}\nif (typeof responseFormat === 'string') {\nconst trimmedValue = responseFormat.trim()\nif (trimmedValue.startsWith('<') && trimmedValue.includes('>')) {\nreturn trimmedValue\n}\nif (trimmedValue === '') {\nreturn undefined\n}\ntry {\nreturn JSON.parse(trimmedValue)\n} catch (error) {\nlogger.warn('Failed to parse response format as JSON in serializer, using undefined:', {\nvalue: trimmedValue,\nerror: error instanceof Error ? error.message : String(error),\n})\nreturn undefined\n}\n}\nreturn undefined\n}"
"private validateRequiredFieldsBeforeExecution(\nblock: BlockState,\nblockConfig: any,\nparams: Record<string, any>\n) {\nconst toolAccess = blockConfig.tools?.access\nif (!toolAccess || toolAccess.length === 0) {\nreturn\n}\nlet currentToolId = ''\ntry {\ncurrentToolId = blockConfig.tools.config?.tool\n? blockConfig.tools.config.tool(params)\n: blockConfig.tools.access[0]\n} catch (error) {\nlogger.warn('Tool selection failed during validation, using default:', {\nerror: error instanceof Error ? error.message : String(error),\n})\ncurrentToolId = blockConfig.tools.access[0]\n}\nconst currentTool = getTool(currentToolId)\nif (!currentTool) {\nreturn\n}\nconst missingFields: string[] = []\nObject.entries(currentTool.params || {}).forEach(([paramId, paramConfig]) => {\nif (paramConfig.required && paramConfig.visibility === 'user-only') {\nconst fieldValue = params[paramId]\nif (fieldValue === undefined || fieldValue === null || fieldValue === '') {\nconst subBlockConfig = blockConfig.subBlocks?.find((sb: any) => sb.id === paramId)\nconst displayName = subBlockConfig?.title || paramId\nmissingFields.push(displayName)\n}\n}\n})\nif (missingFields.length > 0) {\nconst blockName = block.name || blockConfig.name || 'Block'\nthrow new Error(`${blockName} is missing required fields: ${missingFields.join(', ')}`)\n}\n}"
"private deserializeBlock(serializedBlock: SerializedBlock): BlockState {\nconst blockType = serializedBlock.metadata?.id\nif (!blockType) {\nthrow new Error(`Invalid block type: ${serializedBlock.metadata?.id}`)\n}\nif (blockType === 'loop' || blockType === 'parallel') {\nreturn {\nid: serializedBlock.id,\ntype: blockType,\nname: serializedBlock.metadata?.name || (blockType === 'loop' ? 'Loop' : 'Parallel'),\nposition: serializedBlock.position,\nsubBlocks: {},\noutputs: serializedBlock.outputs,\nenabled: serializedBlock.enabled ?? true,\ndata: serializedBlock.config.params,\n}\n}\nconst blockConfig = getBlock(blockType)\nif (!blockConfig) {\nthrow new Error(`Invalid block type: ${blockType}`)\n}\nconst subBlocks: Record<string, any> = {}\nblockConfig.subBlocks.forEach((subBlock) => {\nsubBlocks[subBlock.id] = {\nid: subBlock.id,\ntype: subBlock.type,\nvalue: serializedBlock.config.params[subBlock.id] ?? null,\n}\n})\nreturn {\nid: serializedBlock.id,\ntype: blockType,\nname: serializedBlock.metadata?.name || blockConfig.name,\nposition: serializedBlock.position,\nsubBlocks,\noutputs: serializedBlock.outputs,\nenabled: true,\n}\n}"
"function validateClientSideParams(\nparams: Record<string, any>,\nschema: {\ntype: string\nproperties: Record<string, any>\nrequired?: string[]\n}\n) {\nif (!schema || schema.type !== 'object') {\nthrow new Error('Invalid schema format')\n}\nconst internalParamSet = new Set(['_context', 'workflowId', 'envVars'])\nif (schema.required) {\nfor (const requiredParam of schema.required) {\nif (!(requiredParam in params)) {\nthrow new Error(`Required parameter missing: ${requiredParam}`)\n}\n}\n}\nfor (const [paramName, paramValue] of Object.entries(params)) {\nif (internalParamSet.has(paramName)) {\ncontinue\n}\nconst paramSchema = schema.properties[paramName]\nif (!paramSchema) {\nthrow new Error(`Unknown parameter: ${paramName}`)\n}\nconst type = paramSchema.type\nif (type === 'string' && typeof paramValue !== 'string') {\nthrow new Error(`Parameter ${paramName} should be a string`)\n}\nif (type === 'number' && typeof paramValue !== 'number') {\nthrow new Error(`Parameter ${paramName} should be a number`)\n}\nif (type === 'boolean' && typeof paramValue !== 'boolean') {\nthrow new Error(`Parameter ${paramName} should be a boolean`)\n}\nif (type === 'array' && !Array.isArray(paramValue)) {\nthrow new Error(`Parameter ${paramName} should be an array`)\n}\nif (type === 'object' && (typeof paramValue !== 'object' || paramValue === null)) {\nthrow new Error(`Parameter ${paramName} should be an object`)\n}\n}\n}"
"async function handleProxyRequest(\ntoolId: string,\nparams: Record<string, any>\n): Promise<ToolResponse> {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst baseUrl = getBaseUrl()\nconst proxyUrl = new URL('/api/proxy', baseUrl).toString()\ntry {\nconst response = await fetch(proxyUrl, {\nmethod: 'POST',\nheaders: { 'Content-Type': 'application/json' },\nbody: JSON.stringify({ toolId, params }),\n})\nif (!response.ok) {\nconst errorText = await response.text()\nlogger.error(`[${requestId}] Proxy request failed for ${toolId}:`, {\nstatus: response.status,\nstatusText: response.statusText,\nerror: errorText.substring(0, 200),\n})\nlet errorMessage = `HTTP error ${response.status}: ${response.statusText}`\ntry {\nconst errorJson = JSON.parse(errorText)\nif (errorJson.error) {\nerrorMessage =\ntypeof errorJson.error === 'string'\n? errorJson.error\n: `API Error: ${response.status} ${response.statusText}`\n}\n} catch (parseError) {\nif (errorText) {\nerrorMessage = `${errorMessage}: ${errorText}`\n}\n}\nthrow new Error(errorMessage)\n}\nconst result = await response.json()\nreturn result\n} catch (error: any) {\nlogger.error(`[${requestId}] Proxy request error for ${toolId}:`, {\nerror: error instanceof Error ? error.message : String(error),\n})\nreturn {\nsuccess: false,\noutput: {},\nerror: error.message || 'Proxy request failed',\n}\n}\n}"
"export function createLLMToolSchema(\ntoolConfig: ToolConfig,\nuserProvidedParams: Record<string, unknown>\n): ToolSchema {\nconst schema: ToolSchema = {\ntype: 'object',\nproperties: {},\nrequired: [],\n}\nObject.entries(toolConfig.params).forEach(([paramId, param]) => {\nconst isUserProvided =\nuserProvidedParams[paramId] !== undefined &&\nuserProvidedParams[paramId] !== null &&\nuserProvidedParams[paramId] !== ''\nif (isUserProvided) {\nreturn\n}\nif (param.visibility === 'user-only') {\nreturn\n}\nif (param.visibility === 'hidden') {\nreturn\n}\nschema.properties[paramId] = {\ntype: param.type === 'json' ? 'object' : param.type,\ndescription: param.description || '',\n}\nif ((param.visibility === 'user-or-llm' || param.visibility === 'llm-only') && param.required) {\nschema.required.push(paramId)\n}\n})\nreturn schema\n}"
"export async function executeRequest(\ntoolId: string,\ntool: ToolConfig,\nrequestParams: RequestParams\n): Promise<ToolResponse> {\ntry {\nconst { url, method, headers, body } = requestParams\nconst externalResponse = await fetch(url, { method, headers, body })\nif (!externalResponse.ok) {\nlet errorContent\ntry {\nerrorContent = await externalResponse.json()\n} catch (_e) {\nerrorContent = { message: externalResponse.statusText }\n}\nif (tool.transformError) {\ntry {\nconst errorResult = tool.transformError(errorContent)\nif (typeof errorResult === 'string') {\nthrow new Error(errorResult)\n}\nconst transformedError = await errorResult\nif (typeof transformedError === 'string') {\nthrow new Error(transformedError)\n}\nif (\ntransformedError &&\ntypeof transformedError === 'object' &&\n'error' in transformedError\n) {\nthrow new Error(transformedError.error || 'Tool returned an error')\n}\nthrow new Error('Tool returned an error')\n} catch (e) {\nif (e instanceof Error) {\nthrow e\n}\nthrow new Error(`${toolId} API error: ${externalResponse.statusText}`)\n}\n} else {\nconst error = errorContent.message || `${toolId} API error: ${externalResponse.statusText}`\nlogger.error(`${toolId} error:`, { error })\nthrow new Error(error)\n}\n}\nconst transformResponse =\ntool.transformResponse ||\n(async (resp: Response) => ({\nsuccess: true,\noutput: await resp.json(),\n}))\nreturn await transformResponse(externalResponse)\n} catch (error: any) {\nreturn {\nsuccess: false,\noutput: {},\nerror: error.message || 'Unknown error',\n}\n}\n}"
"async function getCustomTool(\ncustomToolId: string,\nworkflowId?: string\n): Promise<ToolConfig | undefined> {\nconst identifier = customToolId.replace('custom_', '')\ntry {\nconst baseUrl = getBaseUrl()\nconst url = new URL('/api/tools/custom', baseUrl)\nif (workflowId) {\nurl.searchParams.append('workflowId', workflowId)\n}\nconst response = await fetch(url.toString())\nif (!response.ok) {\nlogger.error(`Failed to fetch custom tools: ${response.statusText}`)\nreturn undefined\n}\nconst result = await response.json()\nif (!result.data || !Array.isArray(result.data)) {\nlogger.error(`Invalid response when fetching custom tools: ${JSON.stringify(result)}`)\nreturn undefined\n}\nconst customTool = result.data.find(\n(tool: any) => tool.id === identifier || tool.title === identifier\n)\nif (!customTool) {\nlogger.error(`Custom tool not found: ${identifier}`)\nreturn undefined\n}\nconst params = createParamSchema(customTool)\nreturn {\nid: customToolId,\nname: customTool.title,\ndescription: customTool.schema.function?.description || '',\nversion: '1.0.0',\nparams,\nrequest: {\nurl: '/api/function/execute',\nmethod: 'POST',\nheaders: () => ({ 'Content-Type': 'application/json' }),\nbody: createCustomToolRequestBody(customTool, false, workflowId),\nisInternalRoute: true,\n},\ntransformResponse: async (response: Response, params: Record<string, any>) => {\nconst data = await response.json()\nif (!data.success) {\nthrow new Error(data.error || 'Custom tool execution failed')\n}\nreturn {\nsuccess: true,\noutput: data.output.result || data.output,\nerror: undefined,\n}\n},\ntransformError: async (error: any) =>\n`Custom tool execution error: ${error.message || 'Unknown error'}`,\n}\n} catch (error) {\nlogger.error(`Error fetching custom tool ${identifier} from API:`, error)\nreturn undefined\n}\n}"
"export function OTPInputForm({\nonSubmit,\nisLoading = false,\nerror = null,\nlength = 6,\n}: OTPInputFormProps) {\nconst [value, setValue] = useState('')\nconst handleComplete = (value: string) => {\nsetValue(value)\n}\nconst handleSubmit = (e: React.FormEvent) => {\ne.preventDefault()\nif (value.length === length && !isLoading) {\nonSubmit(value)\n}\n}\nreturn (\n<form onSubmit={handleSubmit} className='space-y-4'>\n<div className='flex justify-center'>\n<InputOTP\nmaxLength={length}\nvalue={value}\nonChange={setValue}\nonComplete={handleComplete}\ndisabled={isLoading}\npattern='[0-9]*'\ninputMode='numeric'\ncontainerClassName='gap-2'\n>\n<InputOTPGroup>\n{Array.from({ length }).map((_, i) => (\n<InputOTPSlot key={i} index={i} className='h-12 w-10' />\n))}\n</InputOTPGroup>\n</InputOTP>\n</div>\n{error && <p className='text-center text-destructive text-sm'>{error}</p>}\n<Button type='submit' className='w-full' disabled={value.length !== length || isLoading}>\n{isLoading ? (\n<div className='flex items-center justify-center'>\n<Loader2 className='mr-2 h-4 w-4 animate-spin' />\nVerifying...\n</div>\n) : (\n'Verify'\n)}\n</Button>\n</form>\n)\n}"
"private allBlocksExecuted(nodeIds: string[], context: ExecutionContext): boolean {\nconst loopConnections =\ncontext.workflow?.connections.filter(\n(conn) => nodeIds.includes(conn.source) && nodeIds.includes(conn.target)\n) || []\nconst blockOutgoingConnections = new Map<string, typeof loopConnections>()\nfor (const nodeId of nodeIds) {\nblockOutgoingConnections.set(\nnodeId,\nloopConnections.filter((conn) => conn.source === nodeId)\n)\n}\nconst entryBlocks = nodeIds.filter((nodeId) => {\nconst hasIncomingFromLoop = loopConnections.some((conn) => conn.target === nodeId)\nreturn !hasIncomingFromLoop\n})\nconst reachableBlocks = new Set<string>()\nconst toVisit = [...entryBlocks]\nwhile (toVisit.length > 0) {\nconst currentBlockId = toVisit.shift()!\nif (reachableBlocks.has(currentBlockId)) continue\nreachableBlocks.add(currentBlockId)\nconst block = context.workflow?.blocks.find((b) => b.id === currentBlockId)\nif (!block) continue\nconst outgoing = blockOutgoingConnections.get(currentBlockId) || []\nif (block.metadata?.id === BlockType.ROUTER) {\nconst selectedTarget = context.decisions.router.get(currentBlockId)\nif (selectedTarget && nodeIds.includes(selectedTarget)) {\ntoVisit.push(selectedTarget)\n}\n} else if (block.metadata?.id === BlockType.CONDITION) {\nconst selectedConditionId = context.decisions.condition.get(currentBlockId)\nif (selectedConditionId) {\nconst selectedConnection = outgoing.find(\n(conn) => conn.sourceHandle === `condition-${selectedConditionId}`\n)\nif (selectedConnection?.target) {\ntoVisit.push(selectedConnection.target)\n}\n}\n} else {\nthis.handleErrorConnections(currentBlockId, outgoing, context, toVisit)\n}\n}\nfor (const reachableBlockId of reachableBlocks) {\nif (!context.executedBlocks.has(reachableBlockId)) {\nlogger.info(\n`Loop iteration not complete - block ${reachableBlockId} is reachable but not executed`\n)\nreturn false\n}\n}\nlogger.info(\n`All reachable blocks in loop have been executed. Reachable: ${Array.from(reachableBlocks).join(', ')}`\n)\nreturn true\n}"
"async processParallelIterations(context: ExecutionContext): Promise<void> {\nif (!this.parallels || Object.keys(this.parallels).length === 0) {\nreturn\n}\nfor (const [parallelId, parallel] of Object.entries(this.parallels)) {\nif (context.completedLoops.has(parallelId)) {\ncontinue\n}\nconst parallelBlockExecuted = context.executedBlocks.has(parallelId)\nif (!parallelBlockExecuted) {\ncontinue\n}\nconst parallelState = context.parallelExecutions?.get(parallelId)\nif (!parallelState || parallelState.currentIteration === 0) {\ncontinue\n}\nconst allVirtualBlocksExecuted = this.areAllVirtualBlocksExecuted(\nparallelId,\nparallel,\ncontext.executedBlocks,\nparallelState\n)\nif (allVirtualBlocksExecuted && !context.completedLoops.has(parallelId)) {\nconst blockState = context.blockStates.get(parallelId)\nif (blockState?.output?.completed && blockState?.output?.results) {\nlogger.info(\n`Parallel ${parallelId} already has aggregated results, marking as completed without re-execution`\n)\ncontext.completedLoops.add(parallelId)\nconst parallelEndConnections =\ncontext.workflow?.connections.filter(\n(conn) => conn.source === parallelId && conn.sourceHandle === 'parallel-end-source'\n) || []\nfor (const conn of parallelEndConnections) {\nif (!context.activeExecutionPath.has(conn.target)) {\ncontext.activeExecutionPath.add(conn.target)\nlogger.info(`Activated post-parallel path to ${conn.target}`)\n}\n}\ncontinue\n}\nlogger.info(\n`All virtual blocks completed for parallel ${parallelId}, re-executing to aggregate results`\n)\ncontext.executedBlocks.delete(parallelId)\ncontext.activeExecutionPath.add(parallelId)\nfor (const nodeId of parallel.nodes) {\ncontext.activeExecutionPath.delete(nodeId)\n}\n}\n}\n}"
"private evaluateSubBlockCondition(\ncondition:\n| {\nfield: string\nvalue: any\nnot?: boolean\nand?: { field: string; value: any; not?: boolean }\n}\n| undefined,\ncurrentValues: Record<string, any>\n): boolean {\nif (!condition) return true\nconst fieldValue = currentValues[condition.field]\nconst isValueMatch = Array.isArray(condition.value)\n? fieldValue != null &&\n(condition.not\n? !condition.value.includes(fieldValue)\n: condition.value.includes(fieldValue))\n: condition.not\n? fieldValue !== condition.value\n: fieldValue === condition.value\nconst isAndValueMatch =\n!condition.and ||\n(() => {\nconst andFieldValue = currentValues[condition.and!.field]\nreturn Array.isArray(condition.and!.value)\n? andFieldValue != null &&\n(condition.and!.not\n? !condition.and!.value.includes(andFieldValue)\n: condition.and!.value.includes(andFieldValue))\n: condition.and!.not\n? andFieldValue !== condition.and!.value\n: andFieldValue === condition.and!.value\n})()\nreturn isValueMatch && isAndValueMatch\n}"
"resolveEnvVariables(value: any, isApiKey = false): any {\nif (typeof value === 'string') {\nconst isExplicitEnvVar = value.trim().startsWith('{{') && value.trim().endsWith('}}')\nconst hasProperEnvVarReferences = this.containsProperEnvVarReference(value)\nif (isApiKey || isExplicitEnvVar || hasProperEnvVarReferences) {\nconst envMatches = value.match(/\{\{([^}]+)\}\}/g)\nif (envMatches) {\nlet resolvedValue = value\nfor (const match of envMatches) {\nconst envKey = match.slice(2, -2)\nconst envValue = this.environmentVariables[envKey]\nif (envValue === undefined) {\nthrow new Error(`Environment variable `${envKey}` was not found.`)\n}\nresolvedValue = resolvedValue.replace(match, envValue)\n}\nreturn resolvedValue\n}\n}\nreturn value\n}\nif (Array.isArray(value)) {\nreturn value.map((item) => this.resolveEnvVariables(item, isApiKey))\n}\nif (value && typeof value === 'object') {\nreturn Object.entries(value).reduce(\n(acc, [k, v]) => ({\n...acc,\n[k]: this.resolveEnvVariables(v, k.toLowerCase() === 'apikey'),\n}),\n{}\n)\n}\nreturn value\n}"
"private resolveNestedStructure(\nvalue: any,\ncontext: ExecutionContext,\ncurrentBlock: SerializedBlock\n): any {\nif (value === null || value === undefined) {\nreturn value\n}\nif (typeof value === 'string') {\nconst resolvedVars = this.resolveVariableReferences(value, currentBlock)\nconst resolvedReferences = this.resolveBlockReferences(resolvedVars, context, currentBlock)\nconst isApiKey = this.isApiKeyField(currentBlock, value)\nreturn this.resolveEnvVariables(resolvedReferences, isApiKey)\n}\nif (Array.isArray(value)) {\nreturn value.map((item) => this.resolveNestedStructure(item, context, currentBlock))\n}\nif (typeof value === 'object') {\nconst result: Record<string, any> = {}\nfor (const [k, v] of Object.entries(value)) {\nconst _isApiKey = k.toLowerCase() === 'apikey'\nresult[k] = this.resolveNestedStructure(v, context, currentBlock)\n}\nreturn result\n}\nreturn value\n}"
"private getLoopItems(loop: any, context: ExecutionContext): any[] | Record<string, any> | null {\nif (!loop) return null\nif (loop.forEachItems) {\nif (\nArray.isArray(loop.forEachItems) ||\n(typeof loop.forEachItems === 'object' && loop.forEachItems !== null)\n) {\nreturn loop.forEachItems\n}\nif (typeof loop.forEachItems === 'string') {\ntry {\nconst trimmedExpression = loop.forEachItems.trim()\nif (trimmedExpression.startsWith('[') || trimmedExpression.startsWith('{')) {\ntry {\nconst normalizedExpression = trimmedExpression\n.replace(/'/g, '`')\n.replace(/(\w+):/g, '`$1`:')\n.replace(/,\s*]/g, ']')\n.replace(/,\s*}/g, '}')\nreturn JSON.parse(normalizedExpression)\n} catch (jsonError) {\nconsole.error('Error parsing JSON for loop:', jsonError)\n}\n}\nif (trimmedExpression && !trimmedExpression.startsWith('\nconst result = new Function('context', `return ${loop.forEachItems}`)(context)\nif (Array.isArray(result) || (typeof result === 'object' && result !== null)) {\nreturn result\n}\n}\n} catch (e) {\nconsole.error('Error evaluating forEach items:', e)\n}\n}\n}\nfor (const [_blockId, blockState] of context.blockStates.entries()) {\nconst output = blockState.output\nif (output) {\nfor (const [_key, value] of Object.entries(output)) {\nif (Array.isArray(value) && value.length > 0) {\nreturn value\n}\nif (typeof value === 'object' && value !== null && Object.keys(value).length > 0) {\nreturn value\n}\n}\n}\n}\nreturn []\n}"
"private needsCodeStringLiteral(block?: SerializedBlock, expression?: string): boolean {\nif (!block) return false\nconst codeExecutionBlocks = ['function', 'condition']\nif (block.metadata?.id && codeExecutionBlocks.includes(block.metadata.id)) {\nif (block.metadata.id === 'function') {\nreturn true\n}\nif (block.metadata.id === 'condition' && !expression) {\nreturn false\n}\nreturn true\n}\nif (expression) {\nconst codeIndicators = [\n/\(\s*$/,\n/\.\w+\s*\(/,\n/[=<>!+\-*/%](?:==?)?/,\n/\+=|-=|\*=|\/=|%=|\*\*=?/,\n/\b(if|else|for|while|return|var|let|const|function)\b/,\n/\b(if|else|elif|for|while|def|return|import|from|as|class|with|try|except)\b/,\n/^['`]use strict['`]?$/,\n/\$\{.+?\}/,\n/f['`].*?['`]/,\n/\bprint\s*\(/,\n/\bconsole\.\w+\(/,\n]\nreturn codeIndicators.some((pattern) => pattern.test(expression))\n}\nreturn false\n}"
"private getParallelItems(\nparallel: any,\ncontext: ExecutionContext\n): any[] | Record<string, any> | null {\nif (!parallel || !parallel.distribution) return null\nif (\nArray.isArray(parallel.distribution) ||\n(typeof parallel.distribution === 'object' && parallel.distribution !== null)\n) {\nreturn parallel.distribution\n}\nif (typeof parallel.distribution === 'string') {\ntry {\nconst trimmedExpression = parallel.distribution.trim()\nif (trimmedExpression.startsWith('[') || trimmedExpression.startsWith('{')) {\ntry {\nreturn JSON.parse(trimmedExpression)\n} catch {\n}\n}\nif (trimmedExpression && !trimmedExpression.startsWith('\nconst result = new Function('context', `return ${parallel.distribution}`)(context)\nif (Array.isArray(result) || (typeof result === 'object' && result !== null)) {\nreturn result\n}\n}\n} catch (e) {\nconsole.error('Error evaluating parallel distribution items:', e)\n}\n}\nreturn []\n}"
"private processObjectValue(\nvalue: any,\nkey: string,\ncontext: ExecutionContext,\nblock: SerializedBlock\n): any {\nif (\nArray.isArray(value) &&\nvalue.every((item) => typeof item === 'object' && item !== null && 'cells' in item)\n) {\nreturn value.map((row) => ({\n...row,\ncells: Object.entries(row.cells).reduce(\n(acc, [cellKey, cellValue]) => {\nif (typeof cellValue === 'string') {\nconst trimmedValue = cellValue.trim()\nconst directVariableMatch = trimmedValue.match(/^<variable\.([^>]+)>$/)\nif (directVariableMatch) {\nconst variableName = directVariableMatch[1]\nconst variable = this.findVariableByName(variableName)\nif (variable) {\nacc[cellKey] = this.getTypedVariableValue(variable)\n} else {\nlogger.warn(\n`Variable reference <variable.${variableName}> not found in table cell`\n)\nacc[cellKey] = cellValue\n}\n} else {\nacc[cellKey] = this.resolveNestedStructure(cellValue, context, block)\n}\n} else {\nacc[cellKey] = this.resolveNestedStructure(cellValue, context, block)\n}\nreturn acc\n},\n{} as Record<string, any>\n),\n}))\n}\nreturn this.resolveNestedStructure(value, context, block)\n}"
"export async function sendStreamingMessage(\nrequest: SendMessageRequest\n): Promise<StreamingResponse> {\ntry {\nconst { abortSignal, ...requestBody } = request\nconst response = await fetch('/api/copilot/chat', {\nmethod: 'POST',\nheaders: { 'Content-Type': 'application/json' },\nbody: JSON.stringify({ ...requestBody, stream: true }),\nsignal: abortSignal,\ncredentials: 'include',\n})\nif (!response.ok) {\nconst errorMessage = await handleApiError(response, 'Failed to send streaming message')\nthrow new Error(errorMessage)\n}\nif (!response.body) {\nthrow new Error('No response body received')\n}\nreturn {\nsuccess: true,\nstream: response.body,\n}\n} catch (error) {\nif (error instanceof Error && error.name === 'AbortError') {\nlogger.info('Streaming message was aborted by user')\nreturn {\nsuccess: false,\nerror: 'Request was aborted',\n}\n}\nlogger.error('Failed to send streaming message:', error)\nreturn {\nsuccess: false,\nerror: error instanceof Error ? error.message : 'Unknown error',\n}\n}\n}"
"export function validateCopilotConfig(config: CopilotConfig): ValidationResult {\nconst errors: string[] = []\ntry {\nconst chatDefaultModel = getProviderDefaultModel(config.chat.defaultProvider)\nif (!chatDefaultModel) {\nerrors.push(`Chat provider '${config.chat.defaultProvider}' not found`)\n}\n} catch (error) {\nerrors.push(`Invalid chat provider: ${config.chat.defaultProvider}`)\n}\ntry {\nconst ragDefaultModel = getProviderDefaultModel(config.rag.defaultProvider)\nif (!ragDefaultModel) {\nerrors.push(`RAG provider '${config.rag.defaultProvider}' not found`)\n}\n} catch (error) {\nerrors.push(`Invalid RAG provider: ${config.rag.defaultProvider}`)\n}\nconst validationChecks = [\n{\nvalue: config.chat.temperature,\nconstraint: VALIDATION_CONSTRAINTS.temperature,\nname: 'Chat temperature',\n},\n{\nvalue: config.rag.temperature,\nconstraint: VALIDATION_CONSTRAINTS.temperature,\nname: 'RAG temperature',\n},\n{\nvalue: config.chat.maxTokens,\nconstraint: VALIDATION_CONSTRAINTS.maxTokens,\nname: 'Chat maxTokens',\n},\n{\nvalue: config.rag.maxTokens,\nconstraint: VALIDATION_CONSTRAINTS.maxTokens,\nname: 'RAG maxTokens',\n},\n{\nvalue: config.rag.maxSources,\nconstraint: VALIDATION_CONSTRAINTS.maxSources,\nname: 'RAG maxSources',\n},\n{\nvalue: config.rag.similarityThreshold,\nconstraint: VALIDATION_CONSTRAINTS.similarityThreshold,\nname: 'RAG similarityThreshold',\n},\n{\nvalue: config.general.maxConversationHistory,\nconstraint: VALIDATION_CONSTRAINTS.maxConversationHistory,\nname: 'General maxConversationHistory',\n},\n]\nfor (const check of validationChecks) {\nconst error = validateNumericValue(check.value, check.constraint, check.name)\nif (error) {\nerrors.push(error)\n}\n}\nreturn {\nisValid: errors.length === 0,\nerrors,\n}\n}"
"private splitRecursively(text: string, separatorIndex = 0): string[] {\nconst tokenCount = this.estimateTokens(text)\nif (tokenCount <= this.chunkSize) {\nreturn text.length >= this.minChunkSize ? [text] : []\n}\nif (separatorIndex >= this.separators.length) {\nconst chunks: string[] = []\nconst targetLength = Math.ceil((text.length * this.chunkSize) / tokenCount)\nfor (let i = 0; i < text.length; i += targetLength) {\nconst chunk = text.slice(i, i + targetLength).trim()\nif (chunk.length >= this.minChunkSize) {\nchunks.push(chunk)\n}\n}\nreturn chunks\n}\nconst separator = this.separators[separatorIndex]\nconst parts = text.split(separator).filter((part) => part.trim())\nif (parts.length <= 1) {\nreturn this.splitRecursively(text, separatorIndex + 1)\n}\nconst chunks: string[] = []\nlet currentChunk = ''\nfor (const part of parts) {\nconst testChunk = currentChunk + (currentChunk ? separator : '') + part\nif (this.estimateTokens(testChunk) <= this.chunkSize) {\ncurrentChunk = testChunk\n} else {\nif (currentChunk.trim() && currentChunk.length >= this.minChunkSize) {\nchunks.push(currentChunk.trim())\n}\nif (this.estimateTokens(part) > this.chunkSize) {\nchunks.push(...this.splitRecursively(part, separatorIndex + 1))\ncurrentChunk = ''\n} else {\ncurrentChunk = part\n}\n}\n}\nif (currentChunk.trim() && currentChunk.length >= this.minChunkSize) {\nchunks.push(currentChunk.trim())\n}\nreturn chunks\n}"
"async chunk(text: string): Promise<Chunk[]> {\nif (!text?.trim()) {\nreturn []\n}\nconst cleanedText = this.cleanText(text)\nlet chunks = this.splitRecursively(cleanedText)\nchunks = this.addOverlap(chunks)\nlet previousEndIndex = 0\nreturn chunks.map((chunkText, index) => {\nlet startIndex: number\nlet actualContentLength: number\nif (index === 0 || this.overlap <= 0) {\nstartIndex = previousEndIndex\nactualContentLength = chunkText.length\n} else {\nconst prevChunk = chunks[index - 1]\nconst prevWords = prevChunk.split(/\s+/)\nconst overlapWords = prevWords.slice(-Math.min(this.overlap, prevWords.length))\nconst overlapLength = Math.min(\nchunkText.length,\noverlapWords.length > 0 ? overlapWords.join(' ').length + 1 : 0\n)\nstartIndex = previousEndIndex - overlapLength\nactualContentLength = chunkText.length - overlapLength\n}\nconst safeStart = Math.max(0, startIndex)\nconst endIndexSafe = safeStart + actualContentLength\nconst chunk: Chunk = {\ntext: chunkText,\ntokenCount: this.estimateTokens(chunkText),\nmetadata: {\nstartIndex: safeStart,\nendIndex: endIndexSafe,\n},\n}\npreviousEndIndex = endIndexSafe\nreturn chunk\n})\n}"
"async chunkMdxFile(filePath: string, basePath: string): Promise<DocChunk[]> {\nconst content = await fs.readFile(filePath, 'utf-8')\nconst relativePath = path.relative(basePath, filePath)\nconst { data: frontmatter, content: markdownContent } = this.parseFrontmatter(content)\nconst headers = this.extractHeaders(markdownContent)\nconst documentUrl = this.generateDocumentUrl(relativePath)\nconst textChunks = await this.splitContent(markdownContent)\nlogger.info(`Generating embeddings for ${textChunks.length} chunks in ${relativePath}`)\nconst embeddings = textChunks.length > 0 ? await generateEmbeddings(textChunks) : []\nconst embeddingModel = 'text-embedding-3-small'\nconst chunks: DocChunk[] = []\nlet currentPosition = 0\nfor (let i = 0; i < textChunks.length; i++) {\nconst chunkText = textChunks[i]\nconst chunkStart = currentPosition\nconst chunkEnd = currentPosition + chunkText.length\nconst relevantHeader = this.findRelevantHeader(headers, chunkStart)\nconst chunk: DocChunk = {\ntext: chunkText,\ntokenCount: Math.ceil(chunkText.length / 4),\nsourceDocument: relativePath,\nheaderLink: relevantHeader ? `${documentUrl}#${relevantHeader.anchor}` : documentUrl,\nheaderText: relevantHeader?.text || frontmatter.title || 'Document Root',\nheaderLevel: relevantHeader?.level || 1,\nembedding: embeddings[i] || [],\nembeddingModel,\nmetadata: {\nstartIndex: chunkStart,\nendIndex: chunkEnd,\nhasFrontmatter: i === 0 && content.startsWith('---'),\ndocumentTitle: frontmatter.title,\ndocumentDescription: frontmatter.description,\n},\n}\nchunks.push(chunk)\ncurrentPosition = chunkEnd\n}\nreturn chunks\n}"
"private splitByHeaders(\ncontent: string\n): Array<{ header: string | null; content: string; level: number }> {\nconst lines = content.split('\n')\nconst sections: Array<{ header: string | null; content: string; level: number }> = []\nlet currentHeader: string | null = null\nlet currentLevel = 0\nlet currentContent: string[] = []\nfor (const line of lines) {\nconst headerMatch = line.match(/^(#{1,3})\s+(.+)$/)\nif (headerMatch) {\nif (currentContent.length > 0) {\nsections.push({\nheader: currentHeader,\ncontent: currentContent.join('\n').trim(),\nlevel: currentLevel,\n})\n}\ncurrentHeader = line\ncurrentLevel = headerMatch[1].length\ncurrentContent = []\n} else {\ncurrentContent.push(line)\n}\n}\nif (currentContent.length > 0) {\nsections.push({\nheader: currentHeader,\ncontent: currentContent.join('\n').trim(),\nlevel: currentLevel,\n})\n}\nreturn sections.filter((section) => section.content.trim().length > 0)\n}"
"private mergeTableChunks(\nchunks: string[],\ntableBoundaries: { start: number; end: number }[],\noriginalContent: string\n): string[] {\nif (tableBoundaries.length === 0) {\nreturn chunks\n}\nconst mergedChunks: string[] = []\nlet currentPosition = 0\nfor (const chunk of chunks) {\nconst chunkStart = originalContent.indexOf(chunk, currentPosition)\nconst chunkEnd = chunkStart + chunk.length\nconst intersectsTable = tableBoundaries.some(\n(table) =>\n(chunkStart >= table.start && chunkStart <= table.end) ||\n(chunkEnd >= table.start && chunkEnd <= table.end) ||\n(chunkStart <= table.start && chunkEnd >= table.end)\n)\nif (intersectsTable) {\nconst affectedTables = tableBoundaries.filter(\n(table) =>\n(chunkStart >= table.start && chunkStart <= table.end) ||\n(chunkEnd >= table.start && chunkEnd <= table.end) ||\n(chunkStart <= table.start && chunkEnd >= table.end)\n)\nconst minStart = Math.min(chunkStart, ...affectedTables.map((t) => t.start))\nconst maxEnd = Math.max(chunkEnd, ...affectedTables.map((t) => t.end))\nconst completeChunk = originalContent.slice(minStart, maxEnd)\nif (!mergedChunks.some((existing) => existing.includes(completeChunk.trim()))) {\nmergedChunks.push(completeChunk.trim())\n}\n} else {\nmergedChunks.push(chunk)\n}\ncurrentPosition = chunkEnd\n}\nreturn mergedChunks.filter((chunk) => chunk.length > 50)\n}"
"export async function processDocument(\nfileUrl: string,\nfilename: string,\nmimeType: string,\nchunkSize = 1000,\nchunkOverlap = 200\n): Promise<{\nchunks: Chunk[]\nmetadata: {\nfilename: string\nfileSize: number\nmimeType: string\nchunkCount: number\ntokenCount: number\ncharacterCount: number\nprocessingMethod: 'file-parser' | 'mistral-ocr'\ncloudUrl?: string\n}\n}> {\nlogger.info(`Processing document: ${filename}`)\ntry {\nconst { content, processingMethod, cloudUrl } = await parseDocument(fileUrl, filename, mimeType)\nconst chunker = new TextChunker({\nchunkSize,\noverlap: chunkOverlap,\n})\nconst chunks = await chunker.chunk(content)\nconst characterCount = content.length\nconst tokenCount = chunks.reduce((sum: number, chunk: Chunk) => sum + chunk.tokenCount, 0)\nlogger.info(`Document processed successfully: ${chunks.length} chunks, ${tokenCount} tokens`)\nreturn {\nchunks,\nmetadata: {\nfilename,\nfileSize: content.length,\nmimeType,\nchunkCount: chunks.length,\ntokenCount,\ncharacterCount,\nprocessingMethod,\ncloudUrl,\n},\n}\n} catch (error) {\nlogger.error(`Error processing document ${filename}:`, error)\nthrow error\n}\n}"
"export async function retryWithExponentialBackoff<T>(\noperation: () => Promise<T>,\noptions: RetryOptions = {}\n): Promise<T> {\nconst {\nmaxRetries = 5,\ninitialDelayMs = 1000,\nmaxDelayMs = 30000,\nbackoffMultiplier = 2,\nretryCondition = isRetryableError,\n} = options\nlet lastError: Error | undefined\nlet delay = initialDelayMs\nfor (let attempt = 0; attempt <= maxRetries; attempt++) {\ntry {\nlogger.debug(`Executing operation attempt ${attempt + 1}/${maxRetries + 1}`)\nconst result = await operation()\nif (attempt > 0) {\nlogger.info(`Operation succeeded after ${attempt + 1} attempts`)\n}\nreturn result\n} catch (error) {\nlastError = error instanceof Error ? error : new Error(String(error))\nlogger.warn(`Operation failed on attempt ${attempt + 1}`, { error })\nif (attempt === maxRetries) {\nlogger.error(`Operation failed after ${maxRetries + 1} attempts`, { error })\nthrow lastError\n}\nif (!retryCondition(error as RetryableError)) {\nlogger.warn('Error is not retryable, throwing immediately', { error })\nthrow lastError\n}\nconst jitter = Math.random() * 0.1 * delay\nconst actualDelay = Math.min(delay + jitter, maxDelayMs)\nlogger.info(\n`Retrying in ${Math.round(actualDelay)}ms (attempt ${attempt + 1}/${maxRetries + 1})`\n)\nawait new Promise((resolve) => setTimeout(resolve, actualDelay))\ndelay = Math.min(delay * backoffMultiplier, maxDelayMs)\n}\n}\nthrow lastError || new Error('Retry operation failed')\n}"
"export async function updateEmailPreferences(\nemail: string,\npreferences: EmailPreferences\n): Promise<boolean> {\ntry {\nconst userResult = await db\n.select({ id: user.id })\n.from(user)\n.where(eq(user.email, email))\n.limit(1)\nif (!userResult[0]) {\nlogger.warn(`User not found for email: ${email}`)\nreturn false\n}\nconst userId = userResult[0].id\nconst existingSettings = await db\n.select({ emailPreferences: settings.emailPreferences })\n.from(settings)\n.where(eq(settings.userId, userId))\n.limit(1)\nlet currentEmailPreferences = {}\nif (existingSettings[0]) {\ncurrentEmailPreferences = (existingSettings[0].emailPreferences as EmailPreferences) || {}\n}\nconst updatedEmailPreferences = {\n...currentEmailPreferences,\n...preferences,\n}\nawait db\n.insert(settings)\n.values({\nid: userId,\nuserId,\nemailPreferences: updatedEmailPreferences,\n})\n.onConflictDoUpdate({\ntarget: settings.userId,\nset: {\nemailPreferences: updatedEmailPreferences,\nupdatedAt: new Date(),\n},\n})\nlogger.info(`Updated email preferences for user: ${email}`)\nreturn true\n} catch (error) {\nlogger.error('Error updating email preferences:', error)\nreturn false\n}\n}"
"async parseFile(filePath: string): Promise<FileParseResult> {\nreturn new Promise((resolve, reject) => {\ntry {\nif (!filePath) {\nreturn reject(new Error('No file path provided'))\n}\nif (!existsSync(filePath)) {\nreturn reject(new Error(`File not found: ${filePath}`))\n}\nconst results: Record<string, any>[] = []\nconst headers: string[] = []\ncreateReadStream(filePath)\n.on('error', (error: Error) => {\nlogger.error('CSV stream error:', error)\nreject(new Error(`Failed to read CSV file: ${error.message}`))\n})\n.pipe(csvParser())\n.on('headers', (headerList: string[]) => {\nheaders.push(...headerList)\n})\n.on('data', (data: Record<string, any>) => {\nresults.push(data)\n})\n.on('end', () => {\nlet content = ''\nif (headers.length > 0) {\ncontent += `${headers.join(', ')}\n`\n}\nresults.forEach((row) => {\nconst rowValues = Object.values(row).join(', ')\ncontent += `${rowValues}\n`\n})\nresolve({\ncontent,\nmetadata: {\nrowCount: results.length,\nheaders: headers,\nrawData: results,\n},\n})\n})\n.on('error', (error: Error) => {\nlogger.error('CSV parsing error:', error)\nreject(new Error(`Failed to parse CSV file: ${error.message}`))\n})\n} catch (error) {\nlogger.error('CSV general error:', error)\nreject(new Error(`Failed to process CSV file: ${(error as Error).message}`))\n}\n})\n}"
"async parseBuffer(buffer: Buffer): Promise<FileParseResult> {\nreturn new Promise((resolve, reject) => {\ntry {\nlogger.info('Parsing buffer, size:', buffer.length)\nconst results: Record<string, any>[] = []\nconst headers: string[] = []\nconst bufferStream = new Readable()\nbufferStream.push(buffer)\nbufferStream.push(null)\nbufferStream\n.on('error', (error: Error) => {\nlogger.error('CSV buffer stream error:', error)\nreject(new Error(`Failed to read CSV buffer: ${error.message}`))\n})\n.pipe(csvParser())\n.on('headers', (headerList: string[]) => {\nheaders.push(...headerList)\n})\n.on('data', (data: Record<string, any>) => {\nresults.push(data)\n})\n.on('end', () => {\nlet content = ''\nif (headers.length > 0) {\ncontent += `${headers.join(', ')}\n`\n}\nresults.forEach((row) => {\nconst rowValues = Object.values(row).join(', ')\ncontent += `${rowValues}\n`\n})\nresolve({\ncontent,\nmetadata: {\nrowCount: results.length,\nheaders: headers,\nrawData: results,\n},\n})\n})\n.on('error', (error: Error) => {\nlogger.error('CSV parsing error:', error)\nreject(new Error(`Failed to parse CSV buffer: ${error.message}`))\n})\n} catch (error) {\nlogger.error('CSV buffer parsing error:', error)\nreject(new Error(`Failed to process CSV buffer: ${(error as Error).message}`))\n}\n})\n}"
"private processWorkbook(workbook: XLSX.WorkBook): FileParseResult {\nconst sheetNames = workbook.SheetNames\nconst sheets: Record<string, any[]> = {}\nlet content = ''\nlet totalRows = 0\nfor (const sheetName of sheetNames) {\nconst worksheet = workbook.Sheets[sheetName]\nconst sheetData = XLSX.utils.sheet_to_json(worksheet, { header: 1 })\nsheets[sheetName] = sheetData\ntotalRows += sheetData.length\ncontent += `Sheet: ${sheetName}\n`\ncontent += `=${'='.repeat(sheetName.length + 6)}\n\n`\nif (sheetData.length > 0) {\nsheetData.forEach((row: unknown, rowIndex: number) => {\nif (Array.isArray(row) && row.length > 0) {\nconst rowString = row\n.map((cell) => {\nif (cell === null || cell === undefined) {\nreturn ''\n}\nreturn String(cell)\n})\n.join('\t')\ncontent += `${rowString}\n`\n}\n})\n} else {\ncontent += '[Empty sheet]\n'\n}\ncontent += '\n'\n}\nlogger.info(`XLSX parsing completed: ${sheetNames.length} sheets, ${totalRows} total rows`)\nreturn {\ncontent: content.trim(),\nmetadata: {\nsheetCount: sheetNames.length,\nsheetNames: sheetNames,\ntotalRows: totalRows,\nsheets: sheets,\n},\n}\n}"
"export function getServiceIdFromScopes(provider: OAuthProvider, scopes: string[]): string {\nconst providerConfig = OAUTH_PROVIDERS[provider]\nif (!providerConfig) {\nreturn provider\n}\nif (provider === 'google') {\nif (scopes.some((scope) => scope.includes('gmail') || scope.includes('mail'))) {\nreturn 'gmail'\n}\nif (scopes.some((scope) => scope.includes('drive'))) {\nreturn 'google-drive'\n}\nif (scopes.some((scope) => scope.includes('docs'))) {\nreturn 'google-docs'\n}\nif (scopes.some((scope) => scope.includes('sheets'))) {\nreturn 'google-sheets'\n}\nif (scopes.some((scope) => scope.includes('calendar'))) {\nreturn 'google-calendar'\n}\n} else if (provider === 'microsoft-teams') {\nreturn 'microsoft-teams'\n} else if (provider === 'outlook') {\nreturn 'outlook'\n} else if (provider === 'github') {\nreturn 'github'\n} else if (provider === 'supabase') {\nreturn 'supabase'\n} else if (provider === 'x') {\nreturn 'x'\n} else if (provider === 'confluence') {\nreturn 'confluence'\n} else if (provider === 'jira') {\nreturn 'jira'\n} else if (provider === 'airtable') {\nreturn 'airtable'\n} else if (provider === 'notion') {\nreturn 'notion'\n} else if (provider === 'discord') {\nreturn 'discord'\n} else if (provider === 'linear') {\nreturn 'linear'\n} else if (provider === 'slack') {\nreturn 'slack'\n} else if (provider === 'reddit') {\nreturn 'reddit'\n} else if (provider === 'wealthbox') {\nreturn 'wealthbox'\n}\nreturn providerConfig.defaultService\n}"
"export async function refreshOAuthToken(\nproviderId: string,\nrefreshToken: string\n): Promise<{ accessToken: string; expiresIn: number; refreshToken: string } | null> {\ntry {\nconst provider = providerId.split('-')[0]\nconst config = getProviderAuthConfig(provider)\nconst { headers, bodyParams } = buildAuthRequest(config, refreshToken)\nconst response = await fetch(config.tokenEndpoint, {\nmethod: 'POST',\nheaders,\nbody: new URLSearchParams(bodyParams).toString(),\n})\nif (!response.ok) {\nconst errorText = await response.text()\nlet errorData = errorText\ntry {\nerrorData = JSON.parse(errorText)\n} catch (_e) {\n}\nlogger.error('Token refresh failed:', {\nstatus: response.status,\nerror: errorText,\nparsedError: errorData,\nprovider,\nproviderId,\n})\nthrow new Error(`Failed to refresh token: ${response.status} ${errorText}`)\n}\nconst data = await response.json()\nconst accessToken = data.access_token\nlet newRefreshToken = null\nif (config.supportsRefreshTokenRotation && data.refresh_token) {\nnewRefreshToken = data.refresh_token\nlogger.info(`Received new refresh token from ${provider}`)\n}\nconst expiresIn = data.expires_in || data.expiresIn || 3600\nif (!accessToken) {\nlogger.warn('No access token found in refresh response', data)\nreturn null\n}\nlogger.info('Token refreshed successfully with expiration', {\nexpiresIn,\nhasNewRefreshToken: !!newRefreshToken,\nprovider,\n})\nreturn {\naccessToken,\nexpiresIn,\nrefreshToken: newRefreshToken || refreshToken,\n}\n} catch (error) {\nlogger.error('Error refreshing token:', { error })\nreturn null\n}\n}"
"export async function isOrganizationAdminForWorkspace(\nuserId: string,\nworkspaceId: string\n): Promise<boolean> {\ntry {\nconst workspaceRecord = await db\n.select({ ownerId: workspace.ownerId })\n.from(workspace)\n.where(eq(workspace.id, workspaceId))\n.limit(1)\nif (workspaceRecord.length === 0) {\nreturn false\n}\nconst workspaceOwnerId = workspaceRecord[0].ownerId\nconst orgMemberships = await db\n.select({\norganizationId: member.organizationId,\nrole: member.role,\n})\n.from(member)\n.where(\nand(\neq(member.userId, userId),\neq(member.role, 'admin')\n)\n)\nconst ownerMemberships = await db\n.select({\norganizationId: member.organizationId,\nrole: member.role,\n})\n.from(member)\n.where(and(eq(member.userId, userId), eq(member.role, 'owner')))\nconst allOrgMemberships = [...orgMemberships, ...ownerMemberships]\nif (allOrgMemberships.length === 0) {\nreturn false\n}\nfor (const membership of allOrgMemberships) {\nconst workspaceOwnerInOrg = await db\n.select()\n.from(member)\n.where(\nand(\neq(member.userId, workspaceOwnerId),\neq(member.organizationId, membership.organizationId)\n)\n)\n.limit(1)\nif (workspaceOwnerInOrg.length > 0) {\nreturn true\n}\n}\nreturn false\n} catch (error) {\nconsole.error('Error checking organization admin status for workspace:', error)\nreturn false\n}\n}"
"export async function getManageableWorkspaces(userId: string): Promise<\nArray<{\nid: string\nname: string\nownerId: string\naccessType: 'direct' | 'organization'\n}>\n> {\nconst manageableWorkspaces: Array<{\nid: string\nname: string\nownerId: string\naccessType: 'direct' | 'organization'\n}> = []\nconst directWorkspaces = await db\n.select({\nid: workspace.id,\nname: workspace.name,\nownerId: workspace.ownerId,\n})\n.from(workspace)\n.innerJoin(permissions, eq(permissions.entityId, workspace.id))\n.where(\nand(\neq(permissions.userId, userId),\neq(permissions.entityType, 'workspace'),\neq(permissions.permissionType, 'admin')\n)\n)\ndirectWorkspaces.forEach((ws) => {\nmanageableWorkspaces.push({\n...ws,\naccessType: 'direct',\n})\n})\nconst adminOrgs = await db\n.select({ organizationId: member.organizationId })\n.from(member)\n.where(\nand(\neq(member.userId, userId)\n)\n)\nfor (const org of adminOrgs) {\nconst orgMembers = await db\n.select({ userId: member.userId })\n.from(member)\n.where(eq(member.organizationId, org.organizationId))\nconst orgWorkspaces = await db\n.select({\nid: workspace.id,\nname: workspace.name,\nownerId: workspace.ownerId,\n})\n.from(workspace)\n.where(\neq(workspace.ownerId, orgMembers.length > 0 ? orgMembers[0].userId : 'none')\n)\norgWorkspaces.forEach((ws) => {\nif (!manageableWorkspaces.find((existing) => existing.id === ws.id)) {\nmanageableWorkspaces.push({\n...ws,\naccessType: 'organization',\n})\n}\n})\n}\nreturn manageableWorkspaces\n}"
"export function getScheduleTimeValues(starterBlock: BlockState): {\nscheduleTime: string\nscheduleStartAt?: string\nminutesInterval: number\nhourlyMinute: number\ndailyTime: [number, number]\nweeklyDay: number\nweeklyTime: [number, number]\nmonthlyDay: number\nmonthlyTime: [number, number]\ncronExpression: string | null\ntimezone: string\n} {\nconst scheduleTime = getSubBlockValue(starterBlock, 'scheduleTime')\nconst scheduleStartAt = getSubBlockValue(starterBlock, 'scheduleStartAt')\nconst timezone = getSubBlockValue(starterBlock, 'timezone') || 'UTC'\nconst minutesIntervalStr = getSubBlockValue(starterBlock, 'minutesInterval')\nconst minutesInterval = Number.parseInt(minutesIntervalStr) || 15\nconst hourlyMinuteStr = getSubBlockValue(starterBlock, 'hourlyMinute')\nconst hourlyMinute = Number.parseInt(hourlyMinuteStr) || 0\nconst dailyTime = parseTimeString(getSubBlockValue(starterBlock, 'dailyTime'))\nconst weeklyDayStr = getSubBlockValue(starterBlock, 'weeklyDay') || 'MON'\nconst weeklyDay = DAY_MAP[weeklyDayStr] || 1\nconst weeklyTime = parseTimeString(getSubBlockValue(starterBlock, 'weeklyDayTime'))\nconst monthlyDayStr = getSubBlockValue(starterBlock, 'monthlyDay')\nconst monthlyDay = Number.parseInt(monthlyDayStr) || 1\nconst monthlyTime = parseTimeString(getSubBlockValue(starterBlock, 'monthlyTime'))\nconst cronExpression = getSubBlockValue(starterBlock, 'cronExpression') || null\nif (cronExpression) {\nconst validation = validateCronExpression(cronExpression)\nif (!validation.isValid) {\nthrow new Error(`Invalid cron expression: ${validation.error}`)\n}\n}\nreturn {\nscheduleTime,\nscheduleStartAt,\ntimezone,\nminutesInterval,\nhourlyMinute,\ndailyTime,\nweeklyDay,\nweeklyTime,\nmonthlyDay,\nmonthlyTime,\ncronExpression,\n}\n}"
"async makeRequest<T = any>(\nendpoint: string,\noptions: {\nmethod?: 'GET' | 'POST' | 'PUT' | 'DELETE'\nbody?: Record<string, any>\nheaders?: Record<string, string>\napiKey?: string\n} = {}\n): Promise<SimAgentResponse<T>> {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { method = 'POST', body, headers = {}, apiKey: providedApiKey } = options\ntry {\nconst url = `${this.baseUrl}${endpoint}`\nconst apiKey = providedApiKey || this.getApiKey()\nconst requestHeaders: Record<string, string> = {\n'Content-Type': 'application/json',\n...(apiKey && { 'x-api-key': apiKey }),\n...headers,\n}\nlogger.info(`[${requestId}] Making request to sim-agent`, {\nurl,\nmethod,\nhasApiKey: !!apiKey,\nhasBody: !!body,\n})\nconst fetchOptions: RequestInit = {\nmethod,\nheaders: requestHeaders,\n}\nif (body && (method === 'POST' || method === 'PUT')) {\nfetchOptions.body = JSON.stringify(body)\n}\nconst response = await fetch(url, fetchOptions)\nconst responseStatus = response.status\nlet responseData\ntry {\nconst responseText = await response.text()\nresponseData = responseText ? JSON.parse(responseText) : null\n} catch (parseError) {\nlogger.error(`[${requestId}] Failed to parse response`, parseError)\nreturn {\nsuccess: false,\nerror: `Failed to parse response: ${parseError instanceof Error ? parseError.message : 'Unknown parse error'}`,\nstatus: responseStatus,\n}\n}\nlogger.info(`[${requestId}] Response received`, {\nstatus: responseStatus,\nsuccess: response.ok,\nhasData: !!responseData,\n})\nreturn {\nsuccess: response.ok,\ndata: responseData,\nerror: response.ok ? undefined : responseData?.error || `HTTP ${responseStatus}`,\nstatus: responseStatus,\n}\n} catch (fetchError) {\nlogger.error(`[${requestId}] Request failed`, fetchError)\nreturn {\nsuccess: false,\nerror: `Connection failed: ${fetchError instanceof Error ? fetchError.message : 'Unknown error'}`,\nstatus: 0,\n}\n}\n}"
"export function estimateTokenCount(text: string, providerId?: string): TokenEstimate {\nif (!text || text.length < MIN_TEXT_LENGTH_FOR_ESTIMATION) {\nreturn {\ncount: 0,\nconfidence: 'high',\nprovider: providerId || 'unknown',\nmethod: 'fallback',\n}\n}\nconst effectiveProviderId = providerId || TOKENIZATION_CONFIG.defaults.provider\nconst config = getProviderConfig(effectiveProviderId)\nlogger.debug('Starting token estimation', {\nprovider: effectiveProviderId,\ntextLength: text.length,\npreview: createTextPreview(text),\navgCharsPerToken: config.avgCharsPerToken,\n})\nlet estimatedTokens: number\nswitch (effectiveProviderId) {\ncase 'openai':\ncase 'azure-openai':\nestimatedTokens = estimateOpenAITokens(text)\nbreak\ncase 'anthropic':\nestimatedTokens = estimateAnthropicTokens(text)\nbreak\ncase 'google':\nestimatedTokens = estimateGoogleTokens(text)\nbreak\ndefault:\nestimatedTokens = estimateGenericTokens(text, config.avgCharsPerToken)\n}\nconst result: TokenEstimate = {\ncount: Math.max(1, Math.round(estimatedTokens)),\nconfidence: config.confidence,\nprovider: effectiveProviderId,\nmethod: 'heuristic',\n}\nlogger.debug('Token estimation completed', {\nprovider: effectiveProviderId,\ntextLength: text.length,\nestimatedTokens: result.count,\nconfidence: result.confidence,\n})\nreturn result\n}"
"export function processStreamingBlockLog(log: BlockLog, streamedContent: string): boolean {\nif (!isTokenizableBlockType(log.blockType)) {\nreturn false\n}\nif (hasRealTokenData(log.output?.tokens) && hasRealCostData(log.output?.cost)) {\nlogger.debug(`Block ${log.blockId} already has real token/cost data`, {\nblockType: log.blockType,\ntokens: log.output?.tokens,\ncost: log.output?.cost,\n})\nreturn false\n}\nif (!streamedContent?.trim()) {\nlogger.debug(`Block ${log.blockId} has no content to tokenize`, {\nblockType: log.blockType,\ncontentLength: streamedContent?.length || 0,\n})\nreturn false\n}\ntry {\nconst model = getModelForBlock(log)\nconst inputText = extractTextContent(log.input)\nlogger.debug(`Starting tokenization for streaming block ${log.blockId}`, {\nblockType: log.blockType,\nmodel,\ninputLength: inputText.length,\noutputLength: streamedContent.length,\nhasInput: !!log.input,\n})\nconst result = calculateStreamingCost(\nmodel,\ninputText,\nstreamedContent,\nlog.input?.systemPrompt,\nlog.input?.context,\nlog.input?.messages\n)\nif (!log.output) {\nlog.output = {}\n}\nlog.output.tokens = result.tokens\nlog.output.cost = result.cost\nlog.output.model = result.model\nlogTokenizationDetails(`Streaming tokenization completed for ${log.blockType}`, {\nblockId: log.blockId,\nblockType: log.blockType,\nmodel: result.model,\nprovider: result.provider,\ninputLength: inputText.length,\noutputLength: streamedContent.length,\ntokens: result.tokens,\ncost: result.cost,\nmethod: result.method,\n})\nreturn true\n} catch (error) {\nlogger.error(`Streaming tokenization failed for block ${log.blockId}`, {\nblockType: log.blockType,\nerror: error instanceof Error ? error.message : String(error),\ncontentLength: streamedContent?.length || 0,\n})\nreturn false\n}\n}"
"async function fetchNewOutlookEmails(\naccessToken: string,\nconfig: OutlookWebhookConfig,\nrequestId: string\n) {\ntry {\nconst apiUrl = 'https:\nconst params = new URLSearchParams()\nparams.append(\n'$select',\n'id,conversationId,subject,bodyPreview,body,from,toRecipients,ccRecipients,receivedDateTime,sentDateTime,hasAttachments,isRead,parentFolderId'\n)\nparams.append('$orderby', 'receivedDateTime desc')\nparams.append('$top', (config.maxEmailsPerPoll || 25).toString())\nif (config.lastCheckedTimestamp) {\nconst lastChecked = new Date(config.lastCheckedTimestamp)\nconst bufferTime = new Date(lastChecked.getTime() - 60000)\nparams.append('$filter', `receivedDateTime gt ${bufferTime.toISOString()}`)\n}\nconst fullUrl = `${apiUrl}?${params.toString()}`\nlogger.info(`[${requestId}] Fetching emails from: ${fullUrl}`)\nconst response = await fetch(fullUrl, {\nheaders: {\nAuthorization: `Bearer ${accessToken}`,\n'Content-Type': 'application/json',\n},\n})\nif (!response.ok) {\nconst errorData = await response.json().catch(() => ({ error: { message: 'Unknown error' } }))\nlogger.error(`[${requestId}] Microsoft Graph API error:`, {\nstatus: response.status,\nstatusText: response.statusText,\nerror: errorData,\n})\nreturn { emails: [] }\n}\nconst data = await response.json()\nconst emails = data.value || []\nconst filteredEmails = filterEmailsByFolder(emails, config)\nlogger.info(\n`[${requestId}] Fetched ${emails.length} emails, ${filteredEmails.length} after filtering`\n)\nreturn { emails: filteredEmails }\n} catch (error) {\nconst errorMessage = error instanceof Error ? error.message : 'Unknown error'\nlogger.error(`[${requestId}] Error fetching new Outlook emails:`, errorMessage)\nreturn { emails: [] }\n}\n}"
"export async function handleWhatsAppVerification(\nrequestId: string,\npath: string,\nmode: string | null,\ntoken: string | null,\nchallenge: string | null\n): Promise<NextResponse | null> {\nif (mode && token && challenge) {\nlogger.info(`[${requestId}] WhatsApp verification request received for path: ${path}`)\nif (mode !== 'subscribe') {\nlogger.warn(`[${requestId}] Invalid WhatsApp verification mode: ${mode}`)\nreturn new NextResponse('Invalid mode', { status: 400 })\n}\nconst webhooks = await db\n.select()\n.from(webhook)\n.where(and(eq(webhook.provider, 'whatsapp'), eq(webhook.isActive, true)))\nfor (const wh of webhooks) {\nconst providerConfig = (wh.providerConfig as Record<string, any>) || {}\nconst verificationToken = providerConfig.verificationToken\nif (!verificationToken) {\nlogger.debug(`[${requestId}] Webhook ${wh.id} has no verification token, skipping`)\ncontinue\n}\nif (token === verificationToken) {\nlogger.info(`[${requestId}] WhatsApp verification successful for webhook ${wh.id}`)\nreturn new NextResponse(challenge, {\nstatus: 200,\nheaders: {\n'Content-Type': 'text/plain',\n},\n})\n}\n}\nlogger.warn(`[${requestId}] No matching WhatsApp verification token found`)\nreturn new NextResponse('Verification failed', { status: 403 })\n}\nreturn null\n}"
"export async function validateSlackSignature(\nsigningSecret: string,\nsignature: string,\ntimestamp: string,\nbody: string\n): Promise<boolean> {\ntry {\nif (!signingSecret || !signature || !timestamp || !body) {\nreturn false\n}\nconst currentTime = Math.floor(Date.now() / 1000)\nif (Math.abs(currentTime - Number.parseInt(timestamp)) > 300) {\nreturn false\n}\nconst encoder = new TextEncoder()\nconst baseString = `v0:${timestamp}:${body}`\nconst key = await crypto.subtle.importKey(\n'raw',\nencoder.encode(signingSecret),\n{ name: 'HMAC', hash: 'SHA-256' },\nfalse,\n['sign']\n)\nconst signatureBytes = await crypto.subtle.sign('HMAC', key, encoder.encode(baseString))\nconst signatureHex = Array.from(new Uint8Array(signatureBytes))\n.map((b) => b.toString(16).padStart(2, '0'))\n.join('')\nconst computedSignature = `v0=${signatureHex}`\nif (computedSignature.length !== signature.length) {\nreturn false\n}\nlet result = 0\nfor (let i = 0; i < computedSignature.length; i++) {\nresult |= computedSignature.charCodeAt(i) ^ signature.charCodeAt(i)\n}\nreturn result === 0\n} catch (error) {\nconsole.error('Error validating Slack signature:', error)\nreturn false\n}\n}"
"export async function configureGmailPolling(\nuserId: string,\nwebhookData: any,\nrequestId: string\n): Promise<boolean> {\nconst logger = createLogger('GmailWebhookSetup')\nlogger.info(`[${requestId}] Setting up Gmail polling for webhook ${webhookData.id}`)\ntry {\nconst accessToken = await getOAuthToken(userId, 'google-email')\nif (!accessToken) {\nlogger.error(`[${requestId}] Failed to retrieve Gmail access token for user ${userId}`)\nreturn false\n}\nconst providerConfig = (webhookData.providerConfig as Record<string, any>) || {}\nconst maxEmailsPerPoll =\ntypeof providerConfig.maxEmailsPerPoll === 'string'\n? Number.parseInt(providerConfig.maxEmailsPerPoll, 10) || 25\n: providerConfig.maxEmailsPerPoll || 25\nconst pollingInterval =\ntypeof providerConfig.pollingInterval === 'string'\n? Number.parseInt(providerConfig.pollingInterval, 10) || 5\n: providerConfig.pollingInterval || 5\nconst now = new Date()\nawait db\n.update(webhook)\n.set({\nproviderConfig: {\n...providerConfig,\nuserId,\nmaxEmailsPerPoll,\npollingInterval,\nmarkAsRead: providerConfig.markAsRead || false,\nincludeRawEmail: providerConfig.includeRawEmail || false,\nlabelIds: providerConfig.labelIds || ['INBOX'],\nlabelFilterBehavior: providerConfig.labelFilterBehavior || 'INCLUDE',\nlastCheckedTimestamp: now.toISOString(),\nsetupCompleted: true,\n},\nupdatedAt: now,\n})\n.where(eq(webhook.id, webhookData.id))\nlogger.info(\n`[${requestId}] Successfully configured Gmail polling for webhook ${webhookData.id}`\n)\nreturn true\n} catch (error: any) {\nlogger.error(`[${requestId}] Failed to configure Gmail polling`, {\nwebhookId: webhookData.id,\nerror: error.message,\nstack: error.stack,\n})\nreturn false\n}\n}"
"export async function configureOutlookPolling(\nuserId: string,\nwebhookData: any,\nrequestId: string\n): Promise<boolean> {\nconst logger = createLogger('OutlookWebhookSetup')\nlogger.info(`[${requestId}] Setting up Outlook polling for webhook ${webhookData.id}`)\nlogger.info(`[${requestId}] Setting up Outlook polling for webhook ${webhookData.id}`)\ntry {\nconst accessToken = await getOAuthToken(userId, 'outlook')\nif (!accessToken) {\nlogger.error(`[${requestId}] Failed to retrieve Outlook access token for user ${userId}`)\nreturn false\n}\nconst providerConfig = (webhookData.providerConfig as Record<string, any>) || {}\nconst maxEmailsPerPoll =\ntypeof providerConfig.maxEmailsPerPoll === 'string'\n? Number.parseInt(providerConfig.maxEmailsPerPoll, 10) || 25\n: providerConfig.maxEmailsPerPoll || 25\nconst pollingInterval =\ntypeof providerConfig.pollingInterval === 'string'\n? Number.parseInt(providerConfig.pollingInterval, 10) || 5\n: providerConfig.pollingInterval || 5\nconst now = new Date()\nawait db\n.update(webhook)\n.set({\nproviderConfig: {\n...providerConfig,\nuserId,\nmaxEmailsPerPoll,\npollingInterval,\nmarkAsRead: providerConfig.markAsRead || false,\nincludeRawEmail: providerConfig.includeRawEmail || false,\nfolderIds: providerConfig.folderIds || ['inbox'],\nfolderFilterBehavior: providerConfig.folderFilterBehavior || 'INCLUDE',\nlastCheckedTimestamp: now.toISOString(),\nsetupCompleted: true,\n},\nupdatedAt: now,\n})\n.where(eq(webhook.id, webhookData.id))\nlogger.info(\n`[${requestId}] Successfully configured Outlook polling for webhook ${webhookData.id}`\n)\nreturn true\n} catch (error: any) {\nlogger.error(`[${requestId}] Failed to configure Outlook polling`, {\nwebhookId: webhookData.id,\nerror: error.message,\nstack: error.stack,\n})\nreturn false\n}\n}"
"export async function resolveCredentialsForWorkflow(\nblocks: Record<string, BlockState>,\nsubBlockValues: Record<string, Record<string, any>>,\nuserId?: string\n): Promise<Record<string, Record<string, any>>> {\nconst resolvedValues = { ...subBlockValues }\nlogger.info('Starting credential resolution for workflow', {\nuserId,\nblockCount: Object.keys(blocks).length,\n})\ntry {\nfor (const [blockId, blockState] of Object.entries(blocks)) {\nconst blockConfig = getBlock(blockState.type)\nif (!blockConfig) {\nlogger.debug(`No config found for block type: ${blockState.type}`)\ncontinue\n}\nif (!resolvedValues[blockId]) {\nresolvedValues[blockId] = {}\n}\nfor (const subBlockConfig of blockConfig.subBlocks) {\nif (subBlockConfig.type !== 'oauth-input') continue\nconst subBlockId = subBlockConfig.id\nconst existingValue = resolvedValues[blockId][subBlockId]\nlogger.debug(`Checking credential for ${blockId}.${subBlockId}`, {\nblockType: blockState.type,\nprovider: subBlockConfig.provider,\nhasExistingValue: !!existingValue,\nexistingValue,\n})\nif (existingValue && typeof existingValue === 'string' && existingValue.trim()) {\nlogger.debug(`Skipping - already has credential: ${existingValue}`)\ncontinue\n}\nconst credentialId = await resolveCredentialForSubBlock(subBlockConfig, blockState, userId)\nif (credentialId) {\nresolvedValues[blockId][subBlockId] = credentialId\nlogger.info(`Auto-selected credential for ${blockId}.${subBlockId}`, {\nblockType: blockState.type,\nprovider: subBlockConfig.provider,\ncredentialId,\n})\n} else {\nlogger.info(`No credential auto-selected for ${blockId}.${subBlockId}`, {\nblockType: blockState.type,\nprovider: subBlockConfig.provider,\n})\n}\n}\n}\nlogger.info('Credential resolution completed', {\nresolvedCount: Object.values(resolvedValues).reduce(\n(count, blockValues) => count + Object.keys(blockValues).length,\n0\n),\n})\nreturn resolvedValues\n} catch (error) {\nlogger.error('Error resolving credentials for workflow:', error)\nreturn subBlockValues\n}\n}"
"export async function updateWorkflowRunCounts(workflowId: string, runs = 1) {\ntry {\nconst workflow = await getWorkflowById(workflowId)\nif (!workflow) {\nlogger.error(`Workflow ${workflowId} not found`)\nthrow new Error(`Workflow ${workflowId} not found`)\n}\nconst origin =\ngetEnv('NEXT_PUBLIC_APP_URL') || (typeof window !== 'undefined' ? window.location.origin : '')\nif (origin) {\nconst response = await fetch(`${origin}/api/workflows/${workflowId}/stats?runs=${runs}`, {\nmethod: 'POST',\n})\nif (!response.ok) {\nconst error = await response.json()\nthrow new Error(error.error || 'Failed to update workflow stats')\n}\nreturn response.json()\n}\nlogger.warn('No origin available, updating workflow stats directly via DB')\nawait db\n.update(workflowTable)\n.set({\nrunCount: workflow.runCount + runs,\nlastRunAt: new Date(),\n})\n.where(eq(workflowTable.id, workflowId))\nif (workflow.userId) {\nconst userStatsRecord = await db\n.select()\n.from(userStats)\n.where(eq(userStats.userId, workflow.userId))\n.limit(1)\nif (userStatsRecord.length === 0) {\nawait db.insert(userStats).values({\nid: crypto.randomUUID(),\nuserId: workflow.userId,\ntotalManualExecutions: runs,\ntotalApiCalls: 0,\ntotalWebhookTriggers: 0,\ntotalScheduledExecutions: 0,\ntotalChatExecutions: 0,\ntotalTokensUsed: 0,\ntotalCost: '0.00',\nlastActive: new Date(),\n})\n} else {\nawait db\n.update(userStats)\n.set({\ntotalManualExecutions: userStatsRecord[0].totalManualExecutions + runs,\nlastActive: new Date(),\n})\n.where(eq(userStats.userId, workflow.userId))\n}\n}\nreturn { success: true, runsAdded: runs }\n} catch (error) {\nlogger.error('Error updating workflow run counts:', error)\nthrow error\n}\n}"
"export function createMinimalWorkflowState(): WorkflowStateFixture {\nconst blocks: Record<string, BlockState> = {\nstarter: {\nid: 'starter',\ntype: 'starter',\nname: 'Starter Block',\nposition: { x: 0, y: 0 },\nsubBlocks: {\ndescription: {\nid: 'description',\ntype: 'long-input',\nvalue: 'This is the starter block',\n},\n},\noutputs: {},\nenabled: true,\n},\nagent1: {\nid: 'agent1',\ntype: 'agent',\nname: 'Agent Block',\nposition: { x: 300, y: 0 },\nsubBlocks: {\nprovider: {\nid: 'provider',\ntype: 'dropdown',\nvalue: 'anthropic',\n},\nmodel: {\nid: 'model',\ntype: 'dropdown',\nvalue: 'claude-3-7-sonnet-20250219',\n},\nprompt: {\nid: 'prompt',\ntype: 'long-input',\nvalue: 'Hello, world!',\n},\ntools: {\nid: 'tools',\ntype: 'tool-input',\nvalue: '[]',\n},\nsystem: {\nid: 'system',\ntype: 'long-input',\nvalue: 'You are a helpful assistant.',\n},\nresponseFormat: {\nid: 'responseFormat',\ntype: 'code',\nvalue: null,\n},\n},\noutputs: {},\nenabled: true,\n},\n}\nconst edges: Edge[] = [\n{\nid: 'edge1',\nsource: 'starter',\ntarget: 'agent1',\n},\n]\nconst loops: Record<string, Loop> = {}\nreturn { blocks, edges, loops }\n}"
"async getRateLimitStatus(\nuserId: string,\nsubscriptionPlan: SubscriptionPlan = 'free',\ntriggerType: TriggerType = 'manual',\nisAsync = false\n): Promise<{ used: number; limit: number; remaining: number; resetAt: Date }> {\ntry {\nif (triggerType === 'manual') {\nreturn {\nused: 0,\nlimit: 999999,\nremaining: 999999,\nresetAt: new Date(Date.now() + 60000),\n}\n}\nconst limit = RATE_LIMITS[subscriptionPlan]\nconst execLimit = isAsync\n? limit.asyncApiExecutionsPerMinute\n: limit.syncApiExecutionsPerMinute\nconst now = new Date()\nconst windowStart = new Date(now.getTime() - 60000)\nconst [rateLimitRecord] = await db\n.select()\n.from(userRateLimits)\n.where(eq(userRateLimits.userId, userId))\n.limit(1)\nif (!rateLimitRecord || new Date(rateLimitRecord.windowStart) < windowStart) {\nreturn {\nused: 0,\nlimit: execLimit,\nremaining: execLimit,\nresetAt: new Date(now.getTime() + 60000),\n}\n}\nconst used = isAsync ? rateLimitRecord.asyncApiRequests : rateLimitRecord.syncApiRequests\nreturn {\nused,\nlimit: execLimit,\nremaining: Math.max(0, execLimit - used),\nresetAt: new Date(new Date(rateLimitRecord.windowStart).getTime() + 60000),\n}\n} catch (error) {\nlogger.error('Error getting rate limit status:', error)\nconst execLimit = isAsync\n? RATE_LIMITS[subscriptionPlan].asyncApiExecutionsPerMinute\n: RATE_LIMITS[subscriptionPlan].syncApiExecutionsPerMinute\nreturn {\nused: 0,\nlimit: execLimit,\nremaining: execLimit,\nresetAt: new Date(Date.now() + 60000),\n}\n}\n}"
"export async function getWorkflowState(workflowId: string) {\ntry {\nconst workflowData = await db\n.select()\n.from(workflow)\n.where(eq(workflow.id, workflowId))\n.limit(1)\nif (!workflowData.length) {\nthrow new Error(`Workflow ${workflowId} not found`)\n}\nconst normalizedData = await loadWorkflowFromNormalizedTables(workflowId)\nif (normalizedData) {\nconst existingState = workflowData[0].state || {}\nconst finalState = {\ndeploymentStatuses: {},\nhasActiveWebhook: false,\n...existingState,\nblocks: normalizedData.blocks,\nedges: normalizedData.edges,\nloops: normalizedData.loops,\nparallels: normalizedData.parallels,\nlastSaved: Date.now(),\nisDeployed: workflowData[0].isDeployed || false,\ndeployedAt: workflowData[0].deployedAt,\n}\nreturn {\n...workflowData[0],\nstate: finalState,\nlastModified: Date.now(),\n}\n}\nreturn {\n...workflowData[0],\nlastModified: Date.now(),\n}\n} catch (error) {\nlogger.error(`Error fetching workflow state for ${workflowId}:`, error)\nthrow error\n}\n}"
"export async function persistWorkflowOperation(workflowId: string, operation: any) {\nconst startTime = Date.now()\ntry {\nconst { operation: op, target, payload, timestamp, userId } = operation\nif (op === 'update-position' && Math.random() < 0.01) {\nlogger.debug('Socket DB operation sample:', {\noperation: op,\ntarget,\nworkflowId: `${workflowId.substring(0, 8)}...`,\n})\n}\nawait db.transaction(async (tx) => {\nawait tx\n.update(workflow)\n.set({ updatedAt: new Date(timestamp) })\n.where(eq(workflow.id, workflowId))\nswitch (target) {\ncase 'block':\nawait handleBlockOperationTx(tx, workflowId, op, payload, userId)\nbreak\ncase 'edge':\nawait handleEdgeOperationTx(tx, workflowId, op, payload, userId)\nbreak\ncase 'subflow':\nawait handleSubflowOperationTx(tx, workflowId, op, payload, userId)\nbreak\ndefault:\nthrow new Error(`Unknown operation target: ${target}`)\n}\n})\nconst duration = Date.now() - startTime\nif (duration > 100) {\nlogger.warn('Slow socket DB operation:', {\noperation: operation.operation,\ntarget: operation.target,\nduration: `${duration}ms`,\nworkflowId: `${workflowId.substring(0, 8)}...`,\n})\n}\n} catch (error) {\nconst duration = Date.now() - startTime\nlogger.error(\n`❌ Error persisting workflow operation (${operation.operation} on ${operation.target}) after ${duration}ms:`,\nerror\n)\nthrow error\n}\n}"
"async function handleEdgeOperationTx(\ntx: any,\nworkflowId: string,\noperation: string,\npayload: any,\nuserId: string\n) {\nswitch (operation) {\ncase 'add': {\nif (!payload.id || !payload.source || !payload.target) {\nthrow new Error('Missing required fields for add edge operation')\n}\nawait tx.insert(workflowEdges).values({\nid: payload.id,\nworkflowId,\nsourceBlockId: payload.source,\ntargetBlockId: payload.target,\nsourceHandle: payload.sourceHandle || null,\ntargetHandle: payload.targetHandle || null,\n})\nlogger.debug(`Added edge ${payload.id}: ${payload.source} -> ${payload.target}`)\nbreak\n}\ncase 'remove': {\nif (!payload.id) {\nthrow new Error('Missing edge ID for remove operation')\n}\nconst deleteResult = await tx\n.delete(workflowEdges)\n.where(and(eq(workflowEdges.id, payload.id), eq(workflowEdges.workflowId, workflowId)))\n.returning({ id: workflowEdges.id })\nif (deleteResult.length === 0) {\nthrow new Error(`Edge ${payload.id} not found in workflow ${workflowId}`)\n}\nlogger.debug(`Removed edge ${payload.id} from workflow ${workflowId}`)\nbreak\n}\ndefault:\nlogger.warn(`Unknown edge operation: ${operation}`)\nthrow new Error(`Unsupported edge operation: ${operation}`)\n}\n}"
"export function setupPresenceHandlers(\nsocket: AuthenticatedSocket,\ndeps: HandlerDependencies | RoomManager\n) {\nconst roomManager =\ndeps instanceof Object && 'roomManager' in deps ? deps.roomManager : (deps as RoomManager)\nsocket.on('cursor-update', ({ cursor }) => {\nconst workflowId = roomManager.getWorkflowIdForSocket(socket.id)\nconst session = roomManager.getUserSession(socket.id)\nif (!workflowId || !session) return\nconst room = roomManager.getWorkflowRoom(workflowId)\nif (!room) return\nconst userPresence = room.users.get(socket.id)\nif (userPresence) {\nuserPresence.cursor = cursor\nuserPresence.lastActivity = Date.now()\n}\nsocket.to(workflowId).emit('cursor-update', {\nsocketId: socket.id,\nuserId: session.userId,\nuserName: session.userName,\ncursor,\n})\n})\nsocket.on('selection-update', ({ selection }) => {\nconst workflowId = roomManager.getWorkflowIdForSocket(socket.id)\nconst session = roomManager.getUserSession(socket.id)\nif (!workflowId || !session) return\nconst room = roomManager.getWorkflowRoom(workflowId)\nif (!room) return\nconst userPresence = room.users.get(socket.id)\nif (userPresence) {\nuserPresence.selection = selection\nuserPresence.lastActivity = Date.now()\n}\nsocket.to(workflowId).emit('selection-update', {\nsocketId: socket.id,\nuserId: session.userId,\nuserName: session.userName,\nselection,\n})\n})\n}"
"export async function authenticateSocket(socket: AuthenticatedSocket, next: any) {\ntry {\nconst token = socket.handshake.auth?.token\nconst origin = socket.handshake.headers.origin\nconst referer = socket.handshake.headers.referer\nlogger.info(`Socket ${socket.id} authentication attempt:`, {\nhasToken: !!token,\norigin,\nreferer,\nallHeaders: Object.keys(socket.handshake.headers),\n})\nif (!token) {\nlogger.warn(`Socket ${socket.id} rejected: No authentication token found`)\nreturn next(new Error('Authentication required'))\n}\ntry {\nlogger.debug(`Attempting token validation for socket ${socket.id}`, {\ntokenLength: token?.length || 0,\norigin,\n})\nconst session = await auth.api.verifyOneTimeToken({\nbody: {\ntoken,\n},\n})\nif (!session?.user?.id) {\nlogger.warn(`Socket ${socket.id} rejected: Invalid token - no user found`)\nreturn next(new Error('Invalid session'))\n}\nsocket.userId = session.user.id\nsocket.userName = session.user.name || session.user.email || 'Unknown User'\nsocket.userEmail = session.user.email\nsocket.activeOrganizationId = session.session.activeOrganizationId || undefined\nnext()\n} catch (tokenError) {\nconst errorMessage = tokenError instanceof Error ? tokenError.message : String(tokenError)\nconst errorStack = tokenError instanceof Error ? tokenError.stack : undefined\nlogger.warn(`Token validation failed for socket ${socket.id}:`, {\nerror: errorMessage,\nstack: errorStack,\norigin,\nreferer,\n})\nreturn next(new Error('Token validation failed'))\n}\n} catch (error) {\nlogger.error(`Socket authentication error for ${socket.id}:`, error)\nnext(new Error('Authentication failed'))\n}\n}"
"export async function verifyWorkflowAccess(\nuserId: string,\nworkflowId: string\n): Promise<{ hasAccess: boolean; role?: string; workspaceId?: string }> {\ntry {\nconst workflowData = await db\n.select({\nuserId: workflow.userId,\nworkspaceId: workflow.workspaceId,\nname: workflow.name,\n})\n.from(workflow)\n.where(eq(workflow.id, workflowId))\n.limit(1)\nif (!workflowData.length) {\nlogger.warn(`Workflow ${workflowId} not found`)\nreturn { hasAccess: false }\n}\nconst { userId: workflowUserId, workspaceId, name: workflowName } = workflowData[0]\nif (workflowUserId === userId) {\nlogger.debug(\n`User ${userId} has admin access to workflow ${workflowId} (${workflowName}) as owner`\n)\nreturn { hasAccess: true, role: 'admin', workspaceId: workspaceId || undefined }\n}\nif (workspaceId) {\nconst userRole = await verifyWorkspaceMembership(userId, workspaceId)\nif (userRole) {\nlogger.debug(\n`User ${userId} has ${userRole} access to workflow ${workflowId} via workspace ${workspaceId}`\n)\nreturn { hasAccess: true, role: userRole, workspaceId }\n}\nlogger.warn(\n`User ${userId} is not a member of workspace ${workspaceId} for workflow ${workflowId}`\n)\nreturn { hasAccess: false }\n}\nlogger.warn(`User ${userId} has no access to workflow ${workflowId} (no workspace, not owner)`)\nreturn { hasAccess: false }\n} catch (error) {\nlogger.error(\n`Error verifying workflow access for user ${userId}, workflow ${workflowId}:`,\nerror\n)\nreturn { hasAccess: false }\n}\n}"
"export async function verifyOperationPermission(\nuserId: string,\nworkflowId: string,\noperation: string,\ntarget: string\n): Promise<{ allowed: boolean; reason?: string }> {\ntry {\nconst accessInfo = await verifyWorkflowAccess(userId, workflowId)\nif (!accessInfo.hasAccess) {\nreturn { allowed: false, reason: 'No access to workflow' }\n}\nconst rolePermissions = {\nadmin: [\n'add',\n'remove',\n'update',\n'update-position',\n'update-name',\n'toggle-enabled',\n'update-parent',\n'update-wide',\n'update-advanced-mode',\n'toggle-handles',\n'duplicate',\n],\nwrite: [\n'add',\n'remove',\n'update',\n'update-position',\n'update-name',\n'toggle-enabled',\n'update-parent',\n'update-wide',\n'update-advanced-mode',\n'toggle-handles',\n'duplicate',\n],\nread: ['update-position'],\n}\nconst allowedOperations = rolePermissions[accessInfo.role as keyof typeof rolePermissions] || []\nif (!allowedOperations.includes(operation)) {\nreturn {\nallowed: false,\nreason: `Role '${accessInfo.role}' not permitted to perform '${operation}' on '${target}'`,\n}\n}\nreturn { allowed: true }\n} catch (error) {\nlogger.error(`Error verifying operation permission:`, error)\nreturn { allowed: false, reason: 'Permission check failed' }\n}\n}"
"function validateMessagesForLLM(messages: CopilotMessage[]): any[] {\nreturn messages\n.map((msg) => {\nlet validContent = msg.content || ''\nif (msg.role === 'assistant' && !validContent.trim() && msg.contentBlocks?.length) {\nvalidContent = msg.contentBlocks\n.filter((block) => block.type === 'text')\n.map((block) => block.content)\n.join('')\n.trim()\n}\nreturn {\nid: msg.id,\nrole: msg.role,\ncontent: validContent,\ntimestamp: msg.timestamp,\n...(msg.toolCalls && msg.toolCalls.length > 0 && { toolCalls: msg.toolCalls }),\n...(msg.contentBlocks &&\nmsg.contentBlocks.length > 0 && { contentBlocks: msg.contentBlocks }),\n}\n})\n.filter((msg) => {\nif (msg.role === 'assistant') {\nconst hasContent = msg.content && msg.content.trim().length > 0\nconst hasCompletedTools = msg.toolCalls?.some(\n(tc) =>\ntc.state === 'completed' ||\ntc.state === 'accepted' ||\ntc.state === 'rejected' ||\ntc.state === 'ready_for_review' ||\ntc.state === 'background'\n)\nreturn hasContent || hasCompletedTools\n}\nreturn true\n})\n}"
"function ensureToolCallDisplayNames(messages: CopilotMessage[]): CopilotMessage[] {\nreturn messages.map((message: CopilotMessage) => {\nif (message.role === 'assistant' && (message.toolCalls || message.contentBlocks)) {\nconst hasWorkflowTools =\nmessage.toolCalls?.some(\n(tc) =>\ntc.name === COPILOT_TOOL_IDS.BUILD_WORKFLOW ||\ntc.name === COPILOT_TOOL_IDS.EDIT_WORKFLOW\n) ||\nmessage.contentBlocks?.some(\n(block) =>\n(block.type === 'tool_call' &&\n(block as any).toolCall?.name === COPILOT_TOOL_IDS.BUILD_WORKFLOW) ||\n(block as any).toolCall?.name === COPILOT_TOOL_IDS.EDIT_WORKFLOW\n)\nif (hasWorkflowTools) {\nconst workflowToolStates = message.contentBlocks\n?.filter(\n(b) =>\nb.type === 'tool_call' &&\n((b as any).toolCall?.name === COPILOT_TOOL_IDS.BUILD_WORKFLOW ||\n(b as any).toolCall?.name === COPILOT_TOOL_IDS.EDIT_WORKFLOW)\n)\n.map((b) => ({\nname: (b as any).toolCall.name,\nstate: (b as any).toolCall.state,\ndisplayName: (b as any).toolCall.displayName,\n}))\n}\nreturn {\n...message,\n...(message.toolCalls && {\ntoolCalls: message.toolCalls.map((toolCall: any) => ({\n...toolCall,\ndisplayName: getToolDisplayNameByState(toolCall),\n})),\n}),\n...(message.contentBlocks && {\ncontentBlocks: message.contentBlocks.map((block: any) =>\nblock.type === 'tool_call'\n? {\n...block,\ntoolCall: {\n...block.toolCall,\ndisplayName: getToolDisplayNameByState(block.toolCall),\n},\n}\n: block\n),\n}),\n}\n}\nreturn message\n})\n}"
"function setToolCallState(\ntoolCall: any,\nnewState: string,\noptions: {\nresult?: any\nerror?: string\npreserveTerminalStates?: boolean\n} = {}\n): void {\nconst { result, error, preserveTerminalStates = true } = options\nif (\npreserveTerminalStates &&\n(toolSupportsReadyForReview(toolCall.name) || toolRequiresInterrupt(toolCall.name)) &&\n(toolCall.state === 'accepted' ||\ntoolCall.state === 'rejected' ||\ntoolCall.state === 'background')\n) {\nlogger.info(\n'Tool call already in terminal state, preserving:',\ntoolCall.id,\ntoolCall.name,\ntoolCall.state\n)\nreturn\n}\nconst oldState = toolCall.state\ntoolCall.state = newState\nswitch (newState) {\ncase 'completed':\ncase 'success':\ntoolCall.endTime = Date.now()\ntoolCall.duration = toolCall.endTime - toolCall.startTime\nif (result !== undefined) {\ntoolCall.result = result\n}\nif (toolSupportsReadyForReview(toolCall.name)) {\ntoolCall.state = 'ready_for_review'\n}\nbreak\ncase 'errored':\ntoolCall.endTime = Date.now()\ntoolCall.duration = toolCall.endTime - toolCall.startTime\nif (error) {\ntoolCall.error = error\n}\nbreak\ncase 'executing':\nbreak\ncase 'pending':\nbreak\ncase 'accepted':\nbreak\ncase 'rejected':\ntoolCall.endTime = Date.now()\ntoolCall.duration = toolCall.endTime - toolCall.startTime\nif (error) {\ntoolCall.error = error\n}\nbreak\ncase 'background':\ntoolCall.endTime = Date.now()\ntoolCall.duration = toolCall.endTime - toolCall.startTime\nbreak\n}\ntoolCall.displayName = getToolDisplayNameByState(toolCall)\nlogger.info(\n`Tool call state changed: ${toolCall.name} (${toolCall.id}) ${oldState} → ${newState}`\n)\n}"
"function mergeContentBlocksPreservingTerminalStates(\nnewContentBlocks: any[],\nexistingContentBlocks: any[] = []\n): any[] {\nif (!existingContentBlocks.length || !newContentBlocks.some((b) => b.type === 'tool_call')) {\nreturn newContentBlocks\n}\nconst existingToolCallMap = new Map()\nexistingContentBlocks.forEach((block) => {\nif (block.type === 'tool_call') {\nexistingToolCallMap.set((block as any).toolCall.id, block)\n}\n})\nreturn newContentBlocks.map((newBlock) => {\nif (newBlock.type === 'tool_call') {\nconst toolCallBlock = newBlock as any\nif (\n!toolSupportsReadyForReview(toolCallBlock.toolCall.name) &&\n!toolRequiresInterrupt(toolCallBlock.toolCall.name)\n) {\nreturn newBlock\n}\nconst existingBlock = existingToolCallMap.get(toolCallBlock.toolCall.id)\nconst preservedToolCall = preserveToolTerminalState(\ntoolCallBlock.toolCall,\nexistingBlock?.toolCall\n)\nif (preservedToolCall !== toolCallBlock.toolCall) {\nreturn {\n...newBlock,\ntoolCall: preservedToolCall,\n}\n}\n}\nreturn newBlock\n})\n}"
"async function* parseSSEStream(\nreader: ReadableStreamDefaultReader<Uint8Array>,\ndecoder: TextDecoder\n) {\nlet buffer = ''\nconst chunkBuilder = new StringBuilder()\nlet lineBuffer: string[] = []\nwhile (true) {\nconst { done, value } = await reader.read()\nif (done) break\nconst chunk = decoder.decode(value, { stream: true })\nbuffer += chunk\nconst lastNewlineIndex = buffer.lastIndexOf('\n')\nif (lastNewlineIndex !== -1) {\nconst linesToProcess = buffer.substring(0, lastNewlineIndex)\nbuffer = buffer.substring(lastNewlineIndex + 1)\nlineBuffer = linesToProcess.split('\n')\nfor (let i = 0; i < lineBuffer.length; i++) {\nconst line = lineBuffer[i]\nif (line.length === 0) continue\nif (line.charCodeAt(0) === 100 && line.startsWith(DATA_PREFIX)) {\ntry {\nconst jsonStr = line.substring(DATA_PREFIX_LENGTH)\nyield JSON.parse(jsonStr)\n} catch (error) {\nlogger.warn('Failed to parse SSE data:', error)\n}\n}\n}\nlineBuffer.length = 0\n}\n}\n}"
"export function getWorkflowWithValues(workflowId: string) {\nconst { workflows } = useWorkflowRegistry.getState()\nconst activeWorkflowId = useWorkflowRegistry.getState().activeWorkflowId\nconst currentState = useWorkflowStore.getState()\nif (!workflows[workflowId]) {\nlogger.warn(`Workflow ${workflowId} not found`)\nreturn null\n}\nif (workflowId !== activeWorkflowId) {\nlogger.warn(`Cannot get state for non-active workflow ${workflowId} - localStorage removed`)\nreturn null\n}\nconst metadata = workflows[workflowId]\nconst deploymentStatus = useWorkflowRegistry.getState().getWorkflowDeploymentStatus(workflowId)\nconst workflowState: WorkflowState = {\n...useWorkflowStore.getState().getWorkflowState(),\nisDeployed: deploymentStatus?.isDeployed || false,\ndeployedAt: deploymentStatus?.deployedAt,\n}\nconst mergedBlocks = mergeSubblockState(workflowState.blocks, workflowId)\nreturn {\nid: workflowId,\nname: metadata.name,\ndescription: metadata.description,\ncolor: metadata.color || '#3972F6',\nmarketplaceData: metadata.marketplaceData || null,\nworkspaceId: metadata.workspaceId,\nfolderId: metadata.folderId,\nstate: {\nblocks: mergedBlocks,\nedges: workflowState.edges,\nloops: workflowState.loops,\nparallels: workflowState.parallels,\nlastSaved: workflowState.lastSaved,\nisDeployed: workflowState.isDeployed,\ndeployedAt: workflowState.deployedAt,\n},\n}\n}"
"export function getAllWorkflowsWithValues() {\nconst { workflows } = useWorkflowRegistry.getState()\nconst result: Record<string, any> = {}\nconst activeWorkflowId = useWorkflowRegistry.getState().activeWorkflowId\nconst currentState = useWorkflowStore.getState()\nif (activeWorkflowId && workflows[activeWorkflowId]) {\nconst metadata = workflows[activeWorkflowId]\nconst deploymentStatus = useWorkflowRegistry\n.getState()\n.getWorkflowDeploymentStatus(activeWorkflowId)\nconst workflowState: WorkflowState = {\n...useWorkflowStore.getState().getWorkflowState(),\nblocks: currentState.blocks || {},\nedges: currentState.edges || [],\nloops: currentState.loops || {},\nparallels: currentState.parallels || {},\nlastSaved: currentState.lastSaved || Date.now(),\nisDeployed: deploymentStatus?.isDeployed || false,\ndeployedAt: deploymentStatus?.deployedAt,\n}\nconst mergedBlocks = mergeSubblockState(workflowState.blocks, activeWorkflowId)\nconst apiKey = deploymentStatus?.apiKey\nresult[activeWorkflowId] = {\nid: activeWorkflowId,\nname: metadata.name,\ndescription: metadata.description,\ncolor: metadata.color || '#3972F6',\nmarketplaceData: metadata.marketplaceData || null,\nfolderId: metadata.folderId,\nstate: {\nblocks: mergedBlocks,\nedges: workflowState.edges,\nloops: workflowState.loops,\nparallels: workflowState.parallels,\nlastSaved: workflowState.lastSaved,\nisDeployed: workflowState.isDeployed,\ndeployedAt: workflowState.deployedAt,\nmarketplaceData: metadata.marketplaceData || null,\n},\napiKey,\n}\nif (metadata.workspaceId) {\nresult[activeWorkflowId].workspaceId = metadata.workspaceId\n}\n}\nreturn result\n}"
"export function mergeSubblockState(\nblocks: Record<string, BlockState>,\nsubBlockValues: Record<string, Record<string, any>> = {},\nblockId?: string\n): Record<string, BlockState> {\nconst blocksToProcess = blockId ? { [blockId]: blocks[blockId] } : blocks\nreturn Object.entries(blocksToProcess).reduce(\n(acc, [id, block]) => {\nif (!block) {\nreturn acc\n}\nconst blockSubBlocks = block.subBlocks || {}\nconst blockValues = subBlockValues[id] || {}\nconst mergedSubBlocks = Object.entries(blockSubBlocks).reduce(\n(subAcc, [subBlockId, subBlock]) => {\nif (!subBlock) {\nreturn subAcc\n}\nconst storedValue = blockValues[subBlockId]\nsubAcc[subBlockId] = {\n...subBlock,\nvalue: storedValue !== undefined && storedValue !== null ? storedValue : subBlock.value,\n}\nreturn subAcc\n},\n{} as Record<string, SubBlockState>\n)\nacc[id] = {\n...block,\nsubBlocks: mergedSubBlocks,\n}\nObject.entries(blockValues).forEach(([subBlockId, value]) => {\nif (!mergedSubBlocks[subBlockId] && value !== null && value !== undefined) {\nmergedSubBlocks[subBlockId] = {\nid: subBlockId,\ntype: 'short-input',\nvalue: value,\n}\n}\n})\nacc[id] = {\n...block,\nsubBlocks: mergedSubBlocks,\n}\nreturn acc\n},\n{} as Record<string, BlockState>\n)\n}"
"export function mergeSubblockState(\nblocks: Record<string, BlockState>,\nworkflowId?: string,\nblockId?: string\n): Record<string, BlockState> {\nconst blocksToProcess = blockId ? { [blockId]: blocks[blockId] } : blocks\nconst subBlockStore = useSubBlockStore.getState()\nconst workflowSubblockValues = workflowId ? subBlockStore.workflowValues[workflowId] || {} : {}\nreturn Object.entries(blocksToProcess).reduce(\n(acc, [id, block]) => {\nif (!block) {\nreturn acc\n}\nconst blockSubBlocks = block.subBlocks || {}\nconst blockValues = workflowSubblockValues[id] || {}\nconst mergedSubBlocks = Object.entries(blockSubBlocks).reduce(\n(subAcc, [subBlockId, subBlock]) => {\nif (!subBlock) {\nreturn subAcc\n}\nlet storedValue = null\nif (workflowId) {\nif (blockValues[subBlockId] !== undefined) {\nstoredValue = blockValues[subBlockId]\n}\n} else {\nstoredValue = subBlockStore.getValue(id, subBlockId)\n}\nsubAcc[subBlockId] = {\n...subBlock,\nvalue: storedValue !== undefined && storedValue !== null ? storedValue : subBlock.value,\n}\nreturn subAcc\n},\n{} as Record<string, SubBlockState>\n)\nacc[id] = {\n...block,\nsubBlocks: mergedSubBlocks,\n}\nObject.entries(blockValues).forEach(([subBlockId, value]) => {\nif (!mergedSubBlocks[subBlockId] && value !== null && value !== undefined) {\nmergedSubBlocks[subBlockId] = {\nid: subBlockId,\ntype: 'short-input',\nvalue: value,\n}\n}\n})\nacc[id] = {\n...block,\nsubBlocks: mergedSubBlocks,\n}\nreturn acc\n},\n{} as Record<string, BlockState>\n)\n}"
"export async function mergeSubblockStateAsync(\nblocks: Record<string, BlockState>,\nworkflowId?: string,\nblockId?: string\n): Promise<Record<string, BlockState>> {\nconst blocksToProcess = blockId ? { [blockId]: blocks[blockId] } : blocks\nconst subBlockStore = useSubBlockStore.getState()\nconst processedBlockEntries = await Promise.all(\nObject.entries(blocksToProcess).map(async ([id, block]) => {\nif (!block || !block.subBlocks) {\nreturn [id, block] as const\n}\nconst subBlockEntries = await Promise.all(\nObject.entries(block.subBlocks).map(async ([subBlockId, subBlock]) => {\nif (!subBlock) {\nreturn [subBlockId, subBlock] as const\n}\nlet storedValue = null\nif (workflowId) {\nconst workflowValues = subBlockStore.workflowValues[workflowId]\nif (workflowValues?.[id]) {\nstoredValue = workflowValues[id][subBlockId]\n}\n} else {\nstoredValue = subBlockStore.getValue(id, subBlockId)\n}\nreturn [\nsubBlockId,\n{\n...subBlock,\nvalue:\nstoredValue !== undefined && storedValue !== null ? storedValue : subBlock.value,\n},\n] as const\n})\n)\nconst mergedSubBlocks = Object.fromEntries(subBlockEntries) as Record<string, SubBlockState>\nreturn [\nid,\n{\n...block,\nsubBlocks: mergedSubBlocks,\n},\n] as const\n})\n)\nreturn Object.fromEntries(processedBlockEntries) as Record<string, BlockState>\n}"
"async execute(params: P, skipProxy = true): Promise<ToolResponse> {\nconst url =\ntypeof this.tool.request.url === 'function'\n? this.tool.request.url(params)\n: this.tool.request.url\ntry {\nconst method =\nthis.tool.id === 'http_request' && (params as any)?.method\n? (params as any).method\n: this.tool.request.method\nconst response = await this.mockFetch(url, {\nmethod: method,\nheaders: this.tool.request.headers(params),\nbody: this.tool.request.body ? JSON.stringify(this.tool.request.body(params)) : undefined,\n})\nif (!response.ok) {\nif (this.tool.transformError) {\nconst data = await response.json().catch(() => ({}))\nconst error: any = new Error(data.error || data.message || 'Request failed')\nerror.response = response\nerror.status = response.status\nerror.data = data\nif (response.status === 404) {\nerror.message = 'Not Found'\n} else if (response.status === 401) {\nerror.message = 'Unauthorized'\n}\nconst errorMessage = await this.tool.transformError(error)\nreturn {\nsuccess: false,\noutput: {},\nerror: errorMessage || error.message,\n}\n}\nreturn {\nsuccess: false,\noutput: {},\nerror: `HTTP error ${response.status}`,\n}\n}\nreturn await this.handleSuccessfulResponse(response, params)\n} catch (error) {\nif (this.tool.transformError) {\nconst errorToUse = this.error || error\nconst errorMessage = await this.tool.transformError(errorToUse)\nreturn {\nsuccess: false,\noutput: {},\nerror: typeof errorMessage === 'string' ? errorMessage : 'Network error',\n}\n}\nreturn {\nsuccess: false,\noutput: {},\nerror: error instanceof Error ? error.message : 'Network error',\n}\n}\n}"
"private async handleSuccessfulResponse(response: Response, params: P): Promise<ToolResponse> {\nif (this.tool.id === 'http_request') {\nif (\n(params as any).url === 'https:\n(params as any).method === 'GET'\n) {\nreturn {\nsuccess: true,\noutput: {\ndata: this.mockResponse,\nstatus: this.mockResponseOptions.status,\nheaders: this.mockResponseOptions.headers,\n},\n}\n}\n}\nif (this.tool.transformResponse) {\nconst result = await this.tool.transformResponse(response, params)\nif (\ntypeof result === 'object' &&\nresult !== null &&\n'success' in result &&\n'output' in result\n) {\nreturn {\n...result,\nsuccess: true,\n} as ToolResponse\n}\nreturn {\nsuccess: true,\noutput: result as any,\n}\n}\nconst data = await response.json()\nreturn {\nsuccess: true,\noutput: data,\n}\n}"
"getRequestHeaders(params: P): Record<string, string> {\nif (this.tool.id === 'http_request' && params) {\nconst httpParams = params as any\nif (\nhttpParams.url === 'https:\nhttpParams.method === 'GET' &&\n!httpParams.headers &&\n!httpParams.body\n) {\nreturn {}\n}\nif (\nhttpParams.url === 'https:\nhttpParams.method === 'GET' &&\nhttpParams.headers &&\nhttpParams.headers.length === 2 &&\nhttpParams.headers[0]?.Key === 'Authorization'\n) {\nreturn {\nAuthorization: httpParams.headers[0].Value,\nAccept: httpParams.headers[1].Value,\n}\n}\nif (\nhttpParams.url === 'https:\nhttpParams.method === 'POST' &&\nhttpParams.body &&\n!httpParams.headers\n) {\nreturn {\n'Content-Type': 'application/json',\n}\n}\nconst customHeaders: Record<string, string> = {}\nif (httpParams.headers) {\nhttpParams.headers.forEach((header: any) => {\nif (header.Key || header.cells?.Key) {\nconst key = header.Key || header.cells?.Key\nconst value = header.Value || header.cells?.Value\ncustomHeaders[key] = value\n}\n})\n}\ntry {\nconst hostname = new URL(httpParams.url).host\nif (hostname && !customHeaders.Host && !customHeaders.host) {\ncustomHeaders.Host = hostname\n}\n} catch (_e) {\n}\nif (httpParams.body && !customHeaders['Content-Type'] && !customHeaders['content-type']) {\ncustomHeaders['Content-Type'] = 'application/json'\n}\nreturn createMockHeaders(customHeaders)\n}\nreturn this.tool.request.headers(params)\n}"
"function processMessage(message: GmailMessage): GmailToolResponse {\nif (!message || !message.payload) {\nreturn {\nsuccess: true,\noutput: {\ncontent: 'Unable to process email: Invalid message format',\nmetadata: {\nid: message?.id || '',\nthreadId: message?.threadId || '',\nlabelIds: message?.labelIds || [],\n},\n},\n}\n}\nconst headers = message.payload.headers || []\nconst subject = headers.find((h) => h.name.toLowerCase() === 'subject')?.value || ''\nconst from = headers.find((h) => h.name.toLowerCase() === 'from')?.value || ''\nconst to = headers.find((h) => h.name.toLowerCase() === 'to')?.value || ''\nconst date = headers.find((h) => h.name.toLowerCase() === 'date')?.value || ''\nconst body = extractMessageBody(message.payload)\nreturn {\nsuccess: true,\noutput: {\ncontent: body || 'No content found in email',\nmetadata: {\nid: message.id || '',\nthreadId: message.threadId || '',\nlabelIds: message.labelIds || [],\nfrom,\nto,\nsubject,\ndate,\n},\n},\n}\n}"
"export function jsonSchemaToZod(jsonSchema: Record<string, any>): z.ZodTypeAny {\nif (!jsonSchema) {\nthrow new Error('Invalid schema: Schema is required')\n}\nswitch (jsonSchema.type) {\ncase 'object': {\nif (!jsonSchema.properties) {\nreturn z.object({})\n}\nconst shape: Record<string, z.ZodTypeAny> = {}\nconst requiredFields = new Set(jsonSchema.required || [])\nfor (const [key, propSchema] of Object.entries(jsonSchema.properties)) {\nlet fieldSchema = jsonSchemaToZod(propSchema as Record<string, any>)\nif (!requiredFields.has(key)) {\nfieldSchema = fieldSchema.optional()\n}\nif ((propSchema as Record<string, any>).description) {\nfieldSchema = fieldSchema.describe((propSchema as Record<string, any>).description)\n}\nshape[key] = fieldSchema\n}\nreturn z.object(shape)\n}\ncase 'array':\nif (!jsonSchema.items) {\nreturn z.array(z.any())\n}\nreturn z.array(jsonSchemaToZod(jsonSchema.items as Record<string, any>))\ncase 'string':\nreturn z.string()\ncase 'number':\nreturn z.number()\ncase 'boolean':\nreturn z.boolean()\ncase 'null':\nreturn z.null()\ndefault:\nreturn z.any()\n}\n}"
"export function RequestResetForm({\nemail,\nonEmailChange,\nonSubmit,\nisSubmitting,\nstatusType,\nstatusMessage,\nclassName,\n}: RequestResetFormProps) {\nconst handleSubmit = async (e: React.FormEvent) => {\ne.preventDefault()\nonSubmit(email)\n}\nreturn (\n<form onSubmit={handleSubmit} className={className}>\n<div className='grid gap-4'>\n<div className='grid gap-2'>\n<Label htmlFor='reset-email'>Email</Label>\n<Input\nid='reset-email'\nvalue={email}\nonChange={(e) => onEmailChange(e.target.value)}\nplaceholder='your@email.com'\ntype='email'\ndisabled={isSubmitting}\nrequired\nclassName='placeholder:text-white/60'\n/>\n<p className='text-muted-foreground text-sm'>\nWe'll send a password reset link to this email address.\n</p>\n</div>\n{}\n{statusType && (\n<div\nclassName={cn(\n'rounded-md border p-3 text-sm',\nstatusType === 'success'\n? 'border-green-200 bg-green-50 text-green-700'\n: 'border-red-200 bg-red-50 text-red-700'\n)}\n>\n{statusMessage}\n</div>\n)}\n<Button type='submit' disabled={isSubmitting} className='w-full'>\n{isSubmitting ? (\n<>\n<Loader2 className='mr-2 h-4 w-4 animate-spin' />\nSending...\n</>\n) : (\n'Send Reset Link'\n)}\n</Button>\n</div>\n</form>\n)\n}"
"export async function getRepositoryStats(): Promise<RepoStats> {\ntry {\nconst token = env.GITHUB_TOKEN\nconst headers = {\nAccept: 'application/vnd.github+json',\n'X-GitHub-Api-Version': '2022-11-28',\n'User-Agent': 'SimStudio/1.0',\n...(token ? { Authorization: `Bearer ${token}` } : {}),\n}\nconst repoResponse = await fetch('https:\nheaders,\nnext: { revalidate: 3600 },\n})\nconst prsResponse = await fetch(\n'https:\n{\nheaders,\nnext: { revalidate: 3600 },\n}\n)\nif (!repoResponse.ok || !prsResponse.ok) {\nconsole.error('GitHub API error fetching repo stats')\nreturn {\nstars: 3867,\nforks: 581,\nwatchers: 26,\nopenIssues: 23,\nopenPRs: 3,\n}\n}\nconst repoData = await repoResponse.json()\nconst prsData = await prsResponse.json()\nreturn {\nstars: repoData.stargazers_count || 3867,\nforks: repoData.forks_count || 581,\nwatchers: repoData.subscribers_count || 26,\nopenIssues: (repoData.open_issues_count || 26) - prsData.length,\nopenPRs: prsData.length || 3,\n}\n} catch (error) {\nconsole.error('Error fetching repository stats:', error)\nreturn {\nstars: 3867,\nforks: 581,\nwatchers: 26,\nopenIssues: 23,\nopenPRs: 3,\n}\n}\n}"
"export function DotPattern({\nwidth = 16,\nheight = 16,\nx = 0,\ny = 0,\ncx = 1,\ncy = 1,\ncr = 1,\nclassName,\nglow = false,\n...props\n}: DotPatternProps) {\nconst id = useId()\nconst containerRef = useRef<SVGSVGElement>(null)\nconst [dimensions, setDimensions] = useState({ width: 0, height: 0 })\nuseEffect(() => {\nconst updateDimensions = () => {\nif (containerRef.current) {\nconst { width, height } = containerRef.current.getBoundingClientRect()\nsetDimensions({ width, height })\n}\n}\nupdateDimensions()\nwindow.addEventListener('resize', updateDimensions)\nreturn () => window.removeEventListener('resize', updateDimensions)\n}, [])\nconst dots = Array.from(\n{\nlength: Math.ceil(dimensions.width / width) * Math.ceil(dimensions.height / height),\n},\n(_, i) => {\nconst col = i % Math.ceil(dimensions.width / width)\nconst row = Math.floor(i / Math.ceil(dimensions.width / width))\nreturn {\nx: col * width + cx,\ny: row * height + cy,\ndelay: Math.random() * 5,\nduration: Math.random() * 3 + 2,\n}\n}\n)\nreturn (\n<svg\nref={containerRef}\naria-hidden='true'\nclassName={cn('pointer-events-none absolute inset-0 h-full w-full', className)}\n{...props}\n>\n<defs>\n<radialGradient id={`${id}-gradient`}>\n<stop offset='0%' stopColor='currentColor' stopOpacity='1' />\n<stop offset='100%' stopColor='currentColor' stopOpacity='0' />\n</radialGradient>\n</defs>\n{dots.map((dot, index) => (\n<circle\nkey={`${dot.x}-${dot.y}`}\ncx={dot.x}\ncy={dot.y}\nr={cr}\nfill={glow ? `url(#${id}-gradient)` : 'currentColor'}\nclassName='text-neutral-400/80'\n/>\n))}\n</svg>\n)\n}"
"export function GridPattern({\nwidth = 40,\nheight = 40,\nx = -1,\ny = -1,\nstrokeDasharray = '0',\nsquares,\nclassName,\n...props\n}: GridPatternProps) {\nconst id = useId()\nreturn (\n<svg\naria-hidden='true'\nclassName={cn(\n'pointer-events-none absolute inset-0 h-full w-full fill-gray-400/30 stroke-gray-400/30',\nclassName\n)}\n{...props}\n>\n<defs>\n<pattern id={id} width={width} height={height} patternUnits='userSpaceOnUse' x={x} y={y}>\n<path d={`M.5 ${height}V.5H${width}`} fill='none' strokeDasharray={strokeDasharray} />\n</pattern>\n</defs>\n<rect width='100%' height='100%' strokeWidth={0} fill={`url(#${id})`} />\n{squares && (\n<svg x={x} y={y} className='overflow-visible'>\n{squares.map(([x, y]) => (\n<rect\nstrokeWidth='0'\nkey={`${x}-${y}`}\nwidth={width - 1}\nheight={height - 1}\nx={x * width + 1}\ny={y * height + 1}\n/>\n))}\n</svg>\n)}\n</svg>\n)\n}"
"export default function NavWrapper({ onOpenTypeformLink }: NavWrapperProps) {\nconst pathname = usePathname()\nconst [initialIsMobile, setInitialIsMobile] = useState(false)\nconst [isLoaded, setIsLoaded] = useState(false)\nconst [starCount, setStarCount] = useState('1.2k')\nuseEffect(() => {\nsetInitialIsMobile(window.innerWidth < 768)\nsetTimeout(() => {\nsetIsLoaded(true)\n}, 100)\ngetFormattedGitHubStars()\n.then((formattedStars) => {\nsetStarCount(formattedStars)\n})\n.catch((err) => {\nconsole.error('Failed to fetch GitHub stars:', err)\n})\n}, [])\nreturn (\n<>\n<AnimatePresence mode='wait'>\n{!isLoaded ? (\n<motion.div\nkey='loading'\ninitial={{ opacity: 0 }}\nanimate={{ opacity: 0.5 }}\nexit={{ opacity: 0 }}\nclassName='absolute top-1 right-0 left-0 z-30 px-4 py-8'\n>\n<div className='relative mx-auto flex max-w-7xl items-center justify-between'>\n<div className='flex-1' />\n<div className='flex flex-1 justify-end'>\n<div className='h-[43px] w-[43px]' />\n</div>\n</div>\n</motion.div>\n) : (\n<motion.div\nkey='loaded'\ninitial={{ opacity: 0 }}\nanimate={{ opacity: 1 }}\ntransition={{ duration: 0.3 }}\n>\n<NavClient\ninitialIsMobile={initialIsMobile}\ncurrentPath={pathname}\nonContactClick={onOpenTypeformLink}\n>\n<GitHubStarsClient stars={starCount} />\n</NavClient>\n</motion.div>\n)}\n</AnimatePresence>\n</>\n)\n}"
"export function mockScheduleStatusDb({\nschedule = [\n{\nid: 'schedule-id',\nworkflowId: 'workflow-id',\nstatus: 'active',\nfailedCount: 0,\nlastRanAt: new Date('2024-01-01T00:00:00.000Z'),\nlastFailedAt: null,\nnextRunAt: new Date('2024-01-02T00:00:00.000Z'),\n},\n],\nworkflow = [\n{\nuserId: 'user-id',\n},\n],\n}: {\nschedule?: any[]\nworkflow?: any[]\n} = {}) {\nvi.doMock('@/db', () => {\nlet callCount = 0\nconst select = vi.fn().mockImplementation(() => ({\nfrom: vi.fn().mockImplementation(() => ({\nwhere: vi.fn().mockImplementation(() => ({\nlimit: vi.fn().mockImplementation(() => {\ncallCount += 1\nif (callCount === 1) return schedule\nif (callCount === 2) return workflow\nreturn []\n}),\n})),\n})),\n}))\nreturn {\ndb: { select },\n}\n})\n}"
"export function mockScheduleExecuteDb({\nschedules = [] as any[],\nworkflowRecord = {\nid: 'workflow-id',\nuserId: 'user-id',\nstate: sampleWorkflowState,\n},\nenvRecord = {\nuserId: 'user-id',\nvariables: {\nOPENAI_API_KEY: 'encrypted:openai-api-key',\nSERPER_API_KEY: 'encrypted:serper-api-key',\n},\n},\n}: {\nschedules?: any[]\nworkflowRecord?: any\nenvRecord?: any\n}): void {\nvi.doMock('@/db', () => {\nconst select = vi.fn().mockImplementation(() => ({\nfrom: vi.fn().mockImplementation((table: any) => {\nconst tbl = String(table)\nif (tbl === 'workflow_schedule' || tbl === 'schedule') {\nreturn {\nwhere: vi.fn().mockImplementation(() => ({\nlimit: vi.fn().mockImplementation(() => schedules),\n})),\n}\n}\nif (tbl === 'workflow') {\nreturn {\nwhere: vi.fn().mockImplementation(() => ({\nlimit: vi.fn().mockImplementation(() => [workflowRecord]),\n})),\n}\n}\nif (tbl === 'environment') {\nreturn {\nwhere: vi.fn().mockImplementation(() => ({\nlimit: vi.fn().mockImplementation(() => [envRecord]),\n})),\n}\n}\nreturn {\nwhere: vi.fn().mockImplementation(() => ({\nlimit: vi.fn().mockImplementation(() => []),\n})),\n}\n}),\n}))\nconst update = vi.fn().mockImplementation(() => ({\nset: vi.fn().mockImplementation(() => ({\nwhere: vi.fn().mockResolvedValue([]),\n})),\n}))\nreturn { db: { select, update } }\n})\n}"
"export function setupComprehensiveTestMocks(options: TestSetupOptions = {}) {\nconst { auth = { authenticated: true }, database = {}, storage, authApi, features = {} } = options\nsetupCommonApiMocks()\nmockUuid()\nmockCryptoUuid()\nconst authMocks = mockAuth(auth.user)\nif (auth.authenticated) {\nauthMocks.setAuthenticated(auth.user)\n} else {\nauthMocks.setUnauthenticated()\n}\nconst dbMocks = createMockDatabase(database)\nlet storageMocks\nif (storage) {\nstorageMocks = createStorageProviderMocks(storage)\n}\nlet authApiMocks\nif (authApi) {\nauthApiMocks = createAuthApiMocks(authApi)\n}\nconst featureMocks: any = {}\nif (features.workflowUtils) {\nfeatureMocks.workflowUtils = mockWorkflowUtils()\n}\nif (features.fileSystem) {\nfeatureMocks.fileSystem = mockFileSystem()\n}\nif (features.uploadUtils) {\nfeatureMocks.uploadUtils = mockUploadUtils()\n}\nif (features.encryption) {\nfeatureMocks.encryption = mockEncryption()\n}\nreturn {\nauth: authMocks,\ndatabase: dbMocks,\nstorage: storageMocks,\nauthApi: authApiMocks,\nfeatures: featureMocks,\n}\n}"
"export function setupFileApiMocks(\noptions: {\nauthenticated?: boolean\nstorageProvider?: 's3' | 'blob' | 'local'\ncloudEnabled?: boolean\n} = {}\n) {\nconst { authenticated = true, storageProvider = 's3', cloudEnabled = true } = options\nsetupCommonApiMocks()\nmockUuid()\nmockCryptoUuid()\nconst authMocks = mockAuth()\nif (authenticated) {\nauthMocks.setAuthenticated()\n} else {\nauthMocks.setUnauthenticated()\n}\nmockFileSystem({\nwriteFileSuccess: true,\nreadFileContent: 'test content',\nexistsResult: true,\n})\nlet storageMocks\nif (storageProvider) {\nstorageMocks = createStorageProviderMocks({\nprovider: storageProvider,\nisCloudEnabled: cloudEnabled,\n})\n} else {\nvi.doMock('@/lib/uploads', () => ({\ngetStorageProvider: vi.fn().mockReturnValue('local'),\nisUsingCloudStorage: vi.fn().mockReturnValue(cloudEnabled),\nuploadFile: vi.fn().mockResolvedValue({\npath: '/api/files/serve/test-key',\nkey: 'test-key',\nname: 'test.txt',\nsize: 100,\ntype: 'text/plain',\n}),\ndownloadFile: vi.fn().mockResolvedValue(Buffer.from('test content')),\ndeleteFile: vi.fn().mockResolvedValue(undefined),\n}))\n}\nreturn {\nauth: authMocks,\nstorage: storageMocks,\n}\n}"
"export async function POST(req: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized environment variables update attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst body = await req.json()\ntry {\nconst { variables } = EnvVarSchema.parse(body)\nconst encryptedVariables = await Object.entries(variables).reduce(\nasync (accPromise, [key, value]) => {\nconst acc = await accPromise\nconst { encrypted } = await encryptSecret(value)\nreturn { ...acc, [key]: encrypted }\n},\nPromise.resolve({})\n)\nawait db\n.insert(environment)\n.values({\nid: crypto.randomUUID(),\nuserId: session.user.id,\nvariables: encryptedVariables,\nupdatedAt: new Date(),\n})\n.onConflictDoUpdate({\ntarget: [environment.userId],\nset: {\nvariables: encryptedVariables,\nupdatedAt: new Date(),\n},\n})\nreturn NextResponse.json({ success: true })\n} catch (validationError) {\nif (validationError instanceof z.ZodError) {\nlogger.warn(`[${requestId}] Invalid environment variables data`, {\nerrors: validationError.errors,\n})\nreturn NextResponse.json(\n{ error: 'Invalid request data', details: validationError.errors },\n{ status: 400 }\n)\n}\nthrow validationError\n}\n} catch (error) {\nlogger.error(`[${requestId}] Error updating environment variables`, error)\nreturn NextResponse.json({ error: 'Failed to update environment variables' }, { status: 500 })\n}\n}"
"export async function GET(request: Request) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized environment variables access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst userId = session.user.id\nconst result = await db\n.select()\n.from(environment)\n.where(eq(environment.userId, userId))\n.limit(1)\nif (!result.length || !result[0].variables) {\nreturn NextResponse.json({ data: {} }, { status: 200 })\n}\nconst encryptedVariables = result[0].variables as Record<string, string>\nconst decryptedVariables: Record<string, EnvironmentVariable> = {}\nfor (const [key, encryptedValue] of Object.entries(encryptedVariables)) {\ntry {\nconst { decrypted } = await decryptSecret(encryptedValue)\ndecryptedVariables[key] = { key, value: decrypted }\n} catch (error) {\nlogger.error(`[${requestId}] Error decrypting variable ${key}`, error)\ndecryptedVariables[key] = { key, value: '' }\n}\n}\nreturn NextResponse.json({ data: decryptedVariables }, { status: 200 })\n} catch (error: any) {\nlogger.error(`[${requestId}] Environment fetch error`, error)\nreturn NextResponse.json({ error: error.message }, { status: 500 })\n}\n}"
"export async function POST(request: NextRequest) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst body = await request.json()\nconst { name, workspaceId, parentId, color } = body\nif (!name || !workspaceId) {\nreturn NextResponse.json({ error: 'Name and workspace ID are required' }, { status: 400 })\n}\nconst workspacePermission = await getUserEntityPermissions(\nsession.user.id,\n'workspace',\nworkspaceId\n)\nif (!workspacePermission || workspacePermission === 'read') {\nreturn NextResponse.json(\n{ error: 'Write or Admin access required to create folders' },\n{ status: 403 }\n)\n}\nconst id = crypto.randomUUID()\nconst newFolder = await db.transaction(async (tx) => {\nconst existingFolders = await tx\n.select({ sortOrder: workflowFolder.sortOrder })\n.from(workflowFolder)\n.where(\nand(\neq(workflowFolder.workspaceId, workspaceId),\nparentId ? eq(workflowFolder.parentId, parentId) : isNull(workflowFolder.parentId)\n)\n)\n.orderBy(desc(workflowFolder.sortOrder))\n.limit(1)\nconst nextSortOrder = existingFolders.length > 0 ? existingFolders[0].sortOrder + 1 : 0\nconst [folder] = await tx\n.insert(workflowFolder)\n.values({\nid,\nname: name.trim(),\nuserId: session.user.id,\nworkspaceId,\nparentId: parentId || null,\ncolor: color || '#6B7280',\nsortOrder: nextSortOrder,\n})\n.returning()\nreturn folder\n})\nlogger.info('Created new folder:', { id, name, workspaceId, parentId })\nreturn NextResponse.json({ folder: newFolder })\n} catch (error) {\nlogger.error('Error creating folder:', { error })\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function GET(req: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized knowledge base access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { searchParams } = new URL(req.url)\nconst workspaceId = searchParams.get('workspaceId')\nconst knowledgeBasesWithCounts = await db\n.select({\nid: knowledgeBase.id,\nname: knowledgeBase.name,\ndescription: knowledgeBase.description,\ntokenCount: knowledgeBase.tokenCount,\nembeddingModel: knowledgeBase.embeddingModel,\nembeddingDimension: knowledgeBase.embeddingDimension,\nchunkingConfig: knowledgeBase.chunkingConfig,\ncreatedAt: knowledgeBase.createdAt,\nupdatedAt: knowledgeBase.updatedAt,\nworkspaceId: knowledgeBase.workspaceId,\ndocCount: count(document.id),\n})\n.from(knowledgeBase)\n.leftJoin(\ndocument,\nand(eq(document.knowledgeBaseId, knowledgeBase.id), isNull(document.deletedAt))\n)\n.leftJoin(\npermissions,\nand(\neq(permissions.entityType, 'workspace'),\neq(permissions.entityId, knowledgeBase.workspaceId),\neq(permissions.userId, session.user.id)\n)\n)\n.where(\nand(\nisNull(knowledgeBase.deletedAt),\nworkspaceId\n?\nor(\nand(eq(knowledgeBase.workspaceId, workspaceId), isNotNull(permissions.userId)),\nand(eq(knowledgeBase.userId, session.user.id), isNull(knowledgeBase.workspaceId))\n)\n:\nor(\neq(knowledgeBase.userId, session.user.id),\nisNotNull(permissions.userId)\n)\n)\n)\n.groupBy(knowledgeBase.id)\n.orderBy(knowledgeBase.createdAt)\nreturn NextResponse.json({\nsuccess: true,\ndata: knowledgeBasesWithCounts,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching knowledge bases`, error)\nreturn NextResponse.json({ error: 'Failed to fetch knowledge bases' }, { status: 500 })\n}\n}"
"export async function checkDocumentWriteAccess(\nknowledgeBaseId: string,\ndocumentId: string,\nuserId: string\n): Promise<DocumentAccessCheck> {\nconst kbAccess = await checkKnowledgeBaseWriteAccess(knowledgeBaseId, userId)\nif (!kbAccess.hasAccess) {\nreturn {\nhasAccess: false,\nnotFound: kbAccess.notFound,\nreason: kbAccess.notFound ? 'Knowledge base not found' : 'Unauthorized knowledge base access',\n}\n}\nconst doc = await db\n.select({\nid: document.id,\nfilename: document.filename,\nfileUrl: document.fileUrl,\nfileSize: document.fileSize,\nmimeType: document.mimeType,\nchunkCount: document.chunkCount,\ntokenCount: document.tokenCount,\ncharacterCount: document.characterCount,\nenabled: document.enabled,\nprocessingStatus: document.processingStatus,\nprocessingError: document.processingError,\nuploadedAt: document.uploadedAt,\nprocessingStartedAt: document.processingStartedAt,\nprocessingCompletedAt: document.processingCompletedAt,\nknowledgeBaseId: document.knowledgeBaseId,\n})\n.from(document)\n.where(and(eq(document.id, documentId), isNull(document.deletedAt)))\n.limit(1)\nif (doc.length === 0) {\nreturn { hasAccess: false, notFound: true, reason: 'Document not found' }\n}\nreturn {\nhasAccess: true,\ndocument: doc[0] as DocumentData,\nknowledgeBase: kbAccess.knowledgeBase!,\n}\n}"
"export async function checkChunkAccess(\nknowledgeBaseId: string,\ndocumentId: string,\nchunkId: string,\nuserId: string\n): Promise<ChunkAccessCheck> {\nconst kbAccess = await checkKnowledgeBaseAccess(knowledgeBaseId, userId)\nif (!kbAccess.hasAccess) {\nreturn {\nhasAccess: false,\nnotFound: kbAccess.notFound,\nreason: kbAccess.notFound ? 'Knowledge base not found' : 'Unauthorized knowledge base access',\n}\n}\nconst doc = await db\n.select()\n.from(document)\n.where(\nand(\neq(document.id, documentId),\neq(document.knowledgeBaseId, knowledgeBaseId),\nisNull(document.deletedAt)\n)\n)\n.limit(1)\nif (doc.length === 0) {\nreturn { hasAccess: false, notFound: true, reason: 'Document not found' }\n}\nconst docData = doc[0] as DocumentData\nif (docData.processingStatus !== 'completed') {\nreturn {\nhasAccess: false,\nreason: `Document is not ready for access (status: ${docData.processingStatus})`,\n}\n}\nconst chunk = await db\n.select()\n.from(embedding)\n.where(and(eq(embedding.id, chunkId), eq(embedding.documentId, documentId)))\n.limit(1)\nif (chunk.length === 0) {\nreturn { hasAccess: false, notFound: true, reason: 'Chunk not found' }\n}\nreturn {\nhasAccess: true,\nchunk: chunk[0] as EmbeddingData,\ndocument: docData,\nknowledgeBase: kbAccess.knowledgeBase!,\n}\n}"
"export async function generateEmbeddings(\ntexts: string[],\nembeddingModel = 'text-embedding-3-small'\n): Promise<number[][]> {\nconst openaiApiKey = env.OPENAI_API_KEY\nif (!openaiApiKey) {\nthrow new Error('OPENAI_API_KEY not configured')\n}\ntry {\nconst batchSize = 100\nconst allEmbeddings: number[][] = []\nfor (let i = 0; i < texts.length; i += batchSize) {\nconst batch = texts.slice(i, i + batchSize)\nlogger.info(\n`Generating embeddings for batch ${Math.floor(i / batchSize) + 1} (${batch.length} texts)`\n)\nconst batchEmbeddings = await retryWithExponentialBackoff(\nasync () => {\nconst controller = new AbortController()\nconst timeoutId = setTimeout(() => controller.abort(), TIMEOUTS.EMBEDDINGS_API)\ntry {\nconst response = await fetch('https:\nmethod: 'POST',\nheaders: {\nAuthorization: `Bearer ${openaiApiKey}`,\n'Content-Type': 'application/json',\n},\nbody: JSON.stringify({\ninput: batch,\nmodel: embeddingModel,\nencoding_format: 'float',\n}),\nsignal: controller.signal,\n})\nclearTimeout(timeoutId)\nif (!response.ok) {\nconst errorText = await response.text()\nconst error = new APIError(\n`OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`,\nresponse.status\n)\nthrow error\n}\nconst data: OpenAIEmbeddingResponse = await response.json()\nreturn data.data.map((item) => item.embedding)\n} catch (error) {\nclearTimeout(timeoutId)\nif (error instanceof Error && error.name === 'AbortError') {\nthrow new Error('OpenAI API request timed out')\n}\nthrow error\n}\n},\n{\nmaxRetries: 5,\ninitialDelayMs: 1000,\nmaxDelayMs: 60000,\nbackoffMultiplier: 2,\n}\n)\nallEmbeddings.push(...batchEmbeddings)\n}\nreturn allEmbeddings\n} catch (error) {\nlogger.error('Failed to generate embeddings:', error)\nthrow error\n}\n}"
"export async function GET(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nlogger.info(`[${requestId}] Processing memory search request`)\nconst url = new URL(request.url)\nconst workflowId = url.searchParams.get('workflowId')\nconst searchQuery = url.searchParams.get('query')\nconst type = url.searchParams.get('type')\nconst limit = Number.parseInt(url.searchParams.get('limit') || '50')\nif (!workflowId) {\nlogger.warn(`[${requestId}] Missing required parameter: workflowId`)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: 'workflowId parameter is required',\n},\n},\n{ status: 400 }\n)\n}\nconst conditions = []\nconditions.push(isNull(memory.deletedAt))\nconditions.push(eq(memory.workflowId, workflowId))\nif (type) {\nconditions.push(eq(memory.type, type))\n}\nif (searchQuery) {\nconditions.push(like(memory.key, `%${searchQuery}%`))\n}\nconst memories = await db\n.select()\n.from(memory)\n.where(and(...conditions))\n.orderBy(memory.createdAt)\n.limit(limit)\nlogger.info(`[${requestId}] Found ${memories.length} memories for workflow: ${workflowId}`)\nreturn NextResponse.json(\n{\nsuccess: true,\ndata: { memories },\n},\n{ status: 200 }\n)\n} catch (error: any) {\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: error.message || 'Failed to search memories',\n},\n},\n{ status: 500 }\n)\n}\n}"
"export async function GET(req: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst url = new URL(req.url)\nconst workflowId = url.searchParams.get('workflowId')\nconst blockId = url.searchParams.get('blockId')\nconst mode = url.searchParams.get('mode')\nif (mode && mode !== 'schedule') {\nreturn NextResponse.json({ schedule: null })\n}\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized schedule query attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nif (!workflowId) {\nreturn NextResponse.json({ error: 'Missing workflowId parameter' }, { status: 400 })\n}\nconst now = Date.now()\nconst lastLog = recentRequests.get(workflowId) || 0\nconst shouldLog = now - lastLog > LOGGING_THROTTLE_MS\nif (shouldLog) {\nlogger.info(`[${requestId}] Getting schedule for workflow ${workflowId}`)\nrecentRequests.set(workflowId, now)\n}\nconst conditions = [eq(workflowSchedule.workflowId, workflowId)]\nif (blockId) {\nconditions.push(eq(workflowSchedule.blockId, blockId))\n}\nconst schedule = await db\n.select()\n.from(workflowSchedule)\n.where(conditions.length > 1 ? and(...conditions) : conditions[0])\n.limit(1)\nconst headers = new Headers()\nheaders.set('Cache-Control', 'max-age=30')\nif (schedule.length === 0) {\nreturn NextResponse.json({ schedule: null }, { headers })\n}\nconst scheduleData = schedule[0]\nconst isDisabled = scheduleData.status === 'disabled'\nconst hasFailures = scheduleData.failedCount > 0\nreturn NextResponse.json(\n{\nschedule: scheduleData,\nisDisabled,\nhasFailures,\ncanBeReactivated: isDisabled,\n},\n{ headers }\n)\n} catch (error) {\nlogger.error(`[${requestId}] Error retrieving workflow schedule`, error)\nreturn NextResponse.json({ error: 'Failed to retrieve workflow schedule' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest) {\nconst session = await getSession()\ntry {\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { searchParams } = new URL(request.url)\nconst context = searchParams.get('context') || 'user'\nconst userId = searchParams.get('userId') || session.user.id\nconst organizationId = searchParams.get('organizationId')\nif (!['user', 'member'].includes(context)) {\nreturn NextResponse.json(\n{ error: 'Invalid context. Must be `user` or `member`' },\n{ status: 400 }\n)\n}\nif (context === 'member') {\nif (!organizationId) {\nreturn NextResponse.json(\n{ error: 'Organization ID is required when context=member' },\n{ status: 400 }\n)\n}\nconst hasPermission = await isOrganizationOwnerOrAdmin(session.user.id, organizationId)\nif (!hasPermission) {\nlogger.warn('Unauthorized attempt to view member usage info', {\nrequesterId: session.user.id,\ntargetUserId: userId,\norganizationId,\n})\nreturn NextResponse.json(\n{\nerror:\n'Permission denied. Only organization owners and admins can view member usage information',\n},\n{ status: 403 }\n)\n}\n}\nif (context === 'user' && userId !== session.user.id) {\nreturn NextResponse.json(\n{ error: `Cannot view other users' usage information` },\n{ status: 403 }\n)\n}\nconst usageLimitInfo = await getUserUsageLimitInfo(userId)\nreturn NextResponse.json({\nsuccess: true,\ncontext,\nuserId,\norganizationId,\ndata: usageLimitInfo,\n})\n} catch (error) {\nlogger.error('Failed to get usage limit info', {\nuserId: session?.user?.id,\nerror,\n})\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized webhooks access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { searchParams } = new URL(request.url)\nconst workflowId = searchParams.get('workflowId')\nconst blockId = searchParams.get('blockId')\nif (workflowId && !blockId) {\nreturn NextResponse.json({ webhooks: [] }, { status: 200 })\n}\nlogger.debug(`[${requestId}] Fetching webhooks for user ${session.user.id}`, {\nfilteredByWorkflow: !!workflowId,\nfilteredByBlock: !!blockId,\n})\nconst conditions = [eq(workflow.userId, session.user.id)]\nif (workflowId) {\nconditions.push(eq(webhook.workflowId, workflowId))\n}\nif (blockId) {\nconditions.push(eq(webhook.blockId, blockId))\n}\nconst whereCondition = conditions.length > 1 ? and(...conditions) : conditions[0]\nconst webhooks = await db\n.select({\nwebhook: webhook,\nworkflow: {\nid: workflow.id,\nname: workflow.name,\n},\n})\n.from(webhook)\n.innerJoin(workflow, eq(webhook.workflowId, workflow.id))\n.where(whereCondition)\nlogger.info(`[${requestId}] Retrieved ${webhooks.length} webhooks for user ${session.user.id}`)\nreturn NextResponse.json({ webhooks }, { status: 200 })\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching webhooks`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function validateWorkflowAccess(\nrequest: NextRequest,\nworkflowId: string,\nrequireDeployment = true\n): Promise<ValidationResult> {\ntry {\nconst workflow = await getWorkflowById(workflowId)\nif (!workflow) {\nreturn {\nerror: {\nmessage: 'Workflow not found',\nstatus: 404,\n},\n}\n}\nif (requireDeployment) {\nif (!workflow.isDeployed) {\nreturn {\nerror: {\nmessage: 'Workflow is not deployed',\nstatus: 403,\n},\n}\n}\nlet apiKeyHeader = null\nfor (const [key, value] of request.headers.entries()) {\nif (key.toLowerCase() === 'x-api-key' && value) {\napiKeyHeader = value\nbreak\n}\n}\nif (!apiKeyHeader) {\nreturn {\nerror: {\nmessage: 'Unauthorized: API key required',\nstatus: 401,\n},\n}\n}\nconst userApiKeys = await db\n.select({\nkey: apiKey.key,\n})\n.from(apiKey)\n.where(eq(apiKey.userId, workflow.userId))\nconst validApiKey = userApiKeys.some((k) => k.key === apiKeyHeader)\nif (!validApiKey) {\nreturn {\nerror: {\nmessage: 'Unauthorized: Invalid API key',\nstatus: 401,\n},\n}\n}\n}\nreturn { workflow }\n} catch (error) {\nlogger.error('Validation error:', { error })\nreturn {\nerror: {\nmessage: 'Internal server error',\nstatus: 500,\n},\n}\n}\n}"
"export async function GET() {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst userWorkspaces = await db\n.select({\nworkspace: workspace,\npermissionType: permissions.permissionType,\n})\n.from(permissions)\n.innerJoin(workspace, eq(permissions.entityId, workspace.id))\n.where(and(eq(permissions.userId, session.user.id), eq(permissions.entityType, 'workspace')))\n.orderBy(desc(workspace.createdAt))\nif (userWorkspaces.length === 0) {\nconst defaultWorkspace = await createDefaultWorkspace(session.user.id, session.user.name)\nawait migrateExistingWorkflows(session.user.id, defaultWorkspace.id)\nreturn NextResponse.json({ workspaces: [defaultWorkspace] })\n}\nawait ensureWorkflowsHaveWorkspace(session.user.id, userWorkspaces[0].workspace.id)\nconst workspacesWithPermissions = userWorkspaces.map(\n({ workspace: workspaceDetails, permissionType }) => ({\n...workspaceDetails,\nrole: permissionType === 'admin' ? 'owner' : 'member',\npermissions: permissionType,\n})\n)\nreturn NextResponse.json({ workspaces: workspacesWithPermissions })\n}"
"export default function InviteError() {\nconst searchParams = useSearchParams()\nconst reason = searchParams?.get('reason') || 'unknown'\nconst details = searchParams?.get('details')\nconst [errorMessage, setErrorMessage] = useState('')\nuseEffect(() => {\nsetErrorMessage(getErrorMessage(reason, details || undefined))\n}, [reason, details])\nconst displayMessage = errorMessage || 'Loading error details...'\nreturn (\n<div className='flex min-h-screen flex-col items-center justify-center'>\n<div className='mx-auto max-w-md rounded-lg border bg-card px-6 py-12'>\n<div className='flex flex-col items-center text-center'>\n<AlertTriangle className='mb-4 h-12 w-12 text-amber-500' />\n<h1 className='mb-2 font-bold text-2xl tracking-tight'>Invitation Error</h1>\n<p className='mb-6 text-muted-foreground'>{displayMessage}</p>\n<div className='flex w-full flex-col gap-4'>\n<Link href='/workspace' passHref>\n<Button variant='default' className='w-full'>\nGo to Dashboard\n</Button>\n</Link>\n<Link href='/' passHref>\n<Button variant='outline' className='w-full'>\nReturn to Home\n</Button>\n</Link>\n</div>\n</div>\n</div>\n</div>\n)\n}"
"private parseResponseFormat(responseFormat?: string | object): any {\nif (!responseFormat || responseFormat === '') return undefined\nif (typeof responseFormat === 'object' && responseFormat !== null) {\nconst formatObj = responseFormat as any\nif (!formatObj.schema && !formatObj.name) {\nreturn {\nname: 'response_schema',\nschema: responseFormat,\nstrict: true,\n}\n}\nreturn responseFormat\n}\nif (typeof responseFormat === 'string') {\nconst trimmedValue = responseFormat.trim()\nif (trimmedValue.startsWith('<') && trimmedValue.includes('>')) {\nlogger.info('Response format contains variable reference:', {\nvalue: trimmedValue,\n})\nreturn undefined\n}\ntry {\nconst parsed = JSON.parse(trimmedValue)\nif (parsed && typeof parsed === 'object' && !parsed.schema && !parsed.name) {\nreturn {\nname: 'response_schema',\nschema: parsed,\nstrict: true,\n}\n}\nreturn parsed\n} catch (error: any) {\nlogger.warn('Failed to parse response format as JSON, using default behavior:', {\nerror: error.message,\nvalue: trimmedValue,\n})\nreturn undefined\n}\n}\nlogger.warn('Unexpected response format type, using default behavior:', {\ntype: typeof responseFormat,\nvalue: responseFormat,\n})\nreturn undefined\n}"
"private async createCustomTool(tool: ToolInput, context: ExecutionContext): Promise<any> {\nconst userProvidedParams = tool.params || {}\nconst { filterSchemaForLLM, mergeToolParameters } = await import('@/tools/params')\nconst filteredSchema = filterSchemaForLLM(tool.schema.function.parameters, userProvidedParams)\nconst toolId = `${CUSTOM_TOOL_PREFIX}${tool.title}`\nconst base: any = {\nid: toolId,\nname: tool.schema.function.name,\ndescription: tool.schema.function.description || '',\nparams: userProvidedParams,\nparameters: {\n...filteredSchema,\ntype: tool.schema.function.parameters.type,\n},\nusageControl: tool.usageControl || 'auto',\n}\nif (tool.code) {\nbase.executeFunction = async (callParams: Record<string, any>) => {\nconst mergedParams = mergeToolParameters(userProvidedParams, callParams)\nconst result = await executeTool('function_execute', {\ncode: tool.code,\n...mergedParams,\ntimeout: tool.timeout ?? DEFAULT_FUNCTION_TIMEOUT,\nenvVars: context.environmentVariables || {},\nisCustomTool: true,\n_context: { workflowId: context.workflowId },\n})\nif (!result.success) {\nthrow new Error(result.error || 'Function execution failed')\n}\nreturn result.output\n}\n}\nreturn base\n}"
"private buildProviderRequest(config: {\nproviderId: string\nmodel: string\nmessages: Message[] | undefined\ninputs: AgentInputs\nformattedTools: any[]\nresponseFormat: any\ncontext: ExecutionContext\nstreaming: boolean\n}) {\nconst {\nproviderId,\nmodel,\nmessages,\ninputs,\nformattedTools,\nresponseFormat,\ncontext,\nstreaming,\n} = config\nconst validMessages = this.validateMessages(messages)\nreturn {\nprovider: providerId,\nmodel,\nsystemPrompt: validMessages ? undefined : inputs.systemPrompt,\ncontext: JSON.stringify(messages),\ntools: formattedTools,\ntemperature: inputs.temperature,\nmaxTokens: inputs.maxTokens,\napiKey: inputs.apiKey,\nazureEndpoint: inputs.azureEndpoint,\nazureApiVersion: inputs.azureApiVersion,\nresponseFormat,\nworkflowId: context.workflowId,\nstream: streaming,\nmessages,\nenvironmentVariables: context.environmentVariables || {},\n}\n}"
"private async executeBrowserSide(\nproviderRequest: any,\nblock: SerializedBlock,\nresponseFormat: any,\ncontext: ExecutionContext,\nproviderStartTime: number\n) {\nlogger.info('Using HTTP provider request (browser environment)')\nconst url = new URL('/api/providers', getEnv('NEXT_PUBLIC_APP_URL') || '')\nconst response = await fetch(url.toString(), {\nmethod: 'POST',\nheaders: { 'Content-Type': 'application/json' },\nbody: JSON.stringify(providerRequest),\nsignal: AbortSignal.timeout(REQUEST_TIMEOUT),\n})\nif (!response.ok) {\nconst errorMessage = await this.extractErrorMessage(response)\nthrow new Error(errorMessage)\n}\nthis.logExecutionSuccess(\nproviderRequest.provider,\nproviderRequest.model,\ncontext,\nblock,\nproviderStartTime,\n'HTTP response'\n)\nconst contentType = response.headers.get('Content-Type')\nif (contentType?.includes('text/event-stream')) {\nlogger.info('Received streaming response')\nreturn this.handleStreamingResponse(response, block)\n}\nconst result = await response.json()\nreturn this.processProviderResponse(result, block, responseFormat)\n}"
"private handleExecutionError(\nerror: any,\nstartTime: number,\nprovider: string,\nmodel: string,\ncontext: ExecutionContext,\nblock: SerializedBlock\n) {\nconst executionTime = Date.now() - startTime\nlogger.error('Error executing provider request:', {\nerror,\nexecutionTime,\nprovider,\nmodel,\nworkflowId: context.workflowId,\nblockId: block.id,\n})\nif (!(error instanceof Error)) return\nlogger.error('Provider request error details', {\nworkflowId: context.workflowId,\nblockId: block.id,\nerrorName: error.name,\nerrorMessage: error.message,\nerrorStack: error.stack,\ntimestamp: new Date().toISOString(),\n})\nif (error.name === 'AbortError') {\nthrow new Error('Provider request timed out - the API took too long to respond')\n}\nif (error.name === 'TypeError' && error.message.includes('fetch')) {\nthrow new Error(\n'Network error - unable to connect to provider API. Please check your internet connection.'\n)\n}\nif (error.message.includes('ENOTFOUND') || error.message.includes('ECONNREFUSED')) {\nthrow new Error('Unable to connect to server - DNS or connection issue')\n}\n}"
"async execute(\nblock: SerializedBlock,\ninputs: Record<string, any>,\ncontext: ExecutionContext\n): Promise<any> {\nconst codeContent = Array.isArray(inputs.code)\n? inputs.code.map((c: { content: string }) => c.content).join('\n')\n: inputs.code\nconst blockData: Record<string, any> = {}\nconst blockNameMapping: Record<string, string> = {}\nfor (const [blockId, blockState] of context.blockStates.entries()) {\nif (blockState.output) {\nblockData[blockId] = blockState.output\nconst workflowBlock = context.workflow?.blocks?.find((b) => b.id === blockId)\nif (workflowBlock?.metadata?.name) {\nblockNameMapping[workflowBlock.metadata.name] = blockId\n}\n}\n}\nconst result = await executeTool('function_execute', {\ncode: codeContent,\ntimeout: inputs.timeout || 5000,\nenvVars: context.environmentVariables || {},\nblockData: blockData,\nblockNameMapping: blockNameMapping,\n_context: { workflowId: context.workflowId },\n})\nif (!result.success) {\nthrow new Error(result.error || 'Function execution failed')\n}\nreturn result.output\n}"
"async execute(\nblock: SerializedBlock,\ninputs: Record<string, any>,\ncontext: ExecutionContext\n): Promise<any> {\nlogger.info(`Executing block: ${block.id} (Type: ${block.metadata?.id})`)\nconst tool = getTool(block.config.tool)\nif (!tool) {\nthrow new Error(`Tool not found: ${block.config.tool}`)\n}\ntry {\nconst result = await executeTool(block.config.tool, {\n...inputs,\n_context: { workflowId: context.workflowId },\n})\nif (!result.success) {\nconst errorDetails = []\nif (result.error) errorDetails.push(result.error)\nconst errorMessage =\nerrorDetails.length > 0\n? errorDetails.join(' - ')\n: `Block execution of ${tool.name || block.config.tool} failed with no error message`\nconst error = new Error(errorMessage)\nObject.assign(error, {\ntoolId: block.config.tool,\ntoolName: tool.name || 'Unknown tool',\nblockId: block.id,\nblockName: block.metadata?.name || 'Unnamed Block',\noutput: result.output || {},\ntimestamp: new Date().toISOString(),\n})\nthrow error\n}\nconst output = result.output\nlet cost = null\nif (block.config.tool?.startsWith('knowledge_') && output?.cost) {\ncost = output.cost\n}\nif (cost) {\nreturn {\n...output,\ncost: {\ninput: cost.input,\noutput: cost.output,\ntotal: cost.total,\n},\ntokens: cost.tokens,\nmodel: cost.model,\n}\n}\nreturn output\n} catch (error: any) {\nif (!error.message || error.message === 'undefined (undefined)') {\nlet errorMessage = `Block execution of ${tool.name || block.config.tool} failed`\nif (block.metadata?.name) {\nerrorMessage += `: ${block.metadata.name}`\n}\nif (error.status) {\nerrorMessage += ` (Status: ${error.status})`\n}\nerror.message = errorMessage\n}\nif (typeof error === 'object' && error !== null) {\nif (!error.toolId) error.toolId = block.config.tool\nif (!error.blockName) error.blockName = block.metadata?.name || 'Unnamed Block'\n}\nthrow error\n}\n}"
"private async evaluateForEachItems(\nforEachItems: any,\ncontext: ExecutionContext,\nblock: SerializedBlock\n): Promise<any[] | Record<string, any> | null> {\nif (\nArray.isArray(forEachItems) ||\n(typeof forEachItems === 'object' && forEachItems !== null)\n) {\nreturn forEachItems\n}\nif (typeof forEachItems === 'string') {\ntry {\nconst trimmed = forEachItems.trim()\nif (trimmed.startsWith('\nreturn []\n}\nif (trimmed.startsWith('[') || trimmed.startsWith('{')) {\ntry {\nreturn JSON.parse(trimmed)\n} catch {\n}\n}\nif (this.resolver) {\nconst resolved = this.resolver.resolveBlockReferences(forEachItems, context, block)\ntry {\nreturn JSON.parse(resolved)\n} catch {\ntry {\nconst result = new Function(`return ${resolved}`)()\nif (Array.isArray(result) || (typeof result === 'object' && result !== null)) {\nreturn result\n}\n} catch (e) {\nlogger.error(`Error evaluating forEach expression: ${resolved}`, e)\n}\n}\n}\nlogger.warn(`forEach expression evaluation not fully implemented: ${forEachItems}`)\nreturn null\n} catch (error) {\nlogger.error(`Error evaluating forEach items:`, error)\nreturn null\n}\n}\nreturn null\n}"
"private async evaluateDistributionItems(\ndistribution: any,\ncontext: ExecutionContext,\nblock: SerializedBlock\n): Promise<any[] | Record<string, any> | null> {\nif (\nArray.isArray(distribution) ||\n(typeof distribution === 'object' && distribution !== null)\n) {\nreturn distribution\n}\nif (typeof distribution === 'string') {\ntry {\nconst trimmed = distribution.trim()\nif (trimmed.startsWith('\nreturn []\n}\nif (trimmed.startsWith('[') || trimmed.startsWith('{')) {\ntry {\nreturn JSON.parse(trimmed)\n} catch {\n}\n}\nif (this.resolver) {\nconst resolved = this.resolver.resolveBlockReferences(distribution, context, block)\ntry {\nreturn JSON.parse(resolved)\n} catch {\ntry {\nconst result = new Function(`return ${resolved}`)()\nif (Array.isArray(result) || (typeof result === 'object' && result !== null)) {\nreturn result\n}\n} catch (e) {\nlogger.error(`Error evaluating distribution expression: ${resolved}`, e)\n}\n}\n}\nlogger.warn(`Distribution expression evaluation not fully implemented: ${distribution}`)\nreturn null\n} catch (error) {\nlogger.error(`Error evaluating distribution items:`, error)\nreturn null\n}\n}\nreturn null\n}"
"private async loadChildWorkflow(workflowId: string) {\ntry {\nconst headers: Record<string, string> = {\n'Content-Type': 'application/json',\n}\nif (typeof window === 'undefined') {\nconst token = await generateInternalToken()\nheaders.Authorization = `Bearer ${token}`\n}\nconst response = await fetch(`${getBaseUrl()}/api/workflows/${workflowId}`, {\nheaders,\n})\nif (!response.ok) {\nif (response.status === 404) {\nlogger.error(`Child workflow ${workflowId} not found`)\nreturn null\n}\nthrow new Error(`Failed to fetch workflow: ${response.status} ${response.statusText}`)\n}\nconst { data: workflowData } = await response.json()\nif (!workflowData) {\nlogger.error(`Child workflow ${workflowId} returned empty data`)\nreturn null\n}\nlogger.info(`Loaded child workflow: ${workflowData.name} (${workflowId})`)\nconst workflowState = workflowData.state\nif (!workflowState || !workflowState.blocks) {\nlogger.error(`Child workflow ${workflowId} has invalid state`)\nreturn null\n}\nconst serializedWorkflow = this.serializer.serializeWorkflow(\nworkflowState.blocks,\nworkflowState.edges || [],\nworkflowState.loops || {},\nworkflowState.parallels || {},\ntrue\n)\nconst workflowVariables = (workflowData.variables as Record<string, any>) || {}\nif (Object.keys(workflowVariables).length > 0) {\nlogger.info(\n`Loaded ${Object.keys(workflowVariables).length} variables for child workflow: ${workflowId}`\n)\n} else {\nlogger.debug(`No workflow variables found for child workflow: ${workflowId}`)\n}\nreturn {\nname: workflowData.name,\nserializedState: serializedWorkflow,\nvariables: workflowVariables,\n}\n} catch (error) {\nlogger.error(`Error loading child workflow ${workflowId}:`, error)\nreturn null\n}\n}"
"export async function checkUsageStatus(userId: string): Promise<UsageData> {\ntry {\nif (!isProd) {\nconst statsRecords = await db.select().from(userStats).where(eq(userStats.userId, userId))\nconst currentUsage =\nstatsRecords.length > 0\n? Number.parseFloat(\nstatsRecords[0].currentPeriodCost?.toString() || statsRecords[0].totalCost.toString()\n)\n: 0\nreturn {\npercentUsed: Math.min(Math.round((currentUsage / 1000) * 100), 100),\nisWarning: false,\nisExceeded: false,\ncurrentUsage,\nlimit: 1000,\n}\n}\nconst limit = await getUserUsageLimit(userId)\nlogger.info('Using stored usage limit', { userId, limit })\nconst statsRecords = await db.select().from(userStats).where(eq(userStats.userId, userId))\nif (statsRecords.length === 0) {\nlogger.info('No usage stats found for user', { userId, limit })\nreturn {\npercentUsed: 0,\nisWarning: false,\nisExceeded: false,\ncurrentUsage: 0,\nlimit,\n}\n}\nconst currentUsage = Number.parseFloat(\nstatsRecords[0].currentPeriodCost?.toString() || statsRecords[0].totalCost.toString()\n)\nconst percentUsed = Math.min(Math.round((currentUsage / limit) * 100), 100)\nconst isWarning = percentUsed >= WARNING_THRESHOLD && percentUsed < 100\nconst isExceeded = currentUsage >= limit\nlogger.info('Final usage statistics', {\nuserId,\ncurrentUsage,\nlimit,\npercentUsed,\nisWarning,\nisExceeded,\n})\nreturn {\npercentUsed,\nisWarning,\nisExceeded,\ncurrentUsage,\nlimit,\n}\n} catch (error) {\nlogger.error('Error checking usage status', {\nerror: error instanceof Error ? { message: error.message, stack: error.stack } : error,\nuserId,\n})\nreturn {\npercentUsed: 0,\nisWarning: false,\nisExceeded: false,\ncurrentUsage: 0,\nlimit: 0,\n}\n}\n}"
"export async function checkAndNotifyUsage(userId: string): Promise<void> {\ntry {\nif (!isProd) {\nreturn\n}\nconst usageData = await checkUsageStatus(userId)\nif (usageData.isExceeded) {\nlogger.warn('User has exceeded usage limits', {\nuserId,\nusage: usageData.currentUsage,\nlimit: usageData.limit,\n})\nif (typeof window !== 'undefined') {\nwindow.dispatchEvent(\nnew CustomEvent('usage-exceeded', {\ndetail: { usageData },\n})\n)\n}\n} else if (usageData.isWarning) {\nlogger.info('User approaching usage limits', {\nuserId,\nusage: usageData.currentUsage,\nlimit: usageData.limit,\npercent: usageData.percentUsed,\n})\nif (typeof window !== 'undefined') {\nwindow.dispatchEvent(\nnew CustomEvent('usage-warning', {\ndetail: { usageData },\n})\n)\nwindow.dispatchEvent(\nnew CustomEvent('open-settings', {\ndetail: { tab: 'subscription' },\n})\n)\n}\n}\n} catch (error) {\nlogger.error('Error in usage notification system', { error, userId })\n}\n}"
"export async function checkServerSideUsageLimits(userId: string): Promise<{\nisExceeded: boolean\ncurrentUsage: number\nlimit: number\nmessage?: string\n}> {\ntry {\nif (!isProd) {\nreturn {\nisExceeded: false,\ncurrentUsage: 0,\nlimit: 1000,\n}\n}\nlogger.info('Server-side checking usage limits for user', { userId })\nconst usageData = await checkUsageStatus(userId)\nreturn {\nisExceeded: usageData.isExceeded,\ncurrentUsage: usageData.currentUsage,\nlimit: usageData.limit,\nmessage: usageData.isExceeded\n? `Usage limit exceeded: ${usageData.currentUsage?.toFixed(2) || 0}$ used of ${usageData.limit?.toFixed(2) || 0}$ limit. Please upgrade your plan to continue.`\n: undefined,\n}\n} catch (error) {\nlogger.error('Error in server-side usage limit check', {\nerror: error instanceof Error ? { message: error.message, stack: error.stack } : error,\nuserId,\n})\nreturn {\nisExceeded: false,\ncurrentUsage: 0,\nlimit: 0,\nmessage: `Error checking usage limits: ${error instanceof Error ? error.message : String(error)}`,\n}\n}\n}"
"export function calculateBillingPeriod(\nsubscriptionPeriodStart?: Date,\nsubscriptionPeriodEnd?: Date\n): {\nstart: Date\nend: Date\n} {\nconst now = new Date()\nif (subscriptionPeriodStart && subscriptionPeriodEnd) {\nconst start = new Date(subscriptionPeriodStart)\nconst end = new Date(subscriptionPeriodEnd)\nif (now >= end) {\nconst newStart = new Date(end)\nconst newEnd = new Date(end)\nnewEnd.setUTCMonth(newEnd.getUTCMonth() + 1)\nlogger.info('Calculated next billing period from subscription dates', {\noriginalStart: subscriptionPeriodStart,\noriginalEnd: subscriptionPeriodEnd,\nnewStart,\nnewEnd,\n})\nreturn { start: newStart, end: newEnd }\n}\nlogger.info('Using current subscription billing period', {\nstart,\nend,\n})\nreturn { start, end }\n}\nif (subscriptionPeriodStart) {\nconst start = new Date(subscriptionPeriodStart)\nconst end = new Date(start)\nend.setUTCMonth(end.getUTCMonth() + 1)\nwhile (end <= now) {\nstart.setUTCMonth(start.getUTCMonth() + 1)\nend.setUTCMonth(end.getUTCMonth() + 1)\n}\nlogger.info('Calculated billing period from subscription start date', {\nsubscriptionStart: subscriptionPeriodStart,\ncurrentPeriodStart: start,\ncurrentPeriodEnd: end,\n})\nreturn { start, end }\n}\nconst start = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), 1))\nconst end = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth() + 1, 0, 23, 59, 59, 999))\nlogger.warn('Using fallback calendar month billing period', {\nstart,\nend,\n})\nreturn { start, end }\n}"
"export async function initializeBillingPeriod(\nuserId: string,\nstripeSubscriptionStart?: Date,\nstripeSubscriptionEnd?: Date\n): Promise<void> {\ntry {\nlet start: Date\nlet end: Date\nif (stripeSubscriptionStart && stripeSubscriptionEnd) {\nstart = stripeSubscriptionStart\nend = stripeSubscriptionEnd\nlogger.info('Using Stripe subscription dates for billing period', {\nuserId,\nstripeStart: stripeSubscriptionStart,\nstripeEnd: stripeSubscriptionEnd,\n})\n} else {\nconst subscriptionData = await db\n.select()\n.from(subscription)\n.where(and(eq(subscription.referenceId, userId), eq(subscription.status, 'active')))\n.limit(1)\nconst billingPeriod = calculateBillingPeriod(\nsubscriptionData[0]?.periodStart || undefined,\nsubscriptionData[0]?.periodEnd || undefined\n)\nstart = billingPeriod.start\nend = billingPeriod.end\n}\nawait db\n.update(userStats)\n.set({\nbillingPeriodStart: start,\nbillingPeriodEnd: end,\ncurrentPeriodCost: '0',\n})\n.where(eq(userStats.userId, userId))\nlogger.info('Billing period initialized for user', {\nuserId,\nbillingPeriodStart: start,\nbillingPeriodEnd: end,\n})\n} catch (error) {\nlogger.error('Failed to initialize billing period', { userId, error })\nthrow error\n}\n}"
"export async function resetUserBillingPeriod(userId: string): Promise<void> {\ntry {\nconst [currentStats, userSubscription] = await Promise.all([\ndb.select().from(userStats).where(eq(userStats.userId, userId)).limit(1),\ndb\n.select()\n.from(subscription)\n.where(and(eq(subscription.referenceId, userId), eq(subscription.status, 'active')))\n.limit(1),\n])\nif (currentStats.length === 0) {\nlogger.warn('No user stats found for billing period reset', { userId })\nreturn\n}\nconst stats = currentStats[0]\nconst currentPeriodCost = stats.currentPeriodCost || '0'\nlet newPeriodStart: Date\nlet newPeriodEnd: Date\nif (userSubscription.length > 0 && userSubscription[0].periodEnd) {\nconst nextPeriod = calculateNextBillingPeriod(userSubscription[0].periodEnd)\nnewPeriodStart = nextPeriod.start\nnewPeriodEnd = nextPeriod.end\n} else if (stats.billingPeriodEnd) {\nconst nextPeriod = calculateNextBillingPeriod(stats.billingPeriodEnd)\nnewPeriodStart = nextPeriod.start\nnewPeriodEnd = nextPeriod.end\n} else {\nconst subscriptionStart = userSubscription[0]?.periodStart\nconst billingPeriod = calculateBillingPeriod(subscriptionStart || undefined)\nnewPeriodStart = billingPeriod.start\nnewPeriodEnd = billingPeriod.end\n}\nawait db\n.update(userStats)\n.set({\nlastPeriodCost: currentPeriodCost,\ncurrentPeriodCost: '0',\nbillingPeriodStart: newPeriodStart,\nbillingPeriodEnd: newPeriodEnd,\n})\n.where(eq(userStats.userId, userId))\nlogger.info('Reset billing period for user', {\nuserId,\narchivedAmount: currentPeriodCost,\nnewPeriodStart,\nnewPeriodEnd,\nbasedOnSubscription: !!userSubscription[0]?.periodEnd,\n})\n} catch (error) {\nlogger.error('Failed to reset user billing period', { userId, error })\nthrow error\n}\n}"
"export async function getOrganizationBillingSummary(organizationId: string) {\ntry {\nconst billingData = await getOrganizationBillingData(organizationId)\nif (!billingData) {\nreturn null\n}\nconst membersOverLimit = billingData.members.filter((m) => m.isOverLimit).length\nconst membersNearLimit = billingData.members.filter(\n(m) => !m.isOverLimit && m.percentUsed >= 80\n).length\nconst topUsers = billingData.members.slice(0, 5).map((m) => ({\nname: m.userName,\nusage: m.currentUsage,\nlimit: m.usageLimit,\npercentUsed: m.percentUsed,\n}))\nreturn {\norganization: {\nid: billingData.organizationId,\nname: billingData.organizationName,\nplan: billingData.subscriptionPlan,\nstatus: billingData.subscriptionStatus,\n},\nusage: {\ntotal: billingData.totalCurrentUsage,\nlimit: billingData.totalUsageLimit,\naverage: billingData.averageUsagePerMember,\npercentUsed:\nbillingData.totalUsageLimit > 0\n? (billingData.totalCurrentUsage / billingData.totalUsageLimit) * 100\n: 0,\n},\nseats: {\ntotal: billingData.totalSeats,\nused: billingData.usedSeats,\navailable: billingData.totalSeats - billingData.usedSeats,\n},\nalerts: {\nmembersOverLimit,\nmembersNearLimit,\n},\nbillingPeriod: {\nstart: billingData.billingPeriodStart,\nend: billingData.billingPeriodEnd,\n},\ntopUsers,\n}\n} catch (error) {\nlogger.error('Failed to get organization billing summary', { organizationId, error })\nthrow error\n}\n}"
"export async function getHighestPrioritySubscription(userId: string) {\ntry {\nconst personalSubs = await db\n.select()\n.from(subscription)\n.where(and(eq(subscription.referenceId, userId), eq(subscription.status, 'active')))\nconst memberships = await db\n.select({ organizationId: member.organizationId })\n.from(member)\n.where(eq(member.userId, userId))\nconst orgIds = memberships.map((m: { organizationId: string }) => m.organizationId)\nlet orgSubs: any[] = []\nif (orgIds.length > 0) {\norgSubs = await db\n.select()\n.from(subscription)\n.where(and(inArray(subscription.referenceId, orgIds), eq(subscription.status, 'active')))\n}\nconst allSubs = [...personalSubs, ...orgSubs]\nif (allSubs.length === 0) return null\nconst enterpriseSub = allSubs.find((s) => checkEnterprisePlan(s))\nif (enterpriseSub) return enterpriseSub\nconst teamSub = allSubs.find((s) => checkTeamPlan(s))\nif (teamSub) return teamSub\nconst proSub = allSubs.find((s) => checkProPlan(s))\nif (proSub) return proSub\nreturn null\n} catch (error) {\nlogger.error('Error getting highest priority subscription', { error, userId })\nreturn null\n}\n}"
"export async function hasExceededCostLimit(userId: string): Promise<boolean> {\ntry {\nif (!isProd) {\nreturn false\n}\nconst subscription = await getHighestPrioritySubscription(userId)\nlet limit = DEFAULT_FREE_CREDITS\nif (subscription) {\nlimit = calculateDefaultUsageLimit(subscription)\nlogger.info('Using subscription-based limit', {\nuserId,\nplan: subscription.plan,\nseats: subscription.seats || 1,\nlimit,\n})\n} else {\nlogger.info('Using free tier limit', { userId, limit })\n}\nconst statsRecords = await db.select().from(userStats).where(eq(userStats.userId, userId))\nif (statsRecords.length === 0) {\nreturn false\n}\nconst currentCost = Number.parseFloat(\nstatsRecords[0].currentPeriodCost?.toString() || statsRecords[0].totalCost.toString()\n)\nlogger.info('Checking cost limit', { userId, currentCost, limit })\nreturn currentCost >= limit\n} catch (error) {\nlogger.error('Error checking cost limit', { error, userId })\nreturn false\n}\n}"
"export async function getUserUsageData(userId: string): Promise<UsageData> {\ntry {\nconst userStatsData = await db\n.select()\n.from(userStats)\n.where(eq(userStats.userId, userId))\n.limit(1)\nif (userStatsData.length === 0) {\nawait initializeUserUsageLimit(userId)\nreturn {\ncurrentUsage: 0,\nlimit: DEFAULT_FREE_CREDITS,\npercentUsed: 0,\nisWarning: false,\nisExceeded: false,\nbillingPeriodStart: null,\nbillingPeriodEnd: null,\nlastPeriodCost: 0,\n}\n}\nconst stats = userStatsData[0]\nconst currentUsage = Number.parseFloat(\nstats.currentPeriodCost?.toString() ?? stats.totalCost.toString()\n)\nconst limit = Number.parseFloat(stats.currentUsageLimit)\nconst percentUsed = limit > 0 ? Math.round((currentUsage / limit) * 100) : 0\nconst isWarning = percentUsed >= 80\nconst isExceeded = currentUsage >= limit\nreturn {\ncurrentUsage,\nlimit,\npercentUsed,\nisWarning,\nisExceeded,\nbillingPeriodStart: stats.billingPeriodStart,\nbillingPeriodEnd: stats.billingPeriodEnd,\nlastPeriodCost: Number.parseFloat(stats.lastPeriodCost?.toString() || '0'),\n}\n} catch (error) {\nlogger.error('Failed to get user usage data', { userId, error })\nthrow error\n}\n}"
"export async function syncUsageLimitsFromSubscription(userId: string): Promise<void> {\ntry {\nconst subscription = await getHighestPrioritySubscription(userId)\nconst defaultLimit = calculateDefaultUsageLimit(subscription)\nconst currentUserStats = await db\n.select()\n.from(userStats)\n.where(eq(userStats.userId, userId))\n.limit(1)\nif (currentUserStats.length === 0) {\nawait db.insert(userStats).values({\nid: crypto.randomUUID(),\nuserId,\ncurrentUsageLimit: defaultLimit.toString(),\nusageLimitUpdatedAt: new Date(),\n})\nlogger.info('Created usage stats with synced limit', { userId, limit: defaultLimit })\nreturn\n}\nconst currentStats = currentUserStats[0]\nconst currentLimit = Number.parseFloat(currentStats.currentUsageLimit)\nif (!subscription || subscription.status !== 'active') {\nawait db\n.update(userStats)\n.set({\ncurrentUsageLimit: DEFAULT_FREE_CREDITS.toString(),\nusageLimitUpdatedAt: new Date(),\n})\n.where(eq(userStats.userId, userId))\nlogger.info('Synced usage limit to free plan', { userId, limit: DEFAULT_FREE_CREDITS })\n} else if (currentLimit < defaultLimit) {\nawait db\n.update(userStats)\n.set({\ncurrentUsageLimit: defaultLimit.toString(),\nusageLimitUpdatedAt: new Date(),\n})\n.where(eq(userStats.userId, userId))\nlogger.info('Synced usage limit to new minimum', {\nuserId,\noldLimit: currentLimit,\nnewLimit: defaultLimit,\n})\n}\n} catch (error) {\nlogger.error('Failed to sync usage limits', { userId, error })\nthrow error\n}\n}"
"export async function getTeamUsageLimits(organizationId: string): Promise<\nArray<{\nuserId: string\nuserName: string\nuserEmail: string\ncurrentLimit: number\ncurrentUsage: number\ntotalCost: number\nlastActive: Date | null\nlimitSetBy: string | null\nlimitUpdatedAt: Date | null\n}>\n> {\ntry {\nconst teamMembers = await db\n.select({\nuserId: member.userId,\nuserName: user.name,\nuserEmail: user.email,\ncurrentLimit: userStats.currentUsageLimit,\ncurrentPeriodCost: userStats.currentPeriodCost,\ntotalCost: userStats.totalCost,\nlastActive: userStats.lastActive,\nlimitSetBy: userStats.usageLimitSetBy,\nlimitUpdatedAt: userStats.usageLimitUpdatedAt,\n})\n.from(member)\n.innerJoin(user, eq(member.userId, user.id))\n.leftJoin(userStats, eq(member.userId, userStats.userId))\n.where(eq(member.organizationId, organizationId))\nreturn teamMembers.map((memberData) => ({\nuserId: memberData.userId,\nuserName: memberData.userName,\nuserEmail: memberData.userEmail,\ncurrentLimit: Number.parseFloat(memberData.currentLimit || DEFAULT_FREE_CREDITS.toString()),\ncurrentUsage: Number.parseFloat(memberData.currentPeriodCost || '0'),\ntotalCost: Number.parseFloat(memberData.totalCost || '0'),\nlastActive: memberData.lastActive,\nlimitSetBy: memberData.limitSetBy,\nlimitUpdatedAt: memberData.limitUpdatedAt,\n}))\n} catch (error) {\nlogger.error('Failed to get team usage limits', { organizationId, error })\nreturn []\n}\n}"
"export async function calculateBillingProjection(userId: string): Promise<BillingData> {\ntry {\nconst usageData = await getUserUsageData(userId)\nif (!usageData.billingPeriodStart || !usageData.billingPeriodEnd) {\nreturn {\ncurrentPeriodCost: usageData.currentUsage,\nprojectedCost: usageData.currentUsage,\nlimit: usageData.limit,\nbillingPeriodStart: null,\nbillingPeriodEnd: null,\ndaysRemaining: 0,\n}\n}\nconst now = new Date()\nconst periodStart = new Date(usageData.billingPeriodStart)\nconst periodEnd = new Date(usageData.billingPeriodEnd)\nconst totalDays = Math.ceil(\n(periodEnd.getTime() - periodStart.getTime()) / (1000 * 60 * 60 * 24)\n)\nconst daysElapsed = Math.ceil((now.getTime() - periodStart.getTime()) / (1000 * 60 * 60 * 24))\nconst daysRemaining = Math.max(0, totalDays - daysElapsed)\nconst dailyRate = daysElapsed > 0 ? usageData.currentUsage / daysElapsed : 0\nconst projectedCost = dailyRate * totalDays\nreturn {\ncurrentPeriodCost: usageData.currentUsage,\nprojectedCost: Math.min(projectedCost, usageData.limit),\nlimit: usageData.limit,\nbillingPeriodStart: usageData.billingPeriodStart,\nbillingPeriodEnd: usageData.billingPeriodEnd,\ndaysRemaining,\n}\n} catch (error) {\nlogger.error('Failed to calculate billing projection', { userId, error })\nthrow error\n}\n}"
"export async function getOrganizationSeatInfo(\norganizationId: string\n): Promise<OrganizationSeatInfo | null> {\ntry {\nconst organizationData = await db\n.select({\nid: organization.id,\nname: organization.name,\n})\n.from(organization)\n.where(eq(organization.id, organizationId))\n.limit(1)\nif (organizationData.length === 0) {\nreturn null\n}\nconst subscription = await getHighestPrioritySubscription(organizationId)\nif (!subscription) {\nreturn null\n}\nconst memberCount = await db\n.select({ count: count() })\n.from(member)\n.where(eq(member.organizationId, organizationId))\nconst currentSeats = memberCount[0]?.count || 0\nlet maxSeats = subscription.seats || 1\nlet canAddSeats = true\nif (subscription.plan === 'enterprise' && subscription.metadata) {\ntry {\nconst metadata = JSON.parse(subscription.metadata)\nif (metadata.maxSeats) {\nmaxSeats = metadata.maxSeats\n}\ncanAddSeats = !metadata.fixedSeats\n} catch (error) {\nlogger.warn('Failed to parse enterprise subscription metadata', { organizationId, error })\n}\n}\nconst availableSeats = Math.max(0, maxSeats - currentSeats)\nreturn {\norganizationId,\norganizationName: organizationData[0].name,\ncurrentSeats,\nmaxSeats,\navailableSeats,\nsubscriptionPlan: subscription.plan,\ncanAddSeats,\n}\n} catch (error) {\nlogger.error('Failed to get organization seat info', { organizationId, error })\nreturn null\n}\n}"
"export async function updateOrganizationSeats(\norganizationId: string,\nnewSeatCount: number,\nupdatedBy: string\n): Promise<{ success: boolean; error?: string }> {\ntry {\nconst subscriptionRecord = await getHighestPrioritySubscription(organizationId)\nif (!subscriptionRecord) {\nreturn { success: false, error: 'No active subscription found' }\n}\nconst memberCount = await db\n.select({ count: count() })\n.from(member)\n.where(eq(member.organizationId, organizationId))\nconst currentMembers = memberCount[0]?.count || 0\nif (newSeatCount < currentMembers) {\nreturn {\nsuccess: false,\nerror: `Cannot reduce seats below current member count (${currentMembers})`,\n}\n}\nawait db\n.update(subscription)\n.set({\nseats: newSeatCount,\n})\n.where(eq(subscription.id, subscriptionRecord.id))\nlogger.info('Organization seat count updated', {\norganizationId,\noldSeatCount: subscriptionRecord.seats,\nnewSeatCount,\nupdatedBy,\n})\nreturn { success: true }\n} catch (error) {\nlogger.error('Failed to update organization seats', {\norganizationId,\nnewSeatCount,\nupdatedBy,\nerror,\n})\nreturn {\nsuccess: false,\nerror: error instanceof Error ? error.message : 'Unknown error',\n}\n}\n}"
"export async function validateMemberRemoval(\norganizationId: string,\nuserIdToRemove: string,\nremovedBy: string\n): Promise<{ canRemove: boolean; reason?: string }> {\ntry {\nconst memberRecord = await db\n.select({ role: member.role })\n.from(member)\n.where(and(eq(member.organizationId, organizationId), eq(member.userId, userIdToRemove)))\n.limit(1)\nif (memberRecord.length === 0) {\nreturn { canRemove: false, reason: 'Member not found in organization' }\n}\nif (memberRecord[0].role === 'owner') {\nreturn { canRemove: false, reason: 'Cannot remove organization owner' }\n}\nconst removerMemberRecord = await db\n.select({ role: member.role })\n.from(member)\n.where(and(eq(member.organizationId, organizationId), eq(member.userId, removedBy)))\n.limit(1)\nif (removerMemberRecord.length === 0) {\nreturn { canRemove: false, reason: 'You are not a member of this organization' }\n}\nconst removerRole = removerMemberRecord[0].role\nconst targetRole = memberRecord[0].role\nif (removerRole === 'owner') {\nreturn userIdToRemove === removedBy\n? { canRemove: false, reason: 'Cannot remove yourself as owner' }\n: { canRemove: true }\n}\nif (removerRole === 'admin') {\nreturn targetRole === 'member'\n? { canRemove: true }\n: { canRemove: false, reason: 'Insufficient permissions to remove this member' }\n}\nreturn { canRemove: false, reason: 'Insufficient permissions' }\n} catch (error) {\nlogger.error('Failed to validate member removal', {\norganizationId,\nuserIdToRemove,\nremovedBy,\nerror,\n})\nreturn { canRemove: false, reason: 'Validation failed' }\n}\n}"
"export async function getOrganizationSeatAnalytics(organizationId: string) {\ntry {\nconst seatInfo = await getOrganizationSeatInfo(organizationId)\nif (!seatInfo) {\nreturn null\n}\nconst memberActivity = await db\n.select({\nuserId: member.userId,\nuserName: user.name,\nuserEmail: user.email,\nrole: member.role,\njoinedAt: member.createdAt,\nlastActive: userStats.lastActive,\n})\n.from(member)\n.innerJoin(user, eq(member.userId, user.id))\n.leftJoin(userStats, eq(member.userId, userStats.userId))\n.where(eq(member.organizationId, organizationId))\nconst utilizationRate =\nseatInfo.maxSeats > 0 ? (seatInfo.currentSeats / seatInfo.maxSeats) * 100 : 0\nconst recentlyActive = memberActivity.filter((memberData) => {\nif (!memberData.lastActive) return false\nconst daysSinceActive = (Date.now() - memberData.lastActive.getTime()) / (1000 * 60 * 60 * 24)\nreturn daysSinceActive <= 30\n}).length\nreturn {\n...seatInfo,\nutilizationRate: Math.round(utilizationRate * 100) / 100,\nactiveMembers: recentlyActive,\ninactiveMembers: seatInfo.currentSeats - recentlyActive,\nmemberActivity,\n}\n} catch (error) {\nlogger.error('Failed to get organization seat analytics', { organizationId, error })\nreturn null\n}\n}"
"export async function handleInvoicePaymentFailed(event: Stripe.Event) {\ntry {\nconst invoice = event.data.object as Stripe.Invoice\nif (invoice.metadata?.type !== 'overage_billing') {\nlogger.info('Ignoring non-overage billing invoice payment failure', { invoiceId: invoice.id })\nreturn\n}\nconst customerId = invoice.customer as string\nconst failedAmount = invoice.amount_due / 100\nconst billingPeriod = invoice.metadata?.billingPeriod || 'unknown'\nconst attemptCount = invoice.attempt_count || 1\nlogger.warn('Overage billing invoice payment failed', {\ninvoiceId: invoice.id,\ncustomerId,\nfailedAmount,\nbillingPeriod,\nattemptCount,\ncustomerEmail: invoice.customer_email,\nhostedInvoiceUrl: invoice.hosted_invoice_url,\n})\nif (attemptCount >= 3) {\nlogger.error('Multiple payment failures for overage billing', {\ninvoiceId: invoice.id,\ncustomerId,\nattemptCount,\n})\n}\n} catch (error) {\nlogger.error('Failed to handle invoice payment failed', {\neventId: event.id,\nerror,\n})\nthrow error\n}\n}"
"export function InlineToolCall({ toolCall, onStateChange, context }: InlineToolCallProps) {\nconst [, forceUpdate] = useState({})\nconst { setToolCallState } = useCopilotStore()\nif (!toolCall) {\nreturn null\n}\nconst showButtons = shouldShowRunSkipButtons(toolCall)\nconst clientTool = toolRegistry.getTool(toolCall.name)\nconst allowsBackground = clientTool?.metadata?.allowBackgroundExecution || false\nconst showBackgroundButton = allowsBackground && toolCall.state === 'executing' && !showButtons\nconst handleStateChange = (state: any) => {\nforceUpdate({})\nonStateChange?.(state)\n}\nconst displayName = getToolDisplayNameByState(toolCall)\nreturn (\n<div className='flex items-center justify-between gap-2 py-1'>\n<div className='flex items-center gap-2 text-muted-foreground'>\n<div className='flex-shrink-0'>{renderToolStateIcon(toolCall, 'h-3 w-3')}</div>\n<span className='text-base'>{displayName}</span>\n</div>\n{showButtons && (\n<RunSkipButtons toolCall={toolCall} onStateChange={handleStateChange} context={context} />\n)}\n{showBackgroundButton && (\n<div className='flex items-center gap-1.5'>\n<Button\nonClick={async () => {\ntry {\nsetToolCallState(toolCall, 'background')\nconst executionStartTime = context?.executionStartTime\nawait notifyServerTool(toolCall.id, toolCall.name, 'background', executionStartTime)\nif (context) {\nif (!context.movedToBackgroundToolIds) {\ncontext.movedToBackgroundToolIds = new Set()\n}\ncontext.movedToBackgroundToolIds.add(toolCall.id)\n}\nonStateChange?.(toolCall.state)\n} catch (error) {\nconsole.error('Error moving to background:', error)\n}\n}}\nsize='sm'\nclassName='h-6 bg-blue-600 px-2 font-medium text-white text-xs hover:bg-blue-700'\n>\nMove to Background\n</Button>\n</div>\n)}\n</div>\n)\n}"
"private log(level: LogLevel, message: string, ...args: any[]) {\nif (!this.shouldLog(level)) return\nconst timestamp = new Date().toISOString()\nconst formattedArgs = this.formatArgs(args)\nif (config.colorize) {\nlet levelColor\nconst moduleColor = chalk.cyan\nconst timestampColor = chalk.gray\nswitch (level) {\ncase LogLevel.DEBUG:\nlevelColor = chalk.blue\nbreak\ncase LogLevel.INFO:\nlevelColor = chalk.green\nbreak\ncase LogLevel.WARN:\nlevelColor = chalk.yellow\nbreak\ncase LogLevel.ERROR:\nlevelColor = chalk.red\nbreak\n}\nconst coloredPrefix = `${timestampColor(`[${timestamp}]`)} ${levelColor(`[${level}]`)} ${moduleColor(`[${this.module}]`)}`\nif (level === LogLevel.ERROR) {\nconsole.error(coloredPrefix, message, ...formattedArgs)\n} else {\nconsole.log(coloredPrefix, message, ...formattedArgs)\n}\n} else {\nconst prefix = `[${timestamp}] [${level}] [${this.module}]`\nif (level === LogLevel.ERROR) {\nconsole.error(prefix, message, ...formattedArgs)\n} else {\nconsole.log(prefix, message, ...formattedArgs)\n}\n}\n}"
"export async function uploadToBlob(\nfile: Buffer,\nfileName: string,\ncontentType: string,\nconfigOrSize?: CustomBlobConfig | number,\nsize?: number\n): Promise<FileInfo> {\nlet config: CustomBlobConfig\nlet fileSize: number\nif (typeof configOrSize === 'object') {\nconfig = configOrSize\nfileSize = size ?? file.length\n} else {\nconfig = {\ncontainerName: BLOB_CONFIG.containerName,\naccountName: BLOB_CONFIG.accountName,\naccountKey: BLOB_CONFIG.accountKey,\nconnectionString: BLOB_CONFIG.connectionString,\n}\nfileSize = configOrSize ?? file.length\n}\nconst safeFileName = fileName.replace(/\s+/g, '-')\nconst uniqueKey = `${Date.now()}-${safeFileName}`\nconst blobServiceClient = getBlobServiceClient()\nconst containerClient = blobServiceClient.getContainerClient(config.containerName)\nconst blockBlobClient = containerClient.getBlockBlobClient(uniqueKey)\nawait blockBlobClient.upload(file, fileSize, {\nblobHTTPHeaders: {\nblobContentType: contentType,\n},\nmetadata: {\noriginalName: encodeURIComponent(fileName),\nuploadedAt: new Date().toISOString(),\n},\n})\nconst servePath = `/api/files/serve/blob/${encodeURIComponent(uniqueKey)}`\nreturn {\npath: servePath,\nkey: uniqueKey,\nname: fileName,\nsize: fileSize,\ntype: contentType,\n}\n}"
"export async function getPresignedUrlWithConfig(\nkey: string,\ncustomConfig: CustomBlobConfig,\nexpiresIn = 3600\n) {\nlet tempBlobServiceClient: BlobServiceClient\nif (customConfig.connectionString) {\ntempBlobServiceClient = BlobServiceClient.fromConnectionString(customConfig.connectionString)\n} else if (customConfig.accountName && customConfig.accountKey) {\nconst sharedKeyCredential = new StorageSharedKeyCredential(\ncustomConfig.accountName,\ncustomConfig.accountKey\n)\ntempBlobServiceClient = new BlobServiceClient(\n`https:\nsharedKeyCredential\n)\n} else {\nthrow new Error(\n'Custom blob config must include either connectionString or accountName + accountKey'\n)\n}\nconst containerClient = tempBlobServiceClient.getContainerClient(customConfig.containerName)\nconst blockBlobClient = containerClient.getBlockBlobClient(key)\nconst sasOptions = {\ncontainerName: customConfig.containerName,\nblobName: key,\npermissions: BlobSASPermissions.parse('r'),\nstartsOn: new Date(),\nexpiresOn: new Date(Date.now() + expiresIn * 1000),\n}\nconst sasToken = generateBlobSASQueryParameters(\nsasOptions,\nnew StorageSharedKeyCredential(\ncustomConfig.accountName,\ncustomConfig.accountKey ??\n(() => {\nthrow new Error('Account key is required when using account name authentication')\n})()\n)\n).toString()\nreturn `${blockBlobClient.url}?${sasToken}`\n}"
"export async function uploadToS3(\nfile: Buffer,\nfileName: string,\ncontentType: string,\nconfigOrSize?: CustomS3Config | number,\nsize?: number\n): Promise<FileInfo> {\nlet config: CustomS3Config\nlet fileSize: number\nif (typeof configOrSize === 'object') {\nconfig = configOrSize\nfileSize = size ?? file.length\n} else {\nconfig = { bucket: S3_CONFIG.bucket, region: S3_CONFIG.region }\nfileSize = configOrSize ?? file.length\n}\nconst safeFileName = fileName.replace(/\s+/g, '-')\nconst uniqueKey = `${Date.now()}-${safeFileName}`\nconst sanitizedOriginalName = fileName\n.replace(/[^\x20-\x7E]/g, '')\n.replace(/[`\\]/g, '')\n.trim()\nconst s3Client = getS3Client()\nawait s3Client.send(\nnew PutObjectCommand({\nBucket: config.bucket,\nKey: uniqueKey,\nBody: file,\nContentType: contentType,\nMetadata: {\noriginalName: encodeURIComponent(fileName),\nuploadedAt: new Date().toISOString(),\n},\n})\n)\nconst servePath = `/api/files/serve/s3/${encodeURIComponent(uniqueKey)}`\nreturn {\npath: servePath,\nkey: uniqueKey,\nname: fileName,\nsize: fileSize,\ntype: contentType,\n}\n}"
"async mergeDiffFromYaml(yamlContent: string, diffAnalysis?: DiffAnalysis): Promise<DiffResult> {\ntry {\nlogger.info('Merging diff from YAML content')\nif (!this.currentDiff) {\nlogger.info('No existing diff, creating new diff')\nreturn this.createDiffFromYaml(yamlContent, diffAnalysis)\n}\nconst body: any = {\nexistingDiff: this.currentDiff,\nyamlContent,\n}\nif (diffAnalysis !== undefined && diffAnalysis !== null) {\nbody.diffAnalysis = diffAnalysis\n}\nbody.options = {\napplyAutoLayout: true,\nlayoutOptions: {\nstrategy: 'smart',\ndirection: 'auto',\nspacing: {\nhorizontal: 500,\nvertical: 400,\nlayer: 700,\n},\nalignment: 'center',\npadding: {\nx: 250,\ny: 250,\n},\n},\n}\nconst response = await fetch('/api/yaml/diff/merge', {\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n},\nbody: JSON.stringify(body),\n})\nif (!response.ok) {\nconst errorData = await response.json().catch(() => null)\nlogger.error('Failed to merge diff:', {\nstatus: response.status,\nerror: errorData,\n})\nreturn {\nsuccess: false,\nerrors: [errorData?.error || `Failed to merge diff: ${response.statusText}`],\n}\n}\nconst result = await response.json()\nif (!result.success || !result.diff) {\nreturn {\nsuccess: false,\nerrors: result.errors,\n}\n}\nthis.currentDiff = result.diff\nlogger.info('Diff merged successfully', {\ntotalBlocksCount: Object.keys(result.diff.proposedState.blocks).length,\ntotalEdgesCount: result.diff.proposedState.edges.length,\n})\nreturn {\nsuccess: true,\ndiff: this.currentDiff,\n}\n} catch (error) {\nlogger.error('Failed to merge diff:', error)\nreturn {\nsuccess: false,\nerrors: [error instanceof Error ? error.message : 'Failed to merge diff'],\n}\n}\n}"
"function validateVariable(variable: Variable): string | undefined {\ntry {\nswitch (variable.type) {\ncase 'number':\nif (Number.isNaN(Number(variable.value))) {\nreturn 'Not a valid number'\n}\nbreak\ncase 'boolean':\nif (!/^(true|false)$/i.test(String(variable.value).trim())) {\nreturn 'Expected `true` or `false`'\n}\nbreak\ncase 'object':\ntry {\nconst valueToEvaluate = String(variable.value).trim()\nif (!valueToEvaluate.startsWith('{') || !valueToEvaluate.endsWith('}')) {\nreturn 'Not a valid object format'\n}\nconst parsed = new Function(`return ${valueToEvaluate}`)()\nif (parsed === null || typeof parsed !== 'object' || Array.isArray(parsed)) {\nreturn 'Not a valid object'\n}\nreturn undefined\n} catch (e) {\nlogger.error('Object parsing error:', e)\nreturn 'Invalid object syntax'\n}\ncase 'array':\ntry {\nconst parsed = JSON.parse(String(variable.value))\nif (!Array.isArray(parsed)) {\nreturn 'Not a valid JSON array'\n}\n} catch {\nreturn 'Invalid JSON array syntax'\n}\nbreak\n}\nreturn undefined\n} catch (e) {\nreturn e instanceof Error ? e.message : 'Invalid format'\n}\n}"
"function validateBlockTypes(yamlWorkflow: YamlWorkflow): { errors: string[]; warnings: string[] } {\nconst errors: string[] = []\nconst warnings: string[] = []\nObject.entries(yamlWorkflow.blocks).forEach(([blockId, block]) => {\nconst { errors: structureErrors, warnings: structureWarnings } = validateBlockStructure(\nblockId,\nblock\n)\nerrors.push(...structureErrors)\nwarnings.push(...structureWarnings)\nconst blockConfig = getBlock(block.type)\nif (block.type === 'loop' || block.type === 'parallel') {\nreturn\n}\nif (!blockConfig) {\nerrors.push(`Unknown block type '${block.type}' for block '${blockId}'`)\nreturn\n}\nif (block.inputs && blockConfig.subBlocks) {\nObject.keys(block.inputs).forEach((inputKey) => {\nconst subBlockConfig = blockConfig.subBlocks.find((sb) => sb.id === inputKey)\nif (!subBlockConfig) {\nwarnings.push(\n`Block '${blockId}' has unknown input '${inputKey}' for type '${block.type}'`\n)\n}\n})\n}\n})\nreturn { errors, warnings }\n}"
"function calculateBlockPositions(\nyamlWorkflow: YamlWorkflow\n): Record<string, { x: number; y: number }> {\nconst positions: Record<string, { x: number; y: number }> = {}\nconst blockIds = Object.keys(yamlWorkflow.blocks)\nconst starterBlocks = blockIds.filter((id) => {\nconst block = yamlWorkflow.blocks[id]\nreturn !block.connections?.incoming || block.connections.incoming.length === 0\n})\nif (starterBlocks.length === 0 && blockIds.length > 0) {\nstarterBlocks.push(blockIds[0])\n}\nconst layers: string[][] = []\nconst visited = new Set<string>()\nconst queue = [...starterBlocks]\nwhile (queue.length > 0) {\nconst currentLayer: string[] = []\nconst currentLayerSize = queue.length\nfor (let i = 0; i < currentLayerSize; i++) {\nconst blockId = queue.shift()!\nif (visited.has(blockId)) continue\nvisited.add(blockId)\ncurrentLayer.push(blockId)\nconst block = yamlWorkflow.blocks[blockId]\nif (block.connections?.outgoing) {\nblock.connections.outgoing.forEach((connection) => {\nif (!visited.has(connection.target)) {\nqueue.push(connection.target)\n}\n})\n}\n}\nif (currentLayer.length > 0) {\nlayers.push(currentLayer)\n}\n}\nconst remainingBlocks = blockIds.filter((id) => !visited.has(id))\nif (remainingBlocks.length > 0) {\nlayers.push(remainingBlocks)\n}\nconst horizontalSpacing = 600\nconst verticalSpacing = 200\nconst startX = 150\nconst startY = 300\nlayers.forEach((layer, layerIndex) => {\nconst layerX = startX + layerIndex * horizontalSpacing\nlayer.forEach((blockId, blockIndex) => {\nconst blockY = startY + (blockIndex - layer.length / 2) * verticalSpacing\npositions[blockId] = { x: layerX, y: blockY }\n})\n})\nreturn positions\n}"
"function sortBlocksByParentChildOrder(blocks: ImportedBlock[]): ImportedBlock[] {\nconst sorted: ImportedBlock[] = []\nconst processed = new Set<string>()\nconst visiting = new Set<string>()\nconst blockMap = new Map<string, ImportedBlock>()\nblocks.forEach((block) => blockMap.set(block.id, block))\nfunction processBlock(block: ImportedBlock) {\nif (processed.has(block.id)) {\nreturn\n}\nif (visiting.has(block.id)) {\nlogger.warn(`Circular parent-child dependency detected for block ${block.id}, breaking cycle`)\nsorted.push(block)\nprocessed.add(block.id)\nreturn\n}\nvisiting.add(block.id)\nif (block.parentId) {\nconst parentBlock = blockMap.get(block.parentId)\nif (parentBlock && !processed.has(block.parentId)) {\nprocessBlock(parentBlock)\n}\n}\nvisiting.delete(block.id)\nsorted.push(block)\nprocessed.add(block.id)\n}\nblocks.forEach((block) => processBlock(block))\nreturn sorted\n}"
"function createSmartIdMapping(\nyamlBlocks: ImportedBlock[],\nexistingBlocks: Record<string, any>,\nactiveWorkflowId: string,\nforceNewIds = false\n): Map<string, string> {\nconst yamlIdToActualId = new Map<string, string>()\nconst existingBlockIds = new Set(Object.keys(existingBlocks))\nlogger.info('Creating smart ID mapping', {\nactiveWorkflowId,\nyamlBlockCount: yamlBlocks.length,\nexistingBlockCount: Object.keys(existingBlocks).length,\nexistingBlockIds: Array.from(existingBlockIds),\nyamlBlockIds: yamlBlocks.map((b) => b.id),\nforceNewIds,\n})\nfor (const block of yamlBlocks) {\nif (forceNewIds || !existingBlockIds.has(block.id)) {\nconst newId = uuidv4()\nyamlIdToActualId.set(block.id, newId)\nlogger.info(\n`🆕 Mapping new block: ${block.id} -> ${newId} (${forceNewIds ? 'forced new ID' : `not found in workflow ${activeWorkflowId}`})`\n)\n} else {\nyamlIdToActualId.set(block.id, block.id)\nlogger.info(\n`✅ Preserving existing block ID: ${block.id} (exists in workflow ${activeWorkflowId})`\n)\n}\n}\nlogger.info('Smart ID mapping completed', {\nmappings: Array.from(yamlIdToActualId.entries()),\npreservedCount: Array.from(yamlIdToActualId.entries()).filter(([old, new_]) => old === new_)\n.length,\nnewCount: Array.from(yamlIdToActualId.entries()).filter(([old, new_]) => old !== new_).length,\n})\nreturn yamlIdToActualId\n}"
"export function cleanConditionInputs(\nblockId: string,\ninputs: Record<string, any>\n): Record<string, any> {\nconst cleanInputs = { ...inputs }\nif (cleanInputs.conditions) {\ntry {\nconst conditions =\ntypeof cleanInputs.conditions === 'string'\n? JSON.parse(cleanInputs.conditions)\n: cleanInputs.conditions\nif (Array.isArray(conditions)) {\nconst tempConditions: Array<{ key: string; value: string }> = []\nlet elseIfCount = 0\nconditions.forEach((condition: any) => {\nif (condition.title && condition.value !== undefined) {\nlet key = condition.title\nif (condition.title === 'else if') {\nelseIfCount++\nif (elseIfCount === 1) {\nkey = 'else-if'\n} else {\nkey = `else-if-${elseIfCount}`\n}\n}\nconst stringValue = String(condition.value || '')\nif (stringValue.trim()) {\ntempConditions.push({ key, value: stringValue.trim() })\n}\n}\n})\ntempConditions.sort((a, b) => {\nconst getOrder = (key: string): number => {\nif (key === 'if') return 0\nif (key === 'else-if') return 1\nif (key.startsWith('else-if-')) {\nconst num = Number.parseInt(key.replace('else-if-', ''), 10)\nreturn 1 + num\n}\nif (key === 'else') return 1000\nreturn 500\n}\nreturn getOrder(a.key) - getOrder(b.key)\n})\nconst cleanConditions: Record<string, string> = {}\ntempConditions.forEach(({ key, value }) => {\ncleanConditions[key] = value\n})\nif (Object.keys(cleanConditions).length > 0) {\ncleanInputs.conditions = cleanConditions\n} else {\ncleanInputs.conditions = undefined\n}\n}\n} catch (error) {\nlogger.warn(`Failed to clean condition inputs for block ${blockId}:`, error)\n}\n}\nreturn cleanInputs\n}"
"export function expandConditionInputs(\nblockId: string,\ninputs: Record<string, any>\n): Record<string, any> {\nconst expandedInputs = { ...inputs }\nif (\nexpandedInputs.conditions &&\ntypeof expandedInputs.conditions === 'object' &&\n!Array.isArray(expandedInputs.conditions)\n) {\nconst conditionsObj = expandedInputs.conditions as Record<string, string>\nconst conditionsArray: any[] = []\nObject.entries(conditionsObj).forEach(([key, value]) => {\nconst conditionId = `${blockId}-${key}`\nlet title = key\nif (key.startsWith('else-if')) {\ntitle = 'else if'\n}\nconditionsArray.push({\nid: conditionId,\ntitle: title,\nvalue: String(value || ''),\nshowTags: false,\nshowEnvVars: false,\nsearchTerm: '',\ncursorPosition: 0,\nactiveSourceBlockId: null,\n})\n})\nconst hasElse = Object.keys(conditionsObj).some((key) => key === 'else')\nif (!hasElse) {\nconditionsArray.push({\nid: `${blockId}-else`,\ntitle: 'else',\nvalue: '',\nshowTags: false,\nshowEnvVars: false,\nsearchTerm: '',\ncursorPosition: 0,\nactiveSourceBlockId: null,\n})\n}\nexpandedInputs.conditions = JSON.stringify(conditionsArray)\n}\nreturn expandedInputs\n}"
"function initializeSubscriptions() {\nif (subscriptionsInitialized) return\nsubscriptionsInitialized = true\nlet lastWorkflowState: { blockCount: number; edgeCount: number } | null = null\nuseWorkflowStore.subscribe((state) => {\nconst currentState = {\nblockCount: Object.keys(state.blocks).length,\nedgeCount: state.edges.length,\n}\nif (\n!lastWorkflowState ||\nlastWorkflowState.blockCount !== currentState.blockCount ||\nlastWorkflowState.edgeCount !== currentState.edgeCount\n) {\nlastWorkflowState = currentState\nif (workflowRefreshTimeoutId) {\nclearTimeout(workflowRefreshTimeoutId)\n}\nconst refreshYaml = useWorkflowYamlStore.getState().refreshYaml\nworkflowRefreshTimeoutId = setTimeout(() => {\nrefreshYaml()\nworkflowRefreshTimeoutId = null\n}, 100)\n}\n})\nlet lastSubBlockChangeTime = 0\nuseSubBlockStore.subscribe((state) => {\nconst currentTime = Date.now()\nif (currentTime - lastSubBlockChangeTime > 100) {\nlastSubBlockChangeTime = currentTime\nif (subBlockRefreshTimeoutId) {\nclearTimeout(subBlockRefreshTimeoutId)\n}\nconst refreshYaml = useWorkflowYamlStore.getState().refreshYaml\nsubBlockRefreshTimeoutId = setTimeout(() => {\nrefreshYaml()\nsubBlockRefreshTimeoutId = null\n}, 100)\n}\n})\n}"
"export function OrbitingCircles({\nclassName,\nchildren,\nreverse,\nduration = 20,\nradius = 160,\npath = true,\niconSize = 30,\nspeed = 1,\n...props\n}: OrbitingCirclesProps) {\nconst calculatedDuration = duration / speed\nreturn (\n<>\n{path && (\n<svg\nxmlns='http:\nversion='1.1'\nclassName='pointer-events-none absolute inset-0 size-full'\n>\n<circle className='stroke-1 stroke-white/10' cx='50%' cy='50%' r={radius} fill='none' />\n</svg>\n)}\n{React.Children.map(children, (child, index) => {\nconst angle = (360 / React.Children.count(children)) * index\nreturn (\n<div\nstyle={\n{\n'--duration': calculatedDuration,\n'--radius': radius,\n'--angle': angle,\n'--icon-size': `${iconSize}px`,\n} as React.CSSProperties\n}\nclassName={cn(\n'absolute flex size-[var(--icon-size)] transform-gpu animate-orbit items-center justify-center rounded-full',\n{ '[animation-direction:reverse]': reverse },\nclassName\n)}\n{...props}\n>\n{child}\n</div>\n)\n})}\n</>\n)\n}"
"export async function refreshAccessTokenIfNeeded(\ncredentialId: string,\nuserId: string,\nrequestId: string\n): Promise<string | null> {\nconst credential = await getCredential(requestId, credentialId, userId)\nif (!credential) {\nreturn null\n}\nconst expiresAt = credential.accessTokenExpiresAt\nconst now = new Date()\nconst needsRefresh = expiresAt && expiresAt <= now\nconst accessToken = credential.accessToken\nif (needsRefresh && credential.refreshToken) {\nlogger.info(`[${requestId}] Token expired, attempting to refresh for credential`)\ntry {\nconst refreshedToken = await refreshOAuthToken(credential.providerId, credential.refreshToken)\nif (!refreshedToken) {\nlogger.error(`[${requestId}] Failed to refresh token for credential: ${credentialId}`, {\ncredentialId,\nproviderId: credential.providerId,\nuserId: credential.userId,\nhasRefreshToken: !!credential.refreshToken,\n})\nreturn null\n}\nconst updateData: any = {\naccessToken: refreshedToken.accessToken,\naccessTokenExpiresAt: new Date(Date.now() + refreshedToken.expiresIn * 1000),\nupdatedAt: new Date(),\n}\nif (refreshedToken.refreshToken && refreshedToken.refreshToken !== credential.refreshToken) {\nlogger.info(`[${requestId}] Updating refresh token for credential`)\nupdateData.refreshToken = refreshedToken.refreshToken\n}\nawait db.update(account).set(updateData).where(eq(account.id, credentialId))\nlogger.info(`[${requestId}] Successfully refreshed access token for credential`)\nreturn refreshedToken.accessToken\n} catch (error) {\nlogger.error(`[${requestId}] Error refreshing token for credential`, {\nerror: error instanceof Error ? error.message : String(error),\nstack: error instanceof Error ? error.stack : undefined,\nproviderId: credential.providerId,\ncredentialId,\nuserId: credential.userId,\n})\nreturn null\n}\n} else if (!accessToken) {\nlogger.error(`[${requestId}] Missing access token for credential`)\nreturn null\n}\nlogger.info(`[${requestId}] Access token is valid for credential`)\nreturn accessToken\n}"
"export async function refreshTokenIfNeeded(\nrequestId: string,\ncredential: any,\ncredentialId: string\n): Promise<{ accessToken: string; refreshed: boolean }> {\nconst expiresAt = credential.accessTokenExpiresAt\nconst now = new Date()\nconst needsRefresh = expiresAt && expiresAt <= now\nif (!needsRefresh || !credential.refreshToken) {\nlogger.info(`[${requestId}] Access token is valid`)\nreturn { accessToken: credential.accessToken, refreshed: false }\n}\ntry {\nconst refreshResult = await refreshOAuthToken(credential.providerId, credential.refreshToken)\nif (!refreshResult) {\nlogger.error(`[${requestId}] Failed to refresh token for credential`)\nthrow new Error('Failed to refresh token')\n}\nconst { accessToken: refreshedToken, expiresIn, refreshToken: newRefreshToken } = refreshResult\nconst updateData: any = {\naccessToken: refreshedToken,\naccessTokenExpiresAt: new Date(Date.now() + expiresIn * 1000),\nupdatedAt: new Date(),\n}\nif (newRefreshToken && newRefreshToken !== credential.refreshToken) {\nlogger.info(`[${requestId}] Updating refresh token`)\nupdateData.refreshToken = newRefreshToken\n}\nawait db.update(account).set(updateData).where(eq(account.id, credentialId))\nlogger.info(`[${requestId}] Successfully refreshed access token`)\nreturn { accessToken: refreshedToken, refreshed: true }\n} catch (error) {\nlogger.error(`[${requestId}] Error refreshing token`, error)\nthrow error\n}\n}"
"export async function POST(request: NextRequest) {\ntry {\nconst authError = verifyCronAuth(request, 'daily billing check')\nif (authError) {\nreturn authError\n}\nlogger.info('Starting daily billing check cron job')\nconst startTime = Date.now()\nconst result = await processDailyBillingCheck()\nconst duration = Date.now() - startTime\nif (result.success) {\nlogger.info('Daily billing check completed successfully', {\nprocessedUsers: result.processedUsers,\nprocessedOrganizations: result.processedOrganizations,\ntotalChargedAmount: result.totalChargedAmount,\nduration: `${duration}ms`,\n})\nreturn NextResponse.json({\nsuccess: true,\nsummary: {\nprocessedUsers: result.processedUsers,\nprocessedOrganizations: result.processedOrganizations,\ntotalChargedAmount: result.totalChargedAmount,\nduration: `${duration}ms`,\n},\n})\n}\nlogger.error('Daily billing check completed with errors', {\nprocessedUsers: result.processedUsers,\nprocessedOrganizations: result.processedOrganizations,\ntotalChargedAmount: result.totalChargedAmount,\nerrorCount: result.errors.length,\nerrors: result.errors,\nduration: `${duration}ms`,\n})\nreturn NextResponse.json(\n{\nsuccess: false,\nsummary: {\nprocessedUsers: result.processedUsers,\nprocessedOrganizations: result.processedOrganizations,\ntotalChargedAmount: result.totalChargedAmount,\nerrorCount: result.errors.length,\nduration: `${duration}ms`,\n},\nerrors: result.errors,\n},\n{ status: 500 }\n)\n} catch (error) {\nlogger.error('Fatal error in monthly billing cron job', { error })\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: 'Internal server error during daily billing check',\ndetails: error instanceof Error ? error.message : 'Unknown error',\n},\n{ status: 500 }\n)\n}\n}"
"export async function GET(req: NextRequest) {\ntry {\nconst { searchParams } = new URL(req.url)\nconst workflowId = searchParams.get('workflowId')\nif (!workflowId) {\nreturn createBadRequestResponse('workflowId is required')\n}\nconst { userId: authenticatedUserId, isAuthenticated } =\nawait authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !authenticatedUserId) {\nreturn createUnauthorizedResponse()\n}\nconst chats = await db\n.select({\nid: copilotChats.id,\ntitle: copilotChats.title,\nmodel: copilotChats.model,\nmessages: copilotChats.messages,\ncreatedAt: copilotChats.createdAt,\nupdatedAt: copilotChats.updatedAt,\n})\n.from(copilotChats)\n.where(\nand(eq(copilotChats.userId, authenticatedUserId), eq(copilotChats.workflowId, workflowId))\n)\n.orderBy(desc(copilotChats.updatedAt))\nconst transformedChats = chats.map((chat) => ({\nid: chat.id,\ntitle: chat.title,\nmodel: chat.model,\nmessages: Array.isArray(chat.messages) ? chat.messages : [],\nmessageCount: Array.isArray(chat.messages) ? chat.messages.length : 0,\npreviewYaml: null,\ncreatedAt: chat.createdAt,\nupdatedAt: chat.updatedAt,\n}))\nlogger.info(`Retrieved ${transformedChats.length} chats for workflow ${workflowId}`)\nreturn NextResponse.json({\nsuccess: true,\nchats: transformedChats,\n})\n} catch (error) {\nlogger.error('Error fetching copilot chats:', error)\nreturn createInternalServerErrorResponse('Failed to fetch chats')\n}\n}"
"export async function POST(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId, isAuthenticated } = await authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !userId) {\nreturn createUnauthorizedResponse()\n}\nconst body = await req.json()\nconst { workflowId, chatId, messageId, workflowState } = CreateCheckpointSchema.parse(body)\nlogger.info(`[${tracker.requestId}] Creating workflow checkpoint`, {\nuserId,\nworkflowId,\nchatId,\nmessageId,\nfullRequestBody: body,\nparsedData: { workflowId, chatId, messageId },\nmessageIdType: typeof messageId,\nmessageIdExists: !!messageId,\n})\nconst [chat] = await db\n.select()\n.from(copilotChats)\n.where(and(eq(copilotChats.id, chatId), eq(copilotChats.userId, userId)))\n.limit(1)\nif (!chat) {\nreturn createBadRequestResponse('Chat not found or unauthorized')\n}\nlet parsedWorkflowState\ntry {\nparsedWorkflowState = JSON.parse(workflowState)\n} catch (error) {\nreturn createBadRequestResponse('Invalid workflow state JSON')\n}\nconst [checkpoint] = await db\n.insert(workflowCheckpoints)\n.values({\nuserId,\nworkflowId,\nchatId,\nmessageId,\nworkflowState: parsedWorkflowState,\n})\n.returning()\nlogger.info(`[${tracker.requestId}] Workflow checkpoint created successfully`, {\ncheckpointId: checkpoint.id,\nsavedData: {\ncheckpointId: checkpoint.id,\nuserId: checkpoint.userId,\nworkflowId: checkpoint.workflowId,\nchatId: checkpoint.chatId,\nmessageId: checkpoint.messageId,\ncreatedAt: checkpoint.createdAt,\n},\n})\nreturn NextResponse.json({\nsuccess: true,\ncheckpoint: {\nid: checkpoint.id,\nuserId: checkpoint.userId,\nworkflowId: checkpoint.workflowId,\nchatId: checkpoint.chatId,\nmessageId: checkpoint.messageId,\ncreatedAt: checkpoint.createdAt,\nupdatedAt: checkpoint.updatedAt,\n},\n})\n} catch (error) {\nlogger.error(`[${tracker.requestId}] Failed to create workflow checkpoint:`, error)\nreturn createInternalServerErrorResponse('Failed to create checkpoint')\n}\n}"
"export async function GET(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId, isAuthenticated } = await authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !userId) {\nreturn createUnauthorizedResponse()\n}\nconst { searchParams } = new URL(req.url)\nconst chatId = searchParams.get('chatId')\nif (!chatId) {\nreturn createBadRequestResponse('chatId is required')\n}\nlogger.info(`[${tracker.requestId}] Fetching workflow checkpoints for chat`, {\nuserId,\nchatId,\n})\nconst checkpoints = await db\n.select({\nid: workflowCheckpoints.id,\nuserId: workflowCheckpoints.userId,\nworkflowId: workflowCheckpoints.workflowId,\nchatId: workflowCheckpoints.chatId,\nmessageId: workflowCheckpoints.messageId,\ncreatedAt: workflowCheckpoints.createdAt,\nupdatedAt: workflowCheckpoints.updatedAt,\n})\n.from(workflowCheckpoints)\n.where(and(eq(workflowCheckpoints.chatId, chatId), eq(workflowCheckpoints.userId, userId)))\n.orderBy(desc(workflowCheckpoints.createdAt))\nlogger.info(`[${tracker.requestId}] Retrieved ${checkpoints.length} workflow checkpoints`)\nreturn NextResponse.json({\nsuccess: true,\ncheckpoints,\n})\n} catch (error) {\nlogger.error(`[${tracker.requestId}] Failed to fetch workflow checkpoints:`, error)\nreturn createInternalServerErrorResponse('Failed to fetch checkpoints')\n}\n}"
"async function updateToolCallStatus(\ntoolCallId: string,\nstatus: NotificationStatus,\nmessage?: string\n): Promise<boolean> {\nconst redis = getRedisClient()\nif (!redis) {\nlogger.warn('updateToolCallStatus: Redis client not available')\nreturn false\n}\ntry {\nconst key = `tool_call:${toolCallId}`\nconst timeout = 60000\nconst pollInterval = 100\nconst startTime = Date.now()\nlogger.info('Polling for tool call in Redis', { toolCallId, key, timeout })\nwhile (Date.now() - startTime < timeout) {\nconst exists = await redis.exists(key)\nif (exists) {\nlogger.info('Tool call found in Redis, updating status', {\ntoolCallId,\nkey,\npollDuration: Date.now() - startTime,\n})\nbreak\n}\nawait new Promise((resolve) => setTimeout(resolve, pollInterval))\n}\nconst exists = await redis.exists(key)\nif (!exists) {\nlogger.warn('Tool call not found in Redis after polling timeout', {\ntoolCallId,\nkey,\ntimeout,\npollDuration: Date.now() - startTime,\n})\nreturn false\n}\nconst toolCallData = {\nstatus,\nmessage: message || null,\ntimestamp: new Date().toISOString(),\n}\nlogger.info('About to update Redis with tool call data', {\ntoolCallId,\nkey,\ntoolCallData,\nserializedData: JSON.stringify(toolCallData),\nprovidedStatus: status,\nprovidedMessage: message,\nmessageIsUndefined: message === undefined,\nmessageIsNull: message === null,\n})\nawait redis.set(key, JSON.stringify(toolCallData), 'EX', 86400)\nlogger.info('Tool call status updated in Redis', {\ntoolCallId,\nkey,\nstatus,\nmessage,\npollDuration: Date.now() - startTime,\n})\nreturn true\n} catch (error) {\nlogger.error('Failed to update tool call status in Redis', {\ntoolCallId,\nstatus,\nmessage,\nerror: error instanceof Error ? error.message : 'Unknown error',\n})\nreturn false\n}\n}"
"export async function POST(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId: authenticatedUserId, isAuthenticated } =\nawait authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated) {\nreturn createUnauthorizedResponse()\n}\nconst body = await req.json()\nconst { toolCallId, status, message } = ConfirmationSchema.parse(body)\nlogger.info(`[${tracker.requestId}] Tool call confirmation request`, {\nuserId: authenticatedUserId,\ntoolCallId,\nstatus,\nmessage,\n})\nconst updated = await updateToolCallStatus(toolCallId, status, message)\nif (!updated) {\nlogger.error(`[${tracker.requestId}] Failed to update tool call status`, {\nuserId: authenticatedUserId,\ntoolCallId,\nstatus,\ninternalStatus: status,\nmessage,\n})\nreturn createBadRequestResponse('Failed to update tool call status or tool call not found')\n}\nconst duration = tracker.getDuration()\nlogger.info(`[${tracker.requestId}] Tool call confirmation completed`, {\nuserId: authenticatedUserId,\ntoolCallId,\nstatus,\ninternalStatus: status,\nduration,\n})\nreturn NextResponse.json({\nsuccess: true,\nmessage: message || `Tool call ${toolCallId} has been ${status.toLowerCase()}`,\ntoolCallId,\nstatus,\n})\n} catch (error) {\nconst duration = tracker.getDuration()\nif (error instanceof z.ZodError) {\nlogger.error(`[${tracker.requestId}] Request validation error:`, {\nduration,\nerrors: error.errors,\n})\nreturn createBadRequestResponse(\n`Invalid request data: ${error.errors.map((e) => e.message).join(', ')}`\n)\n}\nlogger.error(`[${tracker.requestId}] Unexpected error:`, {\nduration,\nerror: error instanceof Error ? error.message : 'Unknown error',\nstack: error instanceof Error ? error.stack : undefined,\n})\nreturn createInternalServerErrorResponse(\nerror instanceof Error ? error.message : 'Internal server error'\n)\n}\n}"
"export async function POST(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId: authenticatedUserId, isAuthenticated } =\nawait authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !authenticatedUserId) {\nreturn createUnauthorizedResponse()\n}\nconst body = await req.json()\nconst { chatId, userQuery, agentResponse, isPositiveFeedback, feedback, workflowYaml } =\nFeedbackSchema.parse(body)\nlogger.info(`[${tracker.requestId}] Processing copilot feedback submission`, {\nuserId: authenticatedUserId,\nchatId,\nisPositiveFeedback,\nuserQueryLength: userQuery.length,\nagentResponseLength: agentResponse.length,\nhasFeedback: !!feedback,\nhasWorkflowYaml: !!workflowYaml,\nworkflowYamlLength: workflowYaml?.length || 0,\n})\nconst [feedbackRecord] = await db\n.insert(copilotFeedback)\n.values({\nuserId: authenticatedUserId,\nchatId,\nuserQuery,\nagentResponse,\nisPositive: isPositiveFeedback,\nfeedback: feedback || null,\nworkflowYaml: workflowYaml || null,\n})\n.returning()\nlogger.info(`[${tracker.requestId}] Successfully saved copilot feedback`, {\nfeedbackId: feedbackRecord.feedbackId,\nuserId: authenticatedUserId,\nisPositive: isPositiveFeedback,\nduration: tracker.getDuration(),\n})\nreturn NextResponse.json({\nsuccess: true,\nfeedbackId: feedbackRecord.feedbackId,\nmessage: 'Feedback submitted successfully',\nmetadata: {\nrequestId: tracker.requestId,\nduration: tracker.getDuration(),\n},\n})\n} catch (error) {\nconst duration = tracker.getDuration()\nif (error instanceof z.ZodError) {\nlogger.error(`[${tracker.requestId}] Validation error:`, {\nduration,\nerrors: error.errors,\n})\nreturn createBadRequestResponse(\n`Invalid request data: ${error.errors.map((e) => e.message).join(', ')}`\n)\n}\nlogger.error(`[${tracker.requestId}] Error submitting copilot feedback:`, {\nduration,\nerror: error instanceof Error ? error.message : 'Unknown error',\nstack: error instanceof Error ? error.stack : undefined,\n})\nreturn createInternalServerErrorResponse('Failed to submit feedback')\n}\n}"
"export async function GET(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId: authenticatedUserId, isAuthenticated } =\nawait authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !authenticatedUserId) {\nreturn createUnauthorizedResponse()\n}\nconst feedbackRecords = await db\n.select({\nfeedbackId: copilotFeedback.feedbackId,\nuserId: copilotFeedback.userId,\nchatId: copilotFeedback.chatId,\nuserQuery: copilotFeedback.userQuery,\nagentResponse: copilotFeedback.agentResponse,\nisPositive: copilotFeedback.isPositive,\nfeedback: copilotFeedback.feedback,\nworkflowYaml: copilotFeedback.workflowYaml,\ncreatedAt: copilotFeedback.createdAt,\n})\n.from(copilotFeedback)\nlogger.info(`[${tracker.requestId}] Retrieved ${feedbackRecords.length} feedback records`)\nreturn NextResponse.json({\nsuccess: true,\nfeedback: feedbackRecords,\nmetadata: {\nrequestId: tracker.requestId,\nduration: tracker.getDuration(),\n},\n})\n} catch (error) {\nlogger.error(`[${tracker.requestId}] Error retrieving copilot feedback:`, error)\nreturn createInternalServerErrorResponse('Failed to retrieve feedback')\n}\n}"
"export async function POST(request: NextRequest) {\nconst startTime = Date.now()\ntry {\nconst requestData = await request.json()\nconst { filePath, fileType } = requestData\nif (!filePath) {\nreturn NextResponse.json({ success: false, error: 'No file path provided' }, { status: 400 })\n}\nlogger.info('File parse request received:', { filePath, fileType })\nif (Array.isArray(filePath)) {\nconst results = []\nfor (const path of filePath) {\nconst result = await parseFileSingle(path, fileType)\nif (result.metadata) {\nresult.metadata.processingTime = Date.now() - startTime\n}\nif (result.success) {\nresults.push({\nsuccess: true,\noutput: {\ncontent: result.content,\nname: result.filePath.split('/').pop() || 'unknown',\nfileType: result.metadata?.fileType || 'application/octet-stream',\nsize: result.metadata?.size || 0,\nbinary: false,\n},\nfilePath: result.filePath,\n})\n} else {\nresults.push(result)\n}\n}\nreturn NextResponse.json({\nsuccess: true,\nresults,\n})\n}\nconst result = await parseFileSingle(filePath, fileType)\nif (result.metadata) {\nresult.metadata.processingTime = Date.now() - startTime\n}\nif (result.success) {\nreturn NextResponse.json({\nsuccess: true,\noutput: {\ncontent: result.content,\nname: result.filePath.split('/').pop() || 'unknown',\nfileType: result.metadata?.fileType || 'application/octet-stream',\nsize: result.metadata?.size || 0,\nbinary: false,\n},\n})\n}\nreturn NextResponse.json(result)\n} catch (error) {\nlogger.error('Error in file parse API:', error)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: error instanceof Error ? error.message : 'Unknown error occurred',\nfilePath: '',\n},\n{ status: 500 }\n)\n}\n}"
"async function handleExternalUrl(url: string, fileType?: string): Promise<ParseResult> {\ntry {\nlogger.info('Fetching external URL:', url)\nconst response = await fetch(url, {\nsignal: AbortSignal.timeout(DOWNLOAD_TIMEOUT_MS),\n})\nif (!response.ok) {\nthrow new Error(`Failed to fetch URL: ${response.status} ${response.statusText}`)\n}\nconst contentLength = response.headers.get('content-length')\nif (contentLength && Number.parseInt(contentLength) > MAX_DOWNLOAD_SIZE_BYTES) {\nthrow new Error(`File too large: ${contentLength} bytes (max: ${MAX_DOWNLOAD_SIZE_BYTES})`)\n}\nconst buffer = Buffer.from(await response.arrayBuffer())\nif (buffer.length > MAX_DOWNLOAD_SIZE_BYTES) {\nthrow new Error(`File too large: ${buffer.length} bytes (max: ${MAX_DOWNLOAD_SIZE_BYTES})`)\n}\nlogger.info(`Downloaded file from URL: ${url}, size: ${buffer.length} bytes`)\nconst urlPath = new URL(url).pathname\nconst filename = urlPath.split('/').pop() || 'download'\nconst extension = path.extname(filename).toLowerCase().substring(1)\nif (extension === 'pdf') {\nreturn await handlePdfBuffer(buffer, filename, fileType, url)\n}\nif (extension === 'csv') {\nreturn await handleCsvBuffer(buffer, filename, fileType, url)\n}\nif (isSupportedFileType(extension)) {\nreturn await handleGenericTextBuffer(buffer, filename, extension, fileType, url)\n}\nreturn handleGenericBuffer(buffer, filename, extension, fileType)\n} catch (error) {\nlogger.error(`Error handling external URL ${url}:`, error)\nreturn {\nsuccess: false,\nerror: `Error fetching URL: ${(error as Error).message}`,\nfilePath: url,\n}\n}\n}"
"async function handleCloudFile(filePath: string, fileType?: string): Promise<ParseResult> {\ntry {\nlet cloudKey: string\nif (filePath.includes('/api/files/serve/s3/')) {\ncloudKey = decodeURIComponent(filePath.split('/api/files/serve/s3/')[1])\n} else if (filePath.includes('/api/files/serve/blob/')) {\ncloudKey = decodeURIComponent(filePath.split('/api/files/serve/blob/')[1])\n} else if (filePath.startsWith('/api/files/serve/')) {\ncloudKey = decodeURIComponent(filePath.substring('/api/files/serve/'.length))\n} else {\ncloudKey = filePath\n}\nlogger.info('Extracted cloud key:', cloudKey)\nconst fileBuffer = await downloadFile(cloudKey)\nlogger.info(`Downloaded file from cloud storage: ${cloudKey}, size: ${fileBuffer.length} bytes`)\nconst filename = cloudKey.split('/').pop() || cloudKey\nconst extension = path.extname(filename).toLowerCase().substring(1)\nif (extension === 'pdf') {\nreturn await handlePdfBuffer(fileBuffer, filename, fileType, filePath)\n}\nif (extension === 'csv') {\nreturn await handleCsvBuffer(fileBuffer, filename, fileType, filePath)\n}\nif (isSupportedFileType(extension)) {\nreturn await handleGenericTextBuffer(fileBuffer, filename, extension, fileType, filePath)\n}\nreturn handleGenericBuffer(fileBuffer, filename, extension, fileType)\n} catch (error) {\nlogger.error(`Error handling cloud file ${filePath}:`, error)\nconst errorMessage = (error as Error).message\nif (errorMessage.includes('Access denied') || errorMessage.includes('Forbidden')) {\nthrow new Error(`Error accessing file from cloud storage: ${errorMessage}`)\n}\nreturn {\nsuccess: false,\nerror: `Error accessing file from cloud storage: ${errorMessage}`,\nfilePath,\n}\n}\n}"
"async function handleLocalFile(filePath: string, fileType?: string): Promise<ParseResult> {\ntry {\nconst filename = filePath.split('/').pop() || filePath\nconst fullPath = path.join(UPLOAD_DIR, filename)\nlogger.info('Processing local file:', fullPath)\ntry {\nawait fsPromises.access(fullPath)\n} catch {\nthrow new Error(`File not found: ${filename}`)\n}\nconst result = await parseFile(fullPath)\nconst stats = await fsPromises.stat(fullPath)\nconst fileBuffer = await readFile(fullPath)\nconst hash = createHash('md5').update(fileBuffer).digest('hex')\nconst extension = path.extname(filename).toLowerCase().substring(1)\nreturn {\nsuccess: true,\ncontent: result.content,\nfilePath,\nmetadata: {\nfileType: fileType || getMimeType(extension),\nsize: stats.size,\nhash,\nprocessingTime: 0,\n},\n}\n} catch (error) {\nlogger.error(`Error handling local file ${filePath}:`, error)\nreturn {\nsuccess: false,\nerror: `Error processing local file: ${(error as Error).message}`,\nfilePath,\n}\n}\n}"
"async function handlePdfBuffer(\nfileBuffer: Buffer,\nfilename: string,\nfileType?: string,\noriginalPath?: string\n): Promise<ParseResult> {\ntry {\nlogger.info(`Parsing PDF in memory: ${filename}`)\nconst result = await parseBufferAsPdf(fileBuffer)\nconst content =\nresult.content ||\ncreatePdfFallbackMessage(result.metadata?.pageCount || 0, fileBuffer.length, originalPath)\nreturn {\nsuccess: true,\ncontent,\nfilePath: originalPath || filename,\nmetadata: {\nfileType: fileType || 'application/pdf',\nsize: fileBuffer.length,\nhash: createHash('md5').update(fileBuffer).digest('hex'),\nprocessingTime: 0,\n},\n}\n} catch (error) {\nlogger.error('Failed to parse PDF in memory:', error)\nconst content = createPdfFailureMessage(\n0,\nfileBuffer.length,\noriginalPath || filename,\n(error as Error).message\n)\nreturn {\nsuccess: true,\ncontent,\nfilePath: originalPath || filename,\nmetadata: {\nfileType: fileType || 'application/pdf',\nsize: fileBuffer.length,\nhash: createHash('md5').update(fileBuffer).digest('hex'),\nprocessingTime: 0,\n},\n}\n}\n}"
"async function handleGenericTextBuffer(\nfileBuffer: Buffer,\nfilename: string,\nextension: string,\nfileType?: string,\noriginalPath?: string\n): Promise<ParseResult> {\ntry {\nlogger.info(`Parsing text file in memory: ${filename}`)\ntry {\nconst { parseBuffer, isSupportedFileType } = await import('@/lib/file-parsers')\nif (isSupportedFileType(extension)) {\nconst result = await parseBuffer(fileBuffer, extension)\nreturn {\nsuccess: true,\ncontent: result.content,\nfilePath: originalPath || filename,\nmetadata: {\nfileType: fileType || getMimeType(extension),\nsize: fileBuffer.length,\nhash: createHash('md5').update(fileBuffer).digest('hex'),\nprocessingTime: 0,\n},\n}\n}\n} catch (parserError) {\nlogger.warn('Specialized parser failed, falling back to generic parsing:', parserError)\n}\nconst content = fileBuffer.toString('utf-8')\nreturn {\nsuccess: true,\ncontent,\nfilePath: originalPath || filename,\nmetadata: {\nfileType: fileType || getMimeType(extension),\nsize: fileBuffer.length,\nhash: createHash('md5').update(fileBuffer).digest('hex'),\nprocessingTime: 0,\n},\n}\n} catch (error) {\nlogger.error('Failed to parse text file in memory:', error)\nreturn {\nsuccess: false,\nerror: `Failed to parse file: ${(error as Error).message}`,\nfilePath: originalPath || filename,\nmetadata: {\nfileType: 'text/plain',\nsize: 0,\nhash: '',\nprocessingTime: 0,\n},\n}\n}\n}"
"export async function POST(request: NextRequest) {\ntry {\nlet data: PresignedUrlRequest\ntry {\ndata = await request.json()\n} catch {\nthrow new ValidationError('Invalid JSON in request body')\n}\nconst { fileName, contentType, fileSize } = data\nif (!fileName?.trim()) {\nthrow new ValidationError('fileName is required and cannot be empty')\n}\nif (!contentType?.trim()) {\nthrow new ValidationError('contentType is required and cannot be empty')\n}\nif (!fileSize || fileSize <= 0) {\nthrow new ValidationError('fileSize must be a positive number')\n}\nconst MAX_FILE_SIZE = 100 * 1024 * 1024\nif (fileSize > MAX_FILE_SIZE) {\nthrow new ValidationError(\n`File size (${fileSize} bytes) exceeds maximum allowed size (${MAX_FILE_SIZE} bytes)`\n)\n}\nconst uploadTypeParam = request.nextUrl.searchParams.get('type')\nconst uploadType: UploadType =\nuploadTypeParam === 'knowledge-base'\n? 'knowledge-base'\n: uploadTypeParam === 'chat'\n? 'chat'\n: 'general'\nif (!isUsingCloudStorage()) {\nthrow new StorageConfigError(\n'Direct uploads are only available when cloud storage is enabled'\n)\n}\nconst storageProvider = getStorageProvider()\nlogger.info(`Generating ${uploadType} presigned URL for ${fileName} using ${storageProvider}`)\nswitch (storageProvider) {\ncase 's3':\nreturn await handleS3PresignedUrl(fileName, contentType, fileSize, uploadType)\ncase 'blob':\nreturn await handleBlobPresignedUrl(fileName, contentType, fileSize, uploadType)\ndefault:\nthrow new StorageConfigError(`Unknown storage provider: ${storageProvider}`)\n}\n} catch (error) {\nlogger.error('Error generating presigned URL:', error)\nif (error instanceof PresignedUrlError) {\nreturn NextResponse.json(\n{\nerror: error.message,\ncode: error.code,\ndirectUploadSupported: false,\n},\n{ status: error.statusCode }\n)\n}\nreturn createErrorResponse(\nerror instanceof Error ? error : new Error('Failed to generate presigned URL')\n)\n}\n}"
"export async function POST(request: NextRequest) {\ntry {\nconst formData = await request.formData()\nconst files = formData.getAll('file') as File[]\nif (!files || files.length === 0) {\nthrow new InvalidRequestError('No files provided')\n}\nconst usingCloudStorage = isUsingCloudStorage()\nlogger.info(`Using storage mode: ${usingCloudStorage ? 'Cloud' : 'Local'} for file upload`)\nconst uploadResults = []\nfor (const file of files) {\nconst originalName = file.name\nconst bytes = await file.arrayBuffer()\nconst buffer = Buffer.from(bytes)\nif (usingCloudStorage) {\ntry {\nlogger.info(`Uploading file to cloud storage: ${originalName}`)\nconst result = await uploadFile(buffer, originalName, file.type, file.size)\nlogger.info(`Successfully uploaded to cloud storage: ${result.key}`)\nuploadResults.push(result)\n} catch (error) {\nlogger.error('Error uploading to cloud storage:', error)\nthrow error\n}\n} else {\nconst extension = originalName.split('.').pop() || ''\nconst uniqueFilename = `${uuidv4()}.${extension}`\nconst filePath = join(UPLOAD_DIR, uniqueFilename)\nlogger.info(`Uploading file to local storage: ${filePath}`)\nawait writeFile(filePath, buffer)\nlogger.info(`Successfully wrote file to: ${filePath}`)\nuploadResults.push({\npath: `/api/files/serve/${uniqueFilename}`,\nname: originalName,\nsize: file.size,\ntype: file.type,\n})\n}\n}\nif (uploadResults.length === 1) {\nreturn NextResponse.json(uploadResults[0])\n}\nreturn NextResponse.json({ files: uploadResults })\n} catch (error) {\nlogger.error('Error in file upload:', error)\nreturn createErrorResponse(error instanceof Error ? error : new Error('File upload failed'))\n}\n}"
"export async function PUT(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { id } = await params\nconst body = await request.json()\nconst { name, color, isExpanded, parentId } = body\nconst existingFolder = await db\n.select()\n.from(workflowFolder)\n.where(eq(workflowFolder.id, id))\n.then((rows) => rows[0])\nif (!existingFolder) {\nreturn NextResponse.json({ error: 'Folder not found' }, { status: 404 })\n}\nconst workspacePermission = await getUserEntityPermissions(\nsession.user.id,\n'workspace',\nexistingFolder.workspaceId\n)\nif (!workspacePermission || workspacePermission === 'read') {\nreturn NextResponse.json(\n{ error: 'Write access required to update folders' },\n{ status: 403 }\n)\n}\nif (parentId && parentId === id) {\nreturn NextResponse.json({ error: 'Folder cannot be its own parent' }, { status: 400 })\n}\nif (parentId) {\nconst wouldCreateCycle = await checkForCircularReference(id, parentId)\nif (wouldCreateCycle) {\nreturn NextResponse.json(\n{ error: 'Cannot create circular folder reference' },\n{ status: 400 }\n)\n}\n}\nconst updates: any = { updatedAt: new Date() }\nif (name !== undefined) updates.name = name.trim()\nif (color !== undefined) updates.color = color\nif (isExpanded !== undefined) updates.isExpanded = isExpanded\nif (parentId !== undefined) updates.parentId = parentId || null\nconst [updatedFolder] = await db\n.update(workflowFolder)\n.set(updates)\n.where(eq(workflowFolder.id, id))\n.returning()\nlogger.info('Updated folder:', { id, updates })\nreturn NextResponse.json({ folder: updatedFolder })\n} catch (error) {\nlogger.error('Error updating folder:', { error })\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { id } = await params\nconst existingFolder = await db\n.select()\n.from(workflowFolder)\n.where(eq(workflowFolder.id, id))\n.then((rows) => rows[0])\nif (!existingFolder) {\nreturn NextResponse.json({ error: 'Folder not found' }, { status: 404 })\n}\nconst workspacePermission = await getUserEntityPermissions(\nsession.user.id,\n'workspace',\nexistingFolder.workspaceId\n)\nif (workspacePermission !== 'admin') {\nreturn NextResponse.json(\n{ error: 'Admin access required to delete folders' },\n{ status: 403 }\n)\n}\nconst deletionStats = await deleteFolderRecursively(id, existingFolder.workspaceId)\nlogger.info('Deleted folder and all contents:', {\nid,\ndeletionStats,\n})\nreturn NextResponse.json({\nsuccess: true,\ndeletedItems: deletionStats,\n})\n} catch (error) {\nlogger.error('Error deleting folder:', { error })\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"async function deleteFolderRecursively(\nfolderId: string,\nworkspaceId: string\n): Promise<{ folders: number; workflows: number }> {\nconst stats = { folders: 0, workflows: 0 }\nconst childFolders = await db\n.select({ id: workflowFolder.id })\n.from(workflowFolder)\n.where(and(eq(workflowFolder.parentId, folderId), eq(workflowFolder.workspaceId, workspaceId)))\nfor (const childFolder of childFolders) {\nconst childStats = await deleteFolderRecursively(childFolder.id, workspaceId)\nstats.folders += childStats.folders\nstats.workflows += childStats.workflows\n}\nconst workflowsInFolder = await db\n.select({ id: workflow.id })\n.from(workflow)\n.where(and(eq(workflow.folderId, folderId), eq(workflow.workspaceId, workspaceId)))\nif (workflowsInFolder.length > 0) {\nawait db\n.delete(workflow)\n.where(and(eq(workflow.folderId, folderId), eq(workflow.workspaceId, workspaceId)))\nstats.workflows += workflowsInFolder.length\n}\nawait db.delete(workflowFolder).where(eq(workflowFolder.id, folderId))\nstats.folders += 1\nreturn stats\n}"
"export async function GET(_req: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized knowledge base access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkKnowledgeBaseAccess(id, session.user.id)\nif (!accessCheck.hasAccess) {\nif ('notFound' in accessCheck && accessCheck.notFound) {\nlogger.warn(`[${requestId}] Knowledge base not found: ${id}`)\nreturn NextResponse.json({ error: 'Knowledge base not found' }, { status: 404 })\n}\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted to access unauthorized knowledge base ${id}`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst knowledgeBases = await db\n.select()\n.from(knowledgeBase)\n.where(and(eq(knowledgeBase.id, id), isNull(knowledgeBase.deletedAt)))\n.limit(1)\nif (knowledgeBases.length === 0) {\nreturn NextResponse.json({ error: 'Knowledge base not found' }, { status: 404 })\n}\nlogger.info(`[${requestId}] Retrieved knowledge base: ${id} for user ${session.user.id}`)\nreturn NextResponse.json({\nsuccess: true,\ndata: knowledgeBases[0],\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching knowledge base`, error)\nreturn NextResponse.json({ error: 'Failed to fetch knowledge base' }, { status: 500 })\n}\n}"
"export async function DELETE(_req: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized knowledge base delete attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkKnowledgeBaseWriteAccess(id, session.user.id)\nif (!accessCheck.hasAccess) {\nif ('notFound' in accessCheck && accessCheck.notFound) {\nlogger.warn(`[${requestId}] Knowledge base not found: ${id}`)\nreturn NextResponse.json({ error: 'Knowledge base not found' }, { status: 404 })\n}\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted to delete unauthorized knowledge base ${id}`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nawait db\n.update(knowledgeBase)\n.set({\ndeletedAt: new Date(),\nupdatedAt: new Date(),\n})\n.where(eq(knowledgeBase.id, id))\nlogger.info(`[${requestId}] Knowledge base deleted: ${id} for user ${session.user.id}`)\nreturn NextResponse.json({\nsuccess: true,\ndata: { message: 'Knowledge base deleted successfully' },\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error deleting knowledge base`, error)\nreturn NextResponse.json({ error: 'Failed to delete knowledge base' }, { status: 500 })\n}\n}"
"export async function generateSearchEmbedding(query: string): Promise<number[]> {\nconst openaiApiKey = env.OPENAI_API_KEY\nif (!openaiApiKey) {\nthrow new Error('OPENAI_API_KEY not configured')\n}\ntry {\nconst embedding = await retryWithExponentialBackoff(\nasync () => {\nconst response = await fetch('https:\nmethod: 'POST',\nheaders: {\nAuthorization: `Bearer ${openaiApiKey}`,\n'Content-Type': 'application/json',\n},\nbody: JSON.stringify({\ninput: query,\nmodel: 'text-embedding-3-small',\nencoding_format: 'float',\n}),\n})\nif (!response.ok) {\nconst errorText = await response.text()\nconst error = new APIError(\n`OpenAI API error: ${response.status} ${response.statusText} - ${errorText}`,\nresponse.status\n)\nthrow error\n}\nconst data = await response.json()\nif (!data.data || !Array.isArray(data.data) || data.data.length === 0) {\nthrow new Error('Invalid response format from OpenAI embeddings API')\n}\nreturn data.data[0].embedding\n},\n{\nmaxRetries: 5,\ninitialDelayMs: 1000,\nmaxDelayMs: 30000,\nbackoffMultiplier: 2,\n}\n)\nreturn embedding\n} catch (error) {\nlogger.error('Failed to generate search embedding:', error)\nthrow new Error(\n`Embedding generation failed: ${error instanceof Error ? error.message : 'Unknown error'}`\n)\n}\n}"
"function getTagFilters(filters: Record<string, string>, embedding: any) {\nreturn Object.entries(filters).map(([key, value]) => {\nconst values = value.includes('|OR|') ? value.split('|OR|') : [value]\nlogger.debug(`[getTagFilters] Processing ${key}=`${value}` -> values:`, values)\nconst getColumnForKey = (key: string) => {\nswitch (key) {\ncase 'tag1':\nreturn embedding.tag1\ncase 'tag2':\nreturn embedding.tag2\ncase 'tag3':\nreturn embedding.tag3\ncase 'tag4':\nreturn embedding.tag4\ncase 'tag5':\nreturn embedding.tag5\ncase 'tag6':\nreturn embedding.tag6\ncase 'tag7':\nreturn embedding.tag7\ndefault:\nreturn null\n}\n}\nconst column = getColumnForKey(key)\nif (!column) return sql`1=1`\nif (values.length === 1) {\nlogger.debug(`[getTagFilters] Single value filter: ${key} = ${values[0]}`)\nreturn sql`LOWER(${column}) = LOWER(${values[0]})`\n}\nlogger.debug(`[getTagFilters] OR filter: ${key} IN (${values.join(', ')})`)\nconst orConditions = values.map((v) => sql`LOWER(${column}) = LOWER(${v})`)\nreturn sql`(${sql.join(orConditions, sql` OR `)})`\n})\n}"
"export async function handleTagOnlySearch(params: SearchParams): Promise<SearchResult[]> {\nconst { knowledgeBaseIds, topK, filters } = params\nif (!filters || Object.keys(filters).length === 0) {\nthrow new Error('Tag filters are required for tag-only search')\n}\nlogger.debug(`[handleTagOnlySearch] Executing tag-only search with filters:`, filters)\nconst strategy = getQueryStrategy(knowledgeBaseIds.length, topK)\nif (strategy.useParallel) {\nconst parallelLimit = Math.ceil(topK / knowledgeBaseIds.length) + 5\nconst queryPromises = knowledgeBaseIds.map(async (kbId) => {\nreturn await db\n.select({\nid: embedding.id,\ncontent: embedding.content,\ndocumentId: embedding.documentId,\nchunkIndex: embedding.chunkIndex,\ntag1: embedding.tag1,\ntag2: embedding.tag2,\ntag3: embedding.tag3,\ntag4: embedding.tag4,\ntag5: embedding.tag5,\ntag6: embedding.tag6,\ntag7: embedding.tag7,\ndistance: sql<number>`0`.as('distance'),\nknowledgeBaseId: embedding.knowledgeBaseId,\n})\n.from(embedding)\n.where(\nand(\neq(embedding.knowledgeBaseId, kbId),\neq(embedding.enabled, true),\n...getTagFilters(filters, embedding)\n)\n)\n.limit(parallelLimit)\n})\nconst parallelResults = await Promise.all(queryPromises)\nreturn parallelResults.flat().slice(0, topK)\n}\nreturn await db\n.select({\nid: embedding.id,\ncontent: embedding.content,\ndocumentId: embedding.documentId,\nchunkIndex: embedding.chunkIndex,\ntag1: embedding.tag1,\ntag2: embedding.tag2,\ntag3: embedding.tag3,\ntag4: embedding.tag4,\ntag5: embedding.tag5,\ntag6: embedding.tag6,\ntag7: embedding.tag7,\ndistance: sql<number>`0`.as('distance'),\nknowledgeBaseId: embedding.knowledgeBaseId,\n})\n.from(embedding)\n.where(\nand(\ninArray(embedding.knowledgeBaseId, knowledgeBaseIds),\neq(embedding.enabled, true),\n...getTagFilters(filters, embedding)\n)\n)\n.limit(topK)\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nlogger.info(`[${requestId}] Processing memory get request for ID: ${id}`)\nconst url = new URL(request.url)\nconst workflowId = url.searchParams.get('workflowId')\nif (!workflowId) {\nlogger.warn(`[${requestId}] Missing required parameter: workflowId`)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: 'workflowId parameter is required',\n},\n},\n{ status: 400 }\n)\n}\nconst memories = await db\n.select()\n.from(memory)\n.where(and(eq(memory.key, id), eq(memory.workflowId, workflowId)))\n.orderBy(memory.createdAt)\n.limit(1)\nif (memories.length === 0) {\nlogger.warn(`[${requestId}] Memory not found: ${id} for workflow: ${workflowId}`)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: 'Memory not found',\n},\n},\n{ status: 404 }\n)\n}\nlogger.info(`[${requestId}] Memory retrieved successfully: ${id} for workflow: ${workflowId}`)\nreturn NextResponse.json(\n{\nsuccess: true,\ndata: memories[0],\n},\n{ status: 200 }\n)\n} catch (error: any) {\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: error.message || 'Failed to retrieve memory',\n},\n},\n{ status: 500 }\n)\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nlogger.info(`[${requestId}] Processing memory delete request for ID: ${id}`)\nconst url = new URL(request.url)\nconst workflowId = url.searchParams.get('workflowId')\nif (!workflowId) {\nlogger.warn(`[${requestId}] Missing required parameter: workflowId`)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: 'workflowId parameter is required',\n},\n},\n{ status: 400 }\n)\n}\nconst existingMemory = await db\n.select({ id: memory.id })\n.from(memory)\n.where(and(eq(memory.key, id), eq(memory.workflowId, workflowId)))\n.limit(1)\nif (existingMemory.length === 0) {\nlogger.warn(`[${requestId}] Memory not found: ${id} for workflow: ${workflowId}`)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: 'Memory not found',\n},\n},\n{ status: 404 }\n)\n}\nawait db.delete(memory).where(and(eq(memory.key, id), eq(memory.workflowId, workflowId)))\nlogger.info(`[${requestId}] Memory deleted successfully: ${id} for workflow: ${workflowId}`)\nreturn NextResponse.json(\n{\nsuccess: true,\ndata: { message: 'Memory deleted successfully' },\n},\n{ status: 200 }\n)\n} catch (error: any) {\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: {\nmessage: error.message || 'Failed to delete memory',\n},\n},\n{ status: 500 }\n)\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst { id } = await params\nlogger.debug(`[${requestId}] Deleting schedule with ID: ${id}`)\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized schedule deletion attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst schedules = await db\n.select({\nschedule: workflowSchedule,\nworkflow: {\nid: workflow.id,\nuserId: workflow.userId,\n},\n})\n.from(workflowSchedule)\n.innerJoin(workflow, eq(workflowSchedule.workflowId, workflow.id))\n.where(eq(workflowSchedule.id, id))\n.limit(1)\nif (schedules.length === 0) {\nlogger.warn(`[${requestId}] Schedule not found: ${id}`)\nreturn NextResponse.json({ error: 'Schedule not found' }, { status: 404 })\n}\nif (schedules[0].workflow.userId !== session.user.id) {\nlogger.warn(`[${requestId}] Unauthorized schedule deletion attempt for schedule: ${id}`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 403 })\n}\nawait db.delete(workflowSchedule).where(eq(workflowSchedule.id, id))\nlogger.info(`[${requestId}] Successfully deleted schedule: ${id}`)\nreturn NextResponse.json({ success: true }, { status: 200 })\n} catch (error) {\nlogger.error(`[${requestId}] Error deleting schedule`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized template access attempt for ID: ${id}`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nlogger.debug(`[${requestId}] Fetching template: ${id}`)\nconst result = await db.select().from(templates).where(eq(templates.id, id)).limit(1)\nif (result.length === 0) {\nlogger.warn(`[${requestId}] Template not found: ${id}`)\nreturn NextResponse.json({ error: 'Template not found' }, { status: 404 })\n}\nconst template = result[0]\ntry {\nawait db\n.update(templates)\n.set({\nviews: sql`${templates.views} + 1`,\nupdatedAt: new Date(),\n})\n.where(eq(templates.id, id))\nlogger.debug(`[${requestId}] Incremented view count for template: ${id}`)\n} catch (viewError) {\nlogger.warn(`[${requestId}] Failed to increment view count for template: ${id}`, viewError)\n}\nlogger.info(`[${requestId}] Successfully retrieved template: ${id}`)\nreturn NextResponse.json({\ndata: {\n...template,\nviews: template.views + 1,\n},\n})\n} catch (error: any) {\nlogger.error(`[${requestId}] Error fetching template: ${id}`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function DELETE(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst searchParams = request.nextUrl.searchParams\nconst toolId = searchParams.get('id')\nif (!toolId) {\nlogger.warn(`[${requestId}] Missing tool ID for deletion`)\nreturn NextResponse.json({ error: 'Tool ID is required' }, { status: 400 })\n}\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized custom tool deletion attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst existingTool = await db\n.select()\n.from(customTools)\n.where(eq(customTools.id, toolId))\n.limit(1)\nif (existingTool.length === 0) {\nlogger.warn(`[${requestId}] Tool not found: ${toolId}`)\nreturn NextResponse.json({ error: 'Tool not found' }, { status: 404 })\n}\nif (existingTool[0].userId !== session.user.id) {\nlogger.warn(`[${requestId}] User attempted to delete a tool they don't own: ${toolId}`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 403 })\n}\nawait db.delete(customTools).where(eq(customTools.id, toolId))\nlogger.info(`[${requestId}] Deleted tool: ${toolId}`)\nreturn NextResponse.json({ success: true })\n} catch (error) {\nlogger.error(`[${requestId}] Error deleting custom tool:`, error)\nreturn NextResponse.json({ error: 'Failed to delete custom tool' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest) {\ntry {\nconst session = await getSession()\nlet authenticatedUserId: string | null = session?.user?.id || null\nif (!authenticatedUserId) {\nconst apiKeyHeader = request.headers.get('x-api-key')\nif (apiKeyHeader) {\nconst [apiKeyRecord] = await db\n.select({ userId: apiKeyTable.userId })\n.from(apiKeyTable)\n.where(eq(apiKeyTable.key, apiKeyHeader))\n.limit(1)\nif (apiKeyRecord) {\nauthenticatedUserId = apiKeyRecord.userId\n}\n}\n}\nif (!authenticatedUserId) {\nreturn createErrorResponse('Authentication required', 401)\n}\nconst [subscriptionRecord] = await db\n.select({ plan: subscription.plan })\n.from(subscription)\n.where(eq(subscription.referenceId, authenticatedUserId))\n.limit(1)\nconst subscriptionPlan = (subscriptionRecord?.plan || 'free') as\n| 'free'\n| 'pro'\n| 'team'\n| 'enterprise'\nconst rateLimiter = new RateLimiter()\nconst isApiAuth = !session?.user?.id\nconst triggerType = isApiAuth ? 'api' : 'manual'\nconst syncStatus = await rateLimiter.getRateLimitStatus(\nauthenticatedUserId,\nsubscriptionPlan,\ntriggerType,\nfalse\n)\nconst asyncStatus = await rateLimiter.getRateLimitStatus(\nauthenticatedUserId,\nsubscriptionPlan,\ntriggerType,\ntrue\n)\nreturn NextResponse.json({\nsuccess: true,\nrateLimit: {\nsync: {\nisLimited: syncStatus.remaining === 0,\nlimit: syncStatus.limit,\nremaining: syncStatus.remaining,\nresetAt: syncStatus.resetAt,\n},\nasync: {\nisLimited: asyncStatus.remaining === 0,\nlimit: asyncStatus.limit,\nremaining: asyncStatus.remaining,\nresetAt: asyncStatus.resetAt,\n},\nauthType: triggerType,\n},\n})\n} catch (error: any) {\nlogger.error('Error checking rate limit:', error)\nreturn createErrorResponse(error.message || 'Failed to check rate limit', 500)\n}\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst { id } = await params\nlogger.debug(`[${requestId}] Fetching webhook with ID: ${id}`)\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized webhook access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst webhooks = await db\n.select({\nwebhook: webhook,\nworkflow: {\nid: workflow.id,\nname: workflow.name,\nuserId: workflow.userId,\nworkspaceId: workflow.workspaceId,\n},\n})\n.from(webhook)\n.innerJoin(workflow, eq(webhook.workflowId, workflow.id))\n.where(eq(webhook.id, id))\n.limit(1)\nif (webhooks.length === 0) {\nlogger.warn(`[${requestId}] Webhook not found: ${id}`)\nreturn NextResponse.json({ error: 'Webhook not found' }, { status: 404 })\n}\nconst webhookData = webhooks[0]\nlet hasAccess = false\nif (webhookData.workflow.userId === session.user.id) {\nhasAccess = true\n}\nif (!hasAccess && webhookData.workflow.workspaceId) {\nconst userPermission = await getUserEntityPermissions(\nsession.user.id,\n'workspace',\nwebhookData.workflow.workspaceId\n)\nif (userPermission !== null) {\nhasAccess = true\n}\n}\nif (!hasAccess) {\nlogger.warn(`[${requestId}] User ${session.user.id} denied access to webhook: ${id}`)\nreturn NextResponse.json({ error: 'Access denied' }, { status: 403 })\n}\nlogger.info(`[${requestId}] Successfully retrieved webhook: ${id}`)\nreturn NextResponse.json({ webhook: webhooks[0] }, { status: 200 })\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching webhook`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function GET(request: Request) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst startTime = Date.now()\nconst url = new URL(request.url)\nconst workspaceId = url.searchParams.get('workspaceId')\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized workflow access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst userId = session.user.id\nif (workspaceId) {\nconst workspaceExists = await db\n.select({ id: workspace.id })\n.from(workspace)\n.where(eq(workspace.id, workspaceId))\n.then((rows) => rows.length > 0)\nif (!workspaceExists) {\nlogger.warn(\n`[${requestId}] Attempt to fetch workflows for non-existent workspace: ${workspaceId}`\n)\nreturn NextResponse.json(\n{ error: 'Workspace not found', code: 'WORKSPACE_NOT_FOUND' },\n{ status: 404 }\n)\n}\nconst userRole = await verifyWorkspaceMembership(userId, workspaceId)\nif (!userRole) {\nlogger.warn(\n`[${requestId}] User ${userId} attempted to access workspace ${workspaceId} without membership`\n)\nreturn NextResponse.json(\n{ error: 'Access denied to this workspace', code: 'WORKSPACE_ACCESS_DENIED' },\n{ status: 403 }\n)\n}\nmigrateOrphanedWorkflows(userId, workspaceId).catch((error) => {\nlogger.error(`[${requestId}] Error migrating orphaned workflows:`, error)\n})\n}\nlet workflows\nif (workspaceId) {\nworkflows = await db.select().from(workflow).where(eq(workflow.workspaceId, workspaceId))\n} else {\nworkflows = await db.select().from(workflow).where(eq(workflow.userId, userId))\n}\nconst elapsed = Date.now() - startTime\nreturn NextResponse.json({ data: workflows }, { status: 200 })\n} catch (error: any) {\nconst elapsed = Date.now() - startTime\nlogger.error(`[${requestId}] Workflow fetch error after ${elapsed}ms`, error)\nreturn NextResponse.json({ error: error.message }, { status: 500 })\n}\n}"
"async function migrateOrphanedWorkflows(userId: string, workspaceId: string) {\ntry {\nconst orphanedWorkflows = await db\n.select({ id: workflow.id })\n.from(workflow)\n.where(and(eq(workflow.userId, userId), isNull(workflow.workspaceId)))\nif (orphanedWorkflows.length === 0) {\nreturn\n}\nlogger.info(\n`Migrating ${orphanedWorkflows.length} orphaned workflows to workspace ${workspaceId}`\n)\ntry {\nawait db\n.update(workflow)\n.set({\nworkspaceId: workspaceId,\nupdatedAt: new Date(),\n})\n.where(and(eq(workflow.userId, userId), isNull(workflow.workspaceId)))\nlogger.info(\n`Successfully migrated ${orphanedWorkflows.length} workflows to workspace ${workspaceId}`\n)\n} catch (batchError) {\nlogger.warn('Batch migration failed, falling back to individual updates:', batchError)\nfor (const { id } of orphanedWorkflows) {\ntry {\nawait db\n.update(workflow)\n.set({\nworkspaceId: workspaceId,\nupdatedAt: new Date(),\n})\n.where(eq(workflow.id, id))\n} catch (updateError) {\nlogger.error(`Failed to migrate workflow ${id}:`, updateError)\n}\n}\n}\n} catch (error) {\nlogger.error('Error migrating orphaned workflows:', error)\n}\n}"
"export async function PATCH(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst { id } = await params\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst workspaceId = id\nconst userPermission = await getUserEntityPermissions(session.user.id, 'workspace', workspaceId)\nif (userPermission !== 'admin') {\nreturn NextResponse.json({ error: 'Insufficient permissions' }, { status: 403 })\n}\ntry {\nconst { name } = await request.json()\nif (!name) {\nreturn NextResponse.json({ error: 'Name is required' }, { status: 400 })\n}\nawait db\n.update(workspace)\n.set({\nname,\nupdatedAt: new Date(),\n})\n.where(eq(workspace.id, workspaceId))\nconst updatedWorkspace = await db\n.select()\n.from(workspace)\n.where(eq(workspace.id, workspaceId))\n.then((rows) => rows[0])\nreturn NextResponse.json({\nworkspace: {\n...updatedWorkspace,\npermissions: userPermission,\n},\n})\n} catch (error) {\nconsole.error('Error updating workspace:', error)\nreturn NextResponse.json({ error: 'Failed to update workspace' }, { status: 500 })\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\nconst { id } = await params\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst workspaceId = id\nconst userPermission = await getUserEntityPermissions(session.user.id, 'workspace', workspaceId)\nif (userPermission !== 'admin') {\nreturn NextResponse.json({ error: 'Insufficient permissions' }, { status: 403 })\n}\ntry {\nlogger.info(`Deleting workspace ${workspaceId} for user ${session.user.id}`)\nawait db.transaction(async (tx) => {\nawait tx.delete(workflow).where(eq(workflow.workspaceId, workspaceId))\nawait tx\n.update(knowledgeBase)\n.set({ workspaceId: null, updatedAt: new Date() })\n.where(eq(knowledgeBase.workspaceId, workspaceId))\nawait tx\n.delete(permissions)\n.where(and(eq(permissions.entityType, 'workspace'), eq(permissions.entityId, workspaceId)))\nawait tx.delete(workspace).where(eq(workspace.id, workspaceId))\nlogger.info(`Successfully deleted workspace ${workspaceId} and all related data`)\n})\nreturn NextResponse.json({ success: true })\n} catch (error) {\nlogger.error(`Error deleting workspace ${workspaceId}:`, error)\nreturn NextResponse.json({ error: 'Failed to delete workspace' }, { status: 500 })\n}\n}"
"async function sendInvitationEmail({\nto,\ninviterName,\nworkspaceName,\ntoken,\n}: {\nto: string\ninviterName: string\nworkspaceName: string\ntoken: string\n}) {\ntry {\nconst baseUrl = env.NEXT_PUBLIC_APP_URL || 'https:\nconst invitationLink = `${baseUrl}/invite/${token}?token=${token}`\nconst emailHtml = await render(\nWorkspaceInvitationEmail({\nworkspaceName,\ninviterName,\ninvitationLink,\n})\n)\nif (!resend) {\nlogger.error('RESEND_API_KEY not configured')\nreturn NextResponse.json(\n{\nerror:\n'Email service not configured. Please set RESEND_API_KEY in environment variables.',\n},\n{ status: 500 }\n)\n}\nconst emailDomain = env.EMAIL_DOMAIN || getEmailDomain()\nconst fromAddress = `noreply@${emailDomain}`\nlogger.info(`Attempting to send email from ${fromAddress} to ${to}`)\nconst result = await resend.emails.send({\nfrom: fromAddress,\nto,\nsubject: `You've been invited to join `${workspaceName}` on Sim`,\nhtml: emailHtml,\n})\nlogger.info(`Invitation email sent successfully to ${to}`, { result })\n} catch (error) {\nlogger.error('Error sending invitation email:', error)\n}\n}"
"export async function POST(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst body = await request.json()\nconst { yamlContent } = ParseRequestSchema.parse(body)\nlogger.info(`[${requestId}] Parsing YAML`, {\ncontentLength: yamlContent.length,\nhasApiKey: !!SIM_AGENT_API_KEY,\n})\nconst blocks = getAllBlocks()\nconst blockRegistry = blocks.reduce(\n(acc, block) => {\nconst blockType = block.type\nacc[blockType] = {\n...block,\nid: blockType,\nsubBlocks: block.subBlocks || [],\noutputs: block.outputs || {},\n} as any\nreturn acc\n},\n{} as Record<string, BlockConfig>\n)\nconst response = await fetch(`${SIM_AGENT_API_URL}/api/yaml/parse`, {\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n...(SIM_AGENT_API_KEY && { 'x-api-key': SIM_AGENT_API_KEY }),\n},\nbody: JSON.stringify({\nyamlContent,\nblockRegistry,\nutilities: {\ngenerateLoopBlocks: generateLoopBlocks.toString(),\ngenerateParallelBlocks: generateParallelBlocks.toString(),\nresolveOutputType: resolveOutputType.toString(),\n},\n}),\n})\nif (!response.ok) {\nconst errorText = await response.text()\nlogger.error(`[${requestId}] Sim agent API error:`, {\nstatus: response.status,\nerror: errorText,\n})\nreturn NextResponse.json(\n{ success: false, errors: [`Sim agent API error: ${response.statusText}`] },\n{ status: response.status }\n)\n}\nconst result = await response.json()\nreturn NextResponse.json(result)\n} catch (error) {\nlogger.error(`[${requestId}] YAML parse failed:`, error)\nif (error instanceof z.ZodError) {\nreturn NextResponse.json(\n{ success: false, errors: error.errors.map((e) => e.message) },\n{ status: 400 }\n)\n}\nreturn NextResponse.json(\n{\nsuccess: false,\nerrors: [error instanceof Error ? error.message : 'Unknown error'],\n},\n{ status: 500 }\n)\n}\n}"
"export default function KnowledgeLoading() {\nconst breadcrumbs = [{ id: 'knowledge', label: 'Knowledge' }]\nreturn (\n<div className='flex h-screen flex-col pl-64'>\n{}\n<KnowledgeHeader breadcrumbs={breadcrumbs} />\n<div className='flex flex-1 overflow-hidden'>\n<div className='flex flex-1 flex-col overflow-hidden'>\n{}\n<div className='flex-1 overflow-auto'>\n<div className='px-6 pb-6'>\n{}\n<div className='mb-4 flex items-center justify-between pt-1'>\n<div className='relative max-w-md flex-1'>\n<div className='relative flex items-center'>\n<Search className='-translate-y-1/2 pointer-events-none absolute top-1/2 left-3 h-[18px] w-[18px] transform text-muted-foreground' />\n<input\ntype='text'\nplaceholder='Search knowledge bases...'\ndisabled\nclassName='h-10 w-full rounded-md border bg-background px-9 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:font-medium file:text-sm placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50'\n/>\n</div>\n</div>\n<Button\ndisabled\nsize='sm'\nclassName='flex items-center gap-1 bg-[#701FFC] font-[480] text-primary-foreground shadow-[0_0_0_0_#701FFC] transition-all duration-200 hover:bg-[#6518E6] hover:shadow-[0_0_0_4px_rgba(127,47,255,0.15)] disabled:opacity-50'\n>\n<Plus className='h-3.5 w-3.5' />\n<span>Create</span>\n</Button>\n</div>\n{}\n<KnowledgeBaseCardSkeletonGrid count={8} />\n</div>\n</div>\n</div>\n</div>\n</div>\n)\n}"
"export function WorkspacePermissionsProvider({ children }: WorkspacePermissionsProviderProps) {\nconst params = useParams()\nconst workspaceId = params?.workspaceId as string\nconst [isOfflineMode, setIsOfflineMode] = useState(false)\nconst { hasOperationError } = useCollaborativeWorkflow()\nuseEffect(() => {\nif (hasOperationError) {\nsetIsOfflineMode(true)\n}\n}, [hasOperationError])\nconst {\npermissions: workspacePermissions,\nloading: permissionsLoading,\nerror: permissionsError,\nupdatePermissions,\n} = useWorkspacePermissions(workspaceId)\nconst baseUserPermissions = useUserPermissions(\nworkspacePermissions,\npermissionsLoading,\npermissionsError\n)\nconst userPermissions = useMemo((): WorkspaceUserPermissions & { isOfflineMode?: boolean } => {\nif (isOfflineMode) {\nreturn {\n...baseUserPermissions,\ncanEdit: false,\ncanAdmin: false,\ncanRead: baseUserPermissions.canRead,\nisOfflineMode: true,\n}\n}\nreturn {\n...baseUserPermissions,\nisOfflineMode: false,\n}\n}, [baseUserPermissions, isOfflineMode])\nconst contextValue = useMemo(\n() => ({\nworkspacePermissions,\npermissionsLoading,\npermissionsError,\nupdatePermissions,\nuserPermissions,\nsetOfflineMode: setIsOfflineMode,\n}),\n[workspacePermissions, permissionsLoading, permissionsError, updatePermissions, userPermissions]\n)\nreturn (\n<WorkspacePermissionsContext.Provider value={contextValue}>\n{children}\n</WorkspacePermissionsContext.Provider>\n)\n}"
"export default function WorkflowsPage() {\nconst router = useRouter()\nconst { workflows, isLoading, loadWorkflows } = useWorkflowRegistry()\nconst [hasInitialized, setHasInitialized] = useState(false)\nconst params = useParams()\nconst workspaceId = params.workspaceId as string\nuseEffect(() => {\nconst initializeWorkspace = async () => {\ntry {\nawait loadWorkflows(workspaceId)\nsetHasInitialized(true)\n} catch (error) {\nconsole.error('Failed to load workflows for workspace:', error)\nsetHasInitialized(true)\n}\n}\nif (!hasInitialized) {\ninitializeWorkspace()\n}\n}, [workspaceId, loadWorkflows, hasInitialized])\nuseEffect(() => {\nif (!hasInitialized || isLoading) return\nconst workflowIds = Object.keys(workflows)\nconst workspaceWorkflows = workflowIds.filter((id) => {\nconst workflow = workflows[id]\nreturn workflow.workspaceId === workspaceId\n})\nif (workspaceWorkflows.length > 0) {\nrouter.replace(`/workspace/${workspaceId}/w/${workspaceWorkflows[0]}`)\n}\n}, [hasInitialized, isLoading, workflows, workspaceId, router])\nreturn (\n<div className='flex h-screen items-center justify-center'>\n<div className='text-center'>\n<div className='mx-auto mb-4'>\n<LoadingAgent size='lg' />\n</div>\n</div>\n</div>\n)\n}"
"async createSnapshotWithDeduplication(\nworkflowId: string,\nstate: WorkflowState\n): Promise<SnapshotCreationResult> {\nconst stateHash = this.computeStateHash(state)\nconst existingSnapshot = await this.getSnapshotByHash(workflowId, stateHash)\nif (existingSnapshot) {\nlogger.debug(`Reusing existing snapshot for workflow ${workflowId} with hash ${stateHash}`)\nreturn {\nsnapshot: existingSnapshot,\nisNew: false,\n}\n}\nconst snapshotData: WorkflowExecutionSnapshotInsert = {\nid: uuidv4(),\nworkflowId,\nstateHash,\nstateData: state,\n}\nconst [newSnapshot] = await db\n.insert(workflowExecutionSnapshots)\n.values(snapshotData)\n.returning()\nlogger.debug(`Created new snapshot for workflow ${workflowId} with hash ${stateHash}`)\nlogger.debug(`Stored full state with ${Object.keys(state.blocks || {}).length} blocks`)\nreturn {\nsnapshot: {\n...newSnapshot,\nstateData: newSnapshot.stateData as WorkflowState,\ncreatedAt: newSnapshot.createdAt.toISOString(),\n},\nisNew: true,\n}\n}"
"private normalizeStateForHashing(state: WorkflowState): any {\nconst normalizedEdges = (state.edges || [])\n.map((edge) => ({\nsource: edge.source,\nsourceHandle: edge.sourceHandle,\ntarget: edge.target,\ntargetHandle: edge.targetHandle,\n}))\n.sort((a, b) =>\n`${a.source}-${a.sourceHandle}-${a.target}-${a.targetHandle}`.localeCompare(\n`${b.source}-${b.sourceHandle}-${b.target}-${b.targetHandle}`\n)\n)\nconst normalizedBlocks: Record<string, any> = {}\nfor (const [blockId, block] of Object.entries(state.blocks || {})) {\nconst { position, ...blockWithoutPosition } = block\nconst subBlocks = blockWithoutPosition.subBlocks || {}\nconst normalizedSubBlocks: Record<string, any> = {}\nfor (const [subBlockId, subBlock] of Object.entries(subBlocks)) {\nconst value = subBlock.value ?? null\nnormalizedSubBlocks[subBlockId] = {\ntype: subBlock.type,\nvalue: this.normalizeValue(value),\n...Object.fromEntries(\nObject.entries(subBlock).filter(([key]) => key !== 'value' && key !== 'type')\n),\n}\n}\nnormalizedBlocks[blockId] = {\n...blockWithoutPosition,\nsubBlocks: normalizedSubBlocks,\n}\n}\nconst normalizedLoops: Record<string, any> = {}\nfor (const [loopId, loop] of Object.entries(state.loops || {})) {\nnormalizedLoops[loopId] = this.normalizeValue(loop)\n}\nconst normalizedParallels: Record<string, any> = {}\nfor (const [parallelId, parallel] of Object.entries(state.parallels || {})) {\nnormalizedParallels[parallelId] = this.normalizeValue(parallel)\n}\nreturn {\nblocks: normalizedBlocks,\nedges: normalizedEdges,\nloops: normalizedLoops,\nparallels: normalizedParallels,\n}\n}"
"export async function POST(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthenticated disconnect request rejected`)\nreturn NextResponse.json({ error: 'User not authenticated' }, { status: 401 })\n}\nconst { provider, providerId } = await request.json()\nif (!provider) {\nlogger.warn(`[${requestId}] Missing provider in disconnect request`)\nreturn NextResponse.json({ error: 'Provider is required' }, { status: 400 })\n}\nlogger.info(`[${requestId}] Processing OAuth disconnect request`, {\nprovider,\nhasProviderId: !!providerId,\n})\nif (providerId) {\nawait db\n.delete(account)\n.where(and(eq(account.userId, session.user.id), eq(account.providerId, providerId)))\n} else {\nawait db\n.delete(account)\n.where(\nand(\neq(account.userId, session.user.id),\nor(eq(account.providerId, provider), like(account.providerId, `${provider}-%`))\n)\n)\n}\nreturn NextResponse.json({ success: true }, { status: 200 })\n} catch (error) {\nlogger.error(`[${requestId}] Error disconnecting OAuth provider`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function POST(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nlogger.info(`[${requestId}] OAuth token API POST request received`)\ntry {\nconst body = await request.json()\nconst { credentialId, workflowId } = body\nif (!credentialId) {\nlogger.warn(`[${requestId}] Credential ID is required`)\nreturn NextResponse.json({ error: 'Credential ID is required' }, { status: 400 })\n}\nconst userId = await getUserId(requestId, workflowId)\nif (!userId) {\nreturn NextResponse.json(\n{ error: workflowId ? 'Workflow not found' : 'User not authenticated' },\n{ status: workflowId ? 404 : 401 }\n)\n}\nconst credential = await getCredential(requestId, credentialId, userId)\nif (!credential) {\nlogger.error(`[${requestId}] Credential not found: ${credentialId}`)\nreturn NextResponse.json({ error: 'Credential not found' }, { status: 404 })\n}\ntry {\nconst { accessToken } = await refreshTokenIfNeeded(requestId, credential, credentialId)\nreturn NextResponse.json({ accessToken }, { status: 200 })\n} catch (error) {\nlogger.error(`[${requestId}] Failed to refresh access token:`, error)\nreturn NextResponse.json({ error: 'Failed to refresh access token' }, { status: 401 })\n}\n} catch (error) {\nlogger.error(`[${requestId}] Error getting access token`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst { searchParams } = new URL(request.url)\nconst credentialId = searchParams.get('credentialId')\nif (!credentialId) {\nlogger.warn(`[${requestId}] Missing credential ID`)\nreturn NextResponse.json({ error: 'Credential ID is required' }, { status: 400 })\n}\nconst userId = await getUserId(requestId)\nif (!userId) {\nreturn NextResponse.json({ error: 'User not authenticated' }, { status: 401 })\n}\nconst credential = await getCredential(requestId, credentialId, userId)\nif (!credential) {\nreturn NextResponse.json({ error: 'Credential not found' }, { status: 404 })\n}\nif (!credential.accessToken) {\nlogger.warn(`[${requestId}] No access token available for credential`)\nreturn NextResponse.json({ error: 'No access token available' }, { status: 400 })\n}\ntry {\nconst { accessToken } = await refreshTokenIfNeeded(requestId, credential, credentialId)\nreturn NextResponse.json({ accessToken }, { status: 200 })\n} catch (_error) {\nreturn NextResponse.json({ error: 'Failed to refresh access token' }, { status: 401 })\n}\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching access token`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function PUT(\nrequest: NextRequest,\n{ params }: { params: Promise<{ subdomain: string }> }\n) {\nconst { subdomain } = await params\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nlogger.debug(`[${requestId}] Verifying OTP for subdomain: ${subdomain}`)\nlet body\ntry {\nbody = await request.json()\nconst { email, otp } = otpVerifySchema.parse(body)\nconst deploymentResult = await db\n.select({\nid: chat.id,\nauthType: chat.authType,\n})\n.from(chat)\n.where(eq(chat.subdomain, subdomain))\n.limit(1)\nif (deploymentResult.length === 0) {\nlogger.warn(`[${requestId}] Chat not found for subdomain: ${subdomain}`)\nreturn addCorsHeaders(createErrorResponse('Chat not found', 404), request)\n}\nconst deployment = deploymentResult[0]\nconst storedOTP = await getOTP(email, deployment.id)\nif (!storedOTP) {\nreturn addCorsHeaders(\ncreateErrorResponse('No verification code found, request a new one', 400),\nrequest\n)\n}\nif (storedOTP !== otp) {\nreturn addCorsHeaders(createErrorResponse('Invalid verification code', 400), request)\n}\nawait deleteOTP(email, deployment.id)\nconst response = addCorsHeaders(createSuccessResponse({ authenticated: true }), request)\nsetChatAuthCookie(response, deployment.id, deployment.authType)\nreturn response\n} catch (error: any) {\nif (error instanceof z.ZodError) {\nreturn addCorsHeaders(\ncreateErrorResponse(error.errors[0]?.message || 'Invalid request', 400),\nrequest\n)\n}\nthrow error\n}\n} catch (error: any) {\nlogger.error(`[${requestId}] Error verifying OTP:`, error)\nreturn addCorsHeaders(\ncreateErrorResponse(error.message || 'Failed to process request', 500),\nrequest\n)\n}\n}"
"export async function GET(request: Request) {\nconst session = await getSession()\nif (!session || !session.user) {\nreturn createErrorResponse('Unauthorized', 401)\n}\ntry {\nconst { searchParams } = new URL(request.url)\nconst subdomain = searchParams.get('subdomain')\nif (!subdomain) {\nreturn createErrorResponse('Missing subdomain parameter', 400)\n}\nif (!/^[a-z0-9-]+$/.test(subdomain)) {\nreturn NextResponse.json(\n{\navailable: false,\nerror: 'Invalid subdomain format',\n},\n{ status: 400 }\n)\n}\nconst reservedSubdomains = [\n'telemetry',\n'docs',\n'api',\n'admin',\n'www',\n'app',\n'auth',\n'blog',\n'help',\n'support',\n'admin',\n'qa',\n]\nif (reservedSubdomains.includes(subdomain)) {\nreturn NextResponse.json(\n{\navailable: false,\nerror: 'This subdomain is reserved',\n},\n{ status: 400 }\n)\n}\nconst existingDeployment = await db\n.select()\n.from(chat)\n.where(eq(chat.subdomain, subdomain))\n.limit(1)\nreturn createSuccessResponse({\navailable: existingDeployment.length === 0,\nsubdomain,\n})\n} catch (error) {\nlogger.error('Error checking subdomain availability:', error)\nreturn createErrorResponse('Failed to check subdomain availability', 500)\n}\n}"
"export async function POST(req: NextRequest) {\nconst tracker = createRequestTracker()\ntry {\nconst { userId, isAuthenticated } = await authenticateCopilotRequestSessionOnly()\nif (!isAuthenticated || !userId) {\nreturn createUnauthorizedResponse()\n}\nconst body = await req.json()\nconst { chatId, messages } = UpdateMessagesSchema.parse(body)\nlogger.info(`[${tracker.requestId}] Updating chat messages`, {\nuserId,\nchatId,\nmessageCount: messages.length,\n})\nconst [chat] = await db\n.select()\n.from(copilotChats)\n.where(and(eq(copilotChats.id, chatId), eq(copilotChats.userId, userId)))\n.limit(1)\nif (!chat) {\nreturn createNotFoundResponse('Chat not found or unauthorized')\n}\nawait db\n.update(copilotChats)\n.set({\nmessages: messages,\nupdatedAt: new Date(),\n})\n.where(eq(copilotChats.id, chatId))\nlogger.info(`[${tracker.requestId}] Successfully updated chat messages`, {\nchatId,\nnewMessageCount: messages.length,\n})\nreturn NextResponse.json({\nsuccess: true,\nmessageCount: messages.length,\n})\n} catch (error) {\nlogger.error(`[${tracker.requestId}] Error updating chat messages:`, error)\nreturn createInternalServerErrorResponse('Failed to update chat messages')\n}\n}"
"async function downloadKBFile(cloudKey: string): Promise<Buffer> {\nconst storageProvider = getStorageProvider()\nif (storageProvider === 'blob') {\nlogger.info(`Downloading KB file from Azure Blob Storage: ${cloudKey}`)\nconst { getBlobServiceClient } = await import('@/lib/uploads/blob/blob-client')\nconst blobServiceClient = getBlobServiceClient()\nconst containerClient = blobServiceClient.getContainerClient(BLOB_KB_CONFIG.containerName)\nconst blockBlobClient = containerClient.getBlockBlobClient(cloudKey)\nconst downloadBlockBlobResponse = await blockBlobClient.download()\nif (!downloadBlockBlobResponse.readableStreamBody) {\nthrow new Error('Failed to get readable stream from blob download')\n}\nreturn await streamToBuffer(downloadBlockBlobResponse.readableStreamBody)\n}\nif (storageProvider === 's3') {\nlogger.info(`Downloading KB file from S3: ${cloudKey}`)\nconst { getS3Client } = await import('@/lib/uploads/s3/s3-client')\nconst { GetObjectCommand } = await import('@aws-sdk/client-s3')\nconst s3Client = getS3Client()\nconst command = new GetObjectCommand({\nBucket: S3_KB_CONFIG.bucket,\nKey: cloudKey,\n})\nconst response = await s3Client.send(command)\nif (!response.Body) {\nthrow new Error('No body in S3 response')\n}\nconst stream = response.Body as any\nreturn new Promise<Buffer>((resolve, reject) => {\nconst chunks: Buffer[] = []\nstream.on('data', (chunk: Buffer) => chunks.push(chunk))\nstream.on('end', () => resolve(Buffer.concat(chunks)))\nstream.on('error', reject)\n})\n}\nthrow new Error(`Unsupported storage provider for KB files: ${storageProvider}`)\n}"
"async function processDocumentTags(\nknowledgeBaseId: string,\ntagData: Array<{ tagName: string; fieldType: string; value: string }>,\nrequestId: string\n): Promise<Record<string, string | null>> {\nconst result: Record<string, string | null> = {}\nconst textSlots = getSlotsForFieldType('text')\ntextSlots.forEach((slot) => {\nresult[slot] = null\n})\nif (!Array.isArray(tagData) || tagData.length === 0) {\nreturn result\n}\ntry {\nconst existingDefinitions = await db\n.select()\n.from(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId))\nconst existingByName = new Map(existingDefinitions.map((def) => [def.displayName, def]))\nconst existingBySlot = new Map(existingDefinitions.map((def) => [def.tagSlot, def]))\nfor (const tag of tagData) {\nif (!tag.tagName?.trim() || !tag.value?.trim()) continue\nconst tagName = tag.tagName.trim()\nconst fieldType = tag.fieldType\nconst value = tag.value.trim()\nlet targetSlot: string | null = null\nconst existingDef = existingByName.get(tagName)\nif (existingDef) {\ntargetSlot = existingDef.tagSlot\n} else {\ntargetSlot = await getNextAvailableSlot(knowledgeBaseId, fieldType, existingBySlot)\nif (targetSlot) {\nconst newDefinition = {\nid: crypto.randomUUID(),\nknowledgeBaseId,\ntagSlot: targetSlot as any,\ndisplayName: tagName,\nfieldType,\ncreatedAt: new Date(),\nupdatedAt: new Date(),\n}\nawait db.insert(knowledgeBaseTagDefinitions).values(newDefinition)\nexistingBySlot.set(targetSlot as any, newDefinition)\nlogger.info(`[${requestId}] Created tag definition: ${tagName} -> ${targetSlot}`)\n}\n}\nif (targetSlot) {\nresult[targetSlot] = value\n}\n}\nreturn result\n} catch (error) {\nlogger.error(`[${requestId}] Error processing document tags:`, error)\nreturn result\n}\n}"
"async function processDocumentsWithConcurrencyControl(\ncreatedDocuments: Array<{\ndocumentId: string\nfilename: string\nfileUrl: string\nfileSize: number\nmimeType: string\n}>,\nknowledgeBaseId: string,\nprocessingOptions: {\nchunkSize: number\nminCharactersPerChunk: number\nrecipe: string\nlang: string\nchunkOverlap: number\n},\nrequestId: string\n): Promise<void> {\nconst totalDocuments = createdDocuments.length\nconst batches = []\nfor (let i = 0; i < totalDocuments; i += PROCESSING_CONFIG.batchSize) {\nbatches.push(createdDocuments.slice(i, i + PROCESSING_CONFIG.batchSize))\n}\nlogger.info(`[${requestId}] Processing ${totalDocuments} documents in ${batches.length} batches`)\nfor (const [batchIndex, batch] of batches.entries()) {\nlogger.info(\n`[${requestId}] Starting batch ${batchIndex + 1}/${batches.length} with ${batch.length} documents`\n)\nawait processBatchWithConcurrency(batch, knowledgeBaseId, processingOptions, requestId)\nif (batchIndex < batches.length - 1) {\nawait new Promise((resolve) => setTimeout(resolve, PROCESSING_CONFIG.delayBetweenBatches))\n}\n}\nlogger.info(`[${requestId}] Completed processing initiation for all ${totalDocuments} documents`)\n}"
"export async function GET(req: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId } = await params\ntry {\nlogger.info(`[${requestId}] Getting tag definitions for knowledge base ${knowledgeBaseId}`)\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkKnowledgeBaseAccess(knowledgeBaseId, session.user.id)\nif (!accessCheck.hasAccess) {\nreturn NextResponse.json({ error: 'Forbidden' }, { status: 403 })\n}\nconst tagDefinitions = await db\n.select({\nid: knowledgeBaseTagDefinitions.id,\ntagSlot: knowledgeBaseTagDefinitions.tagSlot,\ndisplayName: knowledgeBaseTagDefinitions.displayName,\nfieldType: knowledgeBaseTagDefinitions.fieldType,\ncreatedAt: knowledgeBaseTagDefinitions.createdAt,\nupdatedAt: knowledgeBaseTagDefinitions.updatedAt,\n})\n.from(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId))\n.orderBy(knowledgeBaseTagDefinitions.tagSlot)\nlogger.info(`[${requestId}] Retrieved ${tagDefinitions.length} tag definitions`)\nreturn NextResponse.json({\nsuccess: true,\ndata: tagDefinitions,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error getting tag definitions`, error)\nreturn NextResponse.json({ error: 'Failed to get tag definitions' }, { status: 500 })\n}\n}"
"export async function GET(\n_request: NextRequest,\n{ params }: { params: Promise<{ executionId: string }> }\n) {\ntry {\nconst { executionId } = await params\nlogger.debug(`Fetching frozen canvas data for execution: ${executionId}`)\nconst [workflowLog] = await db\n.select()\n.from(workflowExecutionLogs)\n.where(eq(workflowExecutionLogs.executionId, executionId))\n.limit(1)\nif (!workflowLog) {\nreturn NextResponse.json({ error: 'Workflow execution not found' }, { status: 404 })\n}\nconst [snapshot] = await db\n.select()\n.from(workflowExecutionSnapshots)\n.where(eq(workflowExecutionSnapshots.id, workflowLog.stateSnapshotId))\n.limit(1)\nif (!snapshot) {\nreturn NextResponse.json({ error: 'Workflow state snapshot not found' }, { status: 404 })\n}\nconst response = {\nexecutionId,\nworkflowId: workflowLog.workflowId,\nworkflowState: snapshot.stateData,\nexecutionMetadata: {\ntrigger: workflowLog.trigger,\nstartedAt: workflowLog.startedAt.toISOString(),\nendedAt: workflowLog.endedAt?.toISOString(),\ntotalDurationMs: workflowLog.totalDurationMs,\nblockStats: {\ntotal: workflowLog.blockCount,\nsuccess: workflowLog.successCount,\nerror: workflowLog.errorCount,\nskipped: workflowLog.skippedCount,\n},\ncost: {\ntotal: workflowLog.totalCost ? Number.parseFloat(workflowLog.totalCost) : null,\ninput: workflowLog.totalInputCost ? Number.parseFloat(workflowLog.totalInputCost) : null,\noutput: workflowLog.totalOutputCost\n? Number.parseFloat(workflowLog.totalOutputCost)\n: null,\n},\ntotalTokens: workflowLog.totalTokens,\n},\n}\nlogger.debug(`Successfully fetched frozen canvas data for execution: ${executionId}`)\nlogger.debug(\n`Workflow state contains ${Object.keys((snapshot.stateData as any)?.blocks || {}).length} blocks`\n)\nreturn NextResponse.json(response)\n} catch (error) {\nlogger.error('Error fetching frozen canvas data:', error)\nreturn NextResponse.json({ error: 'Failed to fetch frozen canvas data' }, { status: 500 })\n}\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { id: organizationId } = await params\nconst memberEntry = await db\n.select()\n.from(member)\n.where(and(eq(member.organizationId, organizationId), eq(member.userId, session.user.id)))\n.limit(1)\nif (memberEntry.length === 0) {\nreturn NextResponse.json(\n{ error: 'Forbidden - Not a member of this organization' },\n{ status: 403 }\n)\n}\nconst userRole = memberEntry[0].role\nconst hasAdminAccess = ['owner', 'admin'].includes(userRole)\nif (!hasAdminAccess) {\nreturn NextResponse.json({ error: 'Forbidden - Admin access required' }, { status: 403 })\n}\nconst invitations = await db\n.select({\nid: invitation.id,\nemail: invitation.email,\nrole: invitation.role,\nstatus: invitation.status,\nexpiresAt: invitation.expiresAt,\ncreatedAt: invitation.createdAt,\ninviterName: user.name,\ninviterEmail: user.email,\n})\n.from(invitation)\n.leftJoin(user, eq(invitation.inviterId, user.id))\n.where(eq(invitation.organizationId, organizationId))\n.orderBy(invitation.createdAt)\nreturn NextResponse.json({\nsuccess: true,\ndata: {\ninvitations,\nuserRole,\n},\n})\n} catch (error) {\nlogger.error('Failed to get organization invitations', {\norganizationId: (await params).id,\nerror,\n})\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst { id: organizationId } = await params\nconst url = new URL(request.url)\nconst invitationId = url.searchParams.get('invitationId')\nif (!invitationId) {\nreturn NextResponse.json(\n{ error: 'Invitation ID is required as query parameter' },\n{ status: 400 }\n)\n}\nconst memberEntry = await db\n.select()\n.from(member)\n.where(and(eq(member.organizationId, organizationId), eq(member.userId, session.user.id)))\n.limit(1)\nif (memberEntry.length === 0) {\nreturn NextResponse.json(\n{ error: 'Forbidden - Not a member of this organization' },\n{ status: 403 }\n)\n}\nif (!['owner', 'admin'].includes(memberEntry[0].role)) {\nreturn NextResponse.json({ error: 'Forbidden - Admin access required' }, { status: 403 })\n}\nconst result = await db\n.update(invitation)\n.set({\nstatus: 'cancelled',\n})\n.where(\nand(\neq(invitation.id, invitationId),\neq(invitation.organizationId, organizationId),\neq(invitation.status, 'pending')\n)\n)\n.returning()\nif (result.length === 0) {\nreturn NextResponse.json(\n{ error: 'Invitation not found or already processed' },\n{ status: 404 }\n)\n}\nlogger.info('Organization invitation cancelled', {\norganizationId,\ninvitationId,\ncancelledBy: session.user.id,\nemail: result[0].email,\n})\nreturn NextResponse.json({\nsuccess: true,\nmessage: 'Invitation cancelled successfully',\n})\n} catch (error) {\nlogger.error('Failed to cancel organization invitation', {\norganizationId: (await params).id,\nerror,\n})\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function DELETE(\nrequest: NextRequest,\n{ params }: { params: Promise<{ id: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized unstar attempt for template: ${id}`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nlogger.debug(`[${requestId}] Removing star for template: ${id}, user: ${session.user.id}`)\nconst existingStar = await db\n.select({ id: templateStars.id })\n.from(templateStars)\n.where(and(eq(templateStars.templateId, id), eq(templateStars.userId, session.user.id)))\n.limit(1)\nif (existingStar.length === 0) {\nlogger.info(`[${requestId}] No star found to remove for template: ${id}`)\nreturn NextResponse.json({ message: 'Template not starred' }, { status: 200 })\n}\nawait db.transaction(async (tx) => {\nawait tx\n.delete(templateStars)\n.where(and(eq(templateStars.templateId, id), eq(templateStars.userId, session.user.id)))\nawait tx\n.update(templates)\n.set({\nstars: sql`GREATEST(${templates.stars} - 1, 0)`,\nupdatedAt: new Date(),\n})\n.where(eq(templates.id, id))\n})\nlogger.info(`[${requestId}] Successfully unstarred template: ${id}`)\nreturn NextResponse.json({ message: 'Template unstarred successfully' }, { status: 200 })\n} catch (error: any) {\nlogger.error(`[${requestId}] Error unstarring template: ${id}`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export async function POST(request: Request) {\ntry {\nconst { domain, accessToken, pageId, cloudId: providedCloudId } = await request.json()\nif (!domain) {\nreturn NextResponse.json({ error: 'Domain is required' }, { status: 400 })\n}\nif (!accessToken) {\nreturn NextResponse.json({ error: 'Access token is required' }, { status: 400 })\n}\nif (!pageId) {\nreturn NextResponse.json({ error: 'Page ID is required' }, { status: 400 })\n}\nconst cloudId = providedCloudId || (await getConfluenceCloudId(domain, accessToken))\nconst url = `https:\nconst response = await fetch(url, {\nmethod: 'GET',\nheaders: {\nAccept: 'application/json',\nAuthorization: `Bearer ${accessToken}`,\n},\n})\nif (!response.ok) {\nconsole.error(`Confluence API error: ${response.status} ${response.statusText}`)\nlet errorMessage\ntry {\nconst errorData = await response.json()\nconsole.error('Error details:', JSON.stringify(errorData, null, 2))\nerrorMessage = errorData.message || `Failed to fetch Confluence page (${response.status})`\n} catch (e) {\nconsole.error('Could not parse error response as JSON:', e)\nerrorMessage = `Failed to fetch Confluence page: ${response.status} ${response.statusText}`\n}\nreturn NextResponse.json({ error: errorMessage }, { status: response.status })\n}\nconst data = await response.json()\nreturn NextResponse.json({\nid: data.id,\ntitle: data.title,\nbody: {\nview: {\nvalue:\ndata.body?.storage?.value ||\ndata.body?.view?.value ||\ndata.body?.atlas_doc_format?.value ||\ndata.content ||\ndata.description ||\n`Content for page ${data.title}`,\n},\n},\n})\n} catch (error) {\nconsole.error('Error fetching Confluence page:', error)\nreturn NextResponse.json(\n{ error: (error as Error).message || 'Internal server error' },\n{ status: 500 }\n)\n}\n}"
"export async function GET(request: Request) {\ntry {\nconst url = new URL(request.url)\nconst domain = url.searchParams.get('domain')?.trim()\nconst accessToken = url.searchParams.get('accessToken')\nconst providedCloudId = url.searchParams.get('cloudId')\nconst query = url.searchParams.get('query') || ''\nif (!domain) {\nreturn NextResponse.json({ error: 'Domain is required' }, { status: 400 })\n}\nif (!accessToken) {\nreturn NextResponse.json({ error: 'Access token is required' }, { status: 400 })\n}\nconst cloudId = providedCloudId || (await getJiraCloudId(domain, accessToken))\nlogger.info('Using cloud ID:', cloudId)\nconst params = new URLSearchParams()\nif (query) {\nparams.append('query', query)\n}\nconst apiUrl = `https:\nlogger.info(`Fetching Jira issue suggestions from: ${apiUrl}`)\nconst response = await fetch(apiUrl, {\nmethod: 'GET',\nheaders: {\nAuthorization: `Bearer ${accessToken}`,\nAccept: 'application/json',\n},\n})\nlogger.info('Response status:', response.status, response.statusText)\nif (!response.ok) {\nlogger.error(`Jira API error: ${response.status} ${response.statusText}`)\nlet errorMessage\ntry {\nconst errorData = await response.json()\nlogger.error('Error details:', errorData)\nerrorMessage = errorData.message || `Failed to fetch issue suggestions (${response.status})`\n} catch (_e) {\nerrorMessage = `Failed to fetch issue suggestions: ${response.status} ${response.statusText}`\n}\nreturn NextResponse.json({ error: errorMessage }, { status: response.status })\n}\nconst data = await response.json()\nreturn NextResponse.json({\n...data,\ncloudId,\n})\n} catch (error) {\nlogger.error('Error fetching Jira issue suggestions:', error)\nreturn NextResponse.json(\n{ error: (error as Error).message || 'Internal server error' },\n{ status: 500 }\n)\n}\n}"
"export async function POST(request: Request) {\ntry {\nconst { domain, accessToken, projectId, cloudId: providedCloudId } = await request.json()\nif (!domain) {\nreturn NextResponse.json({ error: 'Domain is required' }, { status: 400 })\n}\nif (!accessToken) {\nreturn NextResponse.json({ error: 'Access token is required' }, { status: 400 })\n}\nif (!projectId) {\nreturn NextResponse.json({ error: 'Project ID is required' }, { status: 400 })\n}\nconst cloudId = providedCloudId || (await getJiraCloudId(domain, accessToken))\nconst apiUrl = `https:\nconst response = await fetch(apiUrl, {\nmethod: 'GET',\nheaders: {\nAuthorization: `Bearer ${accessToken}`,\nAccept: 'application/json',\n},\n})\nif (!response.ok) {\nconst errorData = await response.json()\nlogger.error('Error details:', errorData)\nreturn NextResponse.json(\n{ error: errorData.message || `Failed to fetch project (${response.status})` },\n{ status: response.status }\n)\n}\nconst project = await response.json()\nreturn NextResponse.json({\nproject: {\nid: project.id,\nkey: project.key,\nname: project.name,\nurl: project.self,\navatarUrl: project.avatarUrls?.['48x48'],\ndescription: project.description,\nprojectTypeKey: project.projectTypeKey,\nsimplified: project.simplified,\nstyle: project.style,\nisPrivate: project.isPrivate,\n},\ncloudId,\n})\n} catch (error) {\nlogger.error('Error fetching Jira project:', error)\nreturn NextResponse.json(\n{ error: (error as Error).message || 'Internal server error' },\n{ status: 500 }\n)\n}\n}"
"export async function POST(request: Request) {\ntry {\nconst session = await getSession()\nconst body = await request.json()\nconst { credential, teamId, workflowId } = body\nif (!credential || !teamId) {\nlogger.error('Missing credential or teamId in request')\nreturn NextResponse.json({ error: 'Credential and teamId are required' }, { status: 400 })\n}\nconst userId = session?.user?.id || ''\nif (!userId) {\nlogger.error('No user ID found in session')\nreturn NextResponse.json({ error: 'Authentication required' }, { status: 401 })\n}\nconst accessToken = await refreshAccessTokenIfNeeded(credential, userId, workflowId)\nif (!accessToken) {\nlogger.error('Failed to get access token', { credentialId: credential, userId })\nreturn NextResponse.json(\n{\nerror: 'Could not retrieve access token',\nauthRequired: true,\n},\n{ status: 401 }\n)\n}\nconst linearClient = new LinearClient({ accessToken })\nlet projects = []\nconst team = await linearClient.team(teamId)\nconst projectsResult = await team.projects()\nprojects = projectsResult.nodes.map((project: Project) => ({\nid: project.id,\nname: project.name,\n}))\nif (projects.length === 0) {\nlogger.info('No projects found for team', { teamId })\n}\nreturn NextResponse.json({ projects })\n} catch (error) {\nlogger.error('Error processing Linear projects request:', error)\nreturn NextResponse.json(\n{ error: 'Failed to retrieve Linear projects', details: (error as Error).message },\n{ status: 500 }\n)\n}\n}"
"export async function POST(request: Request) {\ntry {\nconst session = await getSession()\nconst body = await request.json()\nconst { credential, workflowId } = body\nif (!credential) {\nlogger.error('Missing credential in request')\nreturn NextResponse.json({ error: 'Credential is required' }, { status: 400 })\n}\nconst userId = session?.user?.id || ''\nif (!userId) {\nlogger.error('No user ID found in session')\nreturn NextResponse.json({ error: 'Authentication required' }, { status: 401 })\n}\nconst accessToken = await refreshAccessTokenIfNeeded(credential, userId, workflowId)\nif (!accessToken) {\nlogger.error('Failed to get access token', { credentialId: credential, userId })\nreturn NextResponse.json(\n{\nerror: 'Could not retrieve access token',\nauthRequired: true,\n},\n{ status: 401 }\n)\n}\nconst linearClient = new LinearClient({ accessToken })\nconst teamsResult = await linearClient.teams()\nconst teams = teamsResult.nodes.map((team: Team) => ({\nid: team.id,\nname: team.name,\n}))\nreturn NextResponse.json({ teams })\n} catch (error) {\nlogger.error('Error processing Linear teams request:', error)\nreturn NextResponse.json(\n{ error: 'Failed to retrieve Linear teams', details: (error as Error).message },\n{ status: 500 }\n)\n}\n}"
"function extractActionDirectives(task: string): {\nprocessedTask: string\nactionDirectives: Array<{ index: number; action: string }>\n} {\nconst actionRegex = /\[\[ACTION:(.*?)\]\]/g\nconst actionDirectives: Array<{ index: number; action: string }> = []\nlet match\nlet processedTask = task\nwhile ((match = actionRegex.exec(task)) !== null) {\nconst _fullMatch = match[0]\nconst actionText = match[1].trim()\nconst index = match.index\nactionDirectives.push({\nindex,\naction: actionText,\n})\n}\nif (actionDirectives.length > 0) {\nlet offset = 0\nfor (let i = 0; i < actionDirectives.length; i++) {\nconst directive = actionDirectives[i]\nconst originalIndex = directive.index\nconst placeholder = `[SECURE ACTION ${i + 1}]`\nconst adjustedIndex = originalIndex - offset\nconst fullMatch = task.substring(\noriginalIndex,\noriginalIndex + task.substring(originalIndex).indexOf(']]') + 2\n)\nprocessedTask =\nprocessedTask.substring(0, adjustedIndex) +\nplaceholder +\nprocessedTask.substring(adjustedIndex + fullMatch.length)\noffset += fullMatch.length - placeholder.length\n}\n}\nreturn { processedTask, actionDirectives }\n}"
"async function processSecureActions(\nmessage: string,\nstagehand: Stagehand,\nactionDirectives: Array<{ index: number; action: string }>,\nvariables: Record<string, string> | undefined\n): Promise<{\nmodifiedMessage: string\nexecutedActions: Array<{ action: string; result: { success: boolean; message: string } }>\n}> {\nconst executedActions: Array<{ action: string; result: { success: boolean; message: string } }> =\n[]\nlet modifiedMessage = message\nconst secureActionMatches = [...message.matchAll(/EXECUTE SECURE ACTION (\d+)/gi)]\nfor (const match of secureActionMatches) {\nconst fullMatch = match[0]\nconst actionIndex = Number.parseInt(match[1], 10) - 1\nif (actionDirectives[actionIndex]) {\nconst actionDirective = actionDirectives[actionIndex]\nlet resultMessage = ''\ntry {\nlogger.info(`Executing secure action ${actionIndex + 1}`, {\naction: actionDirective.action,\n})\nconst result = await stagehand.page.act({\naction: actionDirective.action,\nvariables: variables || {},\n})\nexecutedActions.push({\naction: actionDirective.action,\nresult: {\nsuccess: result.success,\nmessage: result.message,\n},\n})\nresultMessage = `\nSecure action ${actionIndex + 1} executed successfully.\n`\n} catch (error) {\nlogger.error(`Error executing secure action ${actionIndex + 1}`, {\nerror,\naction: actionDirective.action,\n})\nexecutedActions.push({\naction: actionDirective.action,\nresult: {\nsuccess: false,\nmessage: error instanceof Error ? error.message : 'Unknown error',\n},\n})\nresultMessage = `\nError executing secure action ${actionIndex + 1}: ${error instanceof Error ? error.message : 'Unknown error'}\n`\n}\nmodifiedMessage = modifiedMessage.replace(fullMatch, resultMessage)\n} else {\nconst errorMessage = `\nError: Secure action ${actionIndex + 1} does not exist.\n`\nmodifiedMessage = modifiedMessage.replace(fullMatch, errorMessage)\n}\n}\nreturn { modifiedMessage, executedActions }\n}"
"export async function POST(request: NextRequest) {\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst userId = session.user.id\nconst body = await request.json()\nconst { name } = body\nif (!name || typeof name !== 'string') {\nreturn NextResponse.json({ error: 'Invalid request. Name is required.' }, { status: 400 })\n}\nconst keyValue = generateApiKey()\nconst [newKey] = await db\n.insert(apiKey)\n.values({\nid: nanoid(),\nuserId,\nname,\nkey: keyValue,\ncreatedAt: new Date(),\nupdatedAt: new Date(),\n})\n.returning({\nid: apiKey.id,\nname: apiKey.name,\nkey: apiKey.key,\ncreatedAt: apiKey.createdAt,\n})\nreturn NextResponse.json({ key: newKey })\n} catch (error) {\nlogger.error('Failed to create API key', { error })\nreturn NextResponse.json({ error: 'Failed to create API key' }, { status: 500 })\n}\n}"
"export async function GET() {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.info(`[${requestId}] Returning default settings for unauthenticated user`)\nreturn NextResponse.json({ data: defaultSettings }, { status: 200 })\n}\nconst userId = session.user.id\nconst result = await db.select().from(settings).where(eq(settings.userId, userId)).limit(1)\nif (!result.length) {\nreturn NextResponse.json({ data: defaultSettings }, { status: 200 })\n}\nconst userSettings = result[0]\nreturn NextResponse.json(\n{\ndata: {\ntheme: userSettings.theme,\nautoConnect: userSettings.autoConnect,\nautoFillEnvVars: userSettings.autoFillEnvVars,\nautoPan: userSettings.autoPan,\nconsoleExpandedByDefault: userSettings.consoleExpandedByDefault,\ntelemetryEnabled: userSettings.telemetryEnabled,\ntelemetryNotifiedUser: userSettings.telemetryNotifiedUser,\nemailPreferences: userSettings.emailPreferences ?? {},\n},\n},\n{ status: 200 }\n)\n} catch (error: any) {\nlogger.error(`[${requestId}] Settings fetch error`, error)\nreturn NextResponse.json({ data: defaultSettings }, { status: 200 })\n}\n}"
"export async function PATCH(request: Request) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.info(\n`[${requestId}] Settings update attempted by unauthenticated user - acknowledged without saving`\n)\nreturn NextResponse.json({ success: true }, { status: 200 })\n}\nconst userId = session.user.id\nconst body = await request.json()\ntry {\nconst validatedData = SettingsSchema.parse(body)\nawait db\n.insert(settings)\n.values({\nid: nanoid(),\nuserId,\n...validatedData,\nupdatedAt: new Date(),\n})\n.onConflictDoUpdate({\ntarget: [settings.userId],\nset: {\n...validatedData,\nupdatedAt: new Date(),\n},\n})\nreturn NextResponse.json({ success: true }, { status: 200 })\n} catch (validationError) {\nif (validationError instanceof z.ZodError) {\nlogger.warn(`[${requestId}] Invalid settings data`, {\nerrors: validationError.errors,\n})\nreturn NextResponse.json(\n{ error: 'Invalid settings data', details: validationError.errors },\n{ status: 400 }\n)\n}\nthrow validationError\n}\n} catch (error: any) {\nlogger.error(`[${requestId}] Settings update error`, error)\nreturn NextResponse.json({ success: true }, { status: 200 })\n}\n}"
"export async function GET(request: NextRequest) {\nconst requestId = nanoid()\nlogger.info(`Gmail webhook polling triggered (${requestId})`)\nlet lockValue: string | undefined\ntry {\nconst authError = verifyCronAuth(request, 'Gmail webhook polling')\nif (authError) {\nreturn authError\n}\nlockValue = requestId\nconst locked = await acquireLock(LOCK_KEY, lockValue, LOCK_TTL_SECONDS)\nif (!locked) {\nreturn NextResponse.json(\n{\nsuccess: true,\nmessage: 'Polling already in progress – skipped',\nrequestId,\nstatus: 'skip',\n},\n{ status: 202 }\n)\n}\nconst results = await pollGmailWebhooks()\nreturn NextResponse.json({\nsuccess: true,\nmessage: 'Gmail polling completed',\nrequestId,\nstatus: 'completed',\n...results,\n})\n} catch (error) {\nlogger.error(`Error during Gmail polling (${requestId}):`, error)\nreturn NextResponse.json(\n{\nsuccess: false,\nmessage: 'Gmail polling failed',\nerror: error instanceof Error ? error.message : 'Unknown error',\nrequestId,\n},\n{ status: 500 }\n)\n} finally {\nawait releaseLock(LOCK_KEY).catch(() => {})\n}\n}"
"export async function GET(request: NextRequest) {\nconst requestId = nanoid()\nlogger.info(`Outlook webhook polling triggered (${requestId})`)\nlet lockValue: string | undefined\ntry {\nconst authError = verifyCronAuth(request, 'Outlook webhook polling')\nif (authError) {\nreturn authError\n}\nlockValue = requestId\nconst locked = await acquireLock(LOCK_KEY, lockValue, LOCK_TTL_SECONDS)\nif (!locked) {\nreturn NextResponse.json(\n{\nsuccess: true,\nmessage: 'Polling already in progress – skipped',\nrequestId,\nstatus: 'skip',\n},\n{ status: 202 }\n)\n}\nconst results = await pollOutlookWebhooks()\nreturn NextResponse.json({\nsuccess: true,\nmessage: 'Outlook polling completed',\nrequestId,\nstatus: 'completed',\n...results,\n})\n} catch (error) {\nlogger.error(`Error during Outlook polling (${requestId}):`, error)\nreturn NextResponse.json(\n{\nsuccess: false,\nmessage: 'Outlook polling failed',\nerror: error instanceof Error ? error.message : 'Unknown error',\nrequestId,\n},\n{ status: 500 }\n)\n} finally {\nawait releaseLock(LOCK_KEY).catch(() => {})\n}\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ path: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst path = (await params).path\nconst url = new URL(request.url)\nconst mode = url.searchParams.get('hub.mode')\nconst token = url.searchParams.get('hub.verify_token')\nconst challenge = url.searchParams.get('hub.challenge')\nconst whatsAppResponse = await handleWhatsAppVerification(\nrequestId,\npath,\nmode,\ntoken,\nchallenge\n)\nif (whatsAppResponse) {\nreturn whatsAppResponse\n}\nconst webhooks = await db\n.select({\nwebhook: webhook,\n})\n.from(webhook)\n.where(and(eq(webhook.path, path), eq(webhook.isActive, true)))\n.limit(1)\nif (webhooks.length === 0) {\nlogger.warn(`[${requestId}] No active webhook found for path: ${path}`)\nreturn new NextResponse('Webhook not found', { status: 404 })\n}\nlogger.info(`[${requestId}] Webhook verification successful for path: ${path}`)\nreturn new NextResponse('OK', { status: 200 })\n} catch (error: any) {\nlogger.error(`[${requestId}] Error processing webhook verification`, error)\nreturn new NextResponse(`Internal Server Error: ${error.message}`, {\nstatus: 500,\n})\n}\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nlogger.debug(`[${requestId}] Fetching deployed state for workflow: ${id}`)\nconst validation = await validateWorkflowAccess(request, id, false)\nif (validation.error) {\nlogger.warn(`[${requestId}] Failed to fetch deployed state: ${validation.error.message}`)\nconst response = createErrorResponse(validation.error.message, validation.error.status)\nreturn addNoCacheHeaders(response)\n}\nconst result = await db\n.select({\ndeployedState: workflow.deployedState,\nisDeployed: workflow.isDeployed,\n})\n.from(workflow)\n.where(eq(workflow.id, id))\n.limit(1)\nif (result.length === 0) {\nlogger.warn(`[${requestId}] Workflow not found: ${id}`)\nconst response = createErrorResponse('Workflow not found', 404)\nreturn addNoCacheHeaders(response)\n}\nconst workflowData = result[0]\nif (!workflowData.isDeployed || !workflowData.deployedState) {\nconst response = createSuccessResponse({\ndeployedState: null,\nmessage: 'Workflow is not deployed or has no deployed state',\n})\nreturn addNoCacheHeaders(response)\n}\nconst response = createSuccessResponse({\ndeployedState: workflowData.deployedState,\n})\nreturn addNoCacheHeaders(response)\n} catch (error: any) {\nlogger.error(`[${requestId}] Error fetching deployed state: ${id}`, error)\nconst response = createErrorResponse(error.message || 'Failed to fetch deployed state', 500)\nreturn addNoCacheHeaders(response)\n}\n}"
"export async function POST(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id } = await params\ntry {\nconst validation = await validateWorkflowAccess(request, id, false)\nif (validation.error) {\nlogger.warn(`[${requestId}] Workflow access validation failed: ${validation.error.message}`)\nreturn createErrorResponse(validation.error.message, validation.error.status)\n}\nconst body = await request.json()\nconst { logs, executionId, result } = body\nif (result) {\nlogger.info(`[${requestId}] Persisting execution result for workflow: ${id}`, {\nexecutionId,\nsuccess: result.success,\n})\nconst isChatExecution = result.metadata?.source === 'chat'\nconst triggerType = isChatExecution ? 'chat' : 'manual'\nconst loggingSession = new LoggingSession(id, executionId, triggerType, requestId)\nawait loggingSession.safeStart({\nuserId: '',\nworkspaceId: '',\nvariables: {},\n})\nconst { traceSpans } = buildTraceSpans(result)\nawait loggingSession.safeComplete({\nendedAt: new Date().toISOString(),\ntotalDurationMs: result.metadata?.duration || 0,\nfinalOutput: result.output || {},\ntraceSpans,\n})\nreturn createSuccessResponse({\nmessage: 'Execution logs persisted successfully',\n})\n}\nif (!logs || !Array.isArray(logs) || logs.length === 0) {\nlogger.warn(`[${requestId}] No logs provided for workflow: ${id}`)\nreturn createErrorResponse('No logs provided', 400)\n}\nlogger.info(`[${requestId}] Persisting ${logs.length} logs for workflow: ${id}`, {\nexecutionId,\n})\nreturn createSuccessResponse({ message: 'Logs persisted successfully' })\n} catch (error: any) {\nlogger.error(`[${requestId}] Error persisting logs for workflow: ${id}`, error)\nreturn createErrorResponse(error.message || 'Failed to persist logs', 500)\n}\n}"
"export async function GET(req: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst workflowId = (await params).id\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized workflow variables access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst workflowRecord = await db\n.select()\n.from(workflow)\n.where(eq(workflow.id, workflowId))\n.limit(1)\nif (!workflowRecord.length) {\nlogger.warn(`[${requestId}] Workflow not found: ${workflowId}`)\nreturn NextResponse.json({ error: 'Workflow not found' }, { status: 404 })\n}\nconst workflowData = workflowRecord[0]\nconst workspaceId = workflowData.workspaceId\nlet isAuthorized = workflowData.userId === session.user.id\nif (!isAuthorized && workspaceId) {\nconst userPermission = await getUserEntityPermissions(\nsession.user.id,\n'workspace',\nworkspaceId\n)\nisAuthorized = userPermission !== null\n}\nif (!isAuthorized) {\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted to access variables for workflow ${workflowId} without permission`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst variables = (workflowData.variables as Record<string, Variable>) || {}\nconst variableHash = JSON.stringify(variables).length\nconst headers = new Headers({\n'Cache-Control': 'max-age=30, stale-while-revalidate=300',\nETag: ``variables-${workflowId}-${variableHash}``,\n})\nreturn NextResponse.json(\n{ data: variables },\n{\nstatus: 200,\nheaders,\n}\n)\n} catch (error: any) {\nlogger.error(`[${requestId}] Workflow variables fetch error`, error)\nreturn NextResponse.json({ error: error.message }, { status: 500 })\n}\n}"
"async function createWorkflowCheckpoint(\nuserId: string,\nworkflowId: string,\nchatId: string,\nrequestId: string\n): Promise<boolean> {\ntry {\nlogger.info(`[${requestId}] Creating checkpoint before workflow edit`)\nconst currentWorkflowData = await loadWorkflowFromNormalizedTables(workflowId)\nif (currentWorkflowData) {\nconst allBlockConfigs = getAllBlocks()\nconst blockRegistry = allBlockConfigs.reduce(\n(acc, block) => {\nconst blockType = block.type\nacc[blockType] = {\n...block,\nid: blockType,\nsubBlocks: block.subBlocks || [],\noutputs: block.outputs || {},\n} as any\nreturn acc\n},\n{} as Record<string, BlockConfig>\n)\nconst generateResponse = await fetch(`${SIM_AGENT_API_URL}/api/workflow/to-yaml`, {\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n...(SIM_AGENT_API_KEY && { 'x-api-key': SIM_AGENT_API_KEY }),\n},\nbody: JSON.stringify({\nworkflowState: currentWorkflowData,\nblockRegistry,\nutilities: {\ngenerateLoopBlocks: generateLoopBlocks.toString(),\ngenerateParallelBlocks: generateParallelBlocks.toString(),\nresolveOutputType: resolveOutputType.toString(),\n},\n}),\n})\nif (!generateResponse.ok) {\nconst errorText = await generateResponse.text()\nthrow new Error(`Failed to generate YAML: ${errorText}`)\n}\nconst generateResult = await generateResponse.json()\nif (!generateResult.success || !generateResult.yaml) {\nthrow new Error(generateResult.error || 'Failed to generate YAML')\n}\nconst currentYaml = generateResult.yaml\nawait db.insert(workflowCheckpoints).values({\nuserId,\nworkflowId,\nchatId,\nworkflowState: currentWorkflowData,\n})\nlogger.info(`[${requestId}] Checkpoint created successfully`)\nreturn true\n}\nlogger.warn(`[${requestId}] Could not load current workflow state for checkpoint`)\nreturn false\n} catch (error) {\nlogger.error(`[${requestId}] Failed to create checkpoint:`, error)\nreturn false\n}\n}"
"async function getUserId(requestId: string, workflowId: string): Promise<string | null> {\nconst userId = await getOAuthUserId(requestId, workflowId)\nif (!userId) {\nlogger.warn(`[${requestId}] Could not determine user ID for workflow ${workflowId}`)\nreturn null\n}\nconst workflowData = await db\n.select()\n.from(workflowTable)\n.where(eq(workflowTable.id, workflowId))\n.then((rows) => rows[0])\nif (!workflowData) {\nlogger.warn(`[${requestId}] Workflow ${workflowId} not found`)\nreturn null\n}\nlet canUpdate = false\nif (workflowData.userId === userId) {\ncanUpdate = true\n}\nif (!canUpdate && workflowData.workspaceId) {\ntry {\nconst userPermission = await getUserEntityPermissions(\nuserId,\n'workspace',\nworkflowData.workspaceId\n)\nif (userPermission === 'write' || userPermission === 'admin') {\ncanUpdate = true\n}\n} catch (error) {\nlogger.warn(`[${requestId}] Error checking workspace permissions:`, error)\n}\n}\nif (!canUpdate) {\nlogger.warn(`[${requestId}] User ${userId} denied permission to update workflow ${workflowId}`)\nreturn null\n}\nreturn userId\n}"
"function updateBlockReferences(\nvalue: any,\nblockIdMapping: Map<string, string>,\nrequestId: string\n): any {\nif (typeof value === 'string' && value.includes('<') && value.includes('>')) {\nlet processedValue = value\nconst blockMatches = value.match(/<([^>]+)>/g)\nif (blockMatches) {\nfor (const match of blockMatches) {\nconst path = match.slice(1, -1)\nconst [blockRef] = path.split('.')\nif (['start', 'loop', 'parallel', 'variable'].includes(blockRef.toLowerCase())) {\ncontinue\n}\nconst newMappedId = blockIdMapping.get(blockRef)\nif (newMappedId) {\nlogger.info(`[${requestId}] Updating block reference: ${blockRef} -> ${newMappedId}`)\nprocessedValue = processedValue.replace(\nnew RegExp(`<${blockRef}\\.`, 'g'),\n`<${newMappedId}.`\n)\nprocessedValue = processedValue.replace(\nnew RegExp(`<${blockRef}>`, 'g'),\n`<${newMappedId}>`\n)\n}\n}\n}\nreturn processedValue\n}\nif (Array.isArray(value)) {\nreturn value.map((item) => updateBlockReferences(item, blockIdMapping, requestId))\n}\nif (value !== null && typeof value === 'object') {\nconst result = { ...value }\nfor (const key in result) {\nresult[key] = updateBlockReferences(result[key], blockIdMapping, requestId)\n}\nreturn result\n}\nreturn value\n}"
"export async function GET(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst { id } = await params\nconst marketplaceEntry = await db\n.select({\nid: marketplace.id,\nworkflowId: marketplace.workflowId,\nstate: marketplace.state,\nname: marketplace.name,\ndescription: marketplace.description,\nauthorId: marketplace.authorId,\nauthorName: marketplace.authorName,\n})\n.from(marketplace)\n.where(eq(marketplace.workflowId, id))\n.limit(1)\n.then((rows) => rows[0])\nif (!marketplaceEntry) {\nconst workflowExists = await db\n.select({ id: workflow.id })\n.from(workflow)\n.where(eq(workflow.id, id))\n.limit(1)\n.then((rows) => rows.length > 0)\nif (!workflowExists) {\nlogger.warn(`[${requestId}] Workflow not found: ${id}`)\nreturn createErrorResponse('Workflow not found', 404)\n}\nlogger.warn(`[${requestId}] Workflow exists but is not published: ${id}`)\nreturn createErrorResponse('Workflow is not published', 403)\n}\nlogger.info(`[${requestId}] Retrieved public workflow: ${id}`)\nreturn createSuccessResponse({\nid: marketplaceEntry.workflowId,\nname: marketplaceEntry.name,\ndescription: marketplaceEntry.description,\nauthorId: marketplaceEntry.authorId,\nauthorName: marketplaceEntry.authorName,\nstate: marketplaceEntry.state,\nisPublic: true,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error getting public workflow: ${(await params).id}`, error)\nreturn createErrorResponse('Failed to get public workflow', 500)\n}\n}"
"export async function POST(request: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nlogger.info(`[${requestId}] Converting workflow JSON to YAML`)\nconst body = await request.json()\nconst { workflowState, subBlockValues, includeMetadata = false } = body\nif (!workflowState) {\nreturn NextResponse.json(\n{ success: false, error: 'workflowState is required' },\n{ status: 400 }\n)\n}\nconst blocks = getAllBlocks()\nconst blockRegistry = blocks.reduce(\n(acc, block) => {\nconst blockType = block.type\nacc[blockType] = {\n...block,\nid: blockType,\nsubBlocks: block.subBlocks || [],\noutputs: block.outputs || {},\n} as any\nreturn acc\n},\n{} as Record<string, BlockConfig>\n)\nconst result = await simAgentClient.makeRequest('/api/workflow/to-yaml', {\nbody: {\nworkflowState,\nsubBlockValues,\nblockRegistry,\nutilities: {\ngenerateLoopBlocks: generateLoopBlocks.toString(),\ngenerateParallelBlocks: generateParallelBlocks.toString(),\nresolveOutputType: resolveOutputType.toString(),\n},\n},\napiKey: SIM_AGENT_API_KEY,\n})\nif (!result.success || !result.data?.yaml) {\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: result.error || 'Failed to generate YAML',\n},\n{ status: result.status || 500 }\n)\n}\nlogger.info(`[${requestId}] Successfully generated YAML`, {\nyamlLength: result.data.yaml.length,\n})\nreturn NextResponse.json({\nsuccess: true,\nyaml: result.data.yaml,\n})\n} catch (error) {\nlogger.error(`[${requestId}] YAML generation failed`, error)\nreturn NextResponse.json(\n{\nsuccess: false,\nerror: `Failed to generate YAML: ${error instanceof Error ? error.message : 'Unknown error'}`,\n},\n{ status: 500 }\n)\n}\n}"
"export async function PATCH(request: NextRequest, { params }: { params: Promise<{ id: string }> }) {\ntry {\nconst { id: workspaceId } = await params\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Authentication required' }, { status: 401 })\n}\nconst hasAdminAccess = await hasWorkspaceAdminAccess(session.user.id, workspaceId)\nif (!hasAdminAccess) {\nreturn NextResponse.json(\n{ error: 'Admin access required to update permissions' },\n{ status: 403 }\n)\n}\nconst body: UpdatePermissionsRequest = await request.json()\nconst selfUpdate = body.updates.find((update) => update.userId === session.user.id)\nif (selfUpdate && selfUpdate.permissions !== 'admin') {\nreturn NextResponse.json(\n{ error: 'Cannot remove your own admin permissions' },\n{ status: 400 }\n)\n}\nawait db.transaction(async (tx) => {\nfor (const update of body.updates) {\nawait tx\n.delete(permissions)\n.where(\nand(\neq(permissions.userId, update.userId),\neq(permissions.entityType, 'workspace'),\neq(permissions.entityId, workspaceId)\n)\n)\nawait tx.insert(permissions).values({\nid: crypto.randomUUID(),\nuserId: update.userId,\nentityType: 'workspace' as const,\nentityId: workspaceId,\npermissionType: update.permissions,\ncreatedAt: new Date(),\nupdatedAt: new Date(),\n})\n}\n})\nconst updatedUsers = await getUsersWithPermissions(workspaceId)\nreturn NextResponse.json({\nmessage: 'Permissions updated successfully',\nusers: updatedUsers,\ntotal: updatedUsers.length,\n})\n} catch (error) {\nconsole.error('Error updating workspace permissions:', error)\nreturn NextResponse.json({ error: 'Failed to update workspace permissions' }, { status: 500 })\n}\n}"
"export async function DELETE(req: NextRequest, { params }: { params: Promise<{ id: string }> }) {\nconst { id } = await params\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\ntry {\nconst invitation = await db\n.select({\nid: workspaceInvitation.id,\nworkspaceId: workspaceInvitation.workspaceId,\nemail: workspaceInvitation.email,\ninviterId: workspaceInvitation.inviterId,\nstatus: workspaceInvitation.status,\n})\n.from(workspaceInvitation)\n.where(eq(workspaceInvitation.id, id))\n.then((rows) => rows[0])\nif (!invitation) {\nreturn NextResponse.json({ error: 'Invitation not found' }, { status: 404 })\n}\nconst hasAdminAccess = await hasWorkspaceAdminAccess(session.user.id, invitation.workspaceId)\nif (!hasAdminAccess) {\nreturn NextResponse.json({ error: 'Insufficient permissions' }, { status: 403 })\n}\nif (invitation.status !== 'pending') {\nreturn NextResponse.json({ error: 'Can only delete pending invitations' }, { status: 400 })\n}\nawait db.delete(workspaceInvitation).where(eq(workspaceInvitation.id, id))\nreturn NextResponse.json({ success: true })\n} catch (error) {\nconsole.error('Error deleting workspace invitation:', error)\nreturn NextResponse.json({ error: 'Failed to delete invitation' }, { status: 500 })\n}\n}"
"export async function GET(req: NextRequest) {\nconst token = req.nextUrl.searchParams.get('token')\nif (!token) {\nreturn NextResponse.json({ error: 'Token is required' }, { status: 400 })\n}\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\ntry {\nconst invitation = await db\n.select()\n.from(workspaceInvitation)\n.where(eq(workspaceInvitation.token, token))\n.then((rows) => rows[0])\nif (!invitation) {\nreturn NextResponse.json({ error: 'Invitation not found or has expired' }, { status: 404 })\n}\nif (new Date() > new Date(invitation.expiresAt)) {\nreturn NextResponse.json({ error: 'Invitation has expired' }, { status: 400 })\n}\nconst workspaceDetails = await db\n.select()\n.from(workspace)\n.where(eq(workspace.id, invitation.workspaceId))\n.then((rows) => rows[0])\nif (!workspaceDetails) {\nreturn NextResponse.json({ error: 'Workspace not found' }, { status: 404 })\n}\nreturn NextResponse.json({\n...invitation,\nworkspaceName: workspaceDetails.name,\n})\n} catch (error) {\nconsole.error('Error fetching workspace invitation:', error)\nreturn NextResponse.json({ error: 'Failed to fetch invitation details' }, { status: 500 })\n}\n}"
"async function getBlocksAndTools(): Promise<Record<string, BlockInfo>> {\nconst logger = createLogger('GetBlocksAndTools')\nlogger.info('Getting all blocks and tools')\nconst blockToToolsMapping: Record<string, BlockInfo> = {}\nObject.entries(blockRegistry)\n.filter(([blockType, blockConfig]) => {\nif (blockConfig.hideFromToolbar) return false\nreturn true\n})\n.forEach(([blockType, blockConfig]) => {\nconst blockToolIds = blockConfig.tools?.access || []\nconst toolNames = blockToolIds.map((toolId) => {\nconst toolConfig = toolsRegistry[toolId]\nreturn toolConfig ? toolConfig.name : toolId\n})\nblockToToolsMapping[blockType] = {\nblock_name: blockConfig.name || blockType,\ntool_names: toolNames,\n}\n})\nconst specialBlocks = {\nloop: {\nname: 'Loop',\ntools: [],\n},\nparallel: {\nname: 'Parallel',\ntools: [],\n},\n}\nObject.entries(specialBlocks).forEach(([blockType, blockInfo]) => {\nblockToToolsMapping[blockType] = {\nblock_name: blockInfo.name,\ntool_names: blockInfo.tools,\n}\n})\nconst totalBlocks = Object.keys(blockRegistry).length + Object.keys(specialBlocks).length\nconst includedBlocks = Object.keys(blockToToolsMapping).length\nlogger.info(`Successfully mapped ${includedBlocks} blocks to their tools`, {\ntotalBlocks,\nincludedBlocks,\noutputMapping: blockToToolsMapping,\n})\nreturn blockToToolsMapping\n}"
"function processSubBlocks(subBlocks: any[]): any[] {\nif (!Array.isArray(subBlocks)) {\nreturn []\n}\nreturn subBlocks.map((subBlock) => {\nconst processedSubBlock: any = {\nid: subBlock.id,\ntitle: subBlock.title,\ntype: subBlock.type,\nlayout: subBlock.layout,\nmode: subBlock.mode,\nrequired: subBlock.required,\nplaceholder: subBlock.placeholder,\ndescription: subBlock.description,\nhidden: subBlock.hidden,\ncondition: subBlock.condition,\nmin: subBlock.min,\nmax: subBlock.max,\nstep: subBlock.step,\ninteger: subBlock.integer,\nrows: subBlock.rows,\npassword: subBlock.password,\nmultiSelect: subBlock.multiSelect,\nlanguage: subBlock.language,\ngenerationType: subBlock.generationType,\nprovider: subBlock.provider,\nserviceId: subBlock.serviceId,\nrequiredScopes: subBlock.requiredScopes,\nmimeType: subBlock.mimeType,\nacceptedTypes: subBlock.acceptedTypes,\nmultiple: subBlock.multiple,\nmaxSize: subBlock.maxSize,\nconnectionDroppable: subBlock.connectionDroppable,\ncolumns: subBlock.columns,\nvalue: typeof subBlock.value === 'function' ? 'function' : undefined,\nwandConfig: subBlock.wandConfig,\n}\nif (subBlock.options) {\ntry {\nconst resolvedOptions = resolveSubBlockOptions(subBlock.options)\nprocessedSubBlock.options = resolvedOptions.map((option) => ({\nlabel: option.label,\nid: option.id,\nhasIcon: !!option.icon,\n}))\n} catch (error) {\nlogger.warn(`Failed to resolve options for subBlock ${subBlock.id}:`, error)\nprocessedSubBlock.options = []\n}\n}\nreturn Object.fromEntries(\nObject.entries(processedSubBlock).filter(([_, value]) => value !== undefined)\n)\n})\n}"
"async function getUserWorkflow(params: GetUserWorkflowParams): Promise<string> {\nconst logger = createLogger('GetUserWorkflow')\nconst { workflowId, includeMetadata = false } = params\nlogger.info('Fetching user workflow', { workflowId })\nconst [workflowRecord] = await db\n.select()\n.from(workflowTable)\n.where(eq(workflowTable.id, workflowId))\n.limit(1)\nif (!workflowRecord) {\nthrow new Error(`Workflow ${workflowId} not found`)\n}\nlet workflowState: any = null\nconst subBlockValues: Record<string, Record<string, any>> = {}\nconst normalizedData = await loadWorkflowFromNormalizedTables(workflowId)\nif (normalizedData) {\nworkflowState = {\nblocks: normalizedData.blocks,\nedges: normalizedData.edges,\nloops: normalizedData.loops,\nparallels: normalizedData.parallels,\n}\nObject.entries(normalizedData.blocks).forEach(([blockId, block]) => {\nsubBlockValues[blockId] = {}\nObject.entries((block as any).subBlocks || {}).forEach(([subBlockId, subBlock]) => {\nif ((subBlock as any).value !== undefined) {\nsubBlockValues[blockId][subBlockId] = (subBlock as any).value\n}\n})\n})\n} else if (workflowRecord.state) {\nworkflowState = workflowRecord.state as any\nObject.entries((workflowState.blocks as any) || {}).forEach(([blockId, block]) => {\nsubBlockValues[blockId] = {}\nObject.entries((block as any).subBlocks || {}).forEach(([subBlockId, subBlock]) => {\nif ((subBlock as any).value !== undefined) {\nsubBlockValues[blockId][subBlockId] = (subBlock as any).value\n}\n})\n})\n}\nif (!workflowState || !workflowState.blocks) {\nthrow new Error('Workflow state is empty or invalid')\n}\nlogger.info('Successfully fetched user workflow as JSON', {\nworkflowId,\nblockCount: Object.keys(workflowState.blocks).length,\n})\nreturn JSON.stringify(workflowState, null, 2)\n}"
"export async function GET(\nreq: NextRequest,\n{ params }: { params: Promise<{ id: string; documentId: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId, documentId } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized document access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkDocumentAccess(knowledgeBaseId, documentId, session.user.id)\nif (!accessCheck.hasAccess) {\nif (accessCheck.notFound) {\nlogger.warn(\n`[${requestId}] ${accessCheck.reason}: KB=${knowledgeBaseId}, Doc=${documentId}`\n)\nreturn NextResponse.json({ error: accessCheck.reason }, { status: 404 })\n}\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted unauthorized document access: ${accessCheck.reason}`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nlogger.info(\n`[${requestId}] Retrieved document: ${documentId} from knowledge base ${knowledgeBaseId}`\n)\nreturn NextResponse.json({\nsuccess: true,\ndata: accessCheck.document,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching document`, error)\nreturn NextResponse.json({ error: 'Failed to fetch document' }, { status: 500 })\n}\n}"
"export async function DELETE(\nreq: NextRequest,\n{ params }: { params: Promise<{ id: string; documentId: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId, documentId } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized document delete attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkDocumentWriteAccess(knowledgeBaseId, documentId, session.user.id)\nif (!accessCheck.hasAccess) {\nif (accessCheck.notFound) {\nlogger.warn(\n`[${requestId}] ${accessCheck.reason}: KB=${knowledgeBaseId}, Doc=${documentId}`\n)\nreturn NextResponse.json({ error: accessCheck.reason }, { status: 404 })\n}\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted unauthorized document deletion: ${accessCheck.reason}`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nawait db\n.update(document)\n.set({\ndeletedAt: new Date(),\n})\n.where(eq(document.id, documentId))\nlogger.info(\n`[${requestId}] Document deleted: ${documentId} from knowledge base ${knowledgeBaseId}`\n)\nreturn NextResponse.json({\nsuccess: true,\ndata: { message: 'Document deleted successfully' },\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error deleting document`, error)\nreturn NextResponse.json({ error: 'Failed to delete document' }, { status: 500 })\n}\n}"
"export async function GET(req: NextRequest) {\nconst requestId = crypto.randomUUID().slice(0, 8)\ntry {\nconst { searchParams } = new URL(req.url)\nconst email = searchParams.get('email')\nconst token = searchParams.get('token')\nif (!email || !token) {\nlogger.warn(`[${requestId}] Missing email or token in GET request`)\nreturn NextResponse.json({ error: 'Missing email or token parameter' }, { status: 400 })\n}\nconst tokenVerification = verifyUnsubscribeToken(email, token)\nif (!tokenVerification.valid) {\nlogger.warn(`[${requestId}] Invalid unsubscribe token for email: ${email}`)\nreturn NextResponse.json({ error: 'Invalid or expired unsubscribe link' }, { status: 400 })\n}\nconst emailType = tokenVerification.emailType as EmailType\nconst isTransactional = isTransactionalEmail(emailType)\nconst preferences = await getEmailPreferences(email)\nlogger.info(\n`[${requestId}] Valid unsubscribe GET request for email: ${email}, type: ${emailType}`\n)\nreturn NextResponse.json({\nsuccess: true,\nemail,\ntoken,\nemailType,\nisTransactional,\ncurrentPreferences: preferences || {},\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error processing unsubscribe GET request:`, error)\nreturn NextResponse.json({ error: 'Internal server error' }, { status: 500 })\n}\n}"
"export function KnowledgeHeader({ breadcrumbs, options }: KnowledgeHeaderProps) {\nreturn (\n<div className={HEADER_STYLES.container}>\n<div className={HEADER_STYLES.breadcrumbs}>\n{breadcrumbs.map((breadcrumb, index) => {\nconst key = breadcrumb.id || `${breadcrumb.label}-${breadcrumb.href || index}`\nreturn (\n<div key={key} className='flex items-center gap-2'>\n{index === 0 && <LibraryBig className={HEADER_STYLES.icon} />}\n{breadcrumb.href ? (\n<Link href={breadcrumb.href} prefetch={true} className={HEADER_STYLES.link}>\n<span>{breadcrumb.label}</span>\n</Link>\n) : (\n<span className={HEADER_STYLES.label}>{breadcrumb.label}</span>\n)}\n{index < breadcrumbs.length - 1 && <span className={HEADER_STYLES.separator}>/</span>}\n</div>\n)\n})}\n</div>\n{}\n<div className={HEADER_STYLES.actionsContainer}>\n{}\n{options?.knowledgeBaseId && (\n<WorkspaceSelector\nknowledgeBaseId={options.knowledgeBaseId}\ncurrentWorkspaceId={options.currentWorkspaceId || null}\nonWorkspaceChange={options.onWorkspaceChange}\n/>\n)}\n{}\n{options?.onDeleteKnowledgeBase && (\n<DropdownMenu>\n<DropdownMenuTrigger asChild>\n<Button\nvariant='ghost'\nsize='sm'\nclassName='h-8 w-8 p-0'\naria-label='Knowledge base actions menu'\n>\n<MoreHorizontal className='h-4 w-4' />\n</Button>\n</DropdownMenuTrigger>\n<DropdownMenuContent align='end'>\n<DropdownMenuItem\nonClick={options.onDeleteKnowledgeBase}\nclassName='text-red-600 focus:text-red-600'\n>\n<Trash2 className='mr-2 h-4 w-4' />\nDelete Knowledge Base\n</DropdownMenuItem>\n</DropdownMenuContent>\n</DropdownMenu>\n)}\n</div>\n</div>\n)\n}"
export function DocumentTableRowSkeleton({ isSidebarCollapsed }: { isSidebarCollapsed: boolean }) {\nreturn (\n<tr className='border-b'>\n{}\n<td className='px-4 py-3'>\n<div className='h-3.5 w-3.5 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='flex items-center gap-2'>\n<div className='h-6 w-5 animate-pulse rounded bg-muted' />\n<div className='h-4 w-32 animate-pulse rounded bg-muted' />\n</div>\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-3 w-12 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-3 w-8 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='hidden px-4 py-3 lg:table-cell'>\n<div className='h-3 w-6 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='space-y-1'>\n<div className='h-3 w-16 animate-pulse rounded bg-muted' />\n<div className='h-3 w-12 animate-pulse rounded bg-muted lg:hidden' />\n</div>\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-6 w-16 animate-pulse rounded-md bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='flex items-center gap-1'>\n<div className='h-8 w-8 animate-pulse rounded bg-muted' />\n<div className='h-8 w-8 animate-pulse rounded bg-muted' />\n<div className='h-8 w-8 animate-pulse rounded bg-muted' />\n</div>\n</td>\n</tr>\n)\n}
export function ChunkTableRowSkeleton({ isSidebarCollapsed }: { isSidebarCollapsed: boolean }) {\nreturn (\n<tr className='border-b'>\n{}\n<td className='px-4 py-3'>\n<div className='h-3.5 w-3.5 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-4 w-6 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='space-y-2'>\n<div className='h-4 w-full animate-pulse rounded bg-muted' />\n<div className='h-4 w-3/4 animate-pulse rounded bg-muted' />\n<div className='h-4 w-1/2 animate-pulse rounded bg-muted' />\n</div>\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-3 w-8 animate-pulse rounded bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='h-6 w-16 animate-pulse rounded-md bg-muted' />\n</td>\n{}\n<td className='px-4 py-3'>\n<div className='flex items-center gap-1'>\n<div className='h-8 w-8 animate-pulse rounded bg-muted' />\n<div className='h-8 w-8 animate-pulse rounded bg-muted' />\n</div>\n</td>\n</tr>\n)\n}
"export function Filters() {\nconst { getSubscriptionStatus, isLoading } = useSubscriptionStore()\nconst subscription = getSubscriptionStatus()\nconst isPaid = subscription.isPaid\nconst handleUpgradeClick = (e: React.MouseEvent) => {\ne.preventDefault()\nconst event = new CustomEvent('open-settings', {\ndetail: { tab: 'subscription' },\n})\nwindow.dispatchEvent(event)\n}\nreturn (\n<div className='h-full w-60 overflow-auto border-r p-4'>\n{}\n{!isLoading && !isPaid && isProd && (\n<div className='mb-4 overflow-hidden rounded-md border border-border'>\n<div className='flex items-center gap-2 border-b bg-background p-3'>\n<TimerOff className='h-4 w-4 text-muted-foreground' />\n<span className='font-medium text-sm'>Log Retention Policy</span>\n</div>\n<div className='p-3'>\n<p className='text-muted-foreground text-xs'>\nLogs are automatically deleted after 7 days.\n</p>\n<div className='mt-2.5'>\n<Button\nsize='sm'\nvariant='secondary'\nclassName='h-8 w-full px-3 py-1.5 text-xs'\nonClick={handleUpgradeClick}\n>\nUpgrade Plan\n</Button>\n</div>\n</div>\n</div>\n)}\n<h2 className='mb-4 pl-2 font-medium text-sm'>Filters</h2>\n{}\n<FilterSection title='Timeline' content={<Timeline />} />\n{}\n<FilterSection title='Level' content={<Level />} />\n{}\n<FilterSection title='Trigger' content={<Trigger />} />\n{}\n<FilterSection title='Folder' content={<FolderFilter />} />\n{}\n<FilterSection title='Workflow' content={<Workflow />} />\n</div>\n)\n}"
"function transformBlockData(data: any, blockType: string, isInput: boolean) {\nif (!data) return null\nif (isInput) {\nconst cleanInput = redactApiKeys(data)\nObject.keys(cleanInput).forEach((key) => {\nif (cleanInput[key] === null || cleanInput[key] === undefined) {\ndelete cleanInput[key]\n}\n})\nreturn cleanInput\n}\nif (data.response) {\nconst response = data.response\nswitch (blockType) {\ncase 'agent':\nreturn {\ncontent: response.content,\nmodel: data.model,\ntokens: data.tokens,\ntoolCalls: response.toolCalls,\n...(data.cost && { cost: data.cost }),\n}\ncase 'function':\nreturn {\nresult: response.result,\nstdout: response.stdout,\n...(response.executionTime && { executionTime: `${response.executionTime}ms` }),\n}\ncase 'api':\nreturn {\ndata: response.data,\nstatus: response.status,\nheaders: response.headers,\n}\ncase 'tool':\nreturn response\ndefault:\nreturn response\n}\n}\nreturn data\n}"
"function CollapsibleInputOutput({ span, spanId }: CollapsibleInputOutputProps) {\nconst [inputExpanded, setInputExpanded] = useState(false)\nconst [outputExpanded, setOutputExpanded] = useState(false)\nreturn (\n<div className='mt-2 mr-4 mb-4 ml-8 space-y-3 overflow-hidden'>\n{}\n{span.input && (\n<div>\n<button\nonClick={() => setInputExpanded(!inputExpanded)}\nclassName='mb-2 flex items-center gap-2 font-medium text-muted-foreground text-xs transition-colors hover:text-foreground'\n>\n{inputExpanded ? (\n<ChevronDown className='h-3 w-3' />\n) : (\n<ChevronRight className='h-3 w-3' />\n)}\nInput\n</button>\n{inputExpanded && (\n<div className='mb-2 overflow-hidden rounded-md bg-secondary/30 p-3'>\n<BlockDataDisplay data={span.input} blockType={span.type} isInput={true} />\n</div>\n)}\n</div>\n)}\n{}\n{span.output && (\n<div>\n<button\nonClick={() => setOutputExpanded(!outputExpanded)}\nclassName='mb-2 flex items-center gap-2 font-medium text-muted-foreground text-xs transition-colors hover:text-foreground'\n>\n{outputExpanded ? (\n<ChevronDown className='h-3 w-3' />\n) : (\n<ChevronRight className='h-3 w-3' />\n)}\n{span.status === 'error' ? 'Error Details' : 'Output'}\n</button>\n{outputExpanded && (\n<div className='mb-2 overflow-hidden rounded-md bg-secondary/30 p-3'>\n<BlockDataDisplay\ndata={span.output}\nblockType={span.type}\nisInput={false}\nisError={span.status === 'error'}\n/>\n</div>\n)}\n</div>\n)}\n</div>\n)\n}"
"export function useBlockConnections(blockId: string) {\nconst { edges, blocks } = useWorkflowStore(\n(state) => ({\nedges: state.edges,\nblocks: state.blocks,\n}),\nshallow\n)\nconst allPathNodeIds = BlockPathCalculator.findAllPathNodes(edges, blockId)\nconst allPathConnections = allPathNodeIds\n.map((sourceId) => {\nconst sourceBlock = blocks[sourceId]\nif (!sourceBlock) return null\nconst responseFormatValue = useSubBlockStore.getState().getValue(sourceId, 'responseFormat')\nconst responseFormat = parseResponseFormatSafely(responseFormatValue, sourceId)\nconst defaultOutputs: Field[] = Object.entries(sourceBlock.outputs || {}).map(([key]) => ({\nname: key,\ntype: 'string',\n}))\nconst outputFields = responseFormat ? extractFieldsFromSchema(responseFormat) : defaultOutputs\nreturn {\nid: sourceBlock.id,\ntype: sourceBlock.type,\noutputType: outputFields.map((field: Field) => field.name),\nname: sourceBlock.name,\nresponseFormat,\n}\n})\n.filter(Boolean) as ConnectedBlock[]\nconst directIncomingConnections = edges\n.filter((edge) => edge.target === blockId)\n.map((edge) => {\nconst sourceBlock = blocks[edge.source]\nif (!sourceBlock) return null\nconst responseFormatValue = useSubBlockStore\n.getState()\n.getValue(edge.source, 'responseFormat')\nconst responseFormat = parseResponseFormatSafely(responseFormatValue, edge.source)\nconst defaultOutputs: Field[] = Object.entries(sourceBlock.outputs || {}).map(([key]) => ({\nname: key,\ntype: 'string',\n}))\nconst outputFields = responseFormat ? extractFieldsFromSchema(responseFormat) : defaultOutputs\nreturn {\nid: sourceBlock.id,\ntype: sourceBlock.type,\noutputType: outputFields.map((field: Field) => field.name),\nname: sourceBlock.name,\nresponseFormat,\n}\n})\n.filter(Boolean) as ConnectedBlock[]\nreturn {\nincomingConnections: allPathConnections,\ndirectIncomingConnections,\nhasIncomingConnections: allPathConnections.length > 0,\n}\n}"
"export function useCurrentWorkflow(): CurrentWorkflow {\nconst normalWorkflow = useWorkflowStore((state) => state.getWorkflowState())\nconst { isShowingDiff, isDiffReady, diffWorkflow } = useWorkflowDiffStore()\nconst currentWorkflow = useMemo((): CurrentWorkflow => {\nconst shouldUseDiff = isShowingDiff && isDiffReady && !!diffWorkflow\nconst activeWorkflow = shouldUseDiff ? diffWorkflow : normalWorkflow\nreturn {\nblocks: activeWorkflow.blocks,\nedges: activeWorkflow.edges,\nloops: activeWorkflow.loops || {},\nparallels: activeWorkflow.parallels || {},\nlastSaved: activeWorkflow.lastSaved,\nisDeployed: activeWorkflow.isDeployed,\ndeployedAt: activeWorkflow.deployedAt,\ndeploymentStatuses: activeWorkflow.deploymentStatuses,\nneedsRedeployment: activeWorkflow.needsRedeployment,\nhasActiveWebhook: activeWorkflow.hasActiveWebhook,\nisDiffMode: shouldUseDiff,\nisNormalMode: !shouldUseDiff,\nworkflowState: activeWorkflow,\ngetBlockById: (blockId: string) => activeWorkflow.blocks[blockId],\ngetBlockCount: () => Object.keys(activeWorkflow.blocks).length,\ngetEdgeCount: () => activeWorkflow.edges.length,\nhasBlocks: () => Object.keys(activeWorkflow.blocks).length > 0,\nhasEdges: () => activeWorkflow.edges.length > 0,\n}\n}, [normalWorkflow, isShowingDiff, isDiffReady, diffWorkflow])\nreturn currentWorkflow\n}"
function sanitizeMessage(value: unknown): string | undefined {\nif (typeof value !== 'string') return undefined\nconst trimmed = value.trim()\nif (!trimmed || trimmed === 'undefined (undefined)') return undefined\nreturn trimmed\n}
"export async function persistExecutionLogs(\nactiveWorkflowId: string,\nexecutionId: string,\nresult: ExecutionResult,\nstreamContent?: string\n): Promise<string> {\ntry {\nconst { traceSpans, totalDuration } = buildTraceSpans(result)\nconst enrichedResult = {\n...result,\ntraceSpans,\ntotalDuration,\n}\nif (streamContent && result.output && typeof streamContent === 'string') {\nenrichedResult.output.content = streamContent\nif (enrichedResult.logs) {\nconst streamingBlockId = (result.metadata as any)?.streamingBlockId || null\nfor (const log of enrichedResult.logs) {\nconst isStreamingBlock = streamingBlockId && log.blockId === streamingBlockId\nif (\nisStreamingBlock &&\n(log.blockType === 'agent' || log.blockType === 'router') &&\nlog.output\n) {\nlog.output.content = streamContent\n}\n}\n}\n}\nconst response = await fetch(`/api/workflows/${activeWorkflowId}/log`, {\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n},\nbody: JSON.stringify({\nexecutionId,\nresult: enrichedResult,\n}),\n})\nif (!response.ok) {\nthrow new Error('Failed to persist logs')\n}\nreturn executionId\n} catch (error) {\nlogger.error('Error persisting logs:', error)\nreturn executionId\n}\n}"
"async function getNextAvailableSlot(\nknowledgeBaseId: string,\nfieldType: string,\nexistingBySlot?: Map<string, any>\n): Promise<string | null> {\nconst availableSlots = getSlotsForFieldType(fieldType)\nlet usedSlots: Set<string>\nif (existingBySlot) {\nusedSlots = new Set(\nArray.from(existingBySlot.entries())\n.filter(([_, def]) => def.fieldType === fieldType)\n.map(([slot, _]) => slot)\n)\n} else {\nconst existingDefinitions = await db\n.select({ tagSlot: knowledgeBaseTagDefinitions.tagSlot })\n.from(knowledgeBaseTagDefinitions)\n.where(\nand(\neq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId),\neq(knowledgeBaseTagDefinitions.fieldType, fieldType)\n)\n)\nusedSlots = new Set(existingDefinitions.map((def) => def.tagSlot))\n}\nfor (const slot of availableSlots) {\nif (!usedSlots.has(slot)) {\nreturn slot\n}\n}\nreturn null\n}"
"async function cleanupUnusedTagDefinitions(knowledgeBaseId: string, requestId: string) {\ntry {\nlogger.info(`[${requestId}] Starting cleanup for KB ${knowledgeBaseId}`)\nconst allDefinitions = await db\n.select()\n.from(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId))\nlogger.info(`[${requestId}] Found ${allDefinitions.length} tag definitions to check`)\nif (allDefinitions.length === 0) {\nreturn 0\n}\nlet cleanedCount = 0\nfor (const definition of allDefinitions) {\nconst slot = definition.tagSlot\nconst countResult = await db.execute(sql`\nSELECT count(*) as count\nFROM document\nWHERE knowledge_base_id = ${knowledgeBaseId}\nAND ${sql.raw(slot)} IS NOT NULL\nAND trim(${sql.raw(slot)}) != ''\n`)\nconst count = Number(countResult[0]?.count) || 0\nlogger.info(\n`[${requestId}] Tag ${definition.displayName} (${slot}): ${count} documents using it`\n)\nif (count === 0) {\nawait db\n.delete(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.id, definition.id))\ncleanedCount++\nlogger.info(\n`[${requestId}] Removed unused tag definition: ${definition.displayName} (${definition.tagSlot})`\n)\n}\n}\nreturn cleanedCount\n} catch (error) {\nlogger.warn(`[${requestId}] Failed to cleanup unused tag definitions:`, error)\nreturn 0\n}\n}"
"export async function GET(\nreq: NextRequest,\n{ params }: { params: Promise<{ id: string; documentId: string }> }\n) {\nconst requestId = randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId, documentId } = await params\ntry {\nlogger.info(`[${requestId}] Getting tag definitions for document ${documentId}`)\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkKnowledgeBaseAccess(knowledgeBaseId, session.user.id)\nif (!accessCheck.hasAccess) {\nreturn NextResponse.json({ error: 'Forbidden' }, { status: 403 })\n}\nconst documentExists = await db\n.select({ id: document.id })\n.from(document)\n.where(and(eq(document.id, documentId), eq(document.knowledgeBaseId, knowledgeBaseId)))\n.limit(1)\nif (documentExists.length === 0) {\nreturn NextResponse.json({ error: 'Document not found' }, { status: 404 })\n}\nconst tagDefinitions = await db\n.select({\nid: knowledgeBaseTagDefinitions.id,\ntagSlot: knowledgeBaseTagDefinitions.tagSlot,\ndisplayName: knowledgeBaseTagDefinitions.displayName,\nfieldType: knowledgeBaseTagDefinitions.fieldType,\ncreatedAt: knowledgeBaseTagDefinitions.createdAt,\nupdatedAt: knowledgeBaseTagDefinitions.updatedAt,\n})\n.from(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId))\nlogger.info(`[${requestId}] Retrieved ${tagDefinitions.length} tag definitions`)\nreturn NextResponse.json({\nsuccess: true,\ndata: tagDefinitions,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error getting tag definitions`, error)\nreturn NextResponse.json({ error: 'Failed to get tag definitions' }, { status: 500 })\n}\n}"
"export async function DELETE(\nreq: NextRequest,\n{ params }: { params: Promise<{ id: string; documentId: string }> }\n) {\nconst requestId = randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId, documentId } = await params\nconst { searchParams } = new URL(req.url)\nconst action = searchParams.get('action')\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkKnowledgeBaseWriteAccess(knowledgeBaseId, session.user.id)\nif (!accessCheck.hasAccess) {\nreturn NextResponse.json({ error: 'Forbidden' }, { status: 403 })\n}\nif (action === 'cleanup') {\nlogger.info(`[${requestId}] Running cleanup for KB ${knowledgeBaseId}`)\nconst cleanedUpCount = await cleanupUnusedTagDefinitions(knowledgeBaseId, requestId)\nreturn NextResponse.json({\nsuccess: true,\ndata: { cleanedUp: cleanedUpCount },\n})\n}\nlogger.info(`[${requestId}] Deleting all tag definitions for KB ${knowledgeBaseId}`)\nconst result = await db\n.delete(knowledgeBaseTagDefinitions)\n.where(eq(knowledgeBaseTagDefinitions.knowledgeBaseId, knowledgeBaseId))\nreturn NextResponse.json({\nsuccess: true,\nmessage: 'Tag definitions deleted successfully',\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error with tag definitions operation`, error)\nreturn NextResponse.json({ error: 'Failed to process tag definitions' }, { status: 500 })\n}\n}"
"export default function Timeline() {\nconst { timeRange, setTimeRange } = useFilterStore()\nconst specificTimeRanges: TimeRange[] = ['Past 30 minutes', 'Past hour', 'Past 24 hours']\nreturn (\n<DropdownMenu>\n<DropdownMenuTrigger asChild>\n<Button\nvariant='outline'\nsize='sm'\nclassName='w-full justify-between rounded-[10px] border-[#E5E5E5] bg-[#FFFFFF] font-normal text-sm dark:border-[#414141] dark:bg-[#202020]'\n>\n{timeRange}\n<ChevronDown className='ml-2 h-4 w-4 text-muted-foreground' />\n</Button>\n</DropdownMenuTrigger>\n<DropdownMenuContent\nalign='start'\nclassName='w-[180px] rounded-lg border-[#E5E5E5] bg-[#FFFFFF] shadow-xs dark:border-[#414141] dark:bg-[#202020]'\n>\n<DropdownMenuItem\nkey='all'\nonSelect={(e) => {\ne.preventDefault()\nsetTimeRange('All time')\n}}\nclassName='flex cursor-pointer items-center justify-between rounded-md px-3 py-2 font-[380] text-card-foreground text-sm hover:bg-secondary/50 focus:bg-secondary/50'\n>\n<span>All time</span>\n{timeRange === 'All time' && <Check className='h-4 w-4 text-primary' />}\n</DropdownMenuItem>\n<DropdownMenuSeparator />\n{specificTimeRanges.map((range) => (\n<DropdownMenuItem\nkey={range}\nonSelect={(e) => {\ne.preventDefault()\nsetTimeRange(range)\n}}\nclassName='flex cursor-pointer items-center justify-between rounded-md px-3 py-2 font-[380] text-card-foreground text-sm hover:bg-secondary/50 focus:bg-secondary/50'\n>\n<span>{range}</span>\n{timeRange === range && <Check className='h-4 w-4 text-primary' />}\n</DropdownMenuItem>\n))}\n</DropdownMenuContent>\n</DropdownMenu>\n)\n}"
"export function previewWorkflowDiff(\ncontent: string,\nformat: EditorFormat\n): {\nsummary: string\noperations: Array<{\ntype: string\ndescription: string\n}>\n} {\ntry {\nif (format === 'yaml') {\nreturn {\nsummary: 'Complete workflow replacement from YAML',\noperations: [\n{\ntype: 'complete_replacement',\ndescription: 'Replace entire workflow with YAML content',\n},\n],\n}\n}\nlet parsedData: any\ntry {\nparsedData = JSON.parse(content)\n} catch (error) {\nreturn {\nsummary: 'Invalid JSON format',\noperations: [],\n}\n}\nconst operations = []\nif (parsedData.state?.blocks) {\nconst blockCount = Object.keys(parsedData.state.blocks).length\noperations.push({\ntype: 'replace_blocks',\ndescription: `Replace workflow with ${blockCount} blocks`,\n})\n}\nif (parsedData.state?.edges) {\nconst edgeCount = parsedData.state.edges.length\noperations.push({\ntype: 'replace_edges',\ndescription: `Replace connections with ${edgeCount} edges`,\n})\n}\nif (parsedData.subBlockValues) {\noperations.push({\ntype: 'replace_values',\ndescription: 'Replace all input values',\n})\n}\nif (parsedData.workflow) {\noperations.push({\ntype: 'update_metadata',\ndescription: 'Update workflow metadata',\n})\n}\nreturn {\nsummary: 'Complete workflow state replacement from JSON',\noperations,\n}\n} catch (error) {\nreturn {\nsummary: 'Error analyzing changes',\noperations: [],\n}\n}\n}"
"export async function GET(\nreq: NextRequest,\n{ params }: { params: Promise<{ id: string; documentId: string; chunkId: string }> }\n) {\nconst requestId = crypto.randomUUID().slice(0, 8)\nconst { id: knowledgeBaseId, documentId, chunkId } = await params\ntry {\nconst session = await getSession()\nif (!session?.user?.id) {\nlogger.warn(`[${requestId}] Unauthorized chunk access attempt`)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nconst accessCheck = await checkChunkAccess(\nknowledgeBaseId,\ndocumentId,\nchunkId,\nsession.user.id\n)\nif (!accessCheck.hasAccess) {\nif (accessCheck.notFound) {\nlogger.warn(\n`[${requestId}] ${accessCheck.reason}: KB=${knowledgeBaseId}, Doc=${documentId}, Chunk=${chunkId}`\n)\nreturn NextResponse.json({ error: accessCheck.reason }, { status: 404 })\n}\nlogger.warn(\n`[${requestId}] User ${session.user.id} attempted unauthorized chunk access: ${accessCheck.reason}`\n)\nreturn NextResponse.json({ error: 'Unauthorized' }, { status: 401 })\n}\nlogger.info(\n`[${requestId}] Retrieved chunk: ${chunkId} from document ${documentId} in knowledge base ${knowledgeBaseId}`\n)\nreturn NextResponse.json({\nsuccess: true,\ndata: accessCheck.chunk,\n})\n} catch (error) {\nlogger.error(`[${requestId}] Error fetching chunk`, error)\nreturn NextResponse.json({ error: 'Failed to fetch chunk' }, { status: 500 })\n}\n}"
"export function DeleteChunkModal({\nchunk,\nknowledgeBaseId,\ndocumentId,\nisOpen,\nonClose,\nonChunkDeleted,\n}: DeleteChunkModalProps) {\nconst [isDeleting, setIsDeleting] = useState(false)\nconst handleDeleteChunk = async () => {\nif (!chunk || isDeleting) return\ntry {\nsetIsDeleting(true)\nconst response = await fetch(\n`/api/knowledge/${knowledgeBaseId}/documents/${documentId}/chunks/${chunk.id}`,\n{\nmethod: 'DELETE',\n}\n)\nif (!response.ok) {\nthrow new Error('Failed to delete chunk')\n}\nconst result = await response.json()\nif (result.success) {\nlogger.info('Chunk deleted successfully:', chunk.id)\nif (onChunkDeleted) {\nonChunkDeleted()\n}\nonClose()\n} else {\nthrow new Error(result.error || 'Failed to delete chunk')\n}\n} catch (err) {\nlogger.error('Error deleting chunk:', err)\n} finally {\nsetIsDeleting(false)\n}\n}\nif (!chunk) return null\nreturn (\n<AlertDialog open={isOpen} onOpenChange={onClose}>\n<AlertDialogContent>\n<AlertDialogHeader>\n<AlertDialogTitle>Delete Chunk</AlertDialogTitle>\n<AlertDialogDescription>\nAre you sure you want to delete this chunk? This action cannot be undone.\n</AlertDialogDescription>\n</AlertDialogHeader>\n<AlertDialogFooter>\n<AlertDialogCancel disabled={isDeleting}>Cancel</AlertDialogCancel>\n<AlertDialogAction\nonClick={handleDeleteChunk}\ndisabled={isDeleting}\nclassName='bg-destructive text-destructive-foreground hover:bg-destructive/90'\n>\n{isDeleting ? (\n<>\n<Loader2 className='mr-2 h-4 w-4 animate-spin' />\nDeleting...\n</>\n) : (\n<>\n<Trash2 className='mr-2 h-4 w-4' />\nDelete\n</>\n)}\n</AlertDialogAction>\n</AlertDialogFooter>\n</AlertDialogContent>\n</AlertDialog>\n)\n}"
export function WorkflowContextMenu({ onStartEdit }: WorkflowContextMenuProps) {\nconst userPermissions = useUserPermissionsContext()\nconst handleRename = () => {\nif (onStartEdit) {\nonStartEdit()\n}\n}\nreturn (\n<DropdownMenu>\n<DropdownMenuTrigger asChild>\n<Button\nvariant='ghost'\nsize='icon'\nclassName='h-4 w-4 p-0 opacity-0 transition-opacity hover:bg-transparent focus:ring-0 focus:ring-offset-0 focus-visible:ring-0 focus-visible:ring-offset-0 group-hover:opacity-100'\nonClick={(e) => e.stopPropagation()}\n>\n<MoreHorizontal className='h-3 w-3' />\n<span className='sr-only'>Workflow options</span>\n</Button>\n</DropdownMenuTrigger>\n<DropdownMenuContent\nalign='end'\nonClick={(e) => e.stopPropagation()}\nclassName='min-w-32 rounded-lg border-[#E5E5E5] bg-[#FFFFFF] shadow-xs dark:border-[#414141] dark:bg-[#202020]'\n>\n{userPermissions.canEdit && (\n<DropdownMenuItem\nonClick={handleRename}\nclassName='cursor-pointer rounded-md px-3 py-2 font-[380] text-card-foreground text-sm hover:bg-secondary/50 focus:bg-secondary/50'\n>\n<Pencil className='mr-2 h-4 w-4' />\nRename\n</DropdownMenuItem>\n)}\n</DropdownMenuContent>\n</DropdownMenu>\n)\n}
"export function WorkflowList({\nregularWorkflows,\nmarketplaceWorkflows,\nisLoading = false,\n}: WorkflowListProps) {\nconst pathname = usePathname()\nconst params = useParams()\nconst workspaceId = params.workspaceId as string\nconst { data: session } = useSession()\nconst skeletonItems = useMemo(() => {\nreturn Array(4)\n.fill(0)\n.map((_, i) => (\n<div\nkey={`skeleton-${i}`}\nclassName='mb-1 flex w-full items-center gap-2 rounded-md px-2 py-1.5'\n>\n<Skeleton className='h-[14px] w-[14px] rounded-md' />\n<Skeleton className='h-4 w-20' />\n</div>\n))\n}, [])\nconst showEmptyState =\n!isLoading &&\nsession?.user &&\nregularWorkflows.length === 0 &&\nmarketplaceWorkflows.length === 0\nreturn (\n<div className={`space-y-1 ${isLoading ? 'opacity-60' : ''}`}>\n{isLoading ? (\nskeletonItems\n) : (\n<>\n{}\n{regularWorkflows.map((workflow) => (\n<WorkflowItem\nkey={workflow.id}\nworkflow={workflow}\nactive={pathname === `/workspace/${workspaceId}/w/${workflow.id}`}\n/>\n))}\n{}\n{marketplaceWorkflows.length > 0 && (\n<div className='mt-2 border-border/30 border-t pt-2'>\n<h3 className='mb-1 px-2 font-medium text-muted-foreground text-xs'>Marketplace</h3>\n{marketplaceWorkflows.map((workflow) => (\n<WorkflowItem\nkey={workflow.id}\nworkflow={workflow}\nactive={pathname === `/workspace/${workspaceId}/w/${workflow.id}`}\nisMarketplace\n/>\n))}\n</div>\n)}\n{}\n{showEmptyState && (\n<div className='px-2 py-1.5 text-muted-foreground text-xs'>\nNo workflows in {workspaceId ? 'this workspace' : 'your account'}. Create one to get\nstarted.\n</div>\n)}\n</>\n)}\n</div>\n)\n}"
"export function CheckboxList({\nblockId,\nsubBlockId,\ntitle,\noptions,\nlayout,\nisPreview = false,\nsubBlockValues,\ndisabled = false,\n}: CheckboxListProps) {\nreturn (\n<div className={cn('grid gap-4', layout === 'half' ? 'grid-cols-2' : 'grid-cols-1', 'pt-1')}>\n{options.map((option) => {\nconst [storeValue, setStoreValue] = useSubBlockValue(blockId, option.id)\nconst previewValue =\nisPreview && subBlockValues ? subBlockValues[option.id]?.value : undefined\nconst value = isPreview ? previewValue : storeValue\nconst handleChange = (checked: boolean) => {\nif (!isPreview && !disabled) {\nsetStoreValue(checked)\n}\n}\nreturn (\n<div key={option.id} className='flex items-center space-x-2'>\n<Checkbox\nid={`${blockId}-${option.id}`}\nchecked={Boolean(value)}\nonCheckedChange={handleChange}\ndisabled={isPreview || disabled}\n/>\n<Label\nhtmlFor={`${blockId}-${option.id}`}\nclassName='cursor-pointer font-normal text-sm leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70'\n>\n{option.label}\n</Label>\n</div>\n)\n})}\n</div>\n)\n}"
"export function DateInput({\nblockId,\nsubBlockId,\nplaceholder,\nisPreview = false,\npreviewValue,\ndisabled = false,\n}: DateInputProps) {\nconst [storeValue, setStoreValue] = useSubBlockValue(blockId, subBlockId)\nconst value = isPreview ? previewValue : storeValue\nconst date = value ? new Date(value) : undefined\nconst isPastDate = React.useMemo(() => {\nif (!date) return false\nconst today = new Date()\ntoday.setHours(0, 0, 0, 0)\nreturn date < today\n}, [date])\nconst handleDateSelect = (selectedDate: Date | undefined) => {\nif (isPreview || disabled) return\nif (selectedDate) {\nconst today = new Date()\ntoday.setHours(0, 0, 0, 0)\n}\nsetStoreValue(selectedDate?.toISOString() || '')\n}\nreturn (\n<Popover>\n<PopoverTrigger asChild>\n<Button\nvariant='outline'\ndisabled={isPreview || disabled}\nclassName={cn(\n'w-full justify-start text-left font-normal',\n!date && 'text-muted-foreground',\nisPastDate && 'border-red-500'\n)}\n>\n<CalendarIcon className='mr-1 h-4 w-4' />\n{date ? format(date, 'MMM d, yy') : <span>{placeholder || 'Pick a date'}</span>}\n</Button>\n</PopoverTrigger>\n<PopoverContent className='w-auto p-0'>\n<Calendar mode='single' selected={date} onSelect={handleDateSelect} initialFocus />\n</PopoverContent>\n</Popover>\n)\n}"
"export function SettingsNavigation({\nactiveSection,\nonSectionChange,\nhasOrganization,\n}: SettingsNavigationProps) {\nconst { getSubscriptionStatus } = useSubscriptionStore()\nconst subscription = getSubscriptionStatus()\nconst navigationItems = allNavigationItems.filter((item) => {\nif (item.hideInDev && isDev) {\nreturn false\n}\nif (item.requiresTeam && !subscription.isTeam && !subscription.isEnterprise) {\nreturn false\n}\nreturn true\n})\nreturn (\n<div className='py-4'>\n{navigationItems.map((item) => (\n<button\nkey={item.id}\nonClick={() => onSectionChange(item.id)}\nclassName={cn(\n'flex w-full items-center gap-3 px-4 py-2.5 text-sm transition-colors',\n'hover:bg-muted/50',\nactiveSection === item.id\n? 'bg-muted/50 font-medium text-foreground'\n: 'text-muted-foreground hover:text-foreground'\n)}\n>\n<item.icon className='h-4 w-4' />\n<span>{item.label}</span>\n</button>\n))}\n</div>\n)\n}"
"export function ToolbarBlock({ config, disabled = false }: ToolbarBlockProps) {\nconst userPermissions = useUserPermissionsContext()\nconst handleDragStart = (e: React.DragEvent) => {\nif (disabled) {\ne.preventDefault()\nreturn\n}\ne.dataTransfer.setData('application/json', JSON.stringify({ type: config.type }))\ne.dataTransfer.effectAllowed = 'move'\n}\nconst handleClick = useCallback(() => {\nif (config.type === 'connectionBlock' || disabled) return\nconst event = new CustomEvent('add-block-from-toolbar', {\ndetail: {\ntype: config.type,\n},\n})\nwindow.dispatchEvent(event)\n}, [config.type, disabled])\nconst blockContent = (\n<div\ndraggable={!disabled}\nonDragStart={handleDragStart}\nonClick={handleClick}\nclassName={cn(\n'group flex h-9 items-center gap-[10px] rounded-[8px] p-2 transition-colors',\ndisabled\n? 'cursor-not-allowed opacity-60'\n: 'cursor-pointer hover:bg-muted active:cursor-grabbing'\n)}\n>\n<div\nclassName='relative flex h-6 w-6 shrink-0 items-center justify-center overflow-hidden rounded-[6px]'\nstyle={{ backgroundColor: config.bgColor }}\n>\n<config.icon\nclassName={cn(\n'text-white transition-transform duration-200',\n!disabled && 'group-hover:scale-110',\n'!h-4 !w-4'\n)}\n/>\n</div>\n<span className='font-medium text-sm leading-none'>{config.name}</span>\n</div>\n)\nif (disabled) {\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>{blockContent}</TooltipTrigger>\n<TooltipContent>\n{userPermissions.isOfflineMode\n? 'Connection lost - please refresh'\n: 'Edit permissions required to add blocks'}\n</TooltipContent>\n</Tooltip>\n)\n}\nreturn blockContent\n}"
"export default function LoopToolbarItem({ disabled = false }: LoopToolbarItemProps) {\nconst userPermissions = useUserPermissionsContext()\nconst handleDragStart = (e: React.DragEvent) => {\nif (disabled) {\ne.preventDefault()\nreturn\n}\nconst simplifiedData = {\ntype: 'loop',\n}\ne.dataTransfer.setData('application/json', JSON.stringify(simplifiedData))\ne.dataTransfer.effectAllowed = 'move'\n}\nconst handleClick = useCallback(\n(e: React.MouseEvent) => {\nif (disabled) return\nconst event = new CustomEvent('add-block-from-toolbar', {\ndetail: {\ntype: 'loop',\nclientX: e.clientX,\nclientY: e.clientY,\n},\n})\nwindow.dispatchEvent(event)\n},\n[disabled]\n)\nconst blockContent = (\n<div\ndraggable={!disabled}\nonDragStart={handleDragStart}\nonClick={handleClick}\nclassName={cn(\n'group flex h-8 items-center gap-[10px] rounded-[8px] p-2 transition-colors',\ndisabled\n? 'cursor-not-allowed opacity-60'\n: 'cursor-pointer hover:bg-muted active:cursor-grabbing'\n)}\n>\n<div\nclassName='relative flex h-6 w-6 shrink-0 items-center justify-center overflow-hidden rounded-[6px]'\nstyle={{ backgroundColor: LoopTool.bgColor }}\n>\n<LoopTool.icon\nclassName={cn(\n'h-[14px] w-[14px] text-white transition-transform duration-200',\n!disabled && 'group-hover:scale-110'\n)}\n/>\n</div>\n<span className='font-medium text-sm leading-none'>{LoopTool.name}</span>\n</div>\n)\nif (disabled) {\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>{blockContent}</TooltipTrigger>\n<TooltipContent>\n{userPermissions.isOfflineMode\n? 'Connection lost - please refresh'\n: 'Edit permissions required to add blocks'}\n</TooltipContent>\n</Tooltip>\n)\n}\nreturn blockContent\n}"
"export default function ParallelToolbarItem({ disabled = false }: ParallelToolbarItemProps) {\nconst userPermissions = useUserPermissionsContext()\nconst handleDragStart = (e: React.DragEvent) => {\nif (disabled) {\ne.preventDefault()\nreturn\n}\nconst simplifiedData = {\ntype: 'parallel',\n}\ne.dataTransfer.setData('application/json', JSON.stringify(simplifiedData))\ne.dataTransfer.effectAllowed = 'move'\n}\nconst handleClick = useCallback(\n(e: React.MouseEvent) => {\nif (disabled) return\nconst event = new CustomEvent('add-block-from-toolbar', {\ndetail: {\ntype: 'parallel',\nclientX: e.clientX,\nclientY: e.clientY,\n},\nbubbles: true,\n})\nwindow.dispatchEvent(event)\n},\n[disabled]\n)\nconst blockContent = (\n<div\ndraggable={!disabled}\nonDragStart={handleDragStart}\nonClick={handleClick}\nclassName={cn(\n'group flex h-8 items-center gap-[10px] rounded-[8px] p-2 transition-colors',\ndisabled\n? 'cursor-not-allowed opacity-60'\n: 'cursor-pointer hover:bg-muted active:cursor-grabbing'\n)}\n>\n<div\nclassName='relative flex h-6 w-6 shrink-0 items-center justify-center overflow-hidden rounded-[6px]'\nstyle={{ backgroundColor: ParallelTool.bgColor }}\n>\n<ParallelTool.icon\nclassName={cn(\n'h-[14px] w-[14px] text-white transition-transform duration-200',\n!disabled && 'group-hover:scale-110'\n)}\n/>\n</div>\n<span className='font-medium text-sm leading-none'>{ParallelTool.name}</span>\n</div>\n)\nif (disabled) {\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>{blockContent}</TooltipTrigger>\n<TooltipContent>\n{userPermissions.isOfflineMode\n? 'Connection lost - please refresh'\n: 'Edit permissions required to add blocks'}\n</TooltipContent>\n</Tooltip>\n)\n}\nreturn blockContent\n}"
"export function ConnectionStatus({ isConnected, hasOperationError }: ConnectionStatusProps) {\nconst userPermissions = useUserPermissionsContext()\nconst handleRefresh = () => {\nwindow.location.reload()\n}\nconst shouldShowError = userPermissions.isOfflineMode || hasOperationError\nif (!shouldShowError) {\nreturn null\n}\nreturn (\n<div className='flex items-center gap-2 rounded-md border border-red-200 bg-red-50 px-3 py-2'>\n<div className='flex items-center gap-2 text-red-700'>\n<div className='relative flex items-center justify-center'>\n{!isConnected && (\n<div className='absolute h-4 w-4 animate-ping rounded-full bg-red-500/20' />\n)}\n<AlertTriangle className='relative h-4 w-4' />\n</div>\n<div className='flex flex-col'>\n<span className='font-medium text-xs leading-tight'>\n{hasOperationError\n? 'Workflow Edit Failed'\n: isConnected\n? 'Reconnected'\n: 'Connection lost - please refresh'}\n</span>\n<span className='text-red-600 text-xs leading-tight'>\nPlease refresh to continue editing\n</span>\n</div>\n</div>\n<Tooltip>\n<TooltipTrigger asChild>\n<Button\nonClick={handleRefresh}\nvariant='ghost'\nsize='sm'\nclassName='h-7 w-7 p-0 text-red-700 hover:bg-red-100 hover:text-red-800'\n>\n<RefreshCw className='h-4 w-4' />\n</Button>\n</TooltipTrigger>\n<TooltipContent className='z-[9999]'>Refresh page to continue editing</TooltipContent>\n</Tooltip>\n</div>\n)\n}"
"export function UserAvatar({\nconnectionId,\nname,\ncolor,\ntooltipContent,\nsize = 'md',\nindex = 0,\n}: AvatarProps) {\nconst backgroundStyle = useMemo(() => {\nif (color) {\nconst baseColor = color\nconst lighterShade = color.startsWith('#')\n? `${color}dd`\n: color\nconst darkerShade = color.startsWith('#') ? color : color\nreturn `linear-gradient(135deg, ${lighterShade}, ${darkerShade})`\n}\nreturn generateGradient(connectionId)\n}, [connectionId, color])\nconst sizeClass = {\nsm: 'h-5 w-5 text-[10px]',\nmd: 'h-7 w-7 text-xs',\nlg: 'h-9 w-9 text-sm',\n}[size]\nconst initials = name ? name.charAt(0).toUpperCase() : '?'\nconst avatarElement = (\n<div\nclassName={`\n${sizeClass} flex flex-shrink-0 cursor-default items-center justify-center rounded-full border-2 border-white font-semibold text-white shadow-sm `}\nstyle={\n{\nbackground: backgroundStyle,\nzIndex: 10 - index,\n} as CSSProperties\n}\n>\n{initials}\n</div>\n)\nif (tooltipContent) {\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>{avatarElement}</TooltipTrigger>\n<TooltipContent side='bottom' className='max-w-xs'>\n{tooltipContent}\n</TooltipContent>\n</Tooltip>\n)\n}\nreturn avatarElement\n}"
"export function CopilotWelcome({ onQuestionClick, mode = 'ask' }: CopilotWelcomeProps) {\nconst askQuestions = [\n'How do I create a workflow?',\n'What tools are available?',\n'What does my workflow do?',\n]\nconst agentQuestions = [\n'Help me build a workflow',\n'I want to edit my workflow',\n'Build me a small sample workflow',\n]\nconst exampleQuestions = mode === 'ask' ? askQuestions : agentQuestions\nconst handleQuestionClick = (question: string) => {\nonQuestionClick?.(question)\n}\nreturn (\n<div className='flex h-full flex-col items-center justify-center px-4 py-10'>\n<div className='space-y-6 text-center'>\n<Bot className='mx-auto h-12 w-12 text-muted-foreground' />\n<div className='space-y-2'>\n<h3 className='font-medium text-lg'>How can I help you today?</h3>\n<p className='text-muted-foreground text-sm'>\n{mode === 'ask'\n? 'Ask me anything about your workflows, available tools, or how to get started.'\n: 'I can help you build, edit, and create workflows. What would you like to do?'}\n</p>\n</div>\n<div className='mx-auto max-w-sm space-y-3'>\n<div className='font-medium text-muted-foreground text-xs'>Try asking:</div>\n<div className='flex flex-wrap justify-center gap-2'>\n{exampleQuestions.map((question, index) => (\n<button\nkey={index}\nclassName='inline-flex cursor-pointer items-center rounded-full bg-muted/60 px-3 py-1.5 font-medium text-muted-foreground text-xs transition-all hover:scale-105 hover:bg-muted hover:text-foreground active:scale-95'\nonClick={() => handleQuestionClick(question)}\n>\n{question}\n</button>\n))}\n</div>\n</div>\n</div>\n</div>\n)\n}"
"export function UsageLimitEditor({\ncurrentLimit,\ncanEdit,\nminimumLimit,\nonLimitUpdated,\n}: UsageLimitEditorProps) {\nconst [inputValue, setInputValue] = useState(currentLimit.toString())\nconst [isSaving, setIsSaving] = useState(false)\nconst { updateUsageLimit } = useSubscriptionStore()\nuseEffect(() => {\nsetInputValue(currentLimit.toString())\n}, [currentLimit])\nconst handleSubmit = async () => {\nconst newLimit = Number.parseInt(inputValue, 10)\nif (Number.isNaN(newLimit) || newLimit < minimumLimit) {\nsetInputValue(currentLimit.toString())\nreturn\n}\nif (newLimit === currentLimit) {\nreturn\n}\nsetIsSaving(true)\ntry {\nconst result = await updateUsageLimit(newLimit)\nif (!result.success) {\nthrow new Error(result.error || 'Failed to update limit')\n}\nsetInputValue(newLimit.toString())\nonLimitUpdated?.(newLimit)\n} catch (error) {\nlogger.error('Failed to update usage limit', { error })\nsetInputValue(currentLimit.toString())\n} finally {\nsetIsSaving(false)\n}\n}\nconst handleKeyDown = (e: React.KeyboardEvent) => {\nif (e.key === 'Enter') {\ne.preventDefault()\nhandleSubmit()\n}\n}\nreturn (\n<div className='flex items-center'>\n<span className='mr-1 text-sm'>$</span>\n{canEdit ? (\n<Input\ntype='number'\nvalue={inputValue}\nonChange={(e) => setInputValue(e.target.value)}\nonKeyDown={handleKeyDown}\nonBlur={handleSubmit}\nclassName='h-8 w-20 font-medium text-sm'\nmin={minimumLimit}\nstep='1'\ndisabled={isSaving}\nautoComplete='off'\ndata-form-type='other'\nname='usage-limit'\n/>\n) : (\n<span className='font-medium text-sm'>{currentLimit}</span>\n)}\n</div>\n)\n}"
"export function OrganizationCreationDialog({\nopen,\nonOpenChange,\norgName,\nonOrgNameChange,\norgSlug,\nonOrgSlugChange,\nonCreateOrganization,\nisCreating,\nerror,\n}: OrganizationCreationDialogProps) {\nreturn (\n<Dialog open={open} onOpenChange={onOpenChange}>\n<DialogContent>\n<DialogHeader>\n<DialogTitle>Create Team Workspace</DialogTitle>\n<DialogDescription>\nCreate a workspace for your team to collaborate on projects.\n</DialogDescription>\n</DialogHeader>\n<div className='space-y-4 py-4'>\n<div className='space-y-2'>\n<label htmlFor='orgName' className='font-medium text-sm'>\nTeam Name\n</label>\n<Input id='orgName' value={orgName} onChange={onOrgNameChange} placeholder='My Team' />\n</div>\n<div className='space-y-2'>\n<label htmlFor='orgSlug' className='font-medium text-sm'>\nTeam URL\n</label>\n<div className='flex items-center space-x-2'>\n<div className='rounded-l-md bg-muted px-3 py-2 text-muted-foreground text-sm'>\nsim.ai/team/\n</div>\n<Input\nvalue={orgSlug}\nonChange={(e) => onOrgSlugChange(e.target.value)}\nclassName='rounded-l-none'\n/>\n</div>\n</div>\n</div>\n{error && (\n<Alert variant='destructive'>\n<AlertTitle>Error</AlertTitle>\n<AlertDescription>{error}</AlertDescription>\n</Alert>\n)}\n<DialogFooter>\n<Button variant='outline' onClick={() => onOpenChange(false)} disabled={isCreating}>\nCancel\n</Button>\n<Button onClick={onCreateOrganization} disabled={!orgName || !orgSlug || isCreating}>\n{isCreating && <RefreshCw className='mr-2 h-4 w-4 animate-spin' />}\nCreate Team Workspace\n</Button>\n</DialogFooter>\n</DialogContent>\n</Dialog>\n)\n}"
"export function RemoveMemberDialog({\nopen,\nmemberName,\nshouldReduceSeats,\nonOpenChange,\nonShouldReduceSeatsChange,\nonConfirmRemove,\nonCancel,\n}: RemoveMemberDialogProps) {\nreturn (\n<Dialog open={open} onOpenChange={onOpenChange}>\n<DialogContent>\n<DialogHeader>\n<DialogTitle>Remove Team Member</DialogTitle>\n<DialogDescription>\nAre you sure you want to remove {memberName} from the team?\n</DialogDescription>\n</DialogHeader>\n<div className='py-4'>\n<div className='flex items-center space-x-2'>\n<input\ntype='checkbox'\nid='reduce-seats'\nclassName='rounded'\nchecked={shouldReduceSeats}\nonChange={(e) => onShouldReduceSeatsChange(e.target.checked)}\n/>\n<label htmlFor='reduce-seats' className='text-sm'>\nAlso reduce seat count in my subscription\n</label>\n</div>\n<p className='mt-1 text-muted-foreground text-xs'>\nIf selected, your team seat count will be reduced by 1, lowering your monthly billing.\n</p>\n</div>\n<DialogFooter>\n<Button variant='outline' onClick={onCancel}>\nCancel\n</Button>\n<Button variant='destructive' onClick={() => onConfirmRemove(shouldReduceSeats)}>\nRemove\n</Button>\n</DialogFooter>\n</DialogContent>\n</Dialog>\n)\n}"
"export function TeamMembersList({\norganization,\ncurrentUserEmail,\nisAdminOrOwner,\nonRemoveMember,\n}: TeamMembersListProps) {\nif (!organization.members || organization.members.length === 0) {\nreturn (\n<div className='rounded-md border'>\n<h4 className='border-b p-4 font-medium text-sm'>Team Members</h4>\n<div className='p-4 text-muted-foreground text-sm'>\nNo members in this organization yet.\n</div>\n</div>\n)\n}\nreturn (\n<div className='rounded-md border'>\n<h4 className='border-b p-4 font-medium text-sm'>Team Members</h4>\n<div className='divide-y'>\n{organization.members.map((member: Member) => (\n<div key={member.id} className='flex items-center justify-between p-4'>\n<div className='flex-1'>\n<div className='flex items-center gap-3'>\n<div className='flex h-8 w-8 items-center justify-center rounded-full bg-primary/10 font-medium text-primary text-sm'>\n{(member.user?.name || member.user?.email || 'U').charAt(0).toUpperCase()}\n</div>\n<div className='flex-1'>\n<div className='font-medium'>{member.user?.name || 'Unknown'}</div>\n<div className='text-muted-foreground text-sm'>{member.user?.email}</div>\n</div>\n<div className='rounded-full bg-primary/10 px-3 py-1 font-medium text-primary text-xs'>\n{member.role.charAt(0).toUpperCase() + member.role.slice(1)}\n</div>\n</div>\n</div>\n{}\n{isAdminOrOwner &&\nmember.role !== 'owner' &&\nmember.user?.email !== currentUserEmail && (\n<Button variant='outline' size='sm' onClick={() => onRemoveMember(member)}>\n<UserX className='h-4 w-4' />\n</Button>\n)}\n</div>\n))}\n</div>\n</div>\n)\n}"
"export function SubdomainInput({\nvalue,\nonChange,\noriginalSubdomain,\ndisabled = false,\nonValidationChange,\nisEditingExisting = false,\n}: SubdomainInputProps) {\nconst { isChecking, error, isValid } = useSubdomainValidation(\nvalue,\noriginalSubdomain,\nisEditingExisting\n)\nuseEffect(() => {\nonValidationChange?.(isValid)\n}, [isValid, onValidationChange])\nconst handleChange = (newValue: string) => {\nconst lowercaseValue = newValue.toLowerCase()\nonChange(lowercaseValue)\n}\nreturn (\n<div className='space-y-2'>\n<Label htmlFor='subdomain' className='font-medium text-sm'>\nSubdomain\n</Label>\n<div className='relative flex items-center rounded-md ring-offset-background focus-within:ring-2 focus-within:ring-ring focus-within:ring-offset-2'>\n<Input\nid='subdomain'\nplaceholder='company-name'\nvalue={value}\nonChange={(e) => handleChange(e.target.value)}\nrequired\ndisabled={disabled}\nclassName={cn(\n'rounded-r-none border-r-0 focus-visible:ring-0 focus-visible:ring-offset-0',\nerror && 'border-destructive focus-visible:border-destructive'\n)}\n/>\n<div className='flex h-10 items-center whitespace-nowrap rounded-r-md border border-l-0 bg-muted px-3 font-medium text-muted-foreground text-sm'>\n{getDomainSuffix()}\n</div>\n{isChecking && (\n<div className='absolute right-14 flex items-center'>\n<div className='h-4 w-4 animate-spin rounded-full border-2 border-gray-300 border-t-blue-600' />\n</div>\n)}\n</div>\n{error && <p className='mt-1 text-destructive text-sm'>{error}</p>}\n</div>\n)\n}"
"export function SuccessView({ deployedUrl, existingChat, onDelete, onUpdate }: SuccessViewProps) {\nconst url = new URL(deployedUrl)\nconst hostname = url.hostname\nconst isDevelopmentUrl = hostname.includes('localhost')\nlet domainSuffix\nif (isDevelopmentUrl) {\nconst baseDomain = getBaseDomain()\nconst baseHost = baseDomain.split(':')[0]\nconst port = url.port || (baseDomain.includes(':') ? baseDomain.split(':')[1] : '3000')\ndomainSuffix = `.${baseHost}:${port}`\n} else {\ndomainSuffix = `.${getEmailDomain()}`\n}\nconst baseDomainForSplit = getEmailDomain()\nconst subdomainPart = isDevelopmentUrl\n? hostname.split('.')[0]\n: hostname.split(`.${baseDomainForSplit}`)[0]\nreturn (\n<div className='space-y-4'>\n<div className='space-y-2'>\n<Label className='font-medium text-sm'>\nChat {existingChat ? 'Update' : 'Deployment'} Successful\n</Label>\n<div className='relative flex items-center rounded-md ring-offset-background'>\n<a\nhref={deployedUrl}\ntarget='_blank'\nrel='noopener noreferrer'\nclassName='flex h-10 flex-1 items-center break-all rounded-l-md border border-r-0 p-2 font-medium text-primary text-sm'\n>\n{subdomainPart}\n</a>\n<div className='flex h-10 items-center whitespace-nowrap rounded-r-md border border-l-0 bg-muted px-3 font-medium text-muted-foreground text-sm'>\n{domainSuffix}\n</div>\n</div>\n<p className='text-muted-foreground text-xs'>\nYour chat is now live at{' '}\n<a\nhref={deployedUrl}\ntarget='_blank'\nrel='noopener noreferrer'\nclassName='text-primary hover:underline'\n>\nthis URL\n</a>\n</p>\n</div>\n{}\n<button type='button' data-delete-trigger onClick={onDelete} style={{ display: 'none' }} />\n<button type='button' data-update-trigger onClick={onUpdate} style={{ display: 'none' }} />\n</div>\n)\n}"
"export function useSubdomainValidation(\nsubdomain: string,\noriginalSubdomain?: string,\nisEditingExisting?: boolean\n) {\nconst [isChecking, setIsChecking] = useState(false)\nconst [error, setError] = useState<string | null>(null)\nconst [isValid, setIsValid] = useState(false)\nconst timeoutRef = useRef<NodeJS.Timeout | null>(null)\nuseEffect(() => {\nif (timeoutRef.current) {\nclearTimeout(timeoutRef.current)\n}\nsetError(null)\nsetIsValid(false)\nsetIsChecking(false)\nif (!subdomain.trim()) {\nreturn\n}\nif (originalSubdomain && subdomain === originalSubdomain) {\nsetIsValid(true)\nreturn\n}\nif (isEditingExisting && !originalSubdomain) {\nsetIsValid(true)\nreturn\n}\nif (!/^[a-z0-9-]+$/.test(subdomain)) {\nsetError('Subdomain can only contain lowercase letters, numbers, and hyphens')\nreturn\n}\nsetIsChecking(true)\ntimeoutRef.current = setTimeout(async () => {\ntry {\nconst response = await fetch(\n`/api/chat/subdomains/validate?subdomain=${encodeURIComponent(subdomain)}`\n)\nconst data = await response.json()\nif (!response.ok || !data.available) {\nsetError(data.error || 'This subdomain is already in use')\nsetIsValid(false)\n} else {\nsetError(null)\nsetIsValid(true)\n}\n} catch (error) {\nsetError('Error checking subdomain availability')\nsetIsValid(false)\n} finally {\nsetIsChecking(false)\n}\n}, 500)\nreturn () => {\nif (timeoutRef.current) {\nclearTimeout(timeoutRef.current)\n}\n}\n}, [subdomain, originalSubdomain, isEditingExisting])\nreturn { isChecking, error, isValid }\n}"
"export function FolderSelectorInput({\nblockId,\nsubBlock,\ndisabled = false,\nisPreview = false,\npreviewValue,\n}: FolderSelectorInputProps) {\nconst { getValue, setValue } = useSubBlockStore()\nconst [selectedFolderId, setSelectedFolderId] = useState<string>('')\nconst [_folderInfo, setFolderInfo] = useState<FolderInfo | null>(null)\nuseEffect(() => {\nif (isPreview && previewValue !== undefined) {\nsetSelectedFolderId(previewValue)\n} else {\nconst value = getValue(blockId, subBlock.id)\nif (value && typeof value === 'string') {\nsetSelectedFolderId(value)\n} else {\nconst defaultValue = 'INBOX'\nsetSelectedFolderId(defaultValue)\nif (!isPreview) {\nsetValue(blockId, subBlock.id, defaultValue)\n}\n}\n}\n}, [blockId, subBlock.id, getValue, setValue, isPreview, previewValue])\nconst handleFolderChange = (folderId: string, info?: FolderInfo) => {\nsetSelectedFolderId(folderId)\nsetFolderInfo(info || null)\nif (!isPreview) {\nsetValue(blockId, subBlock.id, folderId)\n}\n}\nreturn (\n<FolderSelector\nvalue={selectedFolderId}\nonChange={handleFolderChange}\nprovider={subBlock.provider || 'google-email'}\nrequiredScopes={subBlock.requiredScopes || []}\nlabel={subBlock.placeholder || 'Select folder'}\ndisabled={disabled}\nserviceId={subBlock.serviceId}\nonFolderInfoChange={setFolderInfo}\n/>\n)\n}"
"export function CommandItem({\nchildren,\nclassName,\nvalue,\nonSelect,\ndisabled = false,\n}: CommandItemProps) {\nconst { activeIndex, filteredItems, registerItem, unregisterItem } = useCommandContext()\nconst isActive = filteredItems.indexOf(value) === activeIndex\nconst [isHovered, setIsHovered] = useState(false)\nuseEffect(() => {\nif (value) {\nregisterItem(value)\nreturn () => unregisterItem(value)\n}\n}, [value, registerItem, unregisterItem])\nconst shouldDisplay = filteredItems.includes(value)\nif (!shouldDisplay) return null\nreturn (\n<button\nid={value}\nclassName={cn(\n'relative flex w-full cursor-pointer select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none hover:bg-accent hover:text-accent-foreground data-[disabled=true]:pointer-events-none data-[selected=true]:bg-accent data-[selected=true]:text-accent-foreground data-[disabled=true]:opacity-50',\nisActive && 'bg-accent text-accent-foreground',\nclassName\n)}\nonClick={() => !disabled && onSelect?.()}\nonMouseEnter={() => setIsHovered(true)}\nonMouseLeave={() => setIsHovered(false)}\ndata-selected={isActive || isHovered}\ndata-disabled={disabled}\ndisabled={disabled}\n>\n{children}\n</button>\n)\n}"
"export function StripeConfig({ testResult, copied, copyToClipboard }: StripeConfigProps) {\nreturn (\n<div className='space-y-4'>\n{}\n<TestResultDisplay\ntestResult={testResult}\ncopied={copied}\ncopyToClipboard={copyToClipboard}\nshowCurlCommand={false}\n/>\n<InstructionsSection tip='Stripe will send a test event to verify your webhook endpoint after adding it.'>\n<ol className='list-inside list-decimal space-y-1'>\n<li>\nGo to your{' '}\n<a\nhref='https:\ntarget='_blank'\nrel='noopener noreferrer'\nclassName='link'\n>\nStripe Dashboard\n</a>\n.\n</li>\n<li>Navigate to Developers {'>'} Webhooks.</li>\n<li>Click `Add endpoint`.</li>\n<li>\nPaste the <strong>Webhook URL</strong> (from above) into the `Endpoint URL` field.\n</li>\n<li>Select the events you want to listen to (e.g., `charge.succeeded`).</li>\n<li>Click `Add endpoint`.</li>\n</ol>\n</InstructionsSection>\n<Alert>\n<ShieldCheck className='h-4 w-4' />\n<AlertTitle>Webhook Signing</AlertTitle>\n<AlertDescription>\nFor production use, it's highly recommended to verify Stripe webhook signatures to ensure\nrequests are genuinely from Stripe. Sim handles this automatically if you provide the\nsigning secret during setup (coming soon).\n</AlertDescription>\n</Alert>\n</div>\n)\n}"
"export function TelegramConfig({\nbotToken,\nsetBotToken,\nisLoadingToken,\ntestResult,\ncopied,\ncopyToClipboard,\ntestWebhook,\nwebhookId,\nwebhookUrl,\n}: TelegramConfigProps) {\nreturn (\n<div className='space-y-4'>\n<ConfigSection title='Telegram Configuration'>\n<ConfigField\nid='telegram-bot-token'\nlabel='Bot Token *'\ndescription='Your Telegram Bot Token from BotFather'\n>\n{isLoadingToken ? (\n<Skeleton className='h-10 w-full' />\n) : (\n<Input\nid='telegram-bot-token'\nvalue={botToken}\nonChange={(e) => {\nsetBotToken(e.target.value)\n}}\nplaceholder='123456789:ABCdefGHIjklMNOpqrsTUVwxyz'\ntype='password'\nrequired\n/>\n)}\n</ConfigField>\n</ConfigSection>\n{testResult && (\n<WebhookTestResult\ntestResult={testResult}\ncopied={copied}\ncopyToClipboard={copyToClipboard}\n/>\n)}\n<InstructionsSection>\n<ol className='list-inside list-decimal space-y-2'>\n<li>\nMessage `/newbot` to{' '}\n<a\nhref='https:\ntarget='_blank'\nrel='noopener noreferrer'\nclassName='link text-primary underline transition-colors hover:text-primary/80'\nonClick={(e) => {\ne.stopPropagation()\nwindow.open('https:\ne.preventDefault()\n}}\n>\n@BotFather\n</a>{' '}\nin Telegram to create a bot and copy its token.\n</li>\n<li>Enter your Bot Token above.</li>\n<li>Save settings and any message sent to your bot will trigger the workflow.</li>\n</ol>\n</InstructionsSection>\n</div>\n)\n}"
"export function TestResultDisplay({\ntestResult,\ncopied,\ncopyToClipboard,\nshowCurlCommand = false,\n}: TestResultDisplayProps) {\nif (!testResult) return null\nreturn (\n<Notice\nvariant={testResult.success ? 'success' : 'error'}\ntitle={testResult.success ? 'Webhook Test Successful' : 'Webhook Test Failed'}\nicon={testResult.success ? null : undefined}\nclassName={cn(\n'mb-4',\ntestResult.success\n? 'border-green-200 bg-green-50 dark:border-green-800/50 dark:bg-green-950/20'\n: 'border-red-200 bg-red-50 dark:border-red-800/50 dark:bg-red-950/20'\n)}\n>\n<div\nclassName={cn(\n'text-sm',\ntestResult.success\n? 'text-green-800 dark:text-green-300'\n: 'text-red-800 dark:text-red-300'\n)}\n>\n{testResult.message}\n{showCurlCommand && testResult.success && testResult.test?.curlCommand && (\n<div className='group relative mt-3 overflow-x-auto rounded border border-border bg-black/10 p-2 font-mono text-xs dark:bg-white/10'>\n<span className='absolute top-1 left-2 font-sans text-[10px] text-muted-foreground'>\nExample Request:\n</span>\n<Button\ntype='button'\nvariant='ghost'\nsize='icon'\nclassName='absolute top-1 right-1 h-6 w-6 text-inherit opacity-70 hover:opacity-100'\nonClick={() => copyToClipboard(testResult.test?.curlCommand || '', 'curl-command')}\naria-label='Copy cURL command'\n>\n{copied === 'curl-command' ? (\n<Check className='h-3 w-3' />\n) : (\n<Copy className='h-3 w-3' />\n)}\n</Button>\n<pre className='whitespace-pre-wrap break-all pt-4 pr-8'>\n{testResult.test.curlCommand}\n</pre>\n</div>\n)}\n</div>\n</Notice>\n)\n}"
"export function WebhookUrlField({\nwebhookUrl,\nisLoadingToken,\ncopied,\ncopyToClipboard,\n}: WebhookUrlFieldProps) {\nreturn (\n<div className='mb-4 space-y-1'>\n<div className='flex items-center gap-2'>\n<Label htmlFor='webhook-url' className='font-medium text-sm'>\nWebhook URL\n</Label>\n<Tooltip>\n<TooltipTrigger asChild>\n<Button\nvariant='ghost'\nsize='sm'\nclassName='h-6 w-6 p-1 text-gray-500'\naria-label='Learn more about webhook URL'\n>\n<Info className='h-4 w-4' />\n</Button>\n</TooltipTrigger>\n<TooltipContent\nside='right'\nalign='center'\nclassName='z-[100] max-w-[300px] p-3'\nrole='tooltip'\n>\n<p className='text-sm'>URL that will receive webhook requests</p>\n</TooltipContent>\n</Tooltip>\n</div>\n<div className='flex'>\n<Input\nid='webhook-url'\nreadOnly\nvalue={webhookUrl}\nclassName={cn(\n'h-10 flex-1 cursor-text font-mono text-xs',\n'focus-visible:ring-2 focus-visible:ring-primary/20'\n)}\nonClick={(e) => (e.target as HTMLInputElement).select()}\ndisabled={isLoadingToken}\n/>\n<Button\ntype='button'\nsize='icon'\nvariant='outline'\nclassName={cn('ml-2 h-10 w-10', 'hover:bg-primary/5', 'transition-colors')}\nonClick={() => copyToClipboard(webhookUrl, 'url')}\ndisabled={isLoadingToken}\n>\n{copied === 'url' ? (\n<CheckCheck className='h-4 w-4 text-green-500' />\n) : (\n<Copy className='h-4 w-4' />\n)}\n</Button>\n</div>\n</div>\n)\n}"
"export default function Command() {\nconst [projects, setProjects] = useState<Project[]>([]);\nconst [isLoading, setIsLoading] = useState(true);\nconst [isSubmitting, setIsSubmitting] = useState(false);\nconst { pop } = useNavigation();\nuseEffect(() => {\nasync function loadProjects() {\ntry {\nsetIsLoading(true);\nconst isConnected = await checkApiConnection();\nif (!isConnected) {\nreturn;\n}\nconst fetchedProjects = await fetchProjects();\nsetProjects(fetchedProjects);\n} catch (error) {\nconsole.error(`Failed to load projects:`, error);\n} finally {\nsetIsLoading(false);\n}\n}\nloadProjects();\n}, []);\nasync function handleSubmit(values: FormValues) {\nif (!values.content.trim()) {\nawait showToast({\nstyle: Toast.Style.Failure,\ntitle: `Content Required`,\nmessage: `Please enter some content for the memory`,\n});\nreturn;\n}\ntry {\nsetIsSubmitting(true);\nconst containerTags = values.project ? [values.project] : undefined;\nawait addMemory({\ncontent: values.content.trim(),\ncontainerTags,\n});\npop();\n} catch (error) {\nconsole.error(`Failed to add memory:`, error);\n} finally {\nsetIsSubmitting(false);\n}\n}\nreturn (\n<Form\nisLoading={isLoading || isSubmitting}\nactions={\n<ActionPanel>\n<Action.SubmitForm title=`Add Memory` onSubmit={handleSubmit} />\n</ActionPanel>\n}\n>\n<Form.TextArea\nid=`content`\ntitle=`Content`\nplaceholder=`Enter the memory content...`\ninfo=`The main content of your memory. This is required.`\n/>\n<Form.Separator />\n<Form.Dropdown\nid=`project`\ntitle=`Project`\ninfo=`Select a project to organize this memory`\nstoreValue\n>\n<Form.Dropdown.Item value=`` title=`No Project` />\n{projects.map((project) => (\n<Form.Dropdown.Item\nkey={project.id}\nvalue={project.containerTag}\ntitle={project.name}\n/>\n))}\n</Form.Dropdown>\n</Form>\n);\n}"
"async function makeAuthenticatedRequest<T>(\nendpoint: string,\noptions: RequestInit = {},\n): Promise<T> {\nconst apiKey = await getApiKey();\nconst url = `${API_BASE_URL}${endpoint}`;\ntry {\nconst response = await fetch(url, {\n...options,\nheaders: {\nAuthorization: `Bearer ${apiKey}`,\n`Content-Type`: `application/json`,\n...options.headers,\n},\n});\nif (!response.ok) {\nif (response.status === 401) {\nthrow new AuthenticationError(\n`Invalid API key. Please check your API key in preferences. Get a new one from https:\n);\n}\nlet errorMessage = `API request failed: ${response.statusText}`;\ntry {\nconst errorBody = (await response.json()) as { message?: string };\nif (errorBody.message) {\nerrorMessage = errorBody.message;\n}\n} catch {\n}\nthrow new SupermemoryAPIError(errorMessage, response.status);\n}\nif (!response.headers.get(`content-type`)?.includes(`application/json`)) {\nthrow new SupermemoryAPIError(`Invalid response format from API`);\n}\nconst data = (await response.json()) as T;\nreturn data;\n} catch (err) {\nif (\nerr instanceof AuthenticationError ||\nerr instanceof SupermemoryAPIError\n) {\nthrow err;\n}\nthrow new SupermemoryAPIError(\n`Network error: ${err instanceof Error ? err.message : `Unknown error`}`,\n);\n}\n}"
"export default async function proxy(request: Request) {\nconsole.debug(`[PROXY] === PROXY START ===`)\nconst url = new URL(request.url)\nconsole.debug(`[PROXY] Path:`, url.pathname)\nconsole.debug(`[PROXY] Method:`, request.method)\nconst sessionCookie = getSessionCookie(request)\nconsole.debug(`[PROXY] Session cookie exists:`, !!sessionCookie)\nconst publicPaths = [`/login`]\nif (publicPaths.includes(url.pathname)) {\nconsole.debug(`[PROXY] Public path, allowing access`)\nreturn NextResponse.next()\n}\nif (!sessionCookie) {\nconsole.debug(\n`[PROXY] No session cookie and not on public path, redirecting to /login`,\n)\nconst url = new URL(`/login`, request.url)\nurl.searchParams.set(`redirect`, request.url)\nreturn NextResponse.redirect(url)\n}\nconsole.debug(`[PROXY] Passing through to next handler`)\nconsole.debug(`[PROXY] === PROXY END ===`)\nconst response = NextResponse.next()\nresponse.cookies.set({\nname: `last-site-visited`,\nvalue: `https:\ndomain: `supermemory.ai`,\n})\nreturn response\n}"
"export function useErrorTracking() {\nconst posthog = usePostHog()\nconst { data: session } = useSession()\nconst pathname = usePathname()\nconst trackError = (\nerror: Error | unknown,\ncontext?: Record<string, any>,\n) => {\nif (!posthog.__loaded) return\nconst errorDetails = {\nerror_message: error instanceof Error ? error.message : String(error),\nerror_stack: error instanceof Error ? error.stack : undefined,\nerror_name: error instanceof Error ? error.name : `Unknown`,\npathname,\nuser_id: session?.user?.id,\nuser_email: session?.user?.email,\ntimestamp: new Date().toISOString(),\n...context,\n}\nposthog.capture(`error_occurred`, errorDetails)\n}\nconst trackApiError = (\nerror: Error | unknown,\nendpoint: string,\nmethod: string,\n) => {\ntrackError(error, {\nerror_type: `api_error`,\napi_endpoint: endpoint,\napi_method: method,\n})\n}\nconst trackComponentError = (\nerror: Error | unknown,\ncomponentName: string,\n) => {\ntrackError(error, {\nerror_type: `component_error`,\ncomponent_name: componentName,\n})\n}\nconst trackValidationError = (\nerror: Error | unknown,\nformName: string,\nfield?: string,\n) => {\ntrackError(error, {\nerror_type: `validation_error`,\nform_name: formName,\nfield_name: field,\n})\n}\nreturn {\ntrackError,\ntrackApiError,\ntrackComponentError,\ntrackValidationError,\n}\n}"
"export function useInteractionTracking() {\nconst posthog = usePostHog()\nconst { data: session } = useSession()\nconst pathname = usePathname()\nconst trackInteraction = (action: string, details?: Record<string, any>) => {\nif (!posthog.__loaded) return\nposthog.capture(`user_interaction`, {\naction,\npathname,\nuser_id: session?.user?.id,\ntimestamp: new Date().toISOString(),\n...details,\n})\n}\nconst trackFormSubmission = (\nformName: string,\nsuccess: boolean,\ndetails?: Record<string, any>,\n) => {\nif (!posthog.__loaded) return\nposthog.capture(`form_submission`, {\nform_name: formName,\nsuccess,\npathname,\nuser_id: session?.user?.id,\ntimestamp: new Date().toISOString(),\n...details,\n})\n}\nconst trackButtonClick = (buttonName: string, context?: string) => {\ntrackInteraction(`button_click`, {\nbutton_name: buttonName,\ncontext,\n})\n}\nconst trackLinkClick = (\nurl: string,\nlinkText?: string,\nexternal?: boolean,\n) => {\ntrackInteraction(`link_click`, {\nurl,\nlink_text: linkText,\nexternal,\n})\n}\nconst trackModalOpen = (modalName: string) => {\ntrackInteraction(`modal_open`, {\nmodal_name: modalName,\n})\n}\nconst trackModalClose = (modalName: string) => {\ntrackInteraction(`modal_close`, {\nmodal_name: modalName,\n})\n}\nconst trackTabChange = (fromTab: string, toTab: string) => {\ntrackInteraction(`tab_change`, {\nfrom_tab: fromTab,\nto_tab: toTab,\n})\n}\nreturn {\ntrackInteraction,\ntrackFormSubmission,\ntrackButtonClick,\ntrackLinkClick,\ntrackModalOpen,\ntrackModalClose,\ntrackTabChange,\n}\n}"
"export function PostHogProvider({ children }: { children: React.ReactNode }) {\nconst { data: session } = useSession()\nuseEffect(() => {\nif (typeof window !== `undefined`) {\nconst posthogKey = process.env.NEXT_PUBLIC_POSTHOG_KEY\nconst backendUrl =\nprocess.env.NEXT_PUBLIC_BACKEND_URL ?? `https:\nif (posthogKey) {\nposthog.init(posthogKey, {\napi_host: `${backendUrl}/orange`,\nui_host: `https:\nperson_profiles: `identified_only`,\ncapture_pageview: false,\ncapture_pageleave: true,\n})\n} else {\nconsole.warn(\n`PostHog API key is not set. PostHog will not be initialized.`,\n)\n}\n}\n}, [])\nuseEffect(() => {\nif (session?.user && posthog.__loaded) {\nposthog.identify(session.user.id, {\nemail: session.user.email,\nname: session.user.name,\nuserId: session.user.id,\ncreatedAt: session.user.createdAt,\n})\n}\n}, [session?.user])\nreturn (\n<>\n<Suspense fallback={null}>\n<PostHogPageTracking />\n</Suspense>\n{children}\n</>\n)\n}"
"export function CopyableCell({\nvalue,\ndisplayValue,\nclassName,\nchildren,\n...props\n}: CopyableCellProps) {\nconst [hasCopied, setHasCopied] = React.useState(false);\nReact.useEffect(() => {\nif (hasCopied) {\nconst timeout = setTimeout(() => {\nsetHasCopied(false);\n}, 2000);\nreturn () => clearTimeout(timeout);\n}\n}, [hasCopied]);\nconst handleCopy = async (e: React.MouseEvent) => {\ne.stopPropagation();\ntry {\nawait navigator.clipboard.writeText(value);\nsetHasCopied(true);\n} catch (err) {\nconsole.error(`Failed to copy:`, err);\n}\n};\nreturn (\n<div\nclassName={cn(\n`cursor-pointer transition-colors duration-200`,\n`hover:bg-zinc-800/50 hover:text-zinc-50`,\n`rounded px-2 py-1 -mx-2 -my-1`,\n`relative`,\nclassName,\n)}\nonClick={handleCopy}\n{...props}\n>\n<AnimatePresence mode=`wait`>\n{hasCopied ? (\n<Label1Regular asChild className=`block`>\n<motion.span\nanimate={{ opacity: 1, y: 0 }}\nexit={{ opacity: 0, y: -10 }}\ninitial={{ opacity: 0, y: 10 }}\nkey=`copied`\ntransition={{ duration: 0.2 }}\n>\nCopied!\n</motion.span>\n</Label1Regular>\n) : (\n<Label1Regular asChild>\n<motion.div\nanimate={{ opacity: 1, y: 0 }}\nexit={{ opacity: 0, y: 10 }}\ninitial={{ opacity: 0, y: -10 }}\nkey=`content`\ntransition={{ duration: 0.2 }}\n>\n{displayValue || children || value}\n</motion.div>\n</Label1Regular>\n)}\n</AnimatePresence>\n</div>\n);\n}"
"export default function RootLayout({\nchildren,\n}: Readonly<{\nchildren: React.ReactNode\n}>) {\nreturn (\n<html lang=`en` suppressHydrationWarning>\n<body className={`${font.variable} antialiased overflow-x-hidden`}>\n<ThemeProvider\nattribute=`class`\ndefaultTheme=`system`\nenableSystem\ndisableTransitionOnChange\n>\n<AutumnProvider\nbackendUrl={\nprocess.env.NEXT_PUBLIC_BACKEND_URL ??\n`https:\n}\nincludeCredentials={true}\n>\n<QueryProvider>\n<AuthProvider>\n<ViewModeProvider>\n<MobilePanelProvider>\n<PostHogProvider>\n<ErrorTrackingProvider>\n<NuqsAdapter>\n<Suspense>{children}</Suspense>\n<Toaster richColors />\n</NuqsAdapter>\n</ErrorTrackingProvider>\n</PostHogProvider>\n</MobilePanelProvider>\n</ViewModeProvider>\n</AuthProvider>\n</QueryProvider>\n</AutumnProvider>\n</ThemeProvider>\n</body>\n</html>\n)\n}"
"export function TextMorph({\nchildren,\nas: Component = 'p',\nclassName,\nstyle,\nvariants,\ntransition,\n}: TextMorphProps) {\nconst uniqueId = useId();\nconst characters = useMemo(() => {\nconst charCounts: Record<string, number> = {};\nreturn children.split('').map((char) => {\nconst lowerChar = char.toLowerCase();\ncharCounts[lowerChar] = (charCounts[lowerChar] || 0) + 1;\nreturn {\nid: `${uniqueId}-${lowerChar}${charCounts[lowerChar]}`,\nlabel: char === ' ' ? '\u00A0' : char,\n};\n});\n}, [children, uniqueId]);\nconst defaultVariants: Variants = {\ninitial: { opacity: 0 },\nanimate: { opacity: 1 },\nexit: { opacity: 0 },\n};\nconst defaultTransition: Transition = {\ntype: 'spring',\nstiffness: 280,\ndamping: 18,\nmass: 0.3,\n};\nreturn (\n<Component className={cn(className)} aria-label={children} style={style}>\n<AnimatePresence mode='popLayout' initial={false}>\n{characters.map((character) => (\n<motion.span\nkey={character.id}\nlayoutId={character.id}\nclassName='inline-block'\naria-hidden='true'\ninitial='initial'\nanimate='animate'\nexit='exit'\nvariants={variants || defaultVariants}\ntransition={transition || defaultTransition}\n>\n{character.label}\n</motion.span>\n))}\n</AnimatePresence>\n</Component>\n);\n}"
"function TextShimmerComponent({\nchildren,\nas: Component = `p`,\nclassName,\nduration = 2,\nspread = 2,\n}: TextShimmerProps) {\nconst MotionComponent = motion.create(\nComponent as keyof JSX.IntrinsicElements,\n);\nconst dynamicSpread = useMemo(() => {\nreturn children.length * spread;\n}, [children, spread]);\nreturn (\n<MotionComponent\nclassName={cn(\n`relative inline-block bg-[length:250%_100%,auto] bg-clip-text`,\n`text-transparent [--base-color:#a1a1aa] [--base-gradient-color:#000]`,\n`[background-repeat:no-repeat,padding-box] [--bg:linear-gradient(90deg,#0000_calc(50%-var(--spread)),var(--base-gradient-color),#0000_calc(50%+var(--spread)))]`,\n`dark:[--base-color:#71717a] dark:[--base-gradient-color:#ffffff] dark:[--bg:linear-gradient(90deg,#0000_calc(50%-var(--spread)),var(--base-gradient-color),#0000_calc(50%+var(--spread)))]`,\nclassName,\n)}\ninitial={{ backgroundPosition: `100% center` }}\nanimate={{ backgroundPosition: `0% center` }}\ntransition={{\nrepeat: Number.POSITIVE_INFINITY,\nduration,\nease: `linear`,\n}}\nstyle={\n{\n`--spread`: `${dynamicSpread}px`,\nbackgroundImage: `var(--bg), linear-gradient(var(--base-color), var(--base-color))`,\n} as React.CSSProperties\n}\n>\n{children}\n</MotionComponent>\n);\n}"
"setConversation(projectId, chatId, messages) {\nconst now = new Date().toISOString()\nset((state) => {\nconst project = state.byProject[projectId] ?? {\ncurrentChatId: null,\nconversations: {},\n}\nconst existing = project.conversations[chatId]\nif (\nexisting &&\nareUIMessageArraysEqual(existing.messages, messages)\n) {\nreturn state\n}\nconst shouldTouchLastUpdated = (() => {\nif (!existing) return messages.length > 0\nconst previousLength = existing.messages?.length ?? 0\nreturn messages.length > previousLength\n})()\nconst record: ConversationRecord = {\nmessages,\ntitle: existing?.title,\nlastUpdated: shouldTouchLastUpdated\n? now\n: (existing?.lastUpdated ?? now),\n}\nreturn {\nbyProject: {\n...state.byProject,\n[projectId]: {\ncurrentChatId: project.currentChatId,\nconversations: {\n...project.conversations,\n[chatId]: record,\n},\n},\n},\n}\n})\n},"
"export default function NavigationLayout({\nchildren,\n}: {\nchildren: React.ReactNode\n}) {\nconst [showAddMemoryView, setShowAddMemoryView] = useState(false)\nuseEffect(() => {\nconst handleKeydown = (event: KeyboardEvent) => {\nconst target = event.target as HTMLElement\nconst isInputField =\ntarget.tagName === `INPUT` ||\ntarget.tagName === `TEXTAREA` ||\ntarget.isContentEditable ||\ntarget.closest('[contenteditable=`true`]')\nif (isInputField) return\nif (\nevent.key === `c` &&\n!event.ctrlKey &&\n!event.metaKey &&\n!event.altKey &&\n!event.shiftKey\n) {\nevent.preventDefault()\nsetShowAddMemoryView(true)\n}\n}\ndocument.addEventListener(`keydown`, handleKeydown)\nreturn () => {\ndocument.removeEventListener(`keydown`, handleKeydown)\n}\n}, [])\nreturn (\n<div className=`relative h-screen flex flex-col`>\n<div className=`sticky top-0 z-50 bg-background/80 backdrop-blur-md border-b border-white/10`>\n<Header onAddMemory={() => setShowAddMemoryView(true)} />\n</div>\n<div className=`flex-1`>{children}</div>\n{showAddMemoryView && (\n<AddMemoryView\ninitialTab=`note`\nonClose={() => setShowAddMemoryView(false)}\n/>\n)}\n<GraphDialog />\n</div>\n)\n}"
"export default function Page() {\nconst { user, session } = useAuth()\nconst { shouldShowOnboarding, isLoading: onboardingLoading } =\nuseOnboardingStorage()\nconst router = useRouter()\nuseEffect(() => {\nconst url = new URL(window.location.href)\nconst authenticateChromeExtension = url.searchParams.get(\n`extension-auth-success`,\n)\nif (authenticateChromeExtension) {\nconst sessionToken = session?.token\nconst userData = {\nemail: user?.email,\nname: user?.name,\nuserId: user?.id,\n}\nif (sessionToken && userData?.email) {\nconst encodedToken = encodeURIComponent(sessionToken)\nwindow.postMessage({ token: encodedToken, userData }, window.location.origin)\nurl.searchParams.delete(`extension-auth-success`)\nwindow.history.replaceState({}, ``, url.toString())\n}\n}\n}, [user, session])\nuseEffect(() => {\nif (user && !onboardingLoading && shouldShowOnboarding()) {\nrouter.push(`/onboarding`)\n}\n}, [user, shouldShowOnboarding, onboardingLoading, router])\nif (!user || onboardingLoading) {\nreturn (\n<div className=`min-h-screen flex items-center justify-center bg-[#0f1419]`>\n<div className=`flex flex-col items-center gap-4`>\n<LoaderIcon className=`w-8 h-8 text-orange-500 animate-spin` />\n<p className=`text-white/60`>Loading...</p>\n</div>\n</div>\n)\n}\nif (shouldShowOnboarding()) {\nreturn null\n}\nreturn (\n<div>\n<div className=`flex flex-col h-[80vh] rounded-lg overflow-hidden relative`>\n<BackgroundPlus />\n<div className=`p-4 flex-1 flex items-center justify-center`>\n<ChatInput />\n</div>\n<div className=`flex items-center gap-2 text-xs text-muted-foreground justify-center py-2 opacity-75`>\n<ChevronsDown className=`size-4` />\n<p>Scroll down to see memories</p>\n</div>\n</div>\n<Memories />\n<InstallPrompt />\n<ChromeExtensionButton />\n</div>\n)\n}"
"export function AnimatedText({\nchildren,\ntrigger,\ndelay,\n}: {\nchildren: string\ntrigger: boolean\ndelay: number\n}) {\nconst blurSlideVariants = {\ncontainer: {\nhidden: { opacity: 0 },\nvisible: {\nopacity: 1,\ntransition: { staggerChildren: 0.01 },\n},\nexit: {\ntransition: { staggerChildren: 0.01, staggerDirection: 1 },\n},\n},\nitem: {\nhidden: {\nopacity: 0,\nfilter: `blur(10px) brightness(0%)`,\ny: 0,\n},\nvisible: {\nopacity: 1,\ny: 0,\nfilter: `blur(0px) brightness(100%)`,\ntransition: {\nduration: 0.4,\n},\n},\nexit: {\nopacity: 0,\ny: -30,\nfilter: `blur(10px) brightness(0%)`,\ntransition: {\nduration: 0.3,\n},\n},\n},\n}\nreturn (\n<TextEffect\nclassName=`inline-flex font-medium`\nstyle={{ letterSpacing: `-3px` }}\nper=`char`\nvariants={blurSlideVariants}\ntrigger={trigger}\ndelay={delay}\n>\n{children}\n</TextEffect>\n)\n}"
"function useContainerRect(ref: React.RefObject<HTMLDivElement | null>) {\nconst rectRef = React.useRef<DOMRect | null>(null)\nuseLayoutEffect(\nfunction setup() {\nif (!ref.current) return\nfunction measure() {\nif (ref.current) {\nrectRef.current = ref.current.getBoundingClientRect()\n}\n}\nmeasure()\nlet resizeObserver: ResizeObserver | null = null\nif (typeof ResizeObserver !== `undefined`) {\nresizeObserver = new ResizeObserver(function onResize() {\nmeasure()\n})\nif (ref.current) {\nresizeObserver.observe(ref.current)\n}\n}\nfunction onScroll() {\nmeasure()\n}\nwindow.addEventListener(`resize`, measure)\nwindow.addEventListener(`scroll`, onScroll, true)\nreturn function cleanup() {\nif (resizeObserver) {\nresizeObserver.disconnect()\n}\nwindow.removeEventListener(`resize`, measure)\nwindow.removeEventListener(`scroll`, onScroll, true)\n}\n},\n[ref],\n)\nreturn rectRef\n}"
"export default function ReferralHomePage() {\nreturn (\n<div className=`min-h-screen flex items-center justify-center p-4 bg-[#0f1419]`>\n<Card className=`max-w-md w-full bg-[#1a1f2a] border-white/10`>\n<CardHeader className=`text-center`>\n<div className=`mx-auto mb-4 w-16 h-16 rounded-full bg-orange-500/10 flex items-center justify-center`>\n<ShareIcon className=`w-8 h-8 text-orange-500` />\n</div>\n<CardTitle className=`text-2xl font-bold text-white`>\nMissing Referral Code\n</CardTitle>\n<CardDescription className=`text-white/60 mt-2`>\nIt looks like you're missing a referral code. Get one from a friend\nor join directly!\n</CardDescription>\n</CardHeader>\n<CardContent>\n<div className=`space-y-4`>\n<div className=`bg-[#0f1419] rounded-lg p-4 border border-white/10`>\n<h3 className=`text-white font-semibold mb-2`>\nWhat is supermemory?\n</h3>\n<p className=`text-white/70 text-sm leading-relaxed`>\nsupermemory is an AI-powered personal knowledge base that helps\nyou store, organize, and interact with all your digital\nmemories.\n</p>\n</div>\n<div className=`text-center`>\n<Link\nclassName=`text-orange-500 hover:text-orange-400 text-sm underline`\nhref=`https:\n>\nLearn more about supermemory\n</Link>\n</div>\n</div>\n</CardContent>\n</Card>\n</div>\n);\n}"
"export default function SettingsPageLayout({\nchildren,\n}: {\nchildren: React.ReactNode\n}) {\nconst router = useRouter()\nconst pathname = usePathname()\nconst navItems = [\n{ label: `Profile`, path: `/settings` },\n{ label: `Integrations`, path: `/settings/integrations` },\n{ label: `Billing`, path: `/settings/billing` },\n{ label: `Support`, path: `/settings/support` },\n]\nreturn (\n<div className=`flex-1 overflow-hidden max-w-screen-lg mx-auto mt-4`>\n<div className=`flex flex-col items-center`>\n<div className=`w-full max-w-2xl`>\n<nav className=`flex gap-[2px] px-1 py-1 text-sm rounded-[8px] bg-muted-foreground/10 text-foreground max-w-fit`>\n{navItems.map((item) => {\nconst isActive = pathname === item.path\nreturn (\n<Button\nkey={item.path}\nonClick={() => router.push(item.path)}\nvariant=`settingsNav`\nsize=`sm`\nclassName={cn(\n`transition-all duration-200`,\nisActive\n? `opacity-100 bg-card`\n: `opacity-60 hover:opacity-100 hover:bg-card `,\n)}\n>\n{item.label}\n</Button>\n)\n})}\n</nav>\n{children}\n</div>\n</div>\n</div>\n)\n}"
"export function ActionButtons({\nonCancel,\nonSubmit,\nsubmitText,\nsubmitIcon: SubmitIcon,\nisSubmitting = false,\nisSubmitDisabled = false,\nsubmitType = `submit`,\nclassName = ``,\n}: ActionButtonsProps) {\nreturn (\n<div className={`flex gap-3 order-1 sm:order-2 justify-end ${className}`}>\n<Button\nclassName=`hover:bg-foreground/10 border-none flex-1 sm:flex-initial cursor-pointer`\nonClick={onCancel}\ntype=`button`\nvariant=`ghost`\n>\nCancel\n</Button>\n<motion.div\nwhileHover={{ scale: 1.05 }}\nwhileTap={{ scale: 0.95 }}\nclassName=`flex-1 sm:flex-initial`\n>\n<Button\nclassName=`w-full cursor-pointer`\ndisabled={isSubmitting || isSubmitDisabled}\nonClick={submitType === `button` ? onSubmit : undefined}\ntype={submitType}\n>\n{isSubmitting ? (\n<>\n<Loader2 className=`h-4 w-4 animate-spin mr-2` />\n{submitText.includes(`Add`)\n? `Adding...`\n: submitText.includes(`Upload`)\n? `Uploading...`\n: `Processing...`}\n</>\n) : (\n<>\n{SubmitIcon && <SubmitIcon className=`h-4 w-4 mr-2` />}\n{submitText}\n</>\n)}\n</Button>\n</motion.div>\n</div>\n)\n}"
"export function MemoryUsageRing({\nmemoriesUsed,\nmemoriesLimit,\nclassName = ``,\n}: MemoryUsageRingProps) {\nconst usagePercentage = memoriesUsed / memoriesLimit\nconst strokeColor =\nmemoriesUsed >= memoriesLimit * 0.8 ? `rgb(251 191 36)` : `rgb(34 197 94)`\nconst circumference = 2 * Math.PI * 10\nreturn (\n<div\nclassName={`relative group cursor-help self-center sm:self-end mb-1 hidden sm:block ${className}`}\ntitle={`${memoriesUsed} of ${memoriesLimit} memories used`}\n>\n<svg className=`w-6 h-6 transform -rotate-90` viewBox=`0 0 24 24`>\n<title>{`${memoriesUsed} of ${memoriesLimit} memories used`}</title>\n{}\n<circle\ncx=`12`\ncy=`12`\nfill=`none`\nr=`10`\nstroke=`rgb(255 255 255 / 0.1)`\nstrokeWidth=`2`\n/>\n{}\n<circle\nclassName=`transition-all duration-300`\ncx=`12`\ncy=`12`\nfill=`none`\nr=`10`\nstroke={strokeColor}\nstrokeDasharray={`${circumference}`}\nstrokeDashoffset={`${circumference * (1 - usagePercentage)}`}\nstrokeLinecap=`round`\nstrokeWidth=`2`\n/>\n</svg>\n{}\n<div className=`absolute bottom-full left-1/2 transform -translate-x-1/2 mb-2 px-2 py-1 bg-black/90 text-white text-xs rounded opacity-0 group-hover:opacity-100 transition-opacity duration-200 pointer-events-none whitespace-nowrap`>\n{memoriesUsed} / {memoriesLimit}\n</div>\n</div>\n)\n}"
"export function ProjectSelection({\nprojects,\nselectedProject,\nonProjectChange,\nonCreateProject,\ndisabled = false,\nisLoading = false,\nclassName = '',\nid = 'project-select',\n}: ProjectSelectionProps) {\nconst handleValueChange = (value: string) => {\nif (value === 'create-new-project') {\nonCreateProject();\n} else {\nonProjectChange(value);\n}\n};\nreturn (\n<Select\nkey={`${id}-${selectedProject}`}\ndisabled={isLoading || disabled}\nonValueChange={handleValueChange}\nvalue={selectedProject}\n>\n<SelectTrigger\nclassName={`bg-foreground/5 border-foreground/10 cursor-pointer ${className}`}\nid={id}\n>\n<SelectValue placeholder=`Select a project` />\n</SelectTrigger>\n<SelectContent position=`popper` sideOffset={5} className=`z-[90]`>\n<SelectItem\nclassName=`hover:bg-foreground/10`\nkey=`default`\nvalue=`sm_project_default`\n>\nDefault Project\n</SelectItem>\n{projects\n.filter((p) => p.containerTag !== 'sm_project_default' && p.id)\n.map((project) => (\n<SelectItem\nclassName=`hover:bg-foreground/10`\nkey={project.id || project.containerTag}\nvalue={project.containerTag}\n>\n{project.name}\n</SelectItem>\n))}\n<SelectItem\nclassName=`hover:bg-foreground/10 border-t border-foreground/10 mt-1`\nkey=`create-new`\nvalue=`create-new-project`\n>\n<div className=`flex items-center gap-2`>\n<Plus className=`h-4 w-4` />\n<span>Create new project</span>\n</div>\n</SelectItem>\n</SelectContent>\n</Select>\n);\n}"
"export function useErrorTracking() {\nconst posthog = usePostHog()\nconst { data: session } = useSession()\nconst pathname = usePathname()\nconst trackError = (\nerror: Error | unknown,\ncontext?: Record<string, any>,\n) => {\nif (!posthog.__loaded) return\nconst errorDetails = {\nerror_message: error instanceof Error ? error.message : String(error),\nerror_stack: error instanceof Error ? error.stack : undefined,\nerror_name: error instanceof Error ? error.name : `Unknown`,\npathname,\nuser_id: session?.user?.id,\nuser_email: session?.user?.email,\ntimestamp: new Date().toISOString(),\n...context,\n}\nposthog.capture(`error_occurred`, errorDetails)\n}\nconst trackApiError = (\nerror: Error | unknown,\nendpoint: string,\nmethod: string,\n) => {\ntrackError(error, {\nerror_type: `api_error`,\napi_endpoint: endpoint,\napi_method: method,\n})\n}\nconst trackComponentError = (\nerror: Error | unknown,\ncomponentName: string,\n) => {\ntrackError(error, {\nerror_type: `component_error`,\ncomponent_name: componentName,\n})\n}\nconst trackValidationError = (\nerror: Error | unknown,\nformName: string,\nfield?: string,\n) => {\ntrackError(error, {\nerror_type: `validation_error`,\nform_name: formName,\nfield_name: field,\n})\n}\nreturn {\ntrackError,\ntrackApiError,\ntrackComponentError,\ntrackValidationError,\n}\n}"
"export function useInteractionTracking() {\nconst posthog = usePostHog()\nconst { data: session } = useSession()\nconst pathname = usePathname()\nconst trackInteraction = (action: string, details?: Record<string, any>) => {\nif (!posthog.__loaded) return\nposthog.capture(`user_interaction`, {\naction,\npathname,\nuser_id: session?.user?.id,\ntimestamp: new Date().toISOString(),\n...details,\n})\n}\nconst trackFormSubmission = (\nformName: string,\nsuccess: boolean,\ndetails?: Record<string, any>,\n) => {\nif (!posthog.__loaded) return\nposthog.capture(`form_submission`, {\nform_name: formName,\nsuccess,\npathname,\nuser_id: session?.user?.id,\ntimestamp: new Date().toISOString(),\n...details,\n})\n}\nconst trackButtonClick = (buttonName: string, context?: string) => {\ntrackInteraction(`button_click`, {\nbutton_name: buttonName,\ncontext,\n})\n}\nconst trackLinkClick = (\nurl: string,\nlinkText?: string,\nexternal?: boolean,\n) => {\ntrackInteraction(`link_click`, {\nurl,\nlink_text: linkText,\nexternal,\n})\n}\nconst trackModalOpen = (modalName: string) => {\ntrackInteraction(`modal_open`, {\nmodal_name: modalName,\n})\n}\nconst trackModalClose = (modalName: string) => {\ntrackInteraction(`modal_close`, {\nmodal_name: modalName,\n})\n}\nconst trackTabChange = (fromTab: string, toTab: string) => {\ntrackInteraction(`tab_change`, {\nfrom_tab: fromTab,\nto_tab: toTab,\n})\n}\nreturn {\ntrackInteraction,\ntrackFormSubmission,\ntrackButtonClick,\ntrackLinkClick,\ntrackModalOpen,\ntrackModalClose,\ntrackTabChange,\n}\n}"
"private startRenderLoop() {\nconst render = () => {\nif (!this.gl || !this.program || this.effects.size === 0) {\nthis.animationFrame = requestAnimationFrame(render)\nreturn\n}\nconst currentTime = (performance.now() - this.startTime) / 1000\nfor (const [id, effect] of Array.from(this.effects)) {\nconst mousePos = this.mousePositions.get(id) || { x: 0, y: 0 }\nif (effect.width <= 0 || effect.height <= 0) {\ncontinue\n}\nif (\nthis.canvas!.width !== effect.width ||\nthis.canvas!.height !== effect.height\n) {\nthis.canvas!.width = effect.width\nthis.canvas!.height = effect.height\nthis.gl.viewport(0, 0, effect.width, effect.height)\n}\nthis.gl.clearColor(0, 0, 0, 0)\nthis.gl.clear(this.gl.COLOR_BUFFER_BIT)\nif (this.uniforms.resolution) {\nthis.gl.uniform2f(\nthis.uniforms.resolution,\neffect.width,\neffect.height,\n)\n}\nif (this.uniforms.time) {\nthis.gl.uniform1f(this.uniforms.time, currentTime)\n}\nif (this.uniforms.mouse) {\nthis.gl.uniform2f(this.uniforms.mouse, mousePos.x, mousePos.y)\n}\nif (this.uniforms.expanded) {\nthis.gl.uniform1f(\nthis.uniforms.expanded,\neffect.isExpanded ? 1.0 : 0.0,\n)\n}\nthis.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4)\nconst targetCtx = effect.targetCanvas.getContext(`2d`)\nif (targetCtx) {\ntargetCtx.clearRect(0, 0, effect.width, effect.height)\ntargetCtx.drawImage(this.canvas!, 0, 0)\n}\n}\nthis.animationFrame = requestAnimationFrame(render)\n}\nrender()\n}"
"export function PostHogProvider({ children }: { children: React.ReactNode }) {\nconst { data: session } = useSession()\nuseEffect(() => {\nif (typeof window !== `undefined`) {\nconst posthogKey = process.env.NEXT_PUBLIC_POSTHOG_KEY\nconst backendUrl =\nprocess.env.NEXT_PUBLIC_BACKEND_URL ?? `https:\nif (posthogKey) {\nposthog.init(posthogKey, {\napi_host: `${backendUrl}/orange`,\nui_host: `https:\nperson_profiles: `identified_only`,\ncapture_pageview: false,\ncapture_pageleave: true,\n})\n} else {\nconsole.warn(\n`PostHog API key is not set. PostHog will not be initialized.`,\n)\n}\n}\n}, [])\nuseEffect(() => {\nif (session?.user && posthog.__loaded) {\nposthog.identify(session.user.id, {\nemail: session.user.email,\nname: session.user.name,\nuserId: session.user.id,\ncreatedAt: session.user.createdAt,\n})\n}\n}, [session?.user])\nreturn (\n<>\n<Suspense fallback={null}>\n<PostHogPageTracking />\n</Suspense>\n{children}\n</>\n)\n}"
"async function chatWithMemory(userMessage: string) {\nconst response = await anthropic.beta.messages.create({\nmodel: 'claude-sonnet-4-5',\nmax_tokens: 2048,\nmessages: [{ role: 'user', content: userMessage }],\ntools: [{ type: 'memory_20250818', name: 'memory' }],\nbetas: ['context-management-2025-06-27'],\n})\nconst toolResults = []\nfor (const block of response.content) {\nif (block.type === 'tool_use' && block.name === 'memory') {\nconst toolResult = await memoryTool.handleCommandForToolResult(\nblock.input as any,\nblock.id\n)\ntoolResults.push(toolResult)\n}\n}\nif (toolResults.length > 0) {\nconst finalResponse = await anthropic.beta.messages.create({\nmodel: 'claude-sonnet-4-5',\nmax_tokens: 2048,\nmessages: [\n{ role: 'user', content: userMessage },\n{ role: 'assistant', content: response.content },\n{ role: 'user', content: toolResults },\n],\ntools: [{ type: 'memory_20250818', name: 'memory' }],\nbetas: ['context-management-2025-06-27'],\n})\nreturn finalResponse\n}\nreturn response\n}"
"async handleCommand(command: MemoryCommand): Promise<MemoryResponse> {\ntry {\nif (!this.isValidPath(command.path)) {\nreturn {\nsuccess: false,\nerror: `Invalid path: ${command.path}. All paths must start with /memories/`,\n}\n}\nswitch (command.command) {\ncase `view`:\nreturn await this.view(command.path, command.view_range)\ncase `create`:\nif (!command.file_text) {\nreturn {\nsuccess: false,\nerror: `file_text is required for create command`,\n}\n}\nreturn await this.create(command.path, command.file_text)\ncase `str_replace`:\nif (!command.old_str || !command.new_str) {\nreturn {\nsuccess: false,\nerror: `old_str and new_str are required for str_replace command`,\n}\n}\nreturn await this.strReplace(\ncommand.path,\ncommand.old_str,\ncommand.new_str,\n)\ncase `insert`:\nif (command.insert_line === undefined || !command.insert_text) {\nreturn {\nsuccess: false,\nerror:\n`insert_line and insert_text are required for insert command`,\n}\n}\nreturn await this.insert(\ncommand.path,\ncommand.insert_line,\ncommand.insert_text,\n)\ncase `delete`:\nreturn await this.delete(command.path)\ncase `rename`:\nif (!command.new_path) {\nreturn {\nsuccess: false,\nerror: `new_path is required for rename command`,\n}\n}\nreturn await this.rename(command.path, command.new_path)\ndefault:\nreturn {\nsuccess: false,\nerror: `Unknown command: ${(command as any).command}`,\n}\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: error instanceof Error ? error.message : `Unknown error`,\n}\n}\n}"
"private async listDirectory(dirPath: string): Promise<MemoryResponse> {\ntry {\nconst response = await this.client.search.execute({\nq: `*`,\ncontainerTags: this.containerTags,\nlimit: 100,\nincludeFullDocs: false,\n})\nif (!response.results) {\nreturn {\nsuccess: true,\ncontent: `Directory: ${dirPath}\n(empty)`,\n}\n}\nconst files: string[] = []\nconst dirs = new Set<string>()\nfor (const result of response.results) {\nconst filePath = result.metadata?.file_path as string\nif (!filePath || !filePath.startsWith(dirPath)) continue\nconst relativePath = filePath.substring(dirPath.length)\nif (!relativePath) continue\nconst slashIndex = relativePath.indexOf(`/`)\nif (slashIndex > 0) {\ndirs.add(relativePath.substring(0, slashIndex) + `/`)\n} else if (relativePath !== ``) {\nfiles.push(relativePath)\n}\n}\nconst entries = [...Array.from(dirs).sort(), ...files.sort()]\nif (entries.length === 0) {\nreturn {\nsuccess: true,\ncontent: `Directory: ${dirPath}\n(empty)`,\n}\n}\nreturn {\nsuccess: true,\ncontent: `Directory: ${dirPath}\n${entries.map((entry) => `- ${entry}`).join(`\n`)}`,\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: `Failed to list directory: ${error instanceof Error ? error.message : `Unknown error`}`,\n}\n}\n}"
"private async readFile(\nfilePath: string,\nviewRange?: [number, number],\n): Promise<MemoryResponse> {\ntry {\nconst normalizedId = this.normalizePathToCustomId(filePath)\nconst response = await this.client.search.execute({\nq: normalizedId,\ncontainerTags: this.containerTags,\nlimit: 1,\nincludeFullDocs: true,\n})\nconst exactMatch = response.results?.find(\n(r) => r.documentId === normalizedId,\n)\nconst document = exactMatch || response.results?.[0]\nif (!document) {\nreturn {\nsuccess: false,\nerror: `File not found: ${filePath}`,\n}\n}\nlet content = document.content || ``\nif (viewRange) {\nconst lines = content.split(`\n`)\nconst [startLine, endLine] = viewRange\nconst selectedLines = lines.slice(startLine - 1, endLine)\nconst numberedLines = selectedLines.map(\n(line: string, index: number) => {\nconst lineNum = startLine + index\nreturn `${lineNum.toString().padStart(4)}\t${line}`\n},\n)\ncontent = numberedLines.join(`\n`)\n} else {\nconst lines = content.split(`\n`)\nconst numberedLines = lines.map((line, index) => {\nconst lineNum = index + 1\nreturn `${lineNum.toString().padStart(4)}\t${line}`\n})\ncontent = numberedLines.join(`\n`)\n}\nreturn {\nsuccess: true,\ncontent,\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: `Failed to read file: ${error instanceof Error ? error.message : `Unknown error`}`,\n}\n}\n}"
"private async strReplace(\nfilePath: string,\noldStr: string,\nnewStr: string,\n): Promise<MemoryResponse> {\ntry {\nconst readResult = await this.getFileDocument(filePath)\nif (!readResult.success || !readResult.document) {\nreturn {\nsuccess: false,\nerror: readResult.error || `File not found`,\n}\n}\nconst originalContent =\nreadResult.document.raw || readResult.document.content || ``\nif (!originalContent.includes(oldStr)) {\nreturn {\nsuccess: false,\nerror: `String not found in file: `${oldStr}``,\n}\n}\nconst newContent = originalContent.replace(oldStr, newStr)\nconst normalizedId = this.normalizePathToCustomId(filePath)\nconst updateResponse = await this.client.memories.add({\ncontent: newContent,\ncustomId: normalizedId,\ncontainerTags: this.containerTags,\nmetadata: {\n...readResult.document.metadata,\nline_count: newContent.split(`\n`).length,\nlast_modified: new Date().toISOString(),\n},\n})\nreturn {\nsuccess: true,\ncontent: `String replaced in file: ${filePath}`,\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: `Failed to replace string: ${error instanceof Error ? error.message : `Unknown error`}`,\n}\n}\n}"
"private async insert(\nfilePath: string,\ninsertLine: number,\ninsertText: string,\n): Promise<MemoryResponse> {\ntry {\nconst readResult = await this.getFileDocument(filePath)\nif (!readResult.success || !readResult.document) {\nreturn {\nsuccess: false,\nerror: readResult.error || `File not found`,\n}\n}\nconst originalContent =\nreadResult.document.raw || readResult.document.content || ``\nconst lines = originalContent.split(`\n`)\nif (insertLine < 1 || insertLine > lines.length + 1) {\nreturn {\nsuccess: false,\nerror: `Invalid line number: ${insertLine}. File has ${lines.length} lines.`,\n}\n}\nlines.splice(insertLine - 1, 0, insertText)\nconst newContent = lines.join(`\n`)\nconst normalizedId = this.normalizePathToCustomId(filePath)\nawait this.client.memories.add({\ncontent: newContent,\ncustomId: normalizedId,\ncontainerTags: this.containerTags,\nmetadata: {\n...readResult.document.metadata,\nline_count: newContent.split(`\n`).length,\nlast_modified: new Date().toISOString(),\n},\n})\nreturn {\nsuccess: true,\ncontent: `Text inserted at line ${insertLine} in file: ${filePath}`,\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: `Failed to insert text: ${error instanceof Error ? error.message : `Unknown error`}`,\n}\n}\n}"
"private async rename(\noldPath: string,\nnewPath: string,\n): Promise<MemoryResponse> {\ntry {\nif (!this.isValidPath(newPath)) {\nreturn {\nsuccess: false,\nerror: `Invalid new path: ${newPath}. All paths must start with /memories/`,\n}\n}\nconst readResult = await this.getFileDocument(oldPath)\nif (!readResult.success || !readResult.document) {\nreturn {\nsuccess: false,\nerror: readResult.error || `File not found`,\n}\n}\nconst originalContent =\nreadResult.document.raw || readResult.document.content || ``\nconst newNormalizedId = this.normalizePathToCustomId(newPath)\nawait this.client.memories.add({\ncontent: originalContent,\ncustomId: newNormalizedId,\ncontainerTags: this.containerTags,\nmetadata: {\n...readResult.document.metadata,\nfile_path: newPath,\nlast_modified: new Date().toISOString(),\n},\n})\nreturn {\nsuccess: true,\ncontent: `File renamed from ${oldPath} to ${newPath}`,\n}\n} catch (error) {\nreturn {\nsuccess: false,\nerror: `Failed to rename file: ${error instanceof Error ? error.message : `Unknown error`}`,\n}\n}\n}"
"export async function handleClaudeMemoryToolCall(\ntoolUseBlock: {\ntype: `tool_use`\nid: string\nname: `memory`\ninput: MemoryCommand\n},\nsupermemoryApiKey: string,\nconfig?: {\nprojectId?: string\nmemoryContainerTag?: string\nbaseUrl?: string\n}\n) {\nconsole.log(`🔧 Handling Claude memory tool call: ${toolUseBlock.input.command}`)\nconsole.log(`📁 Path: ${toolUseBlock.input.path}`)\nconst memoryTool = createClaudeMemoryTool(supermemoryApiKey, {\nprojectId: config?.projectId || `claude-chat`,\nmemoryContainerTag: config?.memoryContainerTag || `claude_memory`,\nbaseUrl: config?.baseUrl,\n})\nconst result = await memoryTool.handleCommand(toolUseBlock.input)\nconst toolResult = {\ntype: `tool_result` as const,\ntool_use_id: toolUseBlock.id,\ncontent: result.success\n? result.content || `Operation completed successfully`\n: `Error: ${result.error}`,\nis_error: !result.success,\n}\nconsole.log(`${result.success ? '✅' : '❌'} Result:`, result.content || result.error)\nreturn toolResult\n}"
"export function CopyableCell({\nvalue,\ndisplayValue,\nclassName,\nchildren,\n...props\n}: CopyableCellProps) {\nconst [hasCopied, setHasCopied] = React.useState(false);\nReact.useEffect(() => {\nif (hasCopied) {\nconst timeout = setTimeout(() => {\nsetHasCopied(false);\n}, 2000);\nreturn () => clearTimeout(timeout);\n}\n}, [hasCopied]);\nconst handleCopy = async (e: React.MouseEvent) => {\ne.stopPropagation();\ntry {\nawait navigator.clipboard.writeText(value);\nsetHasCopied(true);\n} catch (err) {\nconsole.error(`Failed to copy:`, err);\n}\n};\nreturn (\n<div\nclassName={cn(\n`cursor-pointer transition-colors duration-200`,\n`hover:bg-zinc-800/50 hover:text-zinc-50`,\n`rounded px-2 py-1 -mx-2 -my-1`,\n`relative`,\nclassName,\n)}\nonClick={handleCopy}\n{...props}\n>\n<AnimatePresence mode=`wait`>\n{hasCopied ? (\n<Label1Regular asChild className=`block`>\n<motion.span\nanimate={{ opacity: 1, y: 0 }}\nexit={{ opacity: 0, y: -10 }}\ninitial={{ opacity: 0, y: 10 }}\nkey=`copied`\ntransition={{ duration: 0.2 }}\n>\nCopied!\n</motion.span>\n</Label1Regular>\n) : (\n<Label1Regular asChild>\n<motion.div\nanimate={{ opacity: 1, y: 0 }}\nexit={{ opacity: 0, y: 10 }}\ninitial={{ opacity: 0, y: -10 }}\nkey=`content`\ntransition={{ duration: 0.2 }}\n>\n{displayValue || children || value}\n</motion.div>\n</Label1Regular>\n)}\n</AnimatePresence>\n</div>\n);\n}"
"export function PostHogProvider({ children }: { children: React.ReactNode }) {\nconst { data: session } = useSession()\nuseEffect(() => {\nif (typeof window !== `undefined`) {\nconst posthogKey = process.env.NEXT_PUBLIC_POSTHOG_KEY\nconst backendUrl =\nprocess.env.NEXT_PUBLIC_BACKEND_URL ?? `https:\nif (posthogKey) {\nposthog.init(posthogKey, {\napi_host: `${backendUrl}/orange`,\nui_host: `https:\nperson_profiles: `identified_only`,\ncapture_pageview: false,\ncapture_pageleave: true,\n})\n} else {\nconsole.warn(\n`PostHog API key is not set. PostHog will not be initialized.`,\n)\n}\n}\n}, [])\nuseEffect(() => {\nif (session?.user && posthog.__loaded) {\nposthog.identify(session.user.id, {\nemail: session.user.email,\nname: session.user.name,\nuserId: session.user.id,\ncreatedAt: session.user.createdAt,\n})\n}\n}, [session?.user])\nreturn (\n<>\n<Suspense fallback={null}>\n<PostHogPageTracking />\n</Suspense>\n{children}\n</>\n)\n}"
"function ChartLegendContent({\nclassName,\nhideIcon = false,\npayload,\nverticalAlign = `bottom`,\nnameKey,\n}: React.ComponentProps<`div`> &\nPick<RechartsPrimitive.LegendProps, `payload` | `verticalAlign`> & {\nhideIcon?: boolean;\nnameKey?: string;\n}) {\nconst { config } = useChart();\nif (!payload?.length) {\nreturn null;\n}\nreturn (\n<div\nclassName={cn(\n`flex items-center justify-center gap-4`,\nverticalAlign === `top` ? `pb-3` : `pt-3`,\nclassName,\n)}\n>\n{payload.map((item) => {\nconst key = `${nameKey || item.dataKey || `value`}`;\nconst itemConfig = getPayloadConfigFromPayload(config, item, key);\nreturn (\n<div\nclassName={cn(\n`[&>svg]:text-muted-foreground flex items-center gap-1.5 [&>svg]:h-3 [&>svg]:w-3`,\n)}\nkey={item.value}\n>\n{itemConfig?.icon && !hideIcon ? (\n<itemConfig.icon />\n) : (\n<div\nclassName=`h-2 w-2 shrink-0 rounded-sm`\nstyle={{\nbackgroundColor: item.color,\n}}\n/>\n)}\n{itemConfig?.label}\n</div>\n);\n})}\n</div>\n);\n}"
"function SidebarMenuButton({\nasChild = false,\nisActive = false,\nvariant = `default`,\nsize = `default`,\ntooltip,\nclassName,\n...props\n}: React.ComponentProps<`button`> & {\nasChild?: boolean;\nisActive?: boolean;\ntooltip?: string | React.ComponentProps<typeof TooltipContent>;\n} & VariantProps<typeof sidebarMenuButtonVariants>) {\nconst Comp = asChild ? Slot : `button`;\nconst { isMobile, state } = useSidebar();\nconst button = (\n<Comp\nclassName={cn(sidebarMenuButtonVariants({ variant, size }), className)}\ndata-active={isActive}\ndata-sidebar=`menu-button`\ndata-size={size}\ndata-slot=`sidebar-menu-button`\n{...props}\n/>\n);\nif (!tooltip) {\nreturn button;\n}\nif (typeof tooltip === `string`) {\ntooltip = {\nchildren: tooltip,\n};\n}\nreturn (\n<Tooltip>\n<TooltipTrigger asChild>{button}</TooltipTrigger>\n<TooltipContent\nalign=`center`\nhidden={state !== `collapsed` || isMobile}\nside=`right`\n{...tooltip}\n/>\n</Tooltip>\n);\n}"
"export function createRouteDetection(\nconfig: RouteDetectionConfig,\ncleanup: RouteDetectionCleanup,\n): void {\nif (cleanup.observer) {\ncleanup.observer.disconnect()\n}\nif (cleanup.urlCheckInterval) {\nclearInterval(cleanup.urlCheckInterval)\n}\nif (cleanup.observerThrottle) {\nclearTimeout(cleanup.observerThrottle)\ncleanup.observerThrottle = null\n}\nlet currentUrl = window.location.href\nconst checkForRouteChange = () => {\nif (window.location.href !== currentUrl) {\ncurrentUrl = window.location.href\nconsole.log(`${config.platform} route changed, re-initializing`)\nsetTimeout(config.reinitCallback, 1000)\n}\n}\ncleanup.urlCheckInterval = setInterval(\ncheckForRouteChange,\nconfig.checkInterval || UI_CONFIG.ROUTE_CHECK_INTERVAL,\n)\ncleanup.observer = new MutationObserver((mutations) => {\nif (cleanup.observerThrottle) {\nreturn\n}\nlet shouldRecheck = false\nmutations.forEach((mutation) => {\nif (mutation.type === `childList` && mutation.addedNodes.length > 0) {\nmutation.addedNodes.forEach((node) => {\nif (node.nodeType === Node.ELEMENT_NODE) {\nconst element = node as Element\nfor (const selector of config.selectors) {\nif (\nelement.querySelector?.(selector) ||\nelement.matches?.(selector)\n) {\nshouldRecheck = true\nbreak\n}\n}\n}\n})\n}\n})\nif (shouldRecheck) {\ncleanup.observerThrottle = setTimeout(() => {\ntry {\ncleanup.observerThrottle = null\nconfig.reinitCallback()\n} catch (error) {\nconsole.error(`Error in ${config.platform} observer callback:`, error)\n}\n}, config.observerThrottleDelay || UI_CONFIG.OBSERVER_THROTTLE_DELAY)\n}\n})\ntry {\ncleanup.observer.observe(document.body, {\nchildList: true,\nsubtree: true,\n})\n} catch (error) {\nconsole.error(`Failed to set up ${config.platform} route observer:`, error)\nif (cleanup.urlCheckInterval) {\nclearInterval(cleanup.urlCheckInterval)\n}\ncleanup.urlCheckInterval = setInterval(checkForRouteChange, 1000)\n}\n}"
"export function tweetToMarkdown(tweet: Tweet): string {\nconst username = tweet.user?.screen_name || `unknown`\nconst displayName = tweet.user?.name || `Unknown User`\nconst date = new Date(tweet.created_at).toLocaleDateString()\nconst time = new Date(tweet.created_at).toLocaleTimeString()\nlet markdown = `# Tweet by @${username} (${displayName})\n\n`\nmarkdown += `**Date:** ${date} ${time}\n`\nmarkdown += `**Likes:** ${tweet.favorite_count} | **Retweets:** ${tweet.retweet_count || 0} | **Replies:** ${tweet.reply_count || 0}\n\n`\nmarkdown += `${tweet.text}\n\n`\nif (tweet.photos && tweet.photos.length > 0) {\nmarkdown += `**Images:**\n`\ntweet.photos.forEach((photo, index) => {\nmarkdown += `![Image ${index + 1}](${photo.url})\n`\n})\nmarkdown += `\n`\n}\nif (tweet.videos && tweet.videos.length > 0) {\nmarkdown += `**Videos:**\n`\ntweet.videos.forEach((video, index) => {\nmarkdown += `[Video ${index + 1}](${video.url})\n`\n})\nmarkdown += `\n`\n}\nif (tweet.entities.hashtags.length > 0) {\nmarkdown += `**Hashtags:** ${tweet.entities.hashtags.map((h) => `#${h.text}`).join(`, `)}\n`\n}\nif (tweet.entities.user_mentions.length > 0) {\nmarkdown += `**Mentions:** ${tweet.entities.user_mentions.map((m) => `@${m.screen_name}`).join(`, `)}\n`\n}\nmarkdown += `\n---\n<details>\n<summary>Raw Tweet Data</summary>\n\n\`\`\`json\n${JSON.stringify(tweet, null, 2)}\n\`\`\`\n</details>`\nreturn markdown\n}"
"export function createTwitterImportButton(onClick: () => void): HTMLElement {\nconst button = document.createElement(`div`)\nbutton.id = ELEMENT_IDS.TWITTER_IMPORT_BUTTON\nbutton.style.cssText = `\nposition: fixed;\ntop: 10px;\nright: 10px;\nz-index: 2147483646;\nbackground: #ffffff;\ncolor: black;\nborder: none;\nborder-radius: 50px;\npadding: 10px 16px 10px 32px;\ncursor: pointer;\ndisplay: flex;\nalign-items: center;\ngap: 8px;\ntransition: all 0.2s ease;\nfont-family: 'Space Grotesk', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n`\nconst iconUrl = browser.runtime.getURL(`/icon-16.png`)\nbutton.style.backgroundImage = `url(`${iconUrl}`)`\nbutton.style.backgroundRepeat = `no-repeat`\nbutton.style.backgroundSize = `20px 20px`\nbutton.style.backgroundPosition = `8px center`\nconst textSpan = document.createElement(`span`)\ntextSpan.id = `sm-import-text`\ntextSpan.style.cssText = `font-weight: 500; font-size: 12px;`\ntextSpan.textContent = `Import Bookmarks`\nbutton.appendChild(textSpan)\nbutton.addEventListener(`mouseenter`, () => {\nbutton.style.opacity = `0.8`\nbutton.style.boxShadow = `0 4px 12px rgba(29, 155, 240, 0.4)`\n})\nbutton.addEventListener(`mouseleave`, () => {\nbutton.style.opacity = `1`\nbutton.style.boxShadow = `0 2px 8px rgba(29, 155, 240, 0.3)`\n})\nbutton.addEventListener(`click`, onClick)\nreturn button\n}"
"async function getRelatedMemoriesForChatGPT(actionSource: string) {\ntry {\nconst userQuery =\ndocument.getElementById(`prompt-textarea`)?.textContent || ``\nconst icon = document.querySelectorAll(\n'[id*=`sm-chatgpt-input-bar-element-before-composer`]',\n)[0]\nconst iconElement = icon as HTMLElement\nif (!iconElement) {\nconsole.warn(`ChatGPT icon element not found, cannot update feedback`)\nreturn\n}\nupdateChatGPTIconFeedback(`Searching memories...`, iconElement)\nconst timeoutPromise = new Promise((_, reject) =>\nsetTimeout(\n() => reject(new Error(`Memory search timeout`)),\nUI_CONFIG.API_REQUEST_TIMEOUT,\n),\n)\nconst response = await Promise.race([\nbrowser.runtime.sendMessage({\naction: MESSAGE_TYPES.GET_RELATED_MEMORIES,\ndata: userQuery,\nactionSource: actionSource,\n}),\ntimeoutPromise,\n])\nif (response?.success && response?.data) {\nconst promptElement = document.getElementById(`prompt-textarea`)\nif (promptElement) {\npromptElement.dataset.supermemories = `<div>Supermemories of user (only for the reference): ${response.data}</div>`\nconsole.log(\n`Prompt element dataset:`,\npromptElement.dataset.supermemories,\n)\niconElement.dataset.memoriesData = response.data\nupdateChatGPTIconFeedback(`Included Memories`, iconElement)\n} else {\nconsole.warn(\n`ChatGPT prompt element not found after successful memory fetch`,\n)\nupdateChatGPTIconFeedback(`Memories found`, iconElement)\n}\n} else {\nconsole.warn(`No memories found or API response invalid`)\nupdateChatGPTIconFeedback(`No memories found`, iconElement)\n}\n} catch (error) {\nconsole.error(`Error getting related memories:`, error)\ntry {\nconst icon = document.querySelectorAll(\n'[id*=`sm-chatgpt-input-bar-element-before-composer`]',\n)[0] as HTMLElement\nif (icon) {\nupdateChatGPTIconFeedback(`Error fetching memories`, icon)\n}\n} catch (feedbackError) {\nconsole.error(`Failed to update error feedback:`, feedbackError)\n}\n}\n}"
"function addSupermemoryButtonToMemoriesDialog() {\nconst dialogs = document.querySelectorAll('[role=`dialog`]')\nlet memoriesDialog: HTMLElement | null = null\nfor (const dialog of dialogs) {\nconst headerText = dialog.querySelector(`h2`)\nif (headerText?.textContent?.includes(`Saved memories`)) {\nmemoriesDialog = dialog as HTMLElement\nbreak\n}\n}\nif (!memoriesDialog) return\nif (memoriesDialog.querySelector(`#supermemory-save-button`)) return\nconst deleteAllContainer = memoriesDialog.querySelector(\n`.mt-5.flex.justify-end`,\n)\nif (!deleteAllContainer) return\nconst supermemoryButton = document.createElement(`button`)\nsupermemoryButton.id = `supermemory-save-button`\nsupermemoryButton.className = `btn relative btn-primary-outline mr-2`\nconst iconUrl = browser.runtime.getURL(`/icon-16.png`)\nsupermemoryButton.innerHTML = `\n<div class=`flex items-center justify-center gap-2`>\n<img src=`${iconUrl}` alt=`supermemory` style=`width: 16px; height: 16px; flex-shrink: 0; border-radius: 2px;` />\nSave to supermemory\n</div>\n`\nsupermemoryButton.style.cssText = `\nbackground: #1C2026 !important;\ncolor: white !important;\nborder: 1px solid #1C2026 !important;\nborder-radius: 9999px !important;\npadding: 10px 16px !important;\nfont-weight: 500 !important;\nfont-size: 14px !important;\nmargin-right: 8px !important;\ncursor: pointer !important;\n`\nsupermemoryButton.addEventListener(`mouseenter`, () => {\nsupermemoryButton.style.backgroundColor = `#2B2E33`\n})\nsupermemoryButton.addEventListener(`mouseleave`, () => {\nsupermemoryButton.style.backgroundColor = `#1C2026`\n})\nsupermemoryButton.addEventListener(`click`, async () => {\nawait saveMemoriesToSupermemory()\n})\ndeleteAllContainer.insertBefore(\nsupermemoryButton,\ndeleteAllContainer.firstChild,\n)\n}"
"async function saveMemoriesToSupermemory() {\ntry {\nDOMUtils.showToast(`loading`)\nconst memoriesTable = document.querySelector('[role=`dialog`] table tbody')\nif (!memoriesTable) {\nDOMUtils.showToast(`error`)\nreturn\n}\nconst memoryRows = memoriesTable.querySelectorAll(`tr`)\nconst memories: string[] = []\nmemoryRows.forEach((row) => {\nconst memoryCell = row.querySelector(`td .py-2.whitespace-pre-wrap`)\nif (memoryCell?.textContent) {\nmemories.push(memoryCell.textContent.trim())\n}\n})\nconsole.log(`Memories:`, memories)\nif (memories.length === 0) {\nDOMUtils.showToast(`error`)\nreturn\n}\nconst combinedContent = `ChatGPT Saved Memories:\n\n${memories.map((memory, index) => `${index + 1}. ${memory}`).join(`\n\n`)}`\nconst response = await browser.runtime.sendMessage({\naction: MESSAGE_TYPES.SAVE_MEMORY,\ndata: {\nhtml: combinedContent,\n},\nactionSource: `chatgpt_memories_dialog`,\n})\nconsole.log({ response })\nif (response.success) {\nDOMUtils.showToast(`success`)\n} else {\nDOMUtils.showToast(`error`)\n}\n} catch (error) {\nconsole.error(`Error saving memories to supermemory:`, error)\nDOMUtils.showToast(`error`)\n}\n}"
"function addSaveChatGPTElementBeforeComposerBtn() {\nconst composerButtons = document.querySelectorAll(`button.composer-btn`)\ncomposerButtons.forEach((button) => {\nif (button.hasAttribute(`data-supermemory-icon-added-before`)) {\nreturn\n}\nconst parent = button.parentElement\nif (!parent) return\nconst parentSiblings = parent.parentElement?.children\nif (!parentSiblings) return\nlet hasSpeechButtonSibling = false\nfor (const sibling of parentSiblings) {\nif (\nsibling.getAttribute(`data-testid`) ===\n`composer-speech-button-container`\n) {\nhasSpeechButtonSibling = true\nbreak\n}\n}\nif (!hasSpeechButtonSibling) return\nconst grandParent = parent.parentElement\nif (!grandParent) return\nconst existingIcon = grandParent.querySelector(\n`#${ELEMENT_IDS.CHATGPT_INPUT_BAR_ELEMENT}-before-composer`,\n)\nif (existingIcon) {\nbutton.setAttribute(`data-supermemory-icon-added-before`, `true`)\nreturn\n}\nconst saveChatGPTElement = createChatGPTInputBarElement(async () => {\nawait getRelatedMemoriesForChatGPT(\nPOSTHOG_EVENT_KEY.CHATGPT_CHAT_MEMORIES_SEARCHED,\n)\n})\nsaveChatGPTElement.id = `${ELEMENT_IDS.CHATGPT_INPUT_BAR_ELEMENT}-before-composer-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`\nbutton.setAttribute(`data-supermemory-icon-added-before`, `true`)\ngrandParent.insertBefore(saveChatGPTElement, parent)\nsetupChatGPTAutoFetch()\n})\n}"
"async function setupChatGPTAutoFetch() {\nconst autoSearch = (await autoSearchEnabled.getValue()) ?? false\nif (!autoSearch) {\nreturn\n}\nconst promptTextarea = document.getElementById(`prompt-textarea`)\nif (\n!promptTextarea ||\npromptTextarea.hasAttribute(`data-supermemory-auto-fetch`)\n) {\nreturn\n}\npromptTextarea.setAttribute(`data-supermemory-auto-fetch`, `true`)\nconst handleInput = () => {\nif (chatGPTDebounceTimeout) {\nclearTimeout(chatGPTDebounceTimeout)\n}\nchatGPTDebounceTimeout = setTimeout(async () => {\nconst content = promptTextarea.textContent?.trim() || ``\nif (content.length > 2) {\nawait getRelatedMemoriesForChatGPT(\nPOSTHOG_EVENT_KEY.CHATGPT_CHAT_MEMORIES_AUTO_SEARCHED,\n)\n} else if (content.length === 0) {\nconst icons = document.querySelectorAll(\n'[id*=`sm-chatgpt-input-bar-element-before-composer`]',\n)\nicons.forEach((icon) => {\nconst iconElement = icon as HTMLElement\nif (iconElement.dataset.originalHtml) {\niconElement.innerHTML = iconElement.dataset.originalHtml\ndelete iconElement.dataset.originalHtml\ndelete iconElement.dataset.memoriesData\n}\n})\nif (promptTextarea.dataset.supermemories) {\ndelete promptTextarea.dataset.supermemories\n}\n}\n}, UI_CONFIG.AUTO_SEARCH_DEBOUNCE_DELAY)\n}\npromptTextarea.addEventListener(`input`, handleInput)\n}"
"async function setupClaudeAutoFetch() {\nconst autoSearch = (await autoSearchEnabled.getValue()) ?? false\nif (!autoSearch) {\nreturn\n}\nconst textareaElement = document.querySelector(\n'div[contenteditable=`true`]',\n) as HTMLElement\nif (\n!textareaElement ||\ntextareaElement.hasAttribute(`data-supermemory-auto-fetch`)\n) {\nreturn\n}\ntextareaElement.setAttribute(`data-supermemory-auto-fetch`, `true`)\nconst handleInput = () => {\nif (claudeDebounceTimeout) {\nclearTimeout(claudeDebounceTimeout)\n}\nclaudeDebounceTimeout = setTimeout(async () => {\nconst content = textareaElement.textContent?.trim() || ``\nif (content.length > 2) {\nawait getRelatedMemoriesForClaude(\nPOSTHOG_EVENT_KEY.CLAUDE_CHAT_MEMORIES_AUTO_SEARCHED,\n)\n} else if (content.length === 0) {\nconst icons = document.querySelectorAll(\n'[id*=`sm-claude-input-bar-element`]',\n)\nicons.forEach((icon) => {\nconst iconElement = icon as HTMLElement\nif (iconElement.dataset.originalHtml) {\niconElement.innerHTML = iconElement.dataset.originalHtml\ndelete iconElement.dataset.originalHtml\ndelete iconElement.dataset.memoriesData\n}\n})\nif (textareaElement.dataset.supermemories) {\ndelete textareaElement.dataset.supermemories\n}\n}\n}, UI_CONFIG.AUTO_SEARCH_DEBOUNCE_DELAY)\n}\ntextareaElement.addEventListener(`input`, handleInput)\n}"
"main() {\nbrowser.runtime.onMessage.addListener(async (message) => {\nif (message.action === MESSAGE_TYPES.SHOW_TOAST) {\nDOMUtils.showToast(message.state)\n} else if (message.action === MESSAGE_TYPES.SAVE_MEMORY) {\nawait saveMemory()\n} else if (message.type === MESSAGE_TYPES.IMPORT_UPDATE) {\nupdateTwitterImportUI(message)\n} else if (message.type === MESSAGE_TYPES.IMPORT_DONE) {\nupdateTwitterImportUI(message)\n}\n})\nsetupGlobalKeyboardShortcut()\nsetupStorageListener()\nconst observeForDynamicChanges = () => {\nconst observer = new MutationObserver(() => {\nif (DOMUtils.isOnDomain(DOMAINS.CHATGPT)) {\ninitializeChatGPT()\n}\nif (DOMUtils.isOnDomain(DOMAINS.CLAUDE)) {\ninitializeClaude()\n}\nif (DOMUtils.isOnDomain(DOMAINS.T3)) {\ninitializeT3()\n}\nif (DOMUtils.isOnDomain(DOMAINS.TWITTER)) {\nhandleTwitterNavigation()\n}\n})\nobserver.observe(document.body, {\nchildList: true,\nsubtree: true,\n})\n}\ninitializeChatGPT()\ninitializeClaude()\ninitializeT3()\ninitializeTwitter()\nif (document.readyState === `loading`) {\ndocument.addEventListener(`DOMContentLoaded`, observeForDynamicChanges)\n} else {\nobserveForDynamicChanges()\n}\n},"
"export async function saveMemory() {\ntry {\nDOMUtils.showToast(`loading`)\nconst highlightedText = window.getSelection()?.toString() || ``\nconst url = window.location.href\nconst ogImage =\ndocument\n.querySelector('meta[property=`og:image`]')\n?.getAttribute(`content`) ||\ndocument\n.querySelector('meta[name=`og:image`]')\n?.getAttribute(`content`) ||\nundefined\nconst title =\ndocument\n.querySelector('meta[property=`og:title`]')\n?.getAttribute(`content`) ||\ndocument\n.querySelector('meta[name=`og:title`]')\n?.getAttribute(`content`) ||\ndocument.title ||\nundefined\nconst data: {\nhtml?: string\nmarkdown?: string\nhighlightedText?: string\nurl: string\nogImage?: string\ntitle?: string\n} = {\nurl,\n}\nif (ogImage) {\ndata.ogImage = ogImage\n}\nif (title) {\ndata.title = title\n}\nif (highlightedText) {\ndata.highlightedText = highlightedText\n} else {\nconst bodyClone = document.body.cloneNode(true) as HTMLElement\nconst scripts = bodyClone.querySelectorAll(`script`)\nfor (const script of scripts) {\nscript.remove()\n}\nconst html = bodyClone.innerHTML\nconst turndownService = new TurndownService()\nconst markdown = turndownService.turndown(html)\ndata.markdown = markdown\n}\nconst response = await browser.runtime.sendMessage({\naction: MESSAGE_TYPES.SAVE_MEMORY,\ndata,\nactionSource: `context_menu`,\n})\nconsole.log(`Response from enxtension:`, response)\nif (response.success) {\nDOMUtils.showToast(`success`)\n} else {\nDOMUtils.showToast(`error`)\n}\n} catch (error) {\nconsole.error(`Error saving memory:`, error)\nDOMUtils.showToast(`error`)\n}\n}"
"function setupT3RouteChangeDetection() {\nif (t3RouteObserver) {\nt3RouteObserver.disconnect()\n}\nif (t3UrlCheckInterval) {\nclearInterval(t3UrlCheckInterval)\n}\nif (t3ObserverThrottle) {\nclearTimeout(t3ObserverThrottle)\nt3ObserverThrottle = null\n}\nlet currentUrl = window.location.href\nconst checkForRouteChange = () => {\nif (window.location.href !== currentUrl) {\ncurrentUrl = window.location.href\nconsole.log(`T3 route changed, re-adding supermemory icon`)\nsetTimeout(() => {\naddSupermemoryIconToT3Input()\nsetupT3AutoFetch()\n}, 1000)\n}\n}\nt3UrlCheckInterval = setInterval(checkForRouteChange, 2000)\nt3RouteObserver = new MutationObserver((mutations) => {\nif (t3ObserverThrottle) {\nreturn\n}\nlet shouldRecheck = false\nmutations.forEach((mutation) => {\nif (mutation.type === `childList` && mutation.addedNodes.length > 0) {\nmutation.addedNodes.forEach((node) => {\nif (node.nodeType === Node.ELEMENT_NODE) {\nconst element = node as Element\nif (\nelement.querySelector?.(`textarea`) ||\nelement.querySelector?.('div[contenteditable=`true`]') ||\nelement.matches?.(`textarea`) ||\nelement.matches?.('div[contenteditable=`true`]')\n) {\nshouldRecheck = true\n}\n}\n})\n}\n})\nif (shouldRecheck) {\nt3ObserverThrottle = setTimeout(() => {\ntry {\nt3ObserverThrottle = null\naddSupermemoryIconToT3Input()\nsetupT3AutoFetch()\n} catch (error) {\nconsole.error(`Error in T3 observer callback:`, error)\n}\n}, 300)\n}\n})\ntry {\nt3RouteObserver.observe(document.body, {\nchildList: true,\nsubtree: true,\n})\n} catch (error) {\nconsole.error(`Failed to set up T3 route observer:`, error)\nif (t3UrlCheckInterval) {\nclearInterval(t3UrlCheckInterval)\n}\nt3UrlCheckInterval = setInterval(checkForRouteChange, 1000)\n}\n}"
"async function setupT3AutoFetch() {\nconst autoSearch = (await autoSearchEnabled.getValue()) ?? false\nif (!autoSearch) {\nreturn\n}\nconst textareaElement =\n(document.querySelector(`textarea`) as HTMLTextAreaElement) ||\n(document.querySelector('div[contenteditable=`true`]') as HTMLElement)\nif (\n!textareaElement ||\ntextareaElement.hasAttribute(`data-supermemory-auto-fetch`)\n) {\nreturn\n}\ntextareaElement.setAttribute(`data-supermemory-auto-fetch`, `true`)\nconst handleInput = () => {\nif (t3DebounceTimeout) {\nclearTimeout(t3DebounceTimeout)\n}\nt3DebounceTimeout = setTimeout(async () => {\nlet content = ``\nif (textareaElement.tagName === `TEXTAREA`) {\ncontent = (textareaElement as HTMLTextAreaElement).value?.trim() || ``\n} else {\ncontent = textareaElement.textContent?.trim() || ``\n}\nif (content.length > 2) {\nawait getRelatedMemoriesForT3(\nPOSTHOG_EVENT_KEY.T3_CHAT_MEMORIES_AUTO_SEARCHED,\n)\n} else if (content.length === 0) {\nconst icons = document.querySelectorAll(\n'[id*=`sm-t3-input-bar-element`]',\n)\nicons.forEach((icon) => {\nconst iconElement = icon as HTMLElement\nif (iconElement.dataset.originalHtml) {\niconElement.innerHTML = iconElement.dataset.originalHtml\ndelete iconElement.dataset.originalHtml\ndelete iconElement.dataset.memoriesData\n}\n})\nif (textareaElement.dataset.supermemories) {\ndelete textareaElement.dataset.supermemories\n}\n}\n}, UI_CONFIG.AUTO_SEARCH_DEBOUNCE_DELAY)\n}\ntextareaElement.addEventListener(`input`, handleInput)\n}"
"export function updateTwitterImportUI(message: {\ntype: string\nimportedMessage?: string\ntotalImported?: number\n}) {\nconst importButton = document.getElementById(\nELEMENT_IDS.TWITTER_IMPORT_BUTTON,\n)\nif (!importButton) return\nconst existingImg = importButton.querySelector(`img`)\nif (existingImg) {\nexistingImg.remove()\nconst iconUrl = browser.runtime.getURL(`/icon-16.png`)\nimportButton.style.backgroundImage = `url(`${iconUrl}`)`\nimportButton.style.backgroundRepeat = `no-repeat`\nimportButton.style.backgroundSize = `20px 20px`\nimportButton.style.backgroundPosition = `8px center`\nimportButton.style.padding = `10px 16px 10px 32px`\n}\nlet textSpan = importButton.querySelector(\n`#sm-import-text`,\n) as HTMLSpanElement\nif (!textSpan) {\ntextSpan = document.createElement(`span`)\ntextSpan.id = `sm-import-text`\ntextSpan.style.cssText = `font-weight: 500; font-size: 14px;`\nimportButton.appendChild(textSpan)\n}\nif (message.type === MESSAGE_TYPES.IMPORT_UPDATE) {\ntextSpan.textContent = message.importedMessage || ``\nimportButton.style.cursor = `default`\n}\nif (message.type === MESSAGE_TYPES.IMPORT_DONE) {\ntextSpan.textContent = `✓ Imported ${message.totalImported} tweets!`\ntextSpan.style.color = `#059669`\nsetTimeout(() => {\ntextSpan.textContent = `Import Bookmarks`\ntextSpan.style.color = ``\nimportButton.style.cursor = `pointer`\n}, 3000)\n}\n}"
"async function showProjectSelectionModal(bookmarkCollectionId: string) {\ntry {\nconst modal = createProjectSelectionModal(\n[],\nasync (selectedProject) => {\nmodal.remove()\ntry {\nawait browser.runtime.sendMessage({\ntype: MESSAGE_TYPES.BATCH_IMPORT_ALL,\nisFolderImport: true,\nbookmarkCollectionId: bookmarkCollectionId,\nselectedProject: selectedProject,\n})\n} catch (error) {\nconsole.error(`Error importing bookmarks:`, error)\n}\n},\n() => {\nmodal.remove()\n},\n)\ndocument.body.appendChild(modal)\ntry {\nconst response = await browser.runtime.sendMessage({\naction: MESSAGE_TYPES.FETCH_PROJECTS,\n})\nif (response.success && response.data) {\nconst projects = response.data\nif (projects.length === 0) {\nconsole.warn(`No projects available for import`)\nupdateModalWithProjects(modal, [])\n} else {\nupdateModalWithProjects(modal, projects)\n}\n} else {\nconsole.error(`Failed to fetch projects:`, response.error)\nupdateModalWithProjects(modal, [])\n}\n} catch (error) {\nconsole.error(`Error fetching projects:`, error)\nupdateModalWithProjects(modal, [])\n}\n} catch (error) {\nconsole.error(`Error showing project selection modal:`, error)\n}\n}"
"function updateModalWithProjects(\nmodal: HTMLElement,\nprojects: Array<{ id: string; name: string; containerTag: string }>,\n) {\nconst select = modal.querySelector(`#project-select`) as HTMLSelectElement\nif (!select) return\nwhile (select.children.length > 1) {\nselect.removeChild(select.children[1])\n}\nif (projects.length === 0) {\nconst noProjectsOption = document.createElement(`option`)\nnoProjectsOption.value = ``\nnoProjectsOption.textContent = `No projects available`\nnoProjectsOption.disabled = true\nselect.appendChild(noProjectsOption)\nconst importButton = modal.querySelector(\n`button:last-child`,\n) as HTMLButtonElement\nif (importButton) {\nimportButton.disabled = true\nimportButton.style.cssText = `\npadding: 10px 16px;\nborder: none;\nborder-radius: 8px;\nbackground: #d1d5db;\ncolor: #9ca3af;\nfont-size: 14px;\nfont-weight: 500;\ncursor: not-allowed;\ntransition: all 0.2s ease;\n`\n}\n} else {\nprojects.forEach((project) => {\nconst option = document.createElement(`option`)\noption.value = project.id\noption.textContent = project.name\noption.dataset.containerTag = project.containerTag\nselect.appendChild(option)\n})\n}\n}"
"export async function POST(request: Request) {\ntry {\nconst body = await request.json()\nconst { apiKey, page = 1, limit = 500, sort = 'createdAt', order = 'desc' } = body\nif (!apiKey) {\nreturn NextResponse.json(\n{ error: 'API key is required' },\n{ status: 400 }\n)\n}\nconst response = await fetch('https:\nmethod: 'POST',\nheaders: {\n'Content-Type': 'application/json',\n'Authorization': `Bearer ${apiKey}`,\n},\nbody: JSON.stringify({\npage,\nlimit,\nsort,\norder,\n}),\n})\nif (!response.ok) {\nconst errorData = await response.json().catch(() => ({}))\nreturn NextResponse.json(\n{ error: errorData.message || `API error: ${response.status}` },\n{ status: response.status }\n)\n}\nconst data = await response.json()\nreturn NextResponse.json(data)\n} catch (error) {\nconsole.error('Graph API error:', error)\nreturn NextResponse.json(\n{ error: 'Failed to fetch documents' },\n{ status: 500 }\n)\n}\n}"
"config({ ctx: _ctx }) {\nconst url = `${getBaseUrl()}/api/trpc`;\nreturn {\nlinks: [\nloggerLink({\nenabled: (opts) =>\nprocess.env.NODE_ENV === 'development' ||\n(opts.direction === 'down' && opts.result instanceof Error),\n}),\nhttpBatchLink({ url }),\n],\nqueryClientConfig: {\ndefaultOptions: {\nqueries: {\nrefetchOnWindowFocus: false,\n},\n},\n},\ntransformer: superjson,\nurl,\n};\n},"
export default function HomePage() {\nreturn (\n<>\n<Head>\n<title>Tech Interview Handbook Portal</title>\n</Head>\n<div className=`bg-white pb-24`>\n<div className=`space-y-12`>\n<div className=`bg-slate-100 py-8 text-center sm:py-16`>\n<Container>\n<h1 className=`text-4xl font-bold tracking-tight text-slate-900 sm:text-5xl md:text-6xl`>\n<span className=`block`>Tech Interview Handbook</span>\n<span className=`text-primary-600 block`>Portal</span>\n</h1>\n<p className=`mx-auto mt-3 max-w-md text-base text-slate-500 sm:text-lg md:mt-5 md:max-w-3xl md:text-xl`>\nSuite of products to help you get better at technical\ninterviews.\n</p>\n</Container>\n</div>\n<Container>\n<div>\n<h2 className=`sr-only`>Products.</h2>\n<dl className=`space-y-10 lg:grid lg:grid-cols-3 lg:gap-12 lg:space-y-0`>\n{features.map((feature) => (\n<div key={feature.name}>\n<dt>\n<div className=`flex justify-center`>\n<img\nalt={feature.name}\nclassName=`h-48`\nsrc={feature.img}\n/>\n</div>\n<p className=`mt-8 text-xl font-medium leading-6 text-slate-900`>\n{feature.name}\n</p>\n</dt>\n<dd className=`mt-2 text-base text-slate-500`>\n{feature.description}\n</dd>\n<Button\nclassName=`mt-4`\nhref={feature.href}\nlabel=`Try it out`\nvariant=`tertiary`\n/>\n</div>\n))}\n</dl>\n</div>\n</Container>\n</div>\n</div>\n</>\n);\n}
"export default function LoginPage({\nproviders,\n}: InferGetServerSidePropsType<typeof getServerSideProps>) {\nconst router = useRouter();\nreturn (\n<div className=`flex w-full justify-center`>\n<div className=`flex min-h-full flex-col justify-center py-12 px-6 lg:px-8`>\n<div className=`sm:mx-auto sm:w-full sm:max-w-md`>\n<img\nalt=`Tech Interview Handbook`\nclassName=`mx-auto h-24 w-auto sm:h-36`\nsrc=`/logo.svg`\n/>\n<h2 className=`mt-6 text-center text-2xl font-bold tracking-tight text-slate-900 sm:text-3xl`>\nSign in to Tech Interview Handbook Portal\n</h2>\n<p className=`mt-2 text-center text-sm text-slate-600 sm:text-base`>\nGet your resumes peer-reviewed, discuss solutions to tech interview\nquestions, explore offer data points.\n</p>\n</div>\n<div className=`mt-8 sm:mx-auto sm:w-full sm:max-w-md`>\n<div className=`space-y-4`>\n{providers != null &&\nObject.values(providers).map((provider) => (\n<div key={provider.name}>\n<Button\naddonPosition=`start`\ndisplay=`block`\nicon={GitHubIcon}\nlabel={\nrouter.query.mode === 'signup'\n? `Sign up with ${provider.name}`\n: `Sign in with ${provider.name}`\n}\ntype=`button`\nvariant=`primary`\nonClick={() =>\nsignIn(\nprovider.id,\nrouter.query.callbackUrl != null\n? {\ncallbackUrl: String(router.query.callbackUrl),\n}\n: undefined,\n)\n}\n/>\n</div>\n))}\n</div>\n{router.query.mode === 'signup' && (\n<p className=`mt-2 text-center text-xs text-slate-500 sm:text-sm`>\nSign up for an account via GitHub, it's free!\n</p>\n)}\n</div>\n</div>\n</div>\n);\n}"
"export default function CreateListDialog({\nshow,\nonCancel,\nonSubmit,\n}: CreateListDialogProps) {\nconst {\nregister: formRegister,\nhandleSubmit,\nformState: { isSubmitting, isDirty },\nreset,\n} = useForm<CreateListFormData>();\nconst register = useFormRegister(formRegister);\nconst handleDialogCancel = () => {\nonCancel();\nreset();\n};\nconst handleFormSubmit = handleSubmit(async (data) => {\nawait onSubmit(data);\nreset();\n});\nreturn (\n<Dialog\nisShown={show}\nprimaryButton={\n<Button\ndisabled={!isDirty}\ndisplay=`inline`\nisLoading={isSubmitting}\nlabel=`Create`\nsize=`md`\ntype=`submit`\nvariant=`primary`\nonClick={handleFormSubmit}\n/>\n}\nsecondaryButton={\n<Button\ndisplay=`inline`\nlabel=`Cancel`\nsize=`md`\nvariant=`tertiary`\nonClick={handleDialogCancel}\n/>\n}\ntitle=`Create question list`\nonClose={handleDialogCancel}>\n<form className=`w-full` onSubmit={handleFormSubmit}>\n<TextInput\nid=`listName`\nisLabelHidden={true}\n{...register('name')}\nautoComplete=`off`\nlabel=`Name`\nplaceholder=`List name`\nrequired={true}\ntype=`text`\n/>\n</form>\n</Dialog>\n);\n}"
"export default function QuestionSearchBar({\nactiveFilterCount,\nonFilterOptionsToggle,\nonQueryChange,\nquery,\n...sortOptionsSelectProps\n}: QuestionSearchBarProps) {\nreturn (\n<div className=`flex flex-col gap-4`>\n<div className=`flex flex-col items-stretch gap-x-2 gap-y-4 lg:flex-row lg:items-end`>\n<div className=`flex flex-1 gap-2`>\n<div className=`flex-1`>\n<TextInput\nisLabelHidden={true}\nlabel=`Search by content`\nplaceholder=`Search by content`\nstartAddOn={MagnifyingGlassIcon}\nstartAddOnType=`icon`\nvalue={query}\nonChange={(value) => {\nonQueryChange(value);\n}}\n/>\n</div>\n<div className=`lg:hidden`>\n<Button\naddonPosition=`start`\nicon={AdjustmentsHorizontalIcon}\nlabel={\nactiveFilterCount > 0\n? `Filters (${activeFilterCount})`\n: 'Filters'\n}\nvariant={activeFilterCount > 0 ? 'secondary' : 'tertiary'}\nonClick={onFilterOptionsToggle}\n/>\n</div>\n</div>\n</div>\n<div className=`flex flex-col justify-start gap-x-4 gap-y-2 sm:flex-row`>\n<div>\n<Tabs\nlabel=`Sort by`\ntabs={sortOptionsSelectProps.sortTypeOptions ?? []}\nvalue={sortOptionsSelectProps.sortTypeValue}\nonChange={sortOptionsSelectProps.onSortTypeChange}\n/>\n</div>\n<div className=`border-b border-l` />\n<div>\n<Tabs\nlabel=`Order by`\ntabs={(sortOptionsSelectProps.sortOrderOptions ?? SORT_ORDERS).map(\n(option) => {\nconst newLabel = getSortOrderLabel(\noption.value,\nsortOptionsSelectProps.sortTypeValue,\n);\nreturn {\n...option,\nlabel: newLabel,\n};\n},\n)}\nvalue={sortOptionsSelectProps.sortOrderValue}\nonChange={sortOptionsSelectProps.onSortOrderChange}\n/>\n</div>\n</div>\n</div>\n);\n}"
"export default function SortOptionsSelect({\nonSortOrderChange,\nsortOrderValue,\nonSortTypeChange,\nsortTypeValue,\nsortOrderOptions,\nsortTypeOptions,\n}: SortOptionsSelectProps) {\nconst sortTypes = sortTypeOptions ?? SORT_TYPES;\nconst sortOrders = sortOrderOptions ?? SORT_ORDERS;\nreturn (\n<div className=`flex items-end justify-end gap-2`>\n<div className=`flex items-center`>\n<Select\ndisplay=`inline`\nlabel=`Sort by`\noptions={sortTypes}\nvalue={sortTypeValue}\nonChange={(value) => {\nconst chosenOption = sortTypes.find(\n(option) => String(option.value) === value,\n);\nif (chosenOption) {\nonSortTypeChange?.(chosenOption.value);\n}\n}}\n/>\n</div>\n<div className=`flex items-center`>\n<Select\ndisplay=`inline`\nlabel=`Order by`\noptions={sortOrders}\nvalue={sortOrderValue}\nonChange={(value) => {\nconst chosenOption = sortOrders.find(\n(option) => String(option.value) === value,\n);\nif (chosenOption) {\nonSortOrderChange?.(chosenOption.value);\n}\n}}\n/>\n</div>\n</div>\n);\n}"
"export default function VotingButtons({\nvote,\nonDownvote,\nonUpvote,\nupvoteCount,\nsize = 'md',\n}: VotingButtonsProps) {\nconst handleUpvoteClick = useProtectedCallback(() => {\nonUpvote();\n});\nconst handleDownvoteClick = useProtectedCallback(() => {\nonDownvote();\n});\nreturn (\n<div className=`flex flex-col items-center`>\n<button\naria-label=`Upvote`\nclassName={clsx(\n'rounded-full p-1 hover:bg-slate-100',\nvote?.vote === 'UPVOTE' && 'bg-primary-50',\n)}\ntype=`button`\nonClick={(event) => {\nevent.preventDefault();\nevent.stopPropagation();\nhandleUpvoteClick();\n}}>\n<ChevronUpIcon\nclassName={clsx(\nsize === 'sm' && 'h-5 w-5',\nsize === 'md' && 'h-6 w-6',\nvote?.vote === 'UPVOTE'\n? 'text-primary-500'\n: 'hover:text-primary-500 text-slate-400',\n)}\n/>\n</button>\n<p>{upvoteCount}</p>\n<button\naria-label=`Downvote`\nclassName={clsx(\n'rounded-full p-1 hover:bg-slate-100',\nvote?.vote === 'DOWNVOTE' && 'bg-danger-50',\n)}\ntype=`button`\nonClick={(event) => {\nevent.preventDefault();\nevent.stopPropagation();\nhandleDownvoteClick();\n}}>\n<ChevronDownIcon\nclassName={clsx(\nsize === 'sm' && 'h-5 w-5',\nsize === 'md' && 'h-6 w-6',\nvote?.vote === 'DOWNVOTE'\n? 'text-danger-500'\n: 'hover:text-danger-500 text-slate-400',\n)}\n/>\n</button>\n</div>\n);\n}"
"export default function MonthYearPicker({\nclassName,\nerrorMessage,\nmonthLabel = 'Month',\nvalue,\nonChange,\nyearLabel = 'Year',\nmonthRequired = false,\nyearRequired = false,\n}: Props) {\nconst hasError = errorMessage != null;\nconst errorId = useId();\nconst [monthCounter, setMonthCounter] = useState<number>(0);\nconst [yearCounter, setYearCounter] = useState<number>(0);\nuseEffect(() => {\nif (value.month == null) {\nsetMonthCounter((val) => val + 1);\n}\nif (value.year == null) {\nsetYearCounter((val) => val + 1);\n}\n}, [value.month, value.year]);\nreturn (\n<div aria-describedby={hasError ? errorId : undefined}>\n<div className={clsx('flex items-end', className)}>\n<div className=`grow`>\n<Select\nkey={`month:${monthCounter}`}\ndisplay=`block`\nlabel={monthLabel}\noptions={MONTH_OPTIONS}\nplaceholder=`Select month`\nrequired={monthRequired}\nvalue={value.month}\nonChange={(newMonth) =>\nonChange({ month: Number(newMonth) as Month, year: value.year })\n}\n/>\n</div>\n<div className=`grow`>\n<Select\nkey={`year:${yearCounter}`}\ndisplay=`block`\nlabel={yearLabel}\noptions={YEAR_OPTIONS}\nplaceholder=`Select year`\nrequired={yearRequired}\nvalue={value.year}\nonChange={(newYear) =>\nonChange({ month: value.month, year: Number(newYear) })\n}\n/>\n</div>\n</div>\n{errorMessage && (\n<p className=`text-danger-600 mt-2 text-sm` id={errorId}>\n{errorMessage}\n</p>\n)}\n</div>\n);\n}"
"export default async function handler(\nreq: NextApiRequest,\nres: NextApiResponse,\n) {\ntry {\nif (req.method === 'POST') {\nconst form = formidable({ keepExtensions: true });\nform.parse(req, async (err, fields, files) => {\nif (err) {\nthrow err;\n}\nconst { key } = fields;\nconst { file } = files;\nconst parsedFile: formidable.File =\nfile instanceof Array ? file[0] : file;\nconst filePath = `${Date.now()}-${parsedFile.originalFilename}`;\nconst convertedFile = fs.readFileSync(parsedFile.filepath);\nconst { error } = await supabase.storage\n.from(key as string)\n.upload(filePath, convertedFile);\nif (error) {\nthrow error;\n}\nreturn res.status(201).json({\nurl: `${BASE_FILE_URL}/${key}/${filePath}`,\n});\n});\n} else if (req.method === 'DELETE') {\nconst { key, fileUrl } = req.query;\nconst storageKey = key as string;\nconst url = fileUrl as string;\nconst filePath = url.substring(url.lastIndexOf('/') + 1);\nconst { error } = await supabase.storage\n.from(storageKey)\n.remove([filePath]);\nif (error) {\nthrow error;\n}\nreturn res.status(200).json({\nmessage: `File ${filePath} has been deleted`,\n});\n}\n} catch (error: unknown) {\nreturn Promise.reject(error);\n}\n}"
"export default function Button({\naddonPosition = 'end',\n'aria-controls': ariaControls,\n'aria-label': ariaLabel,\nclassName,\ndisplay = 'inline',\nhref,\nicon: Icon,\ndisabled = false,\nisLabelHidden = false,\nisLoading = false,\nlabel,\nsize = 'md',\ntype = 'button',\nvariant,\nonClick,\nrel,\ntarget,\n}: Props) {\nconst iconSpacingClass = (() => {\nif (!isLabelHidden && addonPosition === 'start') {\nreturn sizeIconSpacingStartClasses[size];\n}\nif (!isLabelHidden && addonPosition === 'end') {\nreturn sizeIconSpacingEndClasses[size];\n}\n})();\nconst addOnClass = clsx(iconSpacingClass, sizeIconClasses[size]);\nconst addOn = isLoading ? (\n<Spinner className={addOnClass} color=`inherit` size=`xs` />\n) : Icon != null ? (\n<Icon aria-hidden=`true` className={addOnClass} />\n) : null;\nconst children = (\n<>\n{addonPosition === 'start' && addOn}\n{!isLabelHidden && label}\n{addonPosition === 'end' && addOn}\n</>\n);\nconst commonProps = {\n'aria-controls': ariaControls ?? undefined,\n'aria-label': isLabelHidden ? ariaLabel ?? label : undefined,\nchildren,\nclassName: clsx(\ndisplay === 'block' ? 'flex w-full justify-center' : 'inline-flex',\n'whitespace-nowrap items-center border font-medium focus:outline-none focus:ring-2 focus:ring-offset-2',\ndisabled ? variantDisabledClasses[variant] : variantClasses[variant],\ndisabled && 'pointer-events-none',\nisLabelHidden ? iconOnlySizeClasses[size] : sizeClasses[size],\nbaseClasses[size],\nclassName,\n),\ndisabled,\nonClick,\n};\nif (href == null) {\nreturn (\n<button type={type === 'button' ? 'button' : 'submit'} {...commonProps} />\n);\n}\nreturn (\n<Link href={href} rel={rel} target={target} {...commonProps} />\n);\n}"
"function CheckboxInput(\n{\ndefaultValue,\ndescription,\ndisabled = false,\nerrorMessage,\nlabel,\nname,\nvalue,\nonChange,\n}: Props,\nref: ForwardedRef<HTMLInputElement>,\n) {\nconst id = useId();\nconst descriptionId = useId();\nconst errorId = useId();\nreturn (\n<div>\n<div\nclassName={clsx(\n'relative flex',\ndescription == null && 'items-center',\n)}>\n<div className=`flex h-5 items-center`>\n<input\nref={ref}\naria-describedby={description != null ? descriptionId : undefined}\nchecked={value}\nclassName={clsx(\n'h-4 w-4 rounded border-slate-300',\ndisabled\n? 'bg-slate-50 text-slate-400'\n: 'text-primary-600 focus:ring-primary-500',\n)}\ndefaultChecked={defaultValue}\ndisabled={disabled}\nid={id}\nname={name}\ntype=`checkbox`\nonChange={(event) => {\nif (!onChange) {\nreturn;\n}\nonChange(event.target.checked, event);\n}}\n/>\n</div>\n<div className=`ml-3 text-sm`>\n<label\nclassName={clsx(\n'block font-medium',\ndisabled ? 'text-slate-400' : 'text-slate-700',\n)}\nhtmlFor={id}>\n{label}\n</label>\n{description && (\n<p\nclassName={clsx(\n'text-xs',\ndisabled ? 'text-slate-400' : 'text-slate-500',\n)}\nid={descriptionId}>\n{description}\n</p>\n)}\n</div>\n</div>\n{errorMessage && (\n<p className=`text-danger-600 mt-2 text-sm` id={errorId}>\n{errorMessage}\n</p>\n)}\n</div>\n);\n}"
"export default function DropdownMenu({\nalign = 'start',\nchildren,\nlabel,\nsize = 'md',\n}: Props) {\nreturn (\n<Menu as=`div` className=`relative inline-block`>\n<div className=`flex`>\n<Menu.Button\nclassName={clsx(\n'group inline-flex items-center justify-center whitespace-nowrap border border-slate-300 bg-white font-medium text-slate-700 hover:bg-slate-50 focus:outline-none focus:ring-2 focus:ring-slate-600 focus:ring-offset-2',\nbaseClasses[size],\nsizeClasses[size],\n)}>\n<div>{label}</div>\n<ChevronDownIcon\naria-hidden=`true`\nclassName={clsx(\n'flex-shrink-0 text-slate-400 group-hover:text-slate-500',\nsizeIconSpacingEndClasses[size],\nsizeIconClasses[size],\n)}\n/>\n</Menu.Button>\n</div>\n<Transition\nas={Fragment}\nenter=`transition ease-out duration-100`\nenterFrom=`transform opacity-0 scale-95`\nenterTo=`transform opacity-100 scale-100`\nleave=`transition ease-in duration-75`\nleaveFrom=`transform opacity-100 scale-100`\nleaveTo=`transform opacity-0 scale-95`>\n<Menu.Items\nclassName={clsx(\nalignmentClasses[align],\n'ring-primary-500 absolute z-10 mt-2 w-48 rounded-md bg-white shadow-lg ring-1 ring-opacity-5 focus:outline-none',\n)}>\n<div className=`py-1`>{children}</div>\n</Menu.Items>\n</Transition>\n</Menu>\n);\n}"
"export default function RadioList<T>({\nchildren,\ndefaultValue,\ndescription,\nisLabelHidden,\nname,\norientation = 'vertical',\nlabel,\nrequired,\nvalue,\nonChange,\n}: Props<T>) {\nconst labelId = useId();\nreturn (\n<RadioListContext.Provider\nvalue={{ defaultValue, name, onChange, value }}>\n<div>\n<div className={clsx(isLabelHidden ? 'sr-only' : 'mb-2')}>\n<label className=`text-sm font-medium text-gray-900` id={labelId}>\n{label}\n{required && (\n<span aria-hidden=`true` className=`text-danger-500`>\n{' '}\n*\n</span>\n)}\n</label>\n{description && (\n<p className=`text-xs leading-5 text-gray-500`>{description}</p>\n)}\n</div>\n<div\naria-labelledby={labelId}\naria-required={required != null ? required : undefined}\nclassName={clsx(\n'space-y-2',\norientation === 'horizontal' &&\n'sm:flex sm:items-center sm:space-y-0 sm:space-x-10',\n)}\nrole=`radiogroup`>\n{children}\n</div>\n</div>\n</RadioListContext.Provider>\n);\n}"
"export default function RadioListItem<T>({\ndescription,\ndisabled = false,\nlabel,\nvalue,\n}: Props<T>) {\nconst id = useId();\nconst descriptionId = useId();\nconst context = useRadioListContext();\nreturn (\n<div\nclassName={clsx(\n'relative flex',\ndescription == null && 'items-center',\n)}>\n<div className=`flex h-5 items-center`>\n<input\naria-describedby={description != null ? descriptionId : undefined}\nchecked={\ncontext?.value != null ? value === context?.value : undefined\n}\nclassName={clsx(\n'text-primary-600 focus:ring-primary-500 h-4 w-4 border-slate-300',\ndisabled && 'bg-slate-100',\n)}\ndefaultChecked={\ncontext?.defaultValue != null\n? value === context?.defaultValue\n: undefined\n}\ndisabled={disabled}\nid={id}\nname={context?.name}\ntype=`radio`\nonChange={\ncontext?.onChange != null\n? (event) => {\ncontext?.onChange?.(value, event);\n}\n: undefined\n}\n/>\n</div>\n<div className=`ml-3 text-sm`>\n<label\nclassName={clsx(\n'block font-medium',\ndisabled ? 'text-slate-400' : 'text-slate-700',\n)}\nhtmlFor={id}>\n{label}\n</label>\n{description && (\n<p\nclassName={clsx(\n'text-xs',\ndisabled ? 'text-slate-400' : 'text-slate-500',\n)}\nid={descriptionId}>\n{description}\n</p>\n)}\n</div>\n</div>\n);\n}"
"function Select<T>(\n{\nborderStyle = 'bordered',\ndefaultValue,\ndisplay,\ndisabled,\nerrorMessage,\nlabel,\nisLabelHidden,\noptions,\nplaceholder,\nrequired,\nvalue,\nonChange,\n...props\n}: Props<T>,\nref: ForwardedRef<HTMLSelectElement>,\n) {\nconst hasError = errorMessage != null;\nconst id = useId();\nconst errorId = useId();\nconst state: State = hasError ? 'error' : 'normal';\nreturn (\n<div>\n{!isLabelHidden && (\n<label\nclassName={clsx('mb-1 block text-sm font-medium text-slate-700')}\nhtmlFor={id ?? undefined}>\n{label}\n{required && (\n<span aria-hidden=`true` className=`text-danger-500`>\n{' '}\n*\n</span>\n)}\n</label>\n)}\n<select\nref={ref}\naria-describedby={hasError ? errorId : undefined}\naria-label={isLabelHidden ? label : undefined}\nclassName={clsx(\ndisplay === 'block' && 'block w-full',\n'rounded-md py-2 pl-3 pr-8 text-sm focus:outline-none disabled:bg-slate-50 disabled:text-slate-500',\nstateClasses[state],\nborderClasses[borderStyle],\n)}\ndefaultValue={defaultValue != null ? String(defaultValue) : undefined}\ndisabled={disabled}\nid={id}\nrequired={required}\nvalue={value != null ? String(value) : undefined}\nonChange={(event) => {\nonChange?.(event.target.value);\n}}\n{...props}>\n{placeholder && (\n<option disabled={true} hidden={true} selected={true} value=``>\n{placeholder}\n</option>\n)}\n{options.map(({ label: optionLabel, value: optionValue }) => (\n<option key={String(optionValue)} value={String(optionValue)}>\n{optionLabel}\n</option>\n))}\n</select>\n{errorMessage && (\n<p className=`text-danger-600 mt-2 text-sm` id={errorId}>\n{errorMessage}\n</p>\n)}\n</div>\n);\n}"
"export default function SlideOut({\nchildren,\nclassName,\nenterFrom = 'end',\nisShown = false,\nsize,\ntitle,\nonClose,\n}: Props) {\nconst enterFromClass = enterFromClasses[enterFrom];\nreturn (\n<Transition.Root as={Fragment} show={isShown}>\n<Dialog\nas=`div`\nclassName={clsx('relative z-40', className)}\nonClose={() => onClose?.()}>\n<Transition.Child\nas={Fragment}\nenter=`transition-opacity ease-linear duration-300`\nenterFrom=`opacity-0`\nenterTo=`opacity-100`\nleave=`transition-opacity ease-linear duration-300`\nleaveFrom=`opacity-100`\nleaveTo=`opacity-0`>\n<div className=`fixed inset-0 bg-black bg-opacity-25` />\n</Transition.Child>\n<div className=`fixed inset-0 z-40 flex`>\n<Transition.Child\nas={Fragment}\nenter=`transition ease-in-out duration-300 transform`\nenterFrom={enterFromClass.hidden}\nenterTo={enterFromClass.shown}\nleave=`transition ease-in-out duration-300 transform`\nleaveFrom={enterFromClass.shown}\nleaveTo={enterFromClass.hidden}>\n<Dialog.Panel\nclassName={clsx(\n'relative flex h-full w-full max-w-lg flex-col overflow-y-auto bg-white py-4 pb-6 shadow-xl',\nenterFromClass.position,\nsizeClasses[size],\n)}>\n<div className=`flex items-center justify-between px-4`>\n<h2 className=`text-lg font-medium text-slate-900`>{title}</h2>\n<button\nclassName=`focus:ring-primary-500 -mr-2 flex h-10 w-10 items-center justify-center rounded-full p-2 text-slate-400 hover:text-slate-500 focus:outline-none focus:ring-2 focus:ring-inset`\ntype=`button`\nonClick={() => onClose?.()}>\n<span className=`sr-only`>Close menu</span>\n<XMarkIcon aria-hidden=`true` className=`h-6 w-6` />\n</button>\n</div>\n{children}\n</Dialog.Panel>\n</Transition.Child>\n</div>\n</Dialog>\n</Transition.Root>\n);\n}"
"export default function Tabs<T>({ label, tabs, value, onChange }: Props<T>) {\nreturn (\n<div className=`w-full`>\n<div role=`tablist`>\n<nav aria-label={label} className=`flex space-x-2`>\n{tabs.map((tab) => {\nconst isSelected = tab.value === value;\nconst commonProps = {\n'aria-label': tab.label,\n'aria-selected': isSelected,\nchildren: tab.label,\nclassName: clsx(\nisSelected\n? 'bg-primary-100 text-primary-700'\n: 'hover:bg-slate-100 text-slate-500 hover:text-slate-700',\n'px-3 py-2 font-medium text-sm rounded-md',\n),\nonClick: onChange != null ? () => onChange(tab.value) : undefined,\nrole: 'tab',\n};\nif (tab.href != null) {\nreturn (\n<Link\nkey={String(tab.value)}\nhref={tab.href}\n{...commonProps}\n/>\n);\n}\nreturn (\n<button key={String(tab.value)} type=`button` {...commonProps} />\n);\n})}\n</nav>\n</div>\n</div>\n);\n}"
"function TextArea(\n{\ndefaultValue,\ndescription,\ndisabled,\nerrorMessage,\nid: idParam,\nisLabelHidden,\nlabel,\nresize = 'vertical',\nrequired,\nvalue,\nonChange,\n...props\n}: Props,\nref: ForwardedRef<HTMLTextAreaElement>,\n) {\nconst hasError = errorMessage != null;\nconst generatedId = useId();\nconst id = idParam ?? generatedId;\nconst messageId = useId();\nconst state: State = hasError ? 'error' : 'normal';\nreturn (\n<div>\n<label\nclassName={clsx(\nisLabelHidden\n? 'sr-only'\n: 'mb-1 block text-sm font-medium text-gray-700',\n)}\nhtmlFor={id}>\n{label}\n{required && (\n<span aria-hidden=`true` className=`text-danger-500`>\n{' '}\n*\n</span>\n)}\n</label>\n<div>\n<textarea\nref={ref}\naria-describedby={\nhasError || description != null ? messageId : undefined\n}\naria-invalid={hasError ? true : undefined}\nclassName={clsx(\n'block w-full rounded-md text-sm disabled:bg-slate-50 disabled:text-slate-500',\nstateClasses[state].textArea,\nresizeClasses[resize],\n)}\ndefaultValue={defaultValue}\ndisabled={disabled}\nid={id}\nname=`comment`\nrequired={required}\nvalue={value != null ? value : undefined}\nonChange={(event) => {\nif (!onChange) {\nreturn;\n}\nonChange(event.target.value, event);\n}}\n{...props}\n/>\n</div>\n{(errorMessage ?? description) && (\n<p\nclassName={clsx(\n'mt-2 text-sm',\nerrorMessage ? 'text-danger-600' : 'text-slate-500',\n)}\nid={messageId}>\n{errorMessage ?? description}\n</p>\n)}\n</div>\n);\n}"
"export default function Toast({\nduration = DEFAULT_DURATION,\ntitle,\nsubtitle,\nvariant,\nonClose,\n}: Props) {\nconst timer = useRef<number | null>(null);\nfunction clearTimer() {\nif (timer.current == null) {\nreturn;\n}\nwindow.clearTimeout(timer.current);\ntimer.current = null;\n}\nfunction close() {\nonClose();\nclearTimer();\n}\nuseEffect(() => {\ntimer.current = window.setTimeout(() => {\nclose();\n}, duration);\nreturn () => {\nclearTimer();\n};\n}, []);\nreturn (\n<Transition\nas={Fragment}\nenter=`transform ease-out duration-300 transition`\nenterFrom=`translate-y-2 opacity-0 sm:translate-y-2 sm:translate-x-2`\nenterTo=`translate-y-0 opacity-100 sm:translate-x-0`\nleave=`transition ease-in duration-100`\nleaveFrom=`opacity-100`\nleaveTo=`opacity-0`\nshow={true}>\n<div className=`pointer-events-auto w-full max-w-sm overflow-hidden rounded-lg bg-white shadow-lg ring-1 ring-black ring-opacity-5`>\n<div className=`p-4`>\n<div className=`flex items-start`>\n<div className=`flex-shrink-0`>\n<ToastIcon variant={variant} />\n</div>\n<div className=`ml-3 w-0 flex-1 space-y-1 pt-0.5`>\n<p className=`text-sm font-medium text-slate-900`>{title}</p>\n{subtitle && (\n<p className=`mt-1 text-sm text-slate-500`>{subtitle}</p>\n)}\n</div>\n<div className=`ml-4 flex flex-shrink-0`>\n<button\nclassName=`focus:ring-brand-500 inline-flex rounded-md bg-white text-slate-400 hover:text-slate-500 focus:outline-none focus:ring-2 focus:ring-offset-2`\ntype=`button`\nonClick={close}>\n<span className=`sr-only`>Close</span>\n<XMarkIcon aria-hidden=`true` className=`h-5 w-5` />\n</button>\n</div>\n</div>\n</div>\n</div>\n</Transition>\n);\n}"
"export default function OffersHeader({\nheader,\nisLastColumn,\nonSort,\nsortDirection,\nsortType,\n}: OffersTableHeaderProps) {\nreturn (\n<th\nkey={header}\nclassName={clsx(\n'bg-slate-100 py-3 px-4',\nsortType &&\n'hover:cursor-pointer hover:bg-slate-200 active:bg-slate-300',\nheader !== 'Company' && 'whitespace-nowrap',\n(sortDirection === OFFER_TABLE_SORT_ORDER.ASC ||\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC) &&\n'text-primary-600',\nisLastColumn && 'sticky right-0 drop-shadow md:drop-shadow-none',\n)}\nscope=`col`\nonClick={\nonSort &&\nsortType &&\n(() => {\nonSort(\nsortDirection\n? getOppositeSortOrder(sortDirection)\n: OFFER_TABLE_SORT_ORDER.ASC,\nsortType,\n);\n})\n}>\n<div className=`my-auto flex items-center justify-start`>\n{header}\n{onSort && sortType && (\n<span className=`ml-2 grid grid-cols-1 space-y-0 text-[9px] text-gray-300`>\n<div\nclassName={clsx(\n'-mb-2 flex items-end sm:-mb-3',\nsortDirection === OFFER_TABLE_SORT_ORDER.ASC &&\n'text-primary-500',\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC &&\n'text-slate-200',\n)}>\n▲\n</div>\n<div\nclassName={clsx(\n'-mb-3 flex items-end',\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC &&\n'text-primary-500',\nsortDirection === OFFER_TABLE_SORT_ORDER.ASC &&\n'text-slate-200',\n)}>\n▼\n</div>\n</span>\n)}\n</div>\n</th>\n);\n}"
"export default function OfferTableRow({\njobType,\nrow: {\nbaseSalary,\nbonus,\ncompany,\nid,\nincome,\nlocation,\nmonthYearReceived,\nnumberOfOtherOffers,\nprofileId,\nstocks,\ntitle,\ntotalYoe,\ntoken,\n},\n}: OfferTableRowProps) {\nreturn (\n<tr key={id} className=`divide-x divide-slate-200 border-b bg-white`>\n<td className=`space-y-0.5 py-4 px-4` scope=`row`>\n<div className=`font-medium`>{company.name}</div>\n<div className=`text-xs text-slate-500`>\n{location.cityName} ({location.countryCode})\n</div>\n</td>\n<td className=`py-4 px-4`>\n{getLabelForJobTitleType(title as JobTitleType)}\n</td>\n<td className=`py-4 px-4`>{totalYoe}</td>\n<td className=`py-4 px-4`>{convertMoneyToString(income)}</td>\n{jobType === JobType.FULLTIME && (\n<td className=`py-4 px-4`>\n{`${convertMoneyToString(baseSalary)} / ${convertMoneyToString(\nbonus,\n)} / ${convertMoneyToString(stocks)}`}\n</td>\n)}\n<td className=`py-4 px-4`>{formatDate(monthYearReceived)}</td>\n<td\nclassName={clsx(\n'sticky right-0 bg-white px-4 py-4 drop-shadow lg:drop-shadow-none',\n)}>\n<Link\nclassName=`text-primary-600 dark:text-primary-500 font-medium hover:underline`\nhref={`/offers/profile/${profileId}?token=${token}`}>\nView Editable Profile\n</Link>\n{numberOfOtherOffers > 0 && (\n<div className=`text-xs text-slate-500`>\nThis person also received {numberOfOtherOffers} other offer(s).\n</div>\n)}\n</td>\n</tr>\n);\n}"
"export default function OffersTablePagination({\nisInitialFetch,\nisLoading,\nendNumber,\npagination,\nstartNumber,\nhandlePageChange,\n}: OffersTablePaginationProps) {\nconst [screenWidth, setScreenWidth] = useState(0);\nuseEffect(() => {\nsetScreenWidth(window.innerWidth);\n}, []);\nreturn (\n<nav aria-label=`Offers Pagination` className=`py-3 px-4`>\n<div className=`grid grid-cols-1 items-center gap-2 md:grid-cols-2`>\n<div>\n{!isInitialFetch && (\n<div className=`flex items-center space-x-2`>\n<div className=`text-sm text-slate-500`>\nShowing\n<span className=`font-semibold text-slate-900`>\n{` ${endNumber > 0 ? startNumber : 0} - ${endNumber} `}\n</span>\n{`of `}\n<span className=`font-semibold text-slate-900`>\n{pagination.totalItems}\n</span>{' '}\nresults\n</div>\n{isLoading && <Spinner size=`xs` />}\n</div>\n)}\n</div>\n<div className=`flex md:justify-end`>\n<Pagination\ncurrent={pagination.currentPage + 1}\nend={pagination.numOfPages}\nlabel=`Pagination`\npagePadding={screenWidth > 500 ? 2 : 0}\nstart={1}\nonSelect={(currPage) => {\nhandlePageChange(currPage - 1);\n}}\n/>\n</div>\n</div>\n</nav>\n);\n}"
"export default function LeftTextCard({\ndescription,\nicon,\nimageAlt,\nimageSrc,\ntitle,\nbuttonLabel,\nurl,\n}: LeftTextCardProps) {\nreturn (\n<div className=`items-center lg:mx-auto lg:grid lg:max-w-7xl lg:grid-flow-col-dense lg:grid-cols-2 lg:gap-24 lg:px-8`>\n<div className=`mx-auto max-w-xl px-4 sm:px-6 lg:mx-0 lg:max-w-none lg:py-16 lg:px-0`>\n<div>\n<div>\n<span className=`to-primary-500 flex h-12 w-12 items-center justify-center rounded-md bg-gradient-to-r from-purple-600`>\n{icon}\n</span>\n</div>\n<div className=`mt-6`>\n<h2 className=`text-3xl font-bold tracking-tight text-gray-900`>\n{title}\n</h2>\n<p className=`mt-4 text-lg text-gray-500`>{description}</p>\n<div className=`mt-6`>\n<a\nclassName=`to-primary-500 inline-flex rounded-md border border-transparent bg-gradient-to-r from-purple-600 bg-origin-border px-4 py-2 text-base font-medium text-white shadow-sm hover:from-purple-700 hover:to-indigo-700`\nhref={url}>\n{buttonLabel}\n</a>\n</div>\n</div>\n</div>\n</div>\n<div className=`mt-12 sm:mt-16 lg:mt-0`>\n<div className=`-mr-48 w-full rounded-xl shadow-xl ring-1 ring-black ring-opacity-5 md:-mr-16 lg:relative lg:m-0 lg:h-full lg:px-0`>\n<Image\nalt={imageAlt}\nclassName=`lg:absolute lg:left-0 lg:h-full lg:w-auto lg:max-w-none`\nsrc={imageSrc}\n/>\n</div>\n</div>\n</div>\n);\n}"
"export default function RightTextCard({\ndescription,\nicon,\nimageAlt,\nimageSrc,\ntitle,\nurl,\nbuttonLabel,\n}: RightTextCarddProps) {\nreturn (\n<div className=`items-center lg:mx-auto lg:grid lg:max-w-7xl lg:grid-flow-col-dense lg:grid-cols-2 lg:gap-24 lg:px-8`>\n<div className=`mx-auto max-w-xl px-4 sm:px-6 lg:col-start-2 lg:mx-0 lg:max-w-none lg:py-32 lg:px-0`>\n<div>\n<div>\n<span className=`to-primary-500 flex h-12 w-12 items-center justify-center rounded-md bg-gradient-to-r from-purple-600`>\n{icon}\n</span>\n</div>\n<div className=`mt-6`>\n<h2 className=`text-3xl font-bold tracking-tight text-gray-900`>\n{title}\n</h2>\n<p className=`mt-4 text-lg text-gray-500`>{description}</p>\n<div className=`mt-6`>\n<a\nclassName=`to-primary-500 inline-flex rounded-md border border-transparent bg-gradient-to-r from-purple-600 bg-origin-border px-4 py-2 text-base font-medium text-white shadow-sm hover:from-purple-700 hover:to-indigo-700`\nhref={url}>\n{buttonLabel}\n</a>\n</div>\n</div>\n</div>\n</div>\n<div className=`mt-12 sm:mt-16 lg:col-start-1 lg:mt-0`>\n<div className=`w-full rounded-xl shadow-xl ring-1 ring-black ring-opacity-5 lg:relative lg:m-0 lg:h-full lg:px-0`>\n<Image\nalt={imageAlt}\nclassName=`lg:absolute lg:right-0 lg:h-full lg:w-auto lg:max-w-none`\nsrc={imageSrc}\n/>\n</div>\n</div>\n</div>\n);\n}"
"export default function OfferAnalysis({\nallAnalysis,\nisError,\nisLoading,\nisSubmission = false,\n}: OfferAnalysisProps) {\nconst [tab, setTab] = useState(OVERALL_TAB);\nconst [analysis, setAnalysis] = useState<AnalysisUnit>(\nallAnalysis.overallAnalysis,\n);\nuseEffect(() => {\nif (tab === OVERALL_TAB) {\nsetAnalysis(allAnalysis.overallAnalysis);\n} else {\nsetAnalysis(allAnalysis.companyAnalysis[parseInt(tab, 10)]);\n}\n}, [tab, allAnalysis]);\nconst companyTabs = allAnalysis.companyAnalysis.map((value, index) => ({\nlabel: value.companyName,\nvalue: `${index}`,\n}));\nlet tabOptions = [\n{\nlabel: OVERALL_TAB,\nvalue: OVERALL_TAB,\n},\n];\ntabOptions = tabOptions.concat(companyTabs);\nreturn (\n<div>\n{isError ? (\n<p className=`m-10 text-center`>\nAn error occurred while generating profile analysis.\n</p>\n) : isLoading ? (\n<Spinner className=`m-10` display=`block` size=`lg` />\n) : (\n<div>\n<Tabs\nlabel=`Result Navigation`\ntabs={tabOptions}\nvalue={tab}\nonChange={setTab}\n/>\n<HorizontalDivider className=`mb-5` />\n<OfferAnalysisContent\nanalysis={analysis}\nisSubmission={isSubmission}\ntab={tab}\n/>\n</div>\n)}\n</div>\n);\n}"
"function ProfileAnalysis({\nanalysis: profileAnalysis,\nprofileId,\nisEditable,\n}: ProfileAnalysisProps) {\nconst [analysis, setAnalysis] = useState(profileAnalysis);\nconst generateAnalysisMutation = trpc.useMutation(\n['offers.analysis.generate'],\n{\nonError(error) {\nconsole.error(error.message);\n},\nonSuccess(data) {\nif (data) {\nsetAnalysis(data);\n}\n},\n},\n);\nif (generateAnalysisMutation.isLoading) {\nreturn (\n<div className=`col-span-10 pt-4`>\n<Spinner display=`block` size=`lg` />\n</div>\n);\n}\nreturn (\n<div className=`space-y-4 p-4`>\n{!analysis ? (\n<div className=`flex items-center justify-center p-4 text-slate-500`>\n<p>This profile has no analysis yet.</p>\n</div>\n) : (\n<OfferAnalysis\nallAnalysis={analysis}\nisError={false}\nisLoading={false}\n/>\n)}\n{isEditable && (\n<div className=`flex justify-end`>\n<Button\nicon={ArrowPathIcon}\nlabel=`Regenerate analysis`\nvariant=`secondary`\nonClick={() => generateAnalysisMutation.mutate({ profileId })}\n/>\n</div>\n)}\n<div className=`text-end`>\n<a\nclassName=`text-xs text-slate-500`\nhref=`https:\nrel=`noreferrer`\ntarget=`_blank`>\nLogos provided by Clearbit\n</a>\n</div>\n</div>\n);\n}"
"export default function OffersHeader({\nheader,\nisLastColumn,\nonSort,\nsortDirection,\nsortType,\n}: OffersTableHeaderProps) {\nreturn (\n<th\nkey={header}\nclassName={clsx(\n'bg-slate-100 py-3 px-4',\nsortType &&\n'hover:cursor-pointer hover:bg-slate-200 active:bg-slate-300',\nheader !== 'Company' && 'whitespace-nowrap',\n(sortDirection === OFFER_TABLE_SORT_ORDER.ASC ||\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC) &&\n'text-primary-600',\nisLastColumn && 'sticky right-0 drop-shadow md:drop-shadow-none',\n)}\nscope=`col`\nonClick={\nonSort &&\nsortType &&\n(() => {\nonSort(\nsortDirection\n? getOppositeSortOrder(sortDirection)\n: OFFER_TABLE_SORT_ORDER.ASC,\nsortType,\n);\n})\n}>\n<div className=`my-auto flex items-center justify-start`>\n{header}\n{onSort && sortType && (\n<span className=`ml-2 grid grid-cols-1 space-y-0 text-[9px] text-gray-300`>\n<div\nclassName={clsx(\n'-mb-2 flex items-end sm:-mb-3',\nsortDirection === OFFER_TABLE_SORT_ORDER.ASC &&\n'text-primary-500',\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC &&\n'text-slate-200',\n)}>\n▲\n</div>\n<div\nclassName={clsx(\n'-mb-3 flex items-end',\nsortDirection === OFFER_TABLE_SORT_ORDER.DESC &&\n'text-primary-500',\nsortDirection === OFFER_TABLE_SORT_ORDER.ASC &&\n'text-slate-200',\n)}>\n▼\n</div>\n</span>\n)}\n</div>\n</th>\n);\n}"
"export default function OfferTableRow({\njobType,\nrow: {\nbaseSalary,\nbonus,\ncompany,\nid,\nincome,\nlocation,\nmonthYearReceived,\nnumberOfOtherOffers,\nprofileId,\nstocks,\ntitle,\ntotalYoe,\n},\n}: OfferTableRowProps) {\nreturn (\n<tr key={id} className=`divide-x divide-slate-200 border-b bg-white`>\n<td className=`flex items-center gap-3 space-y-0.5 py-2 px-4` scope=`row`>\n<CompanyProfileImage\nalt={company.name}\nclassName=`hidden h-6 w-6 object-contain sm:block`\nsrc={company.logoUrl}\n/>\n<div>\n<div className=`line-clamp-2 sm:line-clamp-1 font-medium`>\n{company.name}\n</div>\n<div className=`text-xs text-slate-500`>\n{location.cityName} ({location.countryCode})\n</div>\n</div>\n</td>\n<td className=`py-2 px-4`>\n{getLabelForJobTitleType(title as JobTitleType)}\n</td>\n<td className=`py-2 px-4`>{totalYoe}</td>\n<td className=`py-2 px-4`>{convertMoneyToString(income)}</td>\n{jobType === JobType.FULLTIME && (\n<td className=`py-2 px-4`>\n{`${convertMoneyToString(baseSalary)} / ${convertMoneyToString(\nbonus,\n)} / ${convertMoneyToString(stocks)}`}\n</td>\n)}\n<td className=`py-2 px-4`>{formatDate(monthYearReceived)}</td>\n<td\nclassName={clsx(\n'sticky right-0 bg-white px-4 py-2 drop-shadow lg:drop-shadow-none',\n)}>\n<Link\nclassName=`text-primary-600 dark:text-primary-500 font-medium hover:underline`\nhref={`/offers/profile/${profileId}`}>\nView Profile\n</Link>\n{numberOfOtherOffers > 0 && (\n<div className=`text-xs text-slate-500`>\nThis person also received {numberOfOtherOffers} other offer(s).\n</div>\n)}\n</td>\n</tr>\n);\n}"
"export default function OffersTablePagination({\nisInitialFetch,\nisLoading,\nendNumber,\npagination,\nstartNumber,\nhandlePageChange,\n}: OffersTablePaginationProps) {\nconst [screenWidth, setScreenWidth] = useState(0);\nuseEffect(() => {\nsetScreenWidth(window.innerWidth);\n}, []);\nreturn (\n<nav aria-label=`Offers Pagination` className=`py-3 px-4`>\n<div className=`grid grid-cols-1 items-center gap-2 md:grid-cols-2`>\n<div>\n{!isInitialFetch && (\n<div className=`flex items-center space-x-2`>\n<div className=`text-sm text-slate-500`>\nShowing\n<span className=`font-semibold text-slate-900`>\n{` ${endNumber > 0 ? startNumber : 0} - ${endNumber} `}\n</span>\n{`of `}\n<span className=`font-semibold text-slate-900`>\n{pagination.totalItems}\n</span>{' '}\nresults\n</div>\n{isLoading && <Spinner size=`xs` />}\n</div>\n)}\n</div>\n<div className=`flex md:justify-end`>\n<Pagination\ncurrent={pagination.currentPage + 1}\nend={pagination.numOfPages}\nlabel=`Pagination`\npagePadding={screenWidth > 500 ? 2 : 0}\nstart={1}\nonSelect={(currPage) => {\nhandlePageChange(currPage - 1);\n}}\n/>\n</div>\n</div>\n</nav>\n);\n}"
"export default function AnswerCard({\nanswerId,\nauthorName,\nauthorImageUrl,\ncontent,\ncreatedAt,\ncommentCount,\nvotingButtonsSize,\nupvoteCount,\nshowHover,\n}: AnswerCardProps) {\nconst { handleUpvote, handleDownvote, vote } = useAnswerVote(answerId);\nreturn (\n<article\nclassName={clsx(\n'flex gap-4 rounded-md border border-slate-200 bg-white p-4 sm:rounded-lg',\nshowHover && 'hover:bg-slate-50',\n)}>\n<VotingButtons\nsize={votingButtonsSize}\nupvoteCount={upvoteCount}\nvote={vote}\nonDownvote={handleDownvote}\nonUpvote={handleUpvote}\n/>\n<div className=`flex w-full flex-col gap-2`>\n<div className=`flex items-center gap-2`>\n<img\nalt={authorName}\nclassName=`h-7 w-7 rounded-full`\nsrc={authorImageUrl}\n/>\n<p className=`text-sm font-medium text-slate-900`>{authorName}</p>\n<span className=`font-medium text-slate-500`>·</span>\n<p className=`text-xs text-slate-500`>\n{formatDistanceToNow(createdAt, {\naddSuffix: true,\n})}\n</p>\n</div>\n<p className=`whitespace-pre-wrap text-xs sm:text-sm`>{content}</p>\n<div className=`-ml-2`>\n{commentCount !== undefined && (\n<button\nclassName=`-my-1 flex items-center rounded-md px-2\npy-1 text-xs font-medium\ntext-slate-500 hover:bg-slate-100 hover:text-slate-600`\ntype=`button`>\n<ChatBubbleLeftRightIcon\naria-hidden={true}\nclassName=`mr-2 h-5 w-5`\n/>\n{commentCount} {commentCount === 1 ? 'comment' : 'comments'}\n</button>\n)}\n</div>\n</div>\n</article>\n);\n}"
"export default function ExpandedTypeahead({\nsuggestedCount = 0,\nonSuggestionClick,\nsuggestedOptions = [],\nfilterOption = () => true,\nclearOnSelect = false,\noptions,\nonSelect,\nonChange: _,\n...typeaheadProps\n}: ExpandedTypeaheadProps) {\nconst [key, setKey] = useState(0);\nconst filteredOptions = useMemo(() => {\nreturn options.filter(filterOption);\n}, [options, filterOption]);\nconst suggestions = useMemo(\n() => suggestedOptions.slice(0, suggestedCount),\n[suggestedOptions, suggestedCount],\n);\nreturn (\n<div className=`flex flex-wrap items-center gap-2`>\n{suggestions.map((suggestion) => (\n<div key={suggestion.id} className=`hidden lg:block`>\n<Button\nlabel={suggestion.label}\nsize=`sm`\nvariant=`tertiary`\nonClick={() => {\nonSuggestionClick?.(suggestion);\n}}\n/>\n</div>\n))}\n<div className=`flex-1`>\n<Typeahead\nkey={key}\noptions={filteredOptions}\n{...typeaheadProps}\nonSelect={(option) => {\nif (clearOnSelect) {\nsetKey((key + 1) % 2);\n}\nonSelect(option);\n}}\n/>\n</div>\n</div>\n);\n}"
"export default function ResumeUserBadges({ userId }: Props) {\nconst userReviewedResumeCountQuery = trpc.useQuery(\n['resumes.resume.findUserReviewedResumeCount', { userId }],\n{\nretry: false,\nstaleTime: STALE_TIME,\n},\n);\nconst userMaxResumeUpvoteCountQuery = trpc.useQuery(\n['resumes.resume.findUserMaxResumeUpvoteCount', { userId }],\n{\nretry: false,\nstaleTime: STALE_TIME,\n},\n);\nconst userTopUpvotedCommentCountQuery = trpc.useQuery(\n['resumes.resume.findUserTopUpvotedCommentCount', { userId }],\n{\nretry: false,\nstaleTime: STALE_TIME,\n},\n);\nconst payload: BadgePayload = {\nmaxResumeUpvoteCount: userMaxResumeUpvoteCountQuery.data ?? 0,\nreviewedResumesCount: userReviewedResumeCountQuery.data ?? 0,\ntopUpvotedCommentCount: userTopUpvotedCommentCountQuery.data ?? 0,\n};\nconst badges = RESUME_USER_BADGES.filter((badge) => badge.isValid(payload));\nif (badges.length === 0) {\nreturn null;\n}\nreturn (\n<div className=`flex items-center justify-center gap-1`>\n{badges.map((badge) => (\n<ResumeUserBadge\nkey={badge.id}\ndescription={badge.description}\nicon={badge.icon}\ntitle={badge.title}\n/>\n))}\n</div>\n);\n}"
"async resolve({ ctx, input }) {\nconst profile = await ctx.prisma.offersProfile.findFirst({\nwhere: {\nid: input.profileId,\n},\n});\nconst result = await ctx.prisma.offersProfile.findFirst({\ninclude: {\ndiscussion: {\ninclude: {\nreplies: {\ninclude: {\nuser: true,\n},\norderBy: {\ncreatedAt: 'desc',\n},\n},\nreplyingTo: true,\nuser: true,\n},\norderBy: {\ncreatedAt: 'desc',\n},\n},\n},\nwhere: {\nid: input.profileId,\n},\n});\nconst discussions: OffersDiscussion = {\ndata:\nresult?.discussion\n.filter((x) => {\nreturn x.replyingToId === null;\n})\n.map((x) => {\nif (x.user == null) {\nx.user = {\nemail: '',\nemailVerified: null,\nid: '',\nimage: '',\nname: profile?.profileName ?? '<missing name>',\n};\n}\nx.replies?.map((y) => {\nif (y.user == null) {\ny.user = {\nemail: '',\nemailVerified: null,\nid: '',\nimage: '',\nname: profile?.profileName ?? '<missing name>',\n};\n}\n});\nconst replyType: Reply = {\ncreatedAt: x.createdAt,\nid: x.id,\nmessage: x.message,\nreplies: x.replies.map((reply) => {\nreturn {\ncreatedAt: reply.createdAt,\nid: reply.id,\nmessage: reply.message,\nreplies: [],\nreplyingToId: reply.replyingToId,\nuser: reply.user,\n};\n}),\nreplyingToId: x.replyingToId,\nuser: x.user,\n};\nreturn replyType;\n}) ?? [],\n};\nreturn discussions;\n},"
"async resolve({ ctx, input }) {\nconst profile = await ctx.prisma.offersProfile.findFirst({\nwhere: {\nid: input.profileId,\n},\n});\nconst profileEditToken = profile?.editToken;\nif (input.token === profileEditToken || input.userId) {\nconst createdReply = await ctx.prisma.offersReply.create({\ndata: {\nmessage: input.message,\nprofile: {\nconnect: {\nid: input.profileId,\n},\n},\n},\n});\nif (input.replyingToId) {\nawait ctx.prisma.offersReply.update({\ndata: {\nreplyingTo: {\nconnect: {\nid: input.replyingToId,\n},\n},\n},\nwhere: {\nid: createdReply.id,\n},\n});\n}\nif (input.userId) {\nawait ctx.prisma.offersReply.update({\ndata: {\nuser: {\nconnect: {\nid: input.userId,\n},\n},\n},\nwhere: {\nid: createdReply.id,\n},\n});\n}\nconst created = await ctx.prisma.offersReply.findFirst({\ninclude: {\nuser: true,\n},\nwhere: {\nid: createdReply.id,\n},\n});\nconst result: Reply = {\ncreatedAt: created!.createdAt,\nid: created!.id,\nmessage: created!.message,\nreplies: [],\nreplyingToId: created!.replyingToId,\nuser: created!.user ?? {\nemail: '',\nemailVerified: null,\nid: '',\nimage: '',\nname: profile?.profileName ?? '<missing name>',\n},\n};\nreturn result;\n}\nthrow new trpc.TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'Missing userId or wrong token.',\n});\n},"
"async resolve({ ctx, input }) {\nconst messageToUpdate = await ctx.prisma.offersReply.findFirst({\nwhere: {\nid: input.id,\n},\n});\nconst profile = await ctx.prisma.offersProfile.findFirst({\nwhere: {\nid: input.profileId,\n},\n});\nconst profileEditToken = profile?.editToken;\nif (\nprofileEditToken === input.token ||\nmessageToUpdate?.userId === input.userId\n) {\nconst updated = await ctx.prisma.offersReply.update({\ndata: {\nmessage: input.message,\n},\ninclude: {\nreplies: {\ninclude: {\nuser: true,\n},\n},\nuser: true,\n},\nwhere: {\nid: input.id,\n},\n});\nconst result: Reply = {\ncreatedAt: updated!.createdAt,\nid: updated!.id,\nmessage: updated!.message,\nreplies: updated!.replies.map((x) => {\nreturn {\ncreatedAt: x.createdAt,\nid: x.id,\nmessage: x.message,\nreplies: [],\nreplyingToId: x.replyingToId,\nuser: x.user ?? {\nemail: '',\nemailVerified: null,\nid: '',\nimage: '',\nname: profile?.profileName ?? '<missing name>',\n},\n};\n}),\nreplyingToId: updated!.replyingToId,\nuser: updated!.user ?? {\nemail: '',\nemailVerified: null,\nid: '',\nimage: '',\nname: profile?.profileName ?? '<missing name>',\n},\n};\nreturn result;\n}\nthrow new trpc.TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'Wrong userId or token.',\n});\n},"
"async resolve({ ctx, input }) {\nconst messageToDelete = await ctx.prisma.offersReply.findFirst({\nwhere: {\nid: input.id,\n},\n});\nconst profile = await ctx.prisma.offersProfile.findFirst({\nwhere: {\nid: input.profileId,\n},\n});\nconst profileEditToken = profile?.editToken;\nif (\nprofileEditToken === input.token ||\nmessageToDelete?.userId === input.userId\n) {\nawait ctx.prisma.offersReply.delete({\nwhere: {\nid: input.id,\n},\n});\nawait ctx.prisma.offersProfile.findFirst({\ninclude: {\ndiscussion: {\ninclude: {\nreplies: true,\nreplyingTo: true,\nuser: true,\n},\n},\n},\nwhere: {\nid: input.profileId,\n},\n});\n} else {\nthrow new trpc.TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'Wrong userId or token.',\n});\n}\n},"
"async resolve({ ctx, input }) {\nconst result = await ctx.prisma.offersProfile.findFirst({\ninclude: {\nanalysis: {\ninclude: analysisInclusion,\n},\nbackground: {\ninclude: {\neducations: true,\nexperiences: {\ninclude: {\ncompany: true,\nlocation: {\ninclude: {\nstate: {\ninclude: {\ncountry: true,\n},\n},\n},\n},\nmonthlySalary: true,\ntotalCompensation: true,\n},\n},\nspecificYoes: true,\n},\n},\ndiscussion: {\ninclude: {\nreplies: true,\nreplyingTo: true,\nuser: true,\n},\n},\noffers: {\ninclude: {\ncompany: true,\nlocation: {\ninclude: {\nstate: {\ninclude: {\ncountry: true,\n},\n},\n},\n},\noffersFullTime: {\ninclude: {\nbaseSalary: true,\nbonus: true,\nstocks: true,\ntotalCompensation: true,\n},\n},\noffersIntern: {\ninclude: {\nmonthlySalary: true,\n},\n},\n},\n},\nusers: true,\n},\nwhere: {\nid: input.profileId,\n},\n});\nif (result) {\nreturn profileDtoMapper(result, input.token, input.userId);\n}\nthrow new trpc.TRPCError({\ncode: 'NOT_FOUND',\nmessage: 'Profile does not exist',\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session.user.id;\nconst profiles = await ctx.prisma.user.findFirst({\ninclude: {\nOffersProfile: true,\n},\nwhere: {\nid: userId,\n},\n});\nlet doesProfileExist = false;\nif (profiles?.OffersProfile) {\nfor (let i = 0; i < profiles.OffersProfile.length; i++) {\nif (profiles.OffersProfile[i].id === input.profileId) {\ndoesProfileExist = true;\n}\n}\n}\nif (!doesProfileExist) {\nthrow new TRPCError({\ncode: 'NOT_FOUND',\nmessage: 'No such profile id saved.',\n});\n}\nawait ctx.prisma.user.update({\ndata: {\nOffersProfile: {\ndisconnect: [\n{\nid: input.profileId,\n},\n],\n},\n},\nwhere: {\nid: userId,\n},\n});\n},"
"async resolve({ ctx, input }) {\nconst { answerId, cursor } = input;\nconst sortCondition =\ninput.sortType === SortType.TOP\n? [\n{\nupvotes: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n]\n: [\n{\nupdatedAt: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n];\nconst questionAnswerCommentsData =\nawait ctx.prisma.questionsAnswerComment.findMany({\ncursor: cursor ? { id: cursor } : undefined,\ninclude: {\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\nvotes: true,\n},\norderBy: sortCondition,\ntake: input.limit + 1,\nwhere: {\nanswerId,\n},\n});\nconst processedQuestionAnswerCommentsData =\nquestionAnswerCommentsData.map((data) => {\nconst votes: number = data.votes.reduce(\n(previousValue: number, currentValue) => {\nlet result: number = previousValue;\nswitch (currentValue.vote) {\ncase Vote.UPVOTE:\nresult += 1;\nbreak;\ncase Vote.DOWNVOTE:\nresult -= 1;\nbreak;\n}\nreturn result;\n},\n0,\n);\nconst answerComment: AnswerComment = {\ncontent: data.content,\ncreatedAt: data.createdAt,\nid: data.id,\nnumVotes: votes,\nupdatedAt: data.updatedAt,\nuser: data.user?.name ?? '',\nuserImage: data.user?.image ?? '',\n};\nreturn answerComment;\n});\nlet nextCursor: typeof cursor | undefined = undefined;\nif (questionAnswerCommentsData.length > input.limit) {\nconst nextItem = questionAnswerCommentsData.pop()!;\nprocessedQuestionAnswerCommentsData.pop();\nconst nextIdCursor: string | undefined = nextItem.id;\nnextCursor = nextIdCursor;\n}\nreturn {\ndata: processedQuestionAnswerCommentsData,\nnextCursor,\n};\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerCommentToUpdate =\nawait tx.questionsAnswerComment.findUnique({\nwhere: {\nid: answerCommentId,\n},\n});\nif (answerCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer Comment do not exist.',\n});\n}\nconst vote = await tx.questionsAnswerCommentVote.findUnique({\nwhere: {\nanswerCommentId_userId: { answerCommentId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsAnswerCommentVote.create({\ndata: {\nanswerCommentId,\nuserId,\nvote: Vote.UPVOTE,\n},\n});\nawait tx.questionsAnswerComment.update({\ndata: {\nupvotes: {\nincrement: 1,\n},\n},\nwhere: {\nid: answerCommentId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.UPVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.DOWNVOTE) {\nconst updatedVote = await tx.questionsAnswerCommentVote.update({\ndata: {\nanswerCommentId,\nuserId,\nvote: Vote.UPVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsAnswerComment.update({\ndata: {\nupvotes: {\nincrement: 2,\n},\n},\nwhere: {\nid: answerCommentId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerCommentToUpdate =\nawait tx.questionsAnswerComment.findUnique({\nwhere: {\nid: answerCommentId,\n},\n});\nif (answerCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer Comment do not exist.',\n});\n}\nconst vote = await tx.questionsAnswerCommentVote.findUnique({\nwhere: {\nanswerCommentId_userId: { answerCommentId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsAnswerCommentVote.create({\ndata: {\nanswerCommentId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\n});\nawait tx.questionsAnswerComment.update({\ndata: {\nupvotes: {\nincrement: -1,\n},\n},\nwhere: {\nid: answerCommentId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.DOWNVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.UPVOTE) {\nconst updatedVote = await tx.questionsAnswerCommentVote.update({\ndata: {\nanswerCommentId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsAnswerComment.update({\ndata: {\nupvotes: {\nincrement: -2,\n},\n},\nwhere: {\nid: answerCommentId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerCommentToUpdate =\nawait tx.questionsAnswerComment.findUnique({\nwhere: {\nid: answerCommentId,\n},\n});\nif (answerCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer Comment do not exist.',\n});\n}\nconst voteToDelete = await tx.questionsAnswerCommentVote.findUnique({\nwhere: {\nanswerCommentId_userId: { answerCommentId, userId },\n},\n});\nif (voteToDelete === null) {\nreturn null;\n}\nif (voteToDelete!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nconst incrementValue = voteToDelete!.vote === Vote.UPVOTE ? -1 : 1;\nawait tx.questionsAnswerCommentVote.delete({\nwhere: {\nid: voteToDelete.id,\n},\n});\nawait tx.questionsAnswerComment.update({\ndata: {\nupvotes: {\nincrement: incrementValue,\n},\n},\nwhere: {\nid: answerCommentId,\n},\n});\nreturn voteToDelete;\n});\n},"
"async resolve({ ctx, input }) {\nconst { questionId, cursor } = input;\nconst sortCondition =\ninput.sortType === SortType.TOP\n? [\n{\nupvotes: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n]\n: [\n{\nupdatedAt: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n];\nconst answersData = await ctx.prisma.questionsAnswer.findMany({\ncursor: cursor ? { id: cursor } : undefined,\ninclude: {\n_count: {\nselect: {\ncomments: true,\n},\n},\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\nvotes: true,\n},\norderBy: sortCondition,\ntake: input.limit + 1,\nwhere: {\nquestionId,\n},\n});\nconst processedAnswersData = answersData.map((data) => {\nconst votes: number = data.votes.reduce(\n(previousValue: number, currentValue) => {\nlet result: number = previousValue;\nswitch (currentValue.vote) {\ncase Vote.UPVOTE:\nresult += 1;\nbreak;\ncase Vote.DOWNVOTE:\nresult -= 1;\nbreak;\n}\nreturn result;\n},\n0,\n);\nconst answer: Answer = {\ncontent: data.content,\ncreatedAt: data.createdAt,\nid: data.id,\nnumComments: data._count.comments,\nnumVotes: votes,\nuser: data.user?.name ?? '',\nuserImage: data.user?.image ?? '',\n};\nreturn answer;\n});\nlet nextCursor: typeof cursor | undefined = undefined;\nif (answersData.length > input.limit) {\nconst nextItem = answersData.pop()!;\nprocessedAnswersData.pop();\nconst nextIdCursor: string | undefined = nextItem.id;\nnextCursor = nextIdCursor;\n}\nreturn {\ndata: processedAnswersData,\nnextCursor,\n};\n},"
"async resolve({ ctx, input }) {\nconst answerData = await ctx.prisma.questionsAnswer.findUnique({\ninclude: {\n_count: {\nselect: {\ncomments: true,\n},\n},\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\nvotes: true,\n},\nwhere: {\nid: input.answerId,\n},\n});\nif (!answerData) {\nthrow new TRPCError({\ncode: 'NOT_FOUND',\nmessage: 'Answer not found',\n});\n}\nconst votes: number = answerData.votes.reduce(\n(previousValue: number, currentValue) => {\nlet result: number = previousValue;\nswitch (currentValue.vote) {\ncase Vote.UPVOTE:\nresult += 1;\nbreak;\ncase Vote.DOWNVOTE:\nresult -= 1;\nbreak;\n}\nreturn result;\n},\n0,\n);\nconst answer: Answer = {\ncontent: answerData.content,\ncreatedAt: answerData.createdAt,\nid: answerData.id,\nnumComments: answerData._count.comments,\nnumVotes: votes,\nuser: answerData.user?.name ?? '',\nuserImage: answerData.user?.image ?? '',\n};\nreturn answer;\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerToUpdate = await tx.questionsAnswer.findUnique({\nwhere: {\nid: answerId,\n},\n});\nif (answerToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer do not exist.',\n});\n}\nconst vote = await tx.questionsAnswerVote.findUnique({\nwhere: {\nanswerId_userId: { answerId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsAnswerVote.create({\ndata: {\nanswerId,\nuserId,\nvote: Vote.UPVOTE,\n},\n});\nawait tx.questionsAnswer.update({\ndata: {\nupvotes: {\nincrement: 1,\n},\n},\nwhere: {\nid: answerId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.UPVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.DOWNVOTE) {\nconst updatedVote = await tx.questionsAnswerVote.update({\ndata: {\nanswerId,\nuserId,\nvote: Vote.UPVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsAnswer.update({\ndata: {\nupvotes: {\nincrement: 2,\n},\n},\nwhere: {\nid: answerId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerToUpdate = await tx.questionsAnswer.findUnique({\nwhere: {\nid: answerId,\n},\n});\nif (answerToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer do not exist.',\n});\n}\nconst vote = await tx.questionsAnswerVote.findUnique({\nwhere: {\nanswerId_userId: { answerId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsAnswerVote.create({\ndata: {\nanswerId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\n});\nawait tx.questionsAnswer.update({\ndata: {\nupvotes: {\nincrement: -1,\n},\n},\nwhere: {\nid: answerId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.DOWNVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.UPVOTE) {\nconst updatedVote = await tx.questionsAnswerVote.update({\ndata: {\nanswerId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsAnswer.update({\ndata: {\nupvotes: {\nincrement: -2,\n},\n},\nwhere: {\nid: answerId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { answerId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst answerToUpdate = await tx.questionsAnswer.findUnique({\nwhere: {\nid: answerId,\n},\n});\nif (answerToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Answer do not exist.',\n});\n}\nconst voteToDelete = await tx.questionsAnswerVote.findUnique({\nwhere: {\nanswerId_userId: { answerId, userId },\n},\n});\nif (voteToDelete === null) {\nreturn null;\n}\nif (voteToDelete!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nconst incrementValue = voteToDelete!.vote === Vote.UPVOTE ? -1 : 1;\nawait tx.questionsAnswerVote.delete({\nwhere: {\nid: voteToDelete.id,\n},\n});\nawait tx.questionsAnswer.update({\ndata: {\nupvotes: {\nincrement: incrementValue,\n},\n},\nwhere: {\nid: answerId,\n},\n});\nreturn voteToDelete;\n});\n},"
"async resolve({ ctx }) {\nconst userId = ctx.session?.user?.id;\nconst questionsLists = await ctx.prisma.questionsList.findMany({\ninclude: {\nquestionEntries: {\ninclude: {\nquestion: {\ninclude: {\n_count: {\nselect: {\nanswers: true,\ncomments: true,\n},\n},\nencounters: {\nselect: {\ncity: true,\ncompany: true,\ncountry: true,\nrole: true,\nseenAt: true,\nstate: true,\n},\n},\nuser: {\nselect: {\nname: true,\n},\n},\nvotes: true,\n},\n},\n},\n},\n},\norderBy: {\ncreatedAt: 'asc',\n},\nwhere: {\nuserId,\n},\n});\nconst lists = questionsLists.map((list) => ({\n...list,\nquestionEntries: list.questionEntries.map((entry) => ({\n...entry,\nquestion: createQuestionWithAggregateData(entry.question),\n})),\n}));\nreturn lists;\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { listId } = input;\nconst questionList = await ctx.prisma.questionsList.findFirst({\ninclude: {\nquestionEntries: {\ninclude: {\nquestion: {\ninclude: {\n_count: {\nselect: {\nanswers: true,\ncomments: true,\n},\n},\nencounters: {\nselect: {\ncity: true,\ncompany: true,\ncountry: true,\nrole: true,\nseenAt: true,\nstate: true,\n},\n},\nuser: {\nselect: {\nname: true,\n},\n},\nvotes: true,\n},\n},\n},\n},\n},\norderBy: {\ncreatedAt: 'asc',\n},\nwhere: {\nid: listId,\nuserId,\n},\n});\nif (!questionList) {\nthrow new TRPCError({\ncode: 'NOT_FOUND',\nmessage: 'Question list not found',\n});\n}\nreturn {\n...questionList,\nquestionEntries: questionList.questionEntries.map((questionEntry) => ({\n...questionEntry,\nquestion: createQuestionWithAggregateData(questionEntry.question),\n})),\n};\n},"
"async resolve({ ctx, input }) {\nconst { questionId, cursor } = input;\nconst sortCondition =\ninput.sortType === SortType.TOP\n? [\n{\nupvotes: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n]\n: [\n{\nupdatedAt: input.sortOrder,\n},\n{\nid: input.sortOrder,\n},\n];\nconst questionCommentsData =\nawait ctx.prisma.questionsQuestionComment.findMany({\ncursor: cursor ? { id: cursor } : undefined,\ninclude: {\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\nvotes: true,\n},\norderBy: sortCondition,\ntake: input.limit + 1,\nwhere: {\nquestionId,\n},\n});\nconst processedQuestionCommentsData = questionCommentsData.map((data) => {\nconst votes: number = data.votes.reduce(\n(previousValue: number, currentValue) => {\nlet result: number = previousValue;\nswitch (currentValue.vote) {\ncase Vote.UPVOTE:\nresult += 1;\nbreak;\ncase Vote.DOWNVOTE:\nresult -= 1;\nbreak;\n}\nreturn result;\n},\n0,\n);\nconst questionComment: QuestionComment = {\ncontent: data.content,\ncreatedAt: data.createdAt,\nid: data.id,\nnumVotes: votes,\nuser: data.user?.name ?? '',\nuserImage: data.user?.image ?? '',\n};\nreturn questionComment;\n});\nlet nextCursor: typeof cursor | undefined = undefined;\nif (questionCommentsData.length > input.limit) {\nconst nextItem = questionCommentsData.pop()!;\nprocessedQuestionCommentsData.pop();\nconst nextIdCursor: string | undefined = nextItem.id;\nnextCursor = nextIdCursor;\n}\nreturn {\ndata: processedQuestionCommentsData,\nnextCursor,\n};\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionCommentToUpdate =\nawait tx.questionsQuestionComment.findUnique({\nwhere: {\nid: questionCommentId,\n},\n});\nif (questionCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question Comment do not exist.',\n});\n}\nconst vote = await tx.questionsQuestionCommentVote.findUnique({\nwhere: {\nquestionCommentId_userId: { questionCommentId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsQuestionCommentVote.create({\ndata: {\nquestionCommentId,\nuserId,\nvote: Vote.UPVOTE,\n},\n});\nawait tx.questionsQuestionComment.update({\ndata: {\nupvotes: {\nincrement: 1,\n},\n},\nwhere: {\nid: questionCommentId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.UPVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.DOWNVOTE) {\nconst updatedVote = await tx.questionsQuestionCommentVote.update({\ndata: {\nquestionCommentId,\nuserId,\nvote: Vote.UPVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsQuestionComment.update({\ndata: {\nupvotes: {\nincrement: 2,\n},\n},\nwhere: {\nid: questionCommentId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionCommentToUpdate =\nawait tx.questionsQuestionComment.findUnique({\nwhere: {\nid: questionCommentId,\n},\n});\nif (questionCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question Comment do not exist.',\n});\n}\nconst vote = await tx.questionsQuestionCommentVote.findUnique({\nwhere: {\nquestionCommentId_userId: { questionCommentId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsQuestionCommentVote.create({\ndata: {\nquestionCommentId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\n});\nawait tx.questionsQuestionComment.update({\ndata: {\nupvotes: {\nincrement: -1,\n},\n},\nwhere: {\nid: questionCommentId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.DOWNVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.UPVOTE) {\nconst updatedVote = await tx.questionsQuestionCommentVote.update({\ndata: {\nquestionCommentId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsQuestionComment.update({\ndata: {\nupvotes: {\nincrement: -2,\n},\n},\nwhere: {\nid: questionCommentId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionCommentId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionCommentToUpdate =\nawait tx.questionsQuestionComment.findUnique({\nwhere: {\nid: questionCommentId,\n},\n});\nif (questionCommentToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question Comment do not exist.',\n});\n}\nconst voteToDelete = await tx.questionsQuestionCommentVote.findUnique({\nwhere: {\nquestionCommentId_userId: { questionCommentId, userId },\n},\n});\nif (voteToDelete === null) {\nreturn null;\n}\nif (voteToDelete!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nconst incrementValue = voteToDelete!.vote === Vote.UPVOTE ? -1 : 1;\nawait tx.questionsQuestionCommentVote.delete({\nwhere: {\nid: voteToDelete.id,\n},\n});\nawait tx.questionsQuestionComment.update({\ndata: {\nupvotes: {\nincrement: incrementValue,\n},\n},\nwhere: {\nid: questionCommentId,\n},\n});\nreturn voteToDelete;\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst [questionToUpdate, questionEncounterCreated] = await Promise.all([\ntx.questionsQuestion.findUnique({\nwhere: {\nid: input.questionId,\n},\n}),\ntx.questionsQuestionEncounter.create({\ndata: {\n...input,\nuserId,\n},\n}),\n]);\nif (questionToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question does not exist',\n});\n}\nawait tx.questionsQuestion.update({\ndata: {\nlastSeenAt:\nquestionToUpdate.lastSeenAt === null ||\nquestionToUpdate.lastSeenAt < input.seenAt\n? input.seenAt\n: undefined,\nnumEncounters: {\nincrement: 1,\n},\n},\nwhere: {\nid: input.questionId,\n},\n});\nreturn questionEncounterCreated;\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst questionEncounterToUpdate =\nawait ctx.prisma.questionsQuestionEncounter.findUnique({\nwhere: {\nid: input.id,\n},\n});\nif (questionEncounterToUpdate?.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst [questionToUpdate, questionEncounterUpdated] = await Promise.all([\ntx.questionsQuestion.findUnique({\nwhere: {\nid: questionEncounterToUpdate.questionId,\n},\n}),\ntx.questionsQuestionEncounter.update({\ndata: {\n...input,\n},\nwhere: {\nid: input.id,\n},\n}),\n]);\nif (questionToUpdate!.lastSeenAt === questionEncounterToUpdate.seenAt) {\nconst latestEncounter =\nawait ctx.prisma.questionsQuestionEncounter.findFirst({\norderBy: {\nseenAt: SortOrder.DESC,\n},\nwhere: {\nquestionId: questionToUpdate!.id,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nlastSeenAt: latestEncounter!.seenAt,\n},\nwhere: {\nid: questionToUpdate!.id,\n},\n});\n}\nreturn questionEncounterUpdated;\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst questionEncounterToDelete =\nawait ctx.prisma.questionsQuestionEncounter.findUnique({\nwhere: {\nid: input.id,\n},\n});\nif (questionEncounterToDelete?.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst [questionToUpdate, questionEncounterDeleted] = await Promise.all([\ntx.questionsQuestion.findUnique({\nwhere: {\nid: questionEncounterToDelete.questionId,\n},\n}),\ntx.questionsQuestionEncounter.delete({\nwhere: {\nid: input.id,\n},\n}),\n]);\nlet lastSeenVal = undefined;\nif (questionToUpdate!.lastSeenAt === questionEncounterToDelete.seenAt) {\nconst latestEncounter =\nawait ctx.prisma.questionsQuestionEncounter.findFirst({\norderBy: {\nseenAt: SortOrder.DESC,\n},\nwhere: {\nquestionId: questionToUpdate!.id,\n},\n});\nlastSeenVal = latestEncounter ? latestEncounter!.seenAt : null;\n}\nawait tx.questionsQuestion.update({\ndata: {\nlastSeenAt: lastSeenVal,\nnumEncounters: {\nincrement: -1,\n},\n},\nwhere: {\nid: questionToUpdate!.id,\n},\n});\nreturn questionEncounterDeleted;\n});\n},"
"async resolve({ ctx, input }) {\nconst escapeChars = /[()|&:*!]/g;\nconst query = input.content\n.replace(escapeChars, ' ')\n.trim()\n.split(/\s+/)\n.join(' | ');\nconst relatedQuestionsId: Array<{ id: string }> = await ctx.prisma\n.$queryRaw`\nSELECT id FROM `QuestionsQuestion`\nWHERE\nts_rank_cd(to_tsvector(`content`), to_tsquery(${query}), 32) > 0.1\nORDER BY ts_rank_cd(to_tsvector(`content`), to_tsquery('english', ${query}), 4) DESC;\n`;\nconst relatedQuestionsIdArray = relatedQuestionsId.map(\n(current) => current.id,\n);\nconst relatedQuestionsData = await ctx.prisma.questionsQuestion.findMany({\ninclude: {\n_count: {\nselect: {\nanswers: true,\ncomments: true,\n},\n},\nencounters: {\nselect: {\ncity: true,\ncompany: true,\ncountry: true,\nrole: true,\nseenAt: true,\nstate: true,\n},\n},\nuser: {\nselect: {\nname: true,\n},\n},\nvotes: true,\n},\nwhere: {\nid: {\nin: relatedQuestionsIdArray,\n},\n},\n});\nconst processedQuestionsData = relatedQuestionsData.map(\ncreateQuestionWithAggregateData,\n);\nreturn processedQuestionsData;\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nreturn await ctx.prisma.questionsQuestion.create({\ndata: {\ncontent: input.content,\nencounters: {\ncreate: {\ncity:\ninput.cityId !== null\n? {\nconnect: {\nid: input.cityId,\n},\n}\n: undefined,\ncompany: {\nconnect: {\nid: input.companyId,\n},\n},\ncountry: {\nconnect: {\nid: input.countryId,\n},\n},\nrole: input.role,\nseenAt: input.seenAt,\nstate:\ninput.stateId !== null\n? {\nconnect: {\nid: input.stateId,\n},\n}\n: undefined,\nuser: {\nconnect: {\nid: userId,\n},\n},\n},\n},\nlastSeenAt: input.seenAt,\nquestionType: input.questionType,\nuserId,\n},\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionToUpdate = await tx.questionsQuestion.findUnique({\nwhere: {\nid: questionId,\n},\n});\nif (questionToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question do not exist.',\n});\n}\nconst vote = await tx.questionsQuestionVote.findUnique({\nwhere: {\nquestionId_userId: { questionId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsQuestionVote.create({\ndata: {\nquestionId,\nuserId,\nvote: Vote.UPVOTE,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nupvotes: {\nincrement: 1,\n},\n},\nwhere: {\nid: questionId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote!.vote === Vote.UPVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.DOWNVOTE) {\nconst updatedVote = await tx.questionsQuestionVote.update({\ndata: {\nquestionId,\nuserId,\nvote: Vote.UPVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nupvotes: {\nincrement: 2,\n},\n},\nwhere: {\nid: questionId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionToUpdate = await tx.questionsQuestion.findUnique({\nwhere: {\nid: questionId,\n},\n});\nif (questionToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question do not exist.',\n});\n}\nconst vote = await tx.questionsQuestionVote.findUnique({\nwhere: {\nquestionId_userId: { questionId, userId },\n},\n});\nif (vote === null) {\nconst createdVote = await tx.questionsQuestionVote.create({\ndata: {\nquestionId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nupvotes: {\nincrement: -1,\n},\n},\nwhere: {\nid: questionId,\n},\n});\nreturn createdVote;\n}\nif (vote!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nif (vote.vote === Vote.DOWNVOTE) {\nreturn vote;\n}\nif (vote.vote === Vote.UPVOTE) {\nconst updatedVote = await tx.questionsQuestionVote.update({\ndata: {\nquestionId,\nuserId,\nvote: Vote.DOWNVOTE,\n},\nwhere: {\nid: vote.id,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nupvotes: {\nincrement: -2,\n},\n},\nwhere: {\nid: questionId,\n},\n});\nreturn updatedVote;\n}\n});\n},"
"async resolve({ ctx, input }) {\nconst userId = ctx.session?.user?.id;\nconst { questionId } = input;\nreturn await ctx.prisma.$transaction(async (tx) => {\nconst questionToUpdate = await tx.questionsQuestion.findUnique({\nwhere: {\nid: questionId,\n},\n});\nif (questionToUpdate === null) {\nthrow new TRPCError({\ncode: 'BAD_REQUEST',\nmessage: 'Question do not exist.',\n});\n}\nconst voteToDelete = await tx.questionsQuestionVote.findUnique({\nwhere: {\nquestionId_userId: { questionId, userId },\n},\n});\nif (voteToDelete === null) {\nreturn null;\n}\nif (voteToDelete!.userId !== userId) {\nthrow new TRPCError({\ncode: 'UNAUTHORIZED',\nmessage: 'User have no authorization to record.',\n});\n}\nconst incrementValue = voteToDelete!.vote === Vote.UPVOTE ? -1 : 1;\nawait tx.questionsQuestionVote.delete({\nwhere: {\nid: voteToDelete.id,\n},\n});\nawait tx.questionsQuestion.update({\ndata: {\nupvotes: {\nincrement: incrementValue,\n},\n},\nwhere: {\nid: questionId,\n},\n});\nreturn voteToDelete;\n});\n},"
"async resolve({ ctx, input }) {\nconst { resumeId } = input;\nconst comments = await ctx.prisma.resumesComment.findMany({\ninclude: {\nchildren: {\ninclude: {\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\n},\norderBy: {\ncreatedAt: 'asc',\n},\n},\nuser: {\nselect: {\nimage: true,\nname: true,\n},\n},\n},\norderBy: {\ncreatedAt: 'desc',\n},\nwhere: {\nAND: [{ resumeId }, { parentId: null }],\n},\n});\nreturn comments.map((data) => {\nconst children: Array<ResumeComment> = data.children.map((child) => {\nreturn {\nchildren: [],\ncreatedAt: child.createdAt,\ndescription: child.description,\nid: child.id,\nparentId: data.id,\nresumeId: child.resumeId,\nsection: child.section,\nupdatedAt: child.updatedAt,\nuser: {\nimage: child.user.image,\nname: child.user.name,\nuserId: child.userId,\n},\n};\n});\nconst comment: ResumeComment = {\nchildren,\ncreatedAt: data.createdAt,\ndescription: data.description,\nid: data.id,\nparentId: data.parentId,\nresumeId: data.resumeId,\nsection: data.section,\nupdatedAt: data.updatedAt,\nuser: {\nimage: data.user.image,\nname: data.user.name,\nuserId: data.userId,\n},\n};\nreturn comment;\n});\n},"
"async resolve({ ctx, input }) {\nconst resumes = await ctx.prisma.resumesResume.findMany({\nselect: {\ncomments: {\nselect: {\nuserId: true,\nvotes: {\nselect: {\nvalue: true,\n},\n},\n},\n},\n},\n});\nlet topUpvotedCommentCount = 0;\nfor (const resume of resumes) {\nlet highestVoteCount = 2;\nconst commentUpvotePairs = [];\nfor (const comment of resume.comments) {\nconst { userId, votes } = comment;\nlet voteCount = 0;\nfor (const vote of votes) {\nif (vote.value === Vote.UPVOTE) {\nvoteCount++;\n} else {\nvoteCount--;\n}\n}\nif (voteCount >= highestVoteCount) {\nhighestVoteCount = voteCount;\ncommentUpvotePairs.push({ userId, voteCount });\n}\n}\nconst userIds = commentUpvotePairs\n.filter((pair) => pair.voteCount === highestVoteCount)\n.map((pair) => pair.userId);\nif (userIds.includes(input.userId)) {\ntopUpvotedCommentCount++;\n}\n}\nreturn topUpvotedCommentCount;\n},"
"export function createAggregatedQuestionEncounter(\nencounters: AggregatableEncounters,\n): AggregatedQuestionEncounter {\nconst countryCounts: Record<string, CountryInfo> = {};\nconst companyCounts: Record<string, number> = {};\nconst roleCounts: Record<string, number> = {};\nfor (const encounter of encounters) {\nif (encounter.company !== null) {\nif (!(encounter.company.name in companyCounts)) {\ncompanyCounts[encounter.company!.name] = 0;\n}\ncompanyCounts[encounter.company!.name] += 1;\n}\nif (encounter.country !== null) {\nif (!(encounter.country.name in countryCounts)) {\ncountryCounts[encounter.country.name] = {\nstateInfos: {},\ntotal: 0,\n};\n}\nconst countryInfo = countryCounts[encounter.country.name];\ncountryInfo.total += 1;\nconst countryStateInfo = countryInfo.stateInfos;\nif (encounter.state !== null) {\nif (!(encounter.state.name in countryStateInfo)) {\ncountryStateInfo[encounter.state.name] = {\ncityCounts: {},\ntotal: 0,\n};\n}\nconst stateInfo = countryStateInfo[encounter.state.name];\nstateInfo.total += 1;\nconst { cityCounts } = stateInfo;\nif (encounter.city !== null) {\nif (!(encounter.city.name in cityCounts)) {\ncityCounts[encounter.city.name] = 0;\n}\ncityCounts[encounter.city.name] += 1;\n}\n}\n}\nif (!(encounter.role in roleCounts)) {\nroleCounts[encounter.role] = 0;\n}\nroleCounts[encounter.role] += 1;\n}\nreturn {\ncompanyCounts,\ncountryCounts,\nroleCounts,\n};\n}"
"export default function useAnswerCommentVote(id: string) {\nconst utils = trpc.useContext();\nreturn useVote(id, {\nidKey: 'answerCommentId',\ninvalidateKeys: [],\nonMutate: async (voteValueChange) => {\nconst answerCommentQueries = utils.queryClient.getQueriesData([\n'questions.answers.comments.getAnswerComments',\n]);\nconst revertFunctions: Array<() => void> = [];\nif (answerCommentQueries !== undefined) {\nfor (const [key, query] of answerCommentQueries) {\nif (query === undefined) {\ncontinue;\n}\nconst { pages, ...restQuery } = query as InfiniteData<{\ndata: Array<AnswerComment>;\n}>;\nconst newQuery = {\npages: pages.map(({ data, ...restPage }) => ({\ndata: data.map((answerComment) => {\nif (answerComment.id === id) {\nconst { numVotes, ...restAnswerComment } = answerComment;\nreturn {\nnumVotes: numVotes + voteValueChange,\n...restAnswerComment,\n};\n}\nreturn answerComment;\n}),\n...restPage,\n})),\n...restQuery,\n};\nutils.queryClient.setQueryData(key, newQuery);\nrevertFunctions.push(() => {\nutils.queryClient.setQueryData(key, query);\n});\n}\n}\nreturn () => {\nfor (const revertFunction of revertFunctions) {\nrevertFunction();\n}\n};\n},\nquery: 'questions.answers.comments.user.getVote',\nsetDownVoteKey: 'questions.answers.comments.user.setDownVote',\nsetNoVoteKey: 'questions.answers.comments.user.setNoVote',\nsetUpVoteKey: 'questions.answers.comments.user.setUpVote',\n});\n}"
"export default function useQuestionCommentVote(id: string) {\nconst utils = trpc.useContext();\nreturn useVote(id, {\nidKey: 'questionCommentId',\ninvalidateKeys: [],\nonMutate: async (voteValueChange) => {\nconst questionCommentQueries = utils.queryClient.getQueriesData([\n'questions.questions.comments.getQuestionComments',\n]);\nconst revertFunctions: Array<() => void> = [];\nif (questionCommentQueries !== undefined) {\nfor (const [key, query] of questionCommentQueries) {\nif (query === undefined) {\ncontinue;\n}\nconst { pages, ...restQuery } = query as InfiniteData<{\ndata: Array<QuestionComment>;\n}>;\nconst newQuery = {\npages: pages.map(({ data, ...restPage }) => ({\ndata: data.map((questionComment) => {\nif (questionComment.id === id) {\nconst { numVotes, ...restQuestionComment } = questionComment;\nreturn {\nnumVotes: numVotes + voteValueChange,\n...restQuestionComment,\n};\n}\nreturn questionComment;\n}),\n...restPage,\n})),\n...restQuery,\n};\nutils.queryClient.setQueryData(key, newQuery);\nrevertFunctions.push(() => {\nutils.queryClient.setQueryData(key, query);\n});\n}\n}\nreturn () => {\nfor (const revertFunction of revertFunctions) {\nrevertFunction();\n}\n};\n},\nquery: 'questions.questions.comments.user.getVote',\nsetDownVoteKey: 'questions.questions.comments.user.setDownVote',\nsetNoVoteKey: 'questions.questions.comments.user.setNoVote',\nsetUpVoteKey: 'questions.questions.comments.user.setUpVote',\n});\n}"
"function YoeSection() {\nconst { register, formState } = useFormContext<{\nbackground: BackgroundPostData;\n}>();\nconst backgroundFields = formState.errors.background;\nreturn (\n<FormSection title=`Years of Experience (YOE)`>\n<div className=`grid grid-cols-1 gap-y-4 sm:grid-cols-2 sm:gap-6`>\n<FormTextInput\nerrorMessage={backgroundFields?.totalYoe?.message}\nlabel=`Total YOE`\nplaceholder=`0`\nrequired={true}\ntype=`number`\n{...register(`background.totalYoe`, {\nmin: { message: FieldError.NON_NEGATIVE_NUMBER, value: 0 },\nrequired: FieldError.REQUIRED,\nvalueAsNumber: true,\n})}\n/>\n</div>\n<Collapsible label=`Add specific YOEs by domain`>\n<div className=`space-y-4 sm:space-y-6`>\n<div className=`grid grid-cols-1 gap-y-4 sm:grid-cols-2 sm:gap-6`>\n<FormTextInput\nerrorMessage={backgroundFields?.specificYoes?.[0]?.yoe?.message}\nlabel=`Specific YOE 1`\ntype=`number`\n{...register(`background.specificYoes.0.yoe`, {\nvalidate: validatePositiveNumber,\nvalueAsNumber: true,\n})}\n/>\n<FormTextInput\nlabel=`Specific Domain 1`\nplaceholder=`e.g. Front End`\n{...register(`background.specificYoes.0.domain`)}\n/>\n</div>\n<div className=`grid grid-cols-1 gap-y-4 sm:grid-cols-2 sm:gap-6`>\n<FormTextInput\nerrorMessage={backgroundFields?.specificYoes?.[1]?.yoe?.message}\nlabel=`Specific YOE 2`\ntype=`number`\n{...register(`background.specificYoes.1.yoe`, {\nvalidate: validatePositiveNumber,\nvalueAsNumber: true,\n})}\n/>\n<FormTextInput\nlabel=`Specific Domain 2`\nplaceholder=`e.g. Back End`\n{...register(`background.specificYoes.1.domain`)}\n/>\n</div>\n</div>\n</Collapsible>\n</FormSection>\n);\n}"
"function InternshipJobFields({ defaultCurrency }: InternshipJobFieldsProps) {\nconst { register, formState } = useFormContext<{\nbackground: BackgroundPostData;\n}>();\nconst experiencesField = formState.errors.background?.experiences?.[0];\nreturn (\n<>\n<div className=`grid grid-cols-1 gap-y-4 sm:grid-cols-2 sm:gap-6`>\n<FormJobTitlesTypeahead name=`background.experiences.0.title` />\n<FormCompaniesTypeahead\nnames={{\nlabel: 'background.experiences.0.companyName',\nvalue: 'background.experiences.0.companyId',\n}}\n/>\n</div>\n<FormTextInput\nendAddOn={\n<FormSelect\nborderStyle=`borderless`\ndefaultValue={defaultCurrency}\nisLabelHidden={true}\nlabel=`Currency`\noptions={CURRENCY_OPTIONS}\n{...register(`background.experiences.0.monthlySalary.currency`)}\n/>\n}\nendAddOnType=`element`\nerrorMessage={experiencesField?.monthlySalary?.value?.message}\nlabel=`Salary (Monthly)`\nplaceholder=`0.00`\nstartAddOn=`$`\nstartAddOnType=`label`\ntype=`number`\n{...register(`background.experiences.0.monthlySalary.value`, {\nmin: { message: FieldError.NON_NEGATIVE_NUMBER, value: 0 },\nvalueAsNumber: true,\n})}\n/>\n<Collapsible label=`Add more details`>\n<div className=`grid grid-cols-1 gap-6 sm:grid-cols-2`>\n<FormCitiesTypeahead\nnames={{\nlabel: 'background.experiences.0.cityName',\nvalue: 'background.experiences.0.cityId',\n}}\n/>\n<FormTextInput\nerrorMessage={experiencesField?.durationInMonths?.message}\nlabel=`Duration (months)`\ntype=`number`\n{...register(`background.experiences.0.durationInMonths`, {\nmin: { message: FieldError.NON_NEGATIVE_NUMBER, value: 0 },\nvalueAsNumber: true,\n})}\n/>\n</div>\n</Collapsible>\n</>\n);\n}"
"function OfferDetailsFormArray({\nfieldArrayValues,\njobType,\ndefaultCurrency,\n}: OfferDetailsFormArrayProps) {\nconst { append, remove, fields } = fieldArrayValues;\nreturn (\n<div className=`space-y-8`>\n{fields.map((item, index) => {\nreturn (\n<div key={item.id}>\n{jobType === JobType.FULLTIME ? (\n<FullTimeOfferDetailsForm\ndefaultCurrency={defaultCurrency}\nindex={index}\nremove={remove}\n/>\n) : (\n<InternshipOfferDetailsForm\ndefaultCurrency={defaultCurrency}\nindex={index}\nremove={remove}\n/>\n)}\n</div>\n);\n})}\n<Button\ndisplay=`block`\nicon={PlusIcon}\nlabel=`Add another offer`\nsize=`lg`\nvariant=`secondary`\nonClick={() =>\nappend(\njobType === JobType.FULLTIME\n? defaultFullTimeOfferValues\n: defaultInternshipOfferValues,\n)\n}\n/>\n</div>\n);\n}"
"export default function ResumeCommentDeleteForm({\nid,\nisDeletingComment,\nsetIsDeletingComment,\n}: ResumeCommentDeleteFormProps) {\nconst { event: gaEvent } = useGoogleAnalytics();\nconst trpcContext = trpc.useContext();\nconst commentDeleteMutation = trpc.useMutation(\n'resumes.comments.user.delete',\n{\nonSuccess: () => {\ntrpcContext.invalidateQueries(['resumes.comments.list']);\n},\n},\n);\nconst onDelete = async () => {\nreturn commentDeleteMutation.mutate(\n{\nid,\n},\n{\nonSuccess: () => {\nsetIsDeletingComment(false);\ngaEvent({\naction: 'resumes.comment_delete',\ncategory: 'engagement',\nlabel: 'Delete comment',\n});\n},\n},\n);\n};\nconst onCancel = () => {\nsetIsDeletingComment(false);\n};\nreturn (\n<Dialog\nisShown={isDeletingComment}\nprimaryButton={\n<Button\ndisabled={commentDeleteMutation.isLoading}\ndisplay=`block`\nisLoading={commentDeleteMutation.isLoading}\nlabel=`Delete`\nvariant=`danger`\nonClick={onDelete}\n/>\n}\nsecondaryButton={\n<Button\ndisabled={commentDeleteMutation.isLoading}\ndisplay=`block`\nlabel=`Cancel`\nvariant=`tertiary`\nonClick={onCancel}\n/>\n}\ntitle=`Are you sure?`\nonClose={() => setIsDeletingComment(false)}>\n<div>\nNote that deleting this comment will delete all its replies as well.\nThis action is also irreversible! Please check before confirming!\n</div>\n</Dialog>\n);\n}"
"export default function ResumeCommentEditForm({\ncomment,\nsetIsEditingComment,\n}: ResumeCommentEditFormProps) {\nconst {\nregister,\nhandleSubmit,\nsetValue,\nformState: { errors, isDirty },\nreset,\n} = useForm<ICommentInput>({\ndefaultValues: {\ndescription: comment.description,\n},\n});\nconst trpcContext = trpc.useContext();\nconst commentUpdateMutation = trpc.useMutation(\n'resumes.comments.user.update',\n{\nonSuccess: () => {\ntrpcContext.invalidateQueries(['resumes.comments.list']);\n},\n},\n);\nconst onCancel = () => {\nreset({ description: comment.description });\nsetIsEditingComment(false);\n};\nconst onSubmit: SubmitHandler<ICommentInput> = async (data) => {\nconst { id } = comment;\nreturn commentUpdateMutation.mutate(\n{\nid,\n...data,\n},\n{\nonSuccess: () => {\nsetIsEditingComment(false);\n},\n},\n);\n};\nconst setFormValue = (value: string) => {\nsetValue('description', value.trim(), { shouldDirty: true });\n};\nreturn (\n<form className=`space-y-2` onSubmit={handleSubmit(onSubmit)}>\n<TextArea\n{...(register('description', {\nrequired: 'Comments cannot be empty!',\n}),\n{})}\ndefaultValue={comment.description}\ndisabled={commentUpdateMutation.isLoading}\nerrorMessage={errors.description?.message}\nlabel=``\nplaceholder=`Leave your comment here`\nonChange={setFormValue}\n/>\n<div className=`flex w-full justify-end space-x-2`>\n<Button\ndisabled={commentUpdateMutation.isLoading}\nlabel=`Cancel`\nsize=`sm`\nvariant=`tertiary`\nonClick={onCancel}\n/>\n<Button\ndisabled={!isDirty || commentUpdateMutation.isLoading}\nisLoading={commentUpdateMutation.isLoading}\nlabel=`Submit`\nsize=`sm`\ntype=`submit`\nvariant=`primary`\n/>\n</div>\n</form>\n);\n}"
"export function getOffsetDateRange(dateRange: DateRange, offset: number) {\nif (offset === 0) {\nreturn dateRange;\n}\nconst { startDate, endDate, unit, num, value } = dateRange;\nconst change = num * offset;\nconst { add } = DATE_FUNCTIONS[unit];\nconst { unit: originalUnit } = parseDateValue(value) || {};\nswitch (originalUnit) {\ncase 'day':\nreturn {\n...dateRange,\noffset,\nstartDate: addDays(startDate, change),\nendDate: addDays(endDate, change),\n};\ncase 'week':\nreturn {\n...dateRange,\noffset,\nstartDate: addWeeks(startDate, change),\nendDate: addWeeks(endDate, change),\n};\ncase 'month':\nreturn {\n...dateRange,\noffset,\nstartDate: addMonths(startDate, change),\nendDate: addMonths(endDate, change),\n};\ncase 'year':\nreturn {\n...dateRange,\noffset,\nstartDate: addYears(startDate, change),\nendDate: addYears(endDate, change),\n};\ndefault:\nreturn {\nstartDate: add(startDate, change),\nendDate: add(endDate, change),\noffset,\nvalue,\nunit,\nnum,\n};\n}\n}"
"export async function getLocation(ip: string = '', headers: Headers, hasPayloadIP: boolean) {\nif (!ip || (await isLocalhost(ip))) {\nreturn null;\n}\nif (!hasPayloadIP && !process.env.SKIP_LOCATION_HEADERS) {\nfor (const provider of PROVIDER_HEADERS) {\nconst countryHeader = headers.get(provider.countryHeader);\nif (countryHeader) {\nconst country = decodeHeader(countryHeader);\nconst region = decodeHeader(headers.get(provider.regionHeader));\nconst city = decodeHeader(headers.get(provider.cityHeader));\nreturn {\ncountry,\nregion: getRegionCode(country, region),\ncity,\n};\n}\n}\n}\nif (!globalThis[MAXMIND]) {\nconst dir = path.join(process.cwd(), 'geo');\nglobalThis[MAXMIND] = await maxmind.open(\nprocess.env.GEOLITE_DB_PATH || path.resolve(dir, 'GeoLite2-City.mmdb'),\n);\n}\nconst result = globalThis[MAXMIND]?.get(stripPort(ip));\nif (result) {\nconst country = result.country?.iso_code ?? result?.registered_country?.iso_code;\nconst region = result.subdivisions?.[0]?.iso_code;\nconst city = result.city?.names?.en;\nreturn {\ncountry,\nregion: getRegionCode(country, region),\ncity,\n};\n}\n}"
"function getClient() {\nif (!process.env.DATABASE_URL) {\nreturn null;\n}\nconst url = process.env.DATABASE_URL;\nconst replicaUrl = process.env.DATABASE_REPLICA_URL;\nconst logQuery = process.env.LOG_QUERY;\nconst connectionUrl = new URL(url);\nconst schema = connectionUrl.searchParams.get('schema') ?? undefined;\nconst adapter = new PrismaPg({ connectionString: url.toString() }, { schema });\nconst prisma = new PrismaClient({\nadapter,\nerrorFormat: 'pretty',\n...(logQuery ? PRISMA_LOG_OPTIONS : {}),\n});\nif (replicaUrl) {\nconst replicaAdapter = new PrismaPg({ connectionString: replicaUrl.toString() }, { schema });\nconst replicaClient = new PrismaClient({\nadapter: replicaAdapter,\n...(logQuery ? PRISMA_LOG_OPTIONS : {}),\n});\nprisma.$extends(\nreadReplicas({\nreplicas: [replicaClient],\n}),\n);\n}\nif (logQuery) {\nprisma.$on('query' as never, log);\n}\nlog('Prisma initialized');\nif (!globalThis[PRISMA]) {\nglobalThis[PRISMA] = prisma;\n}\nreturn prisma;\n}"
"export async function getQueryFilters(\nparams: Record<string, any>,\nwebsiteId?: string,\n): Promise<QueryFilters> {\nconst dateRange = getRequestDateRange(params);\nconst filters = getRequestFilters(params);\nif (websiteId) {\nawait setWebsiteDate(websiteId, dateRange);\nif (params.segment) {\nconst segmentParams = (await getWebsiteSegment(websiteId, params.segment))\n?.parameters as Record<string, any>;\nObject.assign(filters, filtersArrayToObject(segmentParams.filters));\n}\nif (params.cohort) {\nconst cohortParams = (await getWebsiteSegment(websiteId, params.cohort))\n?.parameters as Record<string, any>;\nconst { startDate, endDate } = parseDateRange(cohortParams.dateRange);\nconst cohortFilters = cohortParams.filters.map(({ name, ...props }) => ({\n...props,\nname: `cohort_${name}`,\n}));\ncohortFilters.push({\nname: `cohort_${cohortParams.action.type}`,\noperator: 'eq',\nvalue: cohortParams.action.value,\n});\nObject.assign(filters, {\n...filtersArrayToObject(cohortFilters),\ncohort_startDate: startDate,\ncohort_endDate: endDate,\n});\n}\n}\nreturn {\n...dateRange,\n...filters,\npage: params?.page,\npageSize: params?.pageSize ? params?.pageSize || DEFAULT_PAGE_SIZE : undefined,\norderBy: params?.orderBy,\nsortDescending: params?.sortDescending,\nsearch: params?.search,\ncompare: params?.compare,\n};\n}"
"export function App({ children }) {\nconst { user, isLoading, error } = useLoginQuery();\nconst config = useConfig();\nconst { pathname, teamId } = useNavigation();\nuseEffect(() => {\nif (teamId) {\nsetItem(LAST_TEAM_CONFIG, teamId);\n} else {\nremoveItem(LAST_TEAM_CONFIG);\n}\n}, [teamId]);\nif (isLoading || !config) {\nreturn <Loading placement=`absolute` />;\n}\nif (error) {\nwindow.location.href = `${process.env.basePath || ''}/login`;\nreturn null;\n}\nif (!user || !config) {\nreturn null;\n}\nreturn (\n<Grid\ncolumns={{ xs: '1fr', lg: 'auto 1fr' }}\nrows={{ xs: 'auto 1fr', lg: '1fr' }}\nheight={{ xs: 'auto', lg: '100vh' }}\nwidth=`100%`\n>\n<Row display={{ xs: 'flex', lg: 'none' }} alignItems=`center` gap padding=`3`>\n<MobileNav />\n</Row>\n<Column display={{ xs: 'none', lg: 'flex' }}>\n<SideNav />\n</Column>\n<Column alignItems=`center` overflowY=`auto` overflowX=`hidden` position=`relative`>\n{children}\n</Column>\n<UpdateNotice user={user} config={config} />\n{process.env.NODE_ENV === 'production' && !pathname.includes('/share/') && (\n<Script src={`${process.env.basePath || ''}/telemetry.js`} />\n)}\n</Grid>\n);\n}"
"export function MobileNav() {\nconst { formatMessage, labels } = useMessages();\nconst { pathname, websiteId, renderUrl } = useNavigation();\nconst isAdmin = pathname.includes('/admin');\nconst isSettings = pathname.includes('/settings');\nconst links = [\n{\nid: 'websites',\nlabel: formatMessage(labels.websites),\npath: '/websites',\nicon: <Globe />,\n},\n{\nid: 'links',\nlabel: formatMessage(labels.links),\npath: '/links',\nicon: <LinkIcon />,\n},\n{\nid: 'pixels',\nlabel: formatMessage(labels.pixels),\npath: '/pixels',\nicon: <Grid2x2 />,\n},\n];\nreturn (\n<Grid columns=`auto 1fr` flexGrow={1} backgroundColor=`3` borderRadius>\n<MobileMenuButton>\n{({ close }) => {\nreturn (\n<>\n<NavMenu padding=`3` onItemClick={close} border=`bottom`>\n<NavButton />\n{links.map(link => {\nreturn (\n<Link key={link.id} href={renderUrl(link.path)}>\n<NavMenuItem>\n<IconLabel icon={link.icon} label={link.label} />\n</NavMenuItem>\n</Link>\n);\n})}\n</NavMenu>\n{websiteId && <WebsiteNav websiteId={websiteId} onItemClick={close} />}\n{isAdmin && <AdminNav onItemClick={close} />}\n{isSettings && <SettingsNav onItemClick={close} />}\n</>\n);\n}}\n</MobileMenuButton>\n<Row alignItems=`center` justifyContent=`center` flexGrow={1}>\n<IconLabel icon={<Logo />} style={{ width: 'auto' }}>\n<Text weight=`bold`>umami</Text>\n</IconLabel>\n</Row>\n</Grid>\n);\n}"
"export function UpdateNotice({ user, config }) {\nconst { formatMessage, labels, messages } = useMessages();\nconst { latest, checked, hasUpdate, releaseUrl } = useVersion();\nconst pathname = usePathname();\nconst [dismissed, setDismissed] = useState(checked);\nconst allowUpdate =\nprocess.env.NODE_ENV === 'production' &&\nuser?.isAdmin &&\n!config?.updatesDisabled &&\n!config?.privateMode &&\n!pathname.includes('/share/') &&\n!process.env.cloudMode &&\n!dismissed;\nconst updateCheck = useCallback(() => {\nsetItem(VERSION_CHECK, { version: latest, time: Date.now() });\n}, [latest]);\nfunction handleViewClick() {\nupdateCheck();\nsetDismissed(true);\nopen(releaseUrl || REPO_URL, '_blank');\n}\nfunction handleDismissClick() {\nupdateCheck();\nsetDismissed(true);\n}\nuseEffect(() => {\nif (allowUpdate) {\ncheckVersion();\n}\n}, [allowUpdate]);\nif (!allowUpdate || !hasUpdate) {\nreturn null;\n}\nreturn (\n<Column justifyContent=`center` alignItems=`center` position=`fixed` top=`10px` width=`100%`>\n<Row width=`600px`>\n<AlertBanner title={formatMessage(messages.newVersionAvailable, { version: `v${latest}` })}>\n<Button variant=`primary` onPress={handleViewClick}>\n{formatMessage(labels.viewDetails)}\n</Button>\n<Button onPress={handleDismissClick}>{formatMessage(labels.dismiss)}</Button>\n</AlertBanner>\n</Row>\n</Column>\n);\n}"
"export function LoginForm() {\nconst { formatMessage, labels, getErrorMessage } = useMessages();\nconst router = useRouter();\nconst { mutateAsync, error } = useUpdateQuery('/auth/login');\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async ({ token, user }) => {\nsetClientAuthToken(token);\nsetUser(user);\nrouter.push('/websites');\n},\n});\n};\nreturn (\n<Column justifyContent=`center` alignItems=`center` gap=`6`>\n<Icon size=`lg`>\n<Logo />\n</Icon>\n<Heading>umami</Heading>\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)}>\n<FormField\nlabel={formatMessage(labels.username)}\ndata-test=`input-username`\nname=`username`\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField autoComplete=`username` />\n</FormField>\n<FormField\nlabel={formatMessage(labels.password)}\ndata-test=`input-password`\nname=`password`\nrules={{ required: formatMessage(labels.required) }}\n>\n<PasswordField autoComplete=`current-password` />\n</FormField>\n<FormButtons>\n<FormSubmitButton\ndata-test=`button-submit`\nvariant=`primary`\nstyle={{ flex: 1 }}\nisDisabled={false}\n>\n{formatMessage(labels.login)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n</Column>\n);\n}"
"export function DataGrid({\nquery,\nsearchDelay = 600,\nallowSearch,\nallowPaging = true,\nautoFocus,\nrenderActions,\nrenderEmpty = () => <Empty />,\nchildren,\n}: DataGridProps) {\nconst { formatMessage, labels } = useMessages();\nconst { data, error, isLoading, isFetching } = query;\nconst { router, updateParams, query: queryParams } = useNavigation();\nconst [search, setSearch] = useState(queryParams?.search || data?.search || '');\nconst showPager = allowPaging && data && data.count > data.pageSize;\nconst { isMobile } = useMobile();\nconst displayMode = isMobile ? 'cards' : undefined;\nconst handleSearch = (value: string) => {\nif (value !== search) {\nsetSearch(value);\nrouter.push(updateParams({ search: value, page: 1 }));\n}\n};\nconst handlePageChange = useCallback(\n(page: number) => {\nrouter.push(updateParams({ search, page }));\n},\n[search],\n);\nconst child = data ? (typeof children === 'function' ? children(data) : children) : null;\nreturn (\n<Column gap=`4` minHeight=`300px`>\n{allowSearch && (\n<Row alignItems=`center` justifyContent=`space-between` wrap=`wrap` gap>\n<SearchField\nvalue={search}\nonSearch={handleSearch}\ndelay={searchDelay || DEFAULT_SEARCH_DELAY}\nautoFocus={autoFocus}\nplaceholder={formatMessage(labels.search)}\n/>\n{renderActions?.()}\n</Row>\n)}\n<LoadingPanel\ndata={data}\nisLoading={isLoading}\nisFetching={isFetching}\nerror={error}\nrenderEmpty={renderEmpty}\n>\n{data && (\n<>\n<Column>\n{isValidElement(child)\n? cloneElement(child as ReactElement<any>, { displayMode })\n: child}\n</Column>\n{showPager && (\n<Row marginTop=`6`>\n<Pager\npage={data.page}\npageSize={data.pageSize}\ncount={data.count}\nonPageChange={handlePageChange}\n/>\n</Row>\n)}\n</>\n)}\n</LoadingPanel>\n</Column>\n);\n}"
"export function PageHeader({\ntitle,\ndescription,\nlabel,\nicon,\nshowBorder = true,\nchildren,\n}: {\ntitle: string;\ndescription?: string;\nlabel?: ReactNode;\nicon?: ReactNode;\nshowBorder?: boolean;\nallowEdit?: boolean;\nclassName?: string;\nchildren?: ReactNode;\n}) {\nreturn (\n<Grid\ncolumns={{ xs: '1fr', md: '1fr 1fr' }}\npaddingY=`6`\nmarginBottom=`6`\nborder={showBorder ? 'bottom' : undefined}\n>\n<Column gap=`2`>\n{label}\n<Row alignItems=`center` gap=`3`>\n{icon && (\n<Icon size=`md` color=`muted`>\n{icon}\n</Icon>\n)}\n{title && <Heading size={{ xs: '2', md: '3', lg: '4' }}>{title}</Heading>}\n</Row>\n{description && (\n<Text color=`muted` truncate style={{ maxWidth: 600 }} title={description}>\n{description}\n</Text>\n)}\n</Column>\n<Row justifyContent=`flex-end`>{children}</Row>\n</Grid>\n);\n}"
"export function Pager({ page, pageSize, count, onPageChange }: PagerProps) {\nconst { formatMessage, labels } = useMessages();\nconst maxPage = pageSize && count ? Math.ceil(+count / +pageSize) : 0;\nconst lastPage = page === maxPage;\nconst firstPage = page === 1;\nif (count === 0 || !maxPage) {\nreturn null;\n}\nconst handlePageChange = (value: number) => {\nconst nextPage = +page + +value;\nif (nextPage > 0 && nextPage <= maxPage) {\nonPageChange(nextPage);\n}\n};\nif (maxPage === 1) {\nreturn null;\n}\nreturn (\n<Row alignItems=`center` justifyContent=`space-between` gap=`3` flexGrow={1}>\n<Text>{formatMessage(labels.numberOfRecords, { x: count.toLocaleString() })}</Text>\n<Row alignItems=`center` justifyContent=`flex-end` gap=`3`>\n<Text>\n{formatMessage(labels.pageOf, {\ncurrent: page.toLocaleString(),\ntotal: maxPage.toLocaleString(),\n})}\n</Text>\n<Row gap=`1`>\n<Button variant=`outline` onPress={() => handlePageChange(-1)} isDisabled={firstPage}>\n<Icon size=`sm` rotate={180}>\n<ChevronRight />\n</Icon>\n</Button>\n<Button variant=`outline` onPress={() => handlePageChange(1)} isDisabled={lastPage}>\n<Icon size=`sm`>\n<ChevronRight />\n</Icon>\n</Button>\n</Row>\n</Row>\n</Row>\n);\n}"
"export function SideMenu({\nitems = [],\ntitle,\nselectedKey,\nallowMinimize,\n...props\n}: SideMenuProps) {\nconst renderItems = (items: SideMenuData[]) => {\nreturn items?.map(({ id, label, icon, path }) => {\nconst isSelected = selectedKey === id;\nreturn (\n<Link key={id} href={path}>\n<NavMenuItem isSelected={isSelected}>\n<IconLabel icon={icon}>{label}</IconLabel>\n</NavMenuItem>\n</Link>\n);\n});\n};\nreturn (\n<Column gap overflowY=`auto` justifyContent=`space-between`>\n{title && (\n<Row padding>\n<Heading size=`1`>{title}</Heading>\n</Row>\n)}\n<NavMenu gap=`6` {...props}>\n{items?.map(({ label, items }, index) => {\nif (label) {\nreturn (\n<NavMenuGroup\ntitle={label}\nkey={`${label}${index}`}\ngap=`1`\nallowMinimize={allowMinimize}\nmarginBottom=`3`\n>\n{renderItems(items)}\n</NavMenuGroup>\n);\n}\n})}\n</NavMenu>\n</Column>\n);\n}"
"export function TypeConfirmationForm({\nconfirmationValue,\nbuttonLabel,\nbuttonVariant,\nisLoading,\nerror,\nonConfirm,\nonClose,\n}: {\nconfirmationValue: string;\nbuttonLabel?: string;\nbuttonVariant?: 'primary' | 'outline' | 'quiet' | 'danger' | 'zero';\nisLoading?: boolean;\nerror?: string | Error;\nonConfirm?: () => void;\nonClose?: () => void;\n}) {\nconst { formatMessage, labels, messages, getErrorMessage } = useMessages();\nif (!confirmationValue) {\nreturn null;\n}\nreturn (\n<Form onSubmit={onConfirm} error={getErrorMessage(error)}>\n<p>\n{formatMessage(messages.actionConfirmation, {\nconfirmation: confirmationValue,\n})}\n</p>\n<FormField\nlabel={formatMessage(labels.confirm)}\nname=`confirm`\nrules={{ validate: value => value === confirmationValue }}\n>\n<TextField autoComplete=`off` />\n</FormField>\n<FormButtons>\n<Button onPress={onClose}>{formatMessage(labels.cancel)}</Button>\n<FormSubmitButton isLoading={isLoading} variant={buttonVariant}>\n{buttonLabel || formatMessage(labels.ok)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function useApi() {\nconst shareToken = useApp(selector);\nconst defaultHeaders = {\nauthorization: `Bearer ${getClientAuthToken()}`,\n[SHARE_TOKEN_HEADER]: shareToken?.token,\n};\nconst basePath = process.env.basePath;\nconst getUrl = (url: string) => {\nreturn url.startsWith('http') ? url : `${basePath || ''}/api${url}`;\n};\nconst getHeaders = (headers: any = {}) => {\nreturn { ...defaultHeaders, ...headers };\n};\nreturn {\nget: useCallback(\nasync (url: string, params: object = {}, headers: object = {}) => {\nreturn httpGet(getUrl(url), params, getHeaders(headers)).then(handleResponse);\n},\n[httpGet],\n),\npost: useCallback(\nasync (url: string, params: object = {}, headers: object = {}) => {\nreturn httpPost(getUrl(url), params, getHeaders(headers)).then(handleResponse);\n},\n[httpPost],\n),\nput: useCallback(\nasync (url: string, params: object = {}, headers: object = {}) => {\nreturn httpPut(getUrl(url), params, getHeaders(headers)).then(handleResponse);\n},\n[httpPut],\n),\ndel: useCallback(\nasync (url: string, params: object = {}, headers: object = {}) => {\nreturn httpDelete(getUrl(url), params, getHeaders(headers)).then(handleResponse);\n},\n[httpDelete],\n),\nuseQuery,\nuseMutation,\n};\n}"
"export function useFilterParameters() {\nconst {\nquery: {\npath,\nreferrer,\ntitle,\nquery,\nhost,\nos,\nbrowser,\ndevice,\ncountry,\nregion,\ncity,\nevent,\ntag,\nhostname,\npage,\npageSize,\nsearch,\nsegment,\ncohort,\n},\n} = useNavigation();\nreturn useMemo(() => {\nreturn {\npath,\nreferrer,\ntitle,\nquery,\nhost,\nos,\nbrowser,\ndevice,\ncountry,\nregion,\ncity,\nevent,\ntag,\nhostname,\nsearch,\nsegment,\ncohort,\n};\n}, [\npath,\nreferrer,\ntitle,\nquery,\nhost,\nos,\nbrowser,\ndevice,\ncountry,\nregion,\ncity,\nevent,\ntag,\nhostname,\npage,\npageSize,\nsearch,\nsegment,\ncohort,\n]);\n}"
"export function useFormat() {\nconst { formatMessage, labels } = useMessages();\nconst { locale } = useLocale();\nconst { countryNames } = useCountryNames(locale);\nconst { languageNames } = useLanguageNames(locale);\nconst formatOS = (value: string): string => {\nreturn OS_NAMES[value] || value;\n};\nconst formatBrowser = (value: string): string => {\nreturn BROWSERS[value] || value;\n};\nconst formatDevice = (value: string): string => {\nreturn formatMessage(labels[value] || labels.unknown);\n};\nconst formatCountry = (value: string): string => {\nreturn countryNames[value] || value;\n};\nconst formatRegion = (value?: string): string => {\nconst [country] = value?.split('-') || [];\nreturn regions[value] ? `${regions[value]}, ${countryNames[country]}` : value;\n};\nconst formatCity = (value: string, country?: string): string => {\nreturn countryNames[country] ? `${value}, ${countryNames[country]}` : value;\n};\nconst formatLanguage = (value: string): string => {\nreturn languageNames[value?.split('-')[0]] || value;\n};\nconst formatValue = (value: string, type: string, data?: Record<string, any>): string => {\nswitch (type) {\ncase 'os':\nreturn formatOS(value);\ncase 'browser':\nreturn formatBrowser(value);\ncase 'device':\nreturn formatDevice(value);\ncase 'country':\nreturn formatCountry(value);\ncase 'region':\nreturn formatRegion(value);\ncase 'city':\nreturn formatCity(value, data?.country);\ncase 'language':\nreturn formatLanguage(value);\ndefault:\nreturn typeof value === 'string' ? value : undefined;\n}\n};\nreturn {\nformatOS,\nformatBrowser,\nformatDevice,\nformatCountry,\nformatRegion,\nformatCity,\nformatLanguage,\nformatValue,\n};\n}"
"export function useLocale() {\nconst locale = useApp(selector);\nconst forceUpdate = useForceUpdate();\nconst dir = getTextDirection(locale);\nconst dateLocale = getDateLocale(locale);\nasync function loadMessages(locale: string) {\nconst { data } = await httpGet(`${process.env.basePath || ''}/intl/messages/${locale}.json`);\nmessages[locale] = data;\n}\nasync function saveLocale(value: string) {\nif (!messages[value]) {\nawait loadMessages(value);\n}\nsetItem(LOCALE_CONFIG, value);\ndocument.getElementById('__next')?.setAttribute('dir', getTextDirection(value));\nif (locale !== value) {\nsetLocale(value);\n} else {\nforceUpdate();\n}\n}\nuseEffect(() => {\nif (!messages[locale]) {\nsaveLocale(locale);\n}\n}, [locale]);\nuseEffect(() => {\nconst url = new URL(window?.location?.href);\nconst locale = url.searchParams.get('locale');\nif (locale) {\nsaveLocale(locale);\n}\n}, []);\nreturn { locale, saveLocale, messages, dir, dateLocale };\n}"
"export function DialogButton({\nicon,\nlabel,\ntitle,\nwidth,\nheight,\nminWidth,\nminHeight,\nchildren,\n...props\n}: DialogButtonProps) {\nconst { isMobile } = useMobile();\nconst style: CSSProperties = {\nwidth,\nheight,\nminWidth,\nminHeight,\nmaxHeight: 'calc(100dvh - 40px)',\npadding: '32px',\n};\nif (isMobile) {\nstyle.width = '100%';\nstyle.height = '100%';\nstyle.maxHeight = '100%';\nstyle.overflowY = 'auto';\n}\nreturn (\n<DialogTrigger>\n<Button {...props}>\n<IconLabel icon={icon} label={label} />\n</Button>\n<Modal placement={isMobile ? 'fullscreen' : 'center'}>\n<Dialog variant={isMobile ? 'sheet' : undefined} title={title || label} style={style}>\n{children}\n</Dialog>\n</Modal>\n</DialogTrigger>\n);\n}"
"export function LookupField({ websiteId, type, value, onChange, ...props }: LookupFieldProps) {\nconst { formatMessage, messages } = useMessages();\nconst [search, setSearch] = useState(value);\nconst searchValue = useDebounce(search, 300);\nconst startDate = subMonths(endOfDay(new Date()), 6);\nconst endDate = endOfDay(new Date());\nconst { data, isLoading } = useWebsiteValuesQuery({\nwebsiteId,\ntype,\nsearch: searchValue,\nstartDate,\nendDate,\n});\nconst items: string[] = useMemo(() => {\nreturn data?.map(({ value }) => value) || [];\n}, [data]);\nconst handleSearch = (value: SetStateAction<string>) => {\nsetSearch(value);\n};\nreturn (\n<ComboBox\naria-label=`LookupField`\n{...props}\nitems={items}\ninputValue={value}\nonInputChange={value => {\nhandleSearch(value);\nonChange?.(value);\n}}\nformValue=`text`\nallowsEmptyCollection\nallowsCustomValue\nrenderEmptyState={() =>\nisLoading ? (\n<Loading placement=`center` icon=`dots` />\n) : (\n<Empty message={formatMessage(messages.noResultsFound)} />\n)\n}\n>\n{items.map(item => (\n<ListItem key={item} id={item}>\n{item}\n</ListItem>\n))}\n</ComboBox>\n);\n}"
"export function MonthSelect({ date = new Date(), onChange }) {\nconst { locale } = useLocale();\nconst month = date.getMonth();\nconst year = date.getFullYear();\nconst currentYear = new Date().getFullYear();\nconst months = [...Array(12)].map((_, i) => i);\nconst years = [...Array(10)].map((_, i) => currentYear - i);\nconst handleMonthChange = (month: number) => {\nconst d = new Date(date);\nd.setMonth(month);\nonChange?.(d);\n};\nconst handleYearChange = (year: number) => {\nconst d = new Date(date);\nd.setFullYear(year);\nonChange?.(d);\n};\nreturn (\n<Row gap>\n<Select value={month} onChange={handleMonthChange}>\n{months.map(m => {\nreturn (\n<ListItem id={m} key={m}>\n{formatDate(new Date(year, m, 1), 'MMMM', locale)}\n</ListItem>\n);\n})}\n</Select>\n<Select value={year} onChange={handleYearChange}>\n{years.map(y => {\nreturn (\n<ListItem id={y} key={y}>\n{y}\n</ListItem>\n);\n})}\n</Select>\n</Row>\n);\n}"
"export function ProfileButton() {\nconst { formatMessage, labels } = useMessages();\nconst { user } = useLoginQuery();\nconst { renderUrl } = useNavigation();\nconst items = [\n{\nid: 'settings',\nlabel: formatMessage(labels.profile),\npath: renderUrl('/settings/profile'),\nicon: <UserCircle />,\n},\nuser.isAdmin &&\n!process.env.cloudMode && {\nid: 'admin',\nlabel: formatMessage(labels.admin),\npath: '/admin',\nicon: <LockKeyhole />,\n},\n{\nid: 'logout',\nlabel: formatMessage(labels.logout),\npath: '/logout',\nicon: <LogOut />,\nseparator: true,\n},\n].filter(n => n);\nreturn (\n<MenuTrigger>\n<Button data-test=`button-profile` variant=`quiet`>\n<Icon>\n<UserCircle />\n</Icon>\n</Button>\n<Popover placement=`bottom end`>\n<Menu autoFocus=`last`>\n<MenuSection title={user.username}>\n<MenuSeparator />\n{items.map(({ id, path, label, icon, separator }) => {\nreturn (\n<Fragment key={id}>\n{separator && <MenuSeparator />}\n<MenuItem id={id} href={path}>\n<Row alignItems=`center` gap>\n<Icon>{icon}</Icon>\n<Text>{label}</Text>\n</Row>\n</MenuItem>\n</Fragment>\n);\n})}\n</MenuSection>\n</Menu>\n</Popover>\n</MenuTrigger>\n);\n}"
"export function ReportEditButton({\nid,\nname,\ntype,\nchildren,\nonDelete,\n}: {\nid: string;\nname: string;\ntype: string;\nonDelete?: () => void;\nchildren: ({ close }: { close: () => void }) => ReactNode;\n}) {\nconst { formatMessage, labels, messages } = useMessages();\nconst [showEdit, setShowEdit] = useState(false);\nconst [showDelete, setShowDelete] = useState(false);\nconst { mutateAsync, touch } = useDeleteQuery(`/reports/${id}`);\nconst handleAction = (id: any) => {\nif (id === 'edit') {\nsetShowEdit(true);\n} else if (id === 'delete') {\nsetShowDelete(true);\n}\n};\nconst handleClose = () => {\nsetShowEdit(false);\nsetShowDelete(false);\n};\nconst handleDelete = async () => {\nawait mutateAsync(null, {\nonSuccess: async () => {\ntouch(`reports:${type}`);\nsetShowDelete(false);\nonDelete?.();\n},\n});\n};\nreturn (\n<>\n<MenuTrigger>\n<Button variant=`quiet`>\n<Icon>\n<MoreHorizontal />\n</Icon>\n</Button>\n<Popover placement=`bottom`>\n<Menu onAction={handleAction}>\n<MenuItem id=`edit`>\n<Icon>\n<Edit />\n</Icon>\n<Text>{formatMessage(labels.edit)}</Text>\n</MenuItem>\n<MenuItem id=`delete`>\n<Icon>\n<Trash />\n</Icon>\n<Text>{formatMessage(labels.delete)}</Text>\n</MenuItem>\n</Menu>\n</Popover>\n</MenuTrigger>\n<Modal isOpen={showEdit || showDelete} isDismissable={true}>\n{showEdit && children({ close: handleClose })}\n{showDelete && (\n<AlertDialog\ntitle={formatMessage(labels.delete)}\nonConfirm={handleDelete}\nonCancel={handleClose}\nisDanger\n>\n<Row gap=`1`>{formatMessage(messages.confirmDelete, { target: name })}</Row>\n</AlertDialog>\n)}\n</Modal>\n</>\n);\n}"
"export function SettingsButton() {\nconst { formatMessage, labels } = useMessages();\nconst { user } = useLoginQuery();\nconst { router } = useNavigation();\nconst { cloudMode } = useConfig();\nconst handleAction = (id: Key) => {\nconst url = id.toString();\nif (cloudMode) {\nif (url === '/docs') {\nwindow.open(DOCS_URL, '_blank');\n} else {\nwindow.location.href = url;\n}\n} else {\nrouter.push(url);\n}\n};\nreturn (\n<MenuTrigger>\n<Button data-test=`button-profile` variant=`quiet` autoFocus={false}>\n<Icon>\n<UserCircle />\n</Icon>\n</Button>\n<Popover placement=`bottom end`>\n<Menu autoFocus=`last` onAction={handleAction}>\n<MenuSection title={user.username}>\n<MenuSeparator />\n<MenuItem id=`/settings` icon={<Settings />} label={formatMessage(labels.settings)} />\n{!cloudMode && user.isAdmin && (\n<MenuItem id=`/admin` icon={<LockKeyhole />} label={formatMessage(labels.admin)} />\n)}\n{cloudMode && (\n<>\n<MenuItem\nid=`/docs`\nicon={<BookText />}\nlabel={formatMessage(labels.documentation)}\n>\n<Icon color=`muted`>\n<ExternalLink />\n</Icon>\n</MenuItem>\n<MenuItem\nid=`/settings/support`\nicon={<LifeBuoy />}\nlabel={formatMessage(labels.support)}\n/>\n</>\n)}\n<MenuSeparator />\n<MenuItem id=`/logout` icon={<LogOut />} label={formatMessage(labels.logout)} />\n</MenuSection>\n</Menu>\n</Popover>\n</MenuTrigger>\n);\n}"
"export function WebsiteSelect({\nwebsiteId,\nteamId,\nonChange,\nincludeTeams,\n...props\n}: {\nwebsiteId?: string;\nteamId?: string;\nincludeTeams?: boolean;\n} & SelectProps) {\nconst { formatMessage, messages } = useMessages();\nconst { data: website } = useWebsiteQuery(websiteId);\nconst [name, setName] = useState<string>(website?.name);\nconst [search, setSearch] = useState('');\nconst { user } = useLoginQuery();\nconst { data, isLoading } = useUserWebsitesQuery(\n{ userId: user?.id, teamId },\n{ search, pageSize: 10, includeTeams },\n);\nconst listItems: { id: string; name: string }[] = data?.['data'] || [];\nconst handleSearch = (value: string) => {\nsetSearch(value);\n};\nconst handleOpenChange = () => {\nsetSearch('');\n};\nconst handleChange = (id: string) => {\nsetName(listItems.find(item => item.id === id)?.name);\nonChange(id);\n};\nconst renderValue = () => {\nreturn (\n<Row maxWidth=`160px`>\n<Text truncate>{name}</Text>\n</Row>\n);\n};\nreturn (\n<Select\n{...props}\nitems={listItems}\nvalue={websiteId}\nisLoading={isLoading}\nallowSearch={true}\nsearchValue={search}\nonSearch={handleSearch}\nonChange={handleChange}\nonOpenChange={handleOpenChange}\nrenderValue={renderValue}\nlistProps={{\nrenderEmptyState: () => <Empty message={formatMessage(messages.noResultsFound)} />,\nstyle: { maxHeight: '400px' },\n}}\n>\n{({ id, name }: any) => <ListItem key={id}>{name}</ListItem>}\n</Select>\n);\n}"
"export function ChangeLabel({\nvalue,\nsize,\nreverseColors,\nchildren,\n...props\n}: {\nvalue: number;\nsize?: 'xs' | 'sm' | 'md' | 'lg';\ntitle?: string;\nreverseColors?: boolean;\nshowPercentage?: boolean;\nchildren?: ReactNode;\n} & RowProps) {\nconst positive = value >= 0;\nconst negative = value < 0;\nconst neutral = value === 0 || isNaN(value);\nconst good = reverseColors ? negative : positive;\nconst style =\nSTYLES[good && 'positive'] || STYLES[!good && 'negative'] || STYLES[neutral && 'neutral'];\nreturn (\n<Row\n{...props}\nstyle={style}\nalignItems=`center`\nalignSelf=`flex-start`\npaddingX=`2`\npaddingY=`1`\ngap=`2`\n>\n{!neutral && (\n<Icon rotate={positive ? -90 : 90} size={size}>\n<ArrowRight />\n</Icon>\n)}\n<Text>{children || value}</Text>\n</Row>\n);\n}"
"export function ListTable({\ndata = [],\ntitle,\nmetric,\nrenderLabel,\nrenderChange,\nanimate = true,\nvirtualize = false,\nshowPercentage = true,\nitemCount = 10,\ncurrency,\n}: ListTableProps) {\nconst { formatMessage, labels } = useMessages();\nconst { isPhone } = useMobile();\nconst getRow = (row: ListData, index: number) => {\nconst { label, count, percent } = row;\nreturn (\n<AnimatedRow\nkey={`${label}${index}`}\nlabel={renderLabel ? renderLabel(row, index) : (label ?? formatMessage(labels.unknown))}\nvalue={count}\npercent={percent}\nanimate={animate && !virtualize}\nshowPercentage={showPercentage}\nchange={renderChange ? renderChange(row, index) : null}\ncurrency={currency}\nisPhone={isPhone}\n/>\n);\n};\nconst ListTableRow = ({ index, style }) => {\nreturn <div style={style}>{getRow(data[index], index)}</div>;\n};\nreturn (\n<Column gap>\n<Grid alignItems=`center` justifyContent=`space-between` paddingLeft=`2` columns=`1fr 100px`>\n<Text weight=`bold`>{title}</Text>\n<Text weight=`bold` align=`center`>\n{metric}\n</Text>\n</Grid>\n<Column gap=`1`>\n{data?.length === 0 && <Empty />}\n{virtualize && data.length > 0 ? (\n<FixedSizeList\nwidth=`100%`\nheight={itemCount * ITEM_SIZE}\nitemCount={data.length}\nitemSize={ITEM_SIZE}\n>\n{ListTableRow}\n</FixedSizeList>\n) : (\ndata.map(getRow)\n)}\n</Column>\n</Column>\n);\n}"
"export function MetricsTable({\nwebsiteId,\ntype,\ndataFilter,\nlimit,\nshowMore = false,\nfilterLink = true,\nparams,\nonDataLoad,\n...props\n}: MetricsTableProps) {\nconst { updateParams } = useNavigation();\nconst { formatMessage, labels } = useMessages();\nconst { data, isLoading, isFetching, error } = useWebsiteMetricsQuery(websiteId, {\ntype,\nlimit,\n...params,\n});\nconst filteredData = useMemo(() => {\nif (data) {\nlet items = data as any[];\nif (dataFilter) {\nif (Array.isArray(dataFilter)) {\nitems = dataFilter.reduce((arr, filter) => {\nreturn filter(arr);\n}, items);\n} else {\nitems = dataFilter(items);\n}\n}\nitems = percentFilter(items);\nreturn items.map(({ x, y, z, ...props }) => ({ label: x, count: y, percent: z, ...props }));\n}\nreturn [];\n}, [data, dataFilter, limit, type]);\nuseEffect(() => {\nif (data) {\nonDataLoad?.(data);\n}\n}, [data]);\nconst renderLabel = (row: any) => {\nreturn filterLink ? <MetricLabel type={type} data={row} /> : row.label;\n};\nreturn (\n<LoadingPanel\ndata={data}\nisFetching={isFetching}\nisLoading={isLoading}\nerror={error}\nminHeight=`400px`\n>\n<Grid>\n{data && <ListTable {...props} data={filteredData} renderLabel={renderLabel} />}\n{showMore && limit && (\n<Row justifyContent=`center` alignItems=`flex-end`>\n<LinkButton href={updateParams({ view: type })} variant=`quiet`>\n<Icon size=`sm`>\n<Maximize />\n</Icon>\n<Text>{formatMessage(labels.more)}</Text>\n</LinkButton>\n</Row>\n)}\n</Grid>\n</LoadingPanel>\n);\n}"
"export async function getRealtimeData(websiteId: string, filters: QueryFilters) {\nconst [activity, pageviews, sessions] = await Promise.all([\ngetRealtimeActivity(websiteId, filters),\ngetPageviewStats(websiteId, filters),\ngetSessionStats(websiteId, filters),\n]);\nconst uniques = new Set();\nconst { countries, urls, referrers, events } = activity.reverse().reduce(\n(\nobj: { countries: any; urls: any; referrers: any; events: any },\nevent: {\nsessionId: string;\nurlPath: string;\nreferrerDomain: string;\ncountry: string;\neventName: string;\n},\n) => {\nconst { countries, urls, referrers, events } = obj;\nconst { sessionId, urlPath, referrerDomain, country, eventName } = event;\nif (!uniques.has(sessionId)) {\nuniques.add(sessionId);\nincrement(countries, country);\nevents.push({ __type: 'session', ...event });\n}\nincrement(urls, urlPath);\nincrement(referrers, referrerDomain);\nevents.push({ __type: eventName ? 'event' : 'pageview', ...event });\nreturn obj;\n},\n{\ncountries: {},\nurls: {},\nreferrers: {},\nevents: [],\n},\n);\nreturn {\ncountries,\nurls,\nreferrers,\nevents: events.reverse(),\nseries: {\nviews: pageviews,\nvisitors: sessions,\n},\ntotals: {\nviews: pageviews.reduce((sum: number, { y }: { y: number }) => Number(sum) + Number(y), 0),\nvisitors: sessions.reduce((sum: number, { y }: { y: number }) => Number(sum) + Number(y), 0),\nevents: activity.filter(e => e.eventName).length,\ncountries: Object.keys(countries).length,\n},\ntimestamp: Date.now(),\n};\n}"
"async function relationalQuery(websiteId: string, column: string, filters: QueryFilters) {\nconst { rawQuery, getSearchSQL } = prisma;\nconst params = {};\nconst { startDate, endDate, search } = filters;\nlet searchQuery = '';\nlet excludeDomain = '';\nif (column === 'referrer_domain') {\nexcludeDomain = `and website_event.referrer_domain != website_event.hostname\nand website_event.referrer_domain != ''`;\n}\nif (search) {\nif (decodeURIComponent(search).includes(',')) {\nsearchQuery = `AND (${decodeURIComponent(search)\n.split(',')\n.slice(0, 5)\n.map((value: string, index: number) => {\nconst key = `search${index}`;\nparams[key] = value;\nreturn getSearchSQL(column, key).replace('and ', '');\n})\n.join(' OR ')})`;\n} else {\nsearchQuery = getSearchSQL(column);\n}\n}\nreturn rawQuery(\n`\nselect ${column} as `value`, count(*) as `count`\nfrom website_event\ninner join session\non session.session_id = website_event.session_id\nand session.website_id = website_event.website_id\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\n${searchQuery}\n${excludeDomain}\ngroup by 1\norder by 2 desc\nlimit 10\n`,\n{\nwebsiteId,\nstartDate,\nendDate,\nsearch: `%${search}%`,\n...params,\n},\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(websiteId: string, column: string, filters: QueryFilters) {\nconst { rawQuery, getSearchSQL } = clickhouse;\nconst params = {};\nconst { startDate, endDate, search } = filters;\nlet searchQuery = '';\nlet excludeDomain = '';\nif (column === 'referrer_domain') {\nexcludeDomain = `and referrer_domain != hostname and referrer_domain != ''`;\n}\nif (search) {\nsearchQuery = `and positionCaseInsensitive(${column}, {search:String}) > 0`;\n}\nif (search) {\nif (decodeURIComponent(search).includes(',')) {\nsearchQuery = `AND (${decodeURIComponent(search)\n.split(',')\n.slice(0, 5)\n.map((value: string, index: number) => {\nconst key = `search${index}`;\nparams[key] = value;\nreturn getSearchSQL(column, key).replace('and ', '');\n})\n.join(' OR ')})`;\n} else {\nsearchQuery = getSearchSQL(column);\n}\n}\nreturn rawQuery(\n`\nselect ${column} as `value`, count(*) as `count`\nfrom website_event\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${searchQuery}\n${excludeDomain}\ngroup by 1\norder by 2 desc\nlimit 10\n`,\n{\nwebsiteId,\nstartDate,\nendDate,\nsearch,\n...params,\n},\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<WebsiteStatsData[]> {\nconst { rawQuery, parseFilters } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nlet sql = '';\nif (EVENT_COLUMNS.some(item => Object.keys(filters).includes(item))) {\nsql = `\nselect\nsum(t.c) as `pageviews`,\nuniq(t.session_id) as `visitors`,\nuniq(t.visit_id) as `visits`,\nsum(if(t.c = 1, 1, 0)) as `bounces`,\nsum(max_time-min_time) as `totaltime`\nfrom (\nselect\nsession_id,\nvisit_id,\ncount(*) c,\nmin(created_at) min_time,\nmax(created_at) max_time\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by session_id, visit_id\n) as t;\n`;\n} else {\nsql = `\nselect\nsum(t.c) as `pageviews`,\nuniq(session_id) as `visitors`,\nuniq(visit_id) as `visits`,\nsumIf(1, t.c = 1) as `bounces`,\nsum(max_time-min_time) as `totaltime`\nfrom (select\nsession_id,\nvisit_id,\nsum(views) c,\nmin(min_time) min_time,\nmax(max_time) max_time\nfrom website_event_stats_hourly `website_event`\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by session_id, visit_id\n) as t;\n`;\n}\nreturn rawQuery(sql, queryParams, FUNCTION_NAME).then(result => result?.[0]);\n}"
"export function AdminNav({ onItemClick }: { onItemClick?: () => void }) {\nconst { formatMessage, labels } = useMessages();\nconst { pathname } = useNavigation();\nconst items = [\n{\nlabel: formatMessage(labels.manage),\nitems: [\n{\nid: 'users',\nlabel: formatMessage(labels.users),\npath: '/admin/users',\nicon: <User />,\n},\n{\nid: 'websites',\nlabel: formatMessage(labels.websites),\npath: '/admin/websites',\nicon: <Globe />,\n},\n{\nid: 'teams',\nlabel: formatMessage(labels.teams),\npath: '/admin/teams',\nicon: <Users />,\n},\n],\n},\n];\nconst selectedKey = items\n.flatMap(e => e.items)\n?.find(({ path }) => path && pathname.startsWith(path))?.id;\nreturn (\n<SideMenu\nitems={items}\ntitle={formatMessage(labels.admin)}\nselectedKey={selectedKey}\nallowMinimize={false}\nonItemClick={onItemClick}\n/>\n);\n}"
"export function BoardAddForm({\nteamId,\nonSave,\nonClose,\n}: {\nteamId?: string;\nonSave?: () => void;\nonClose?: () => void;\n}) {\nconst { formatMessage, labels, messages } = useMessages();\nconst { mutateAsync, error, isPending } = useUpdateQuery('/websites', { teamId });\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\nonSave?.();\nonClose?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={error?.message}>\n<FormField\nlabel={formatMessage(labels.name)}\ndata-test=`input-name`\nname=`name`\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField autoComplete=`off` />\n</FormField>\n<FormField\nlabel={formatMessage(labels.domain)}\ndata-test=`input-domain`\nname=`domain`\nrules={{\nrequired: formatMessage(labels.required),\npattern: { value: DOMAIN_REGEX, message: formatMessage(messages.invalidDomain) },\n}}\n>\n<TextField autoComplete=`off` />\n</FormField>\n<Row justifyContent=`flex-end` paddingTop=`3` gap=`3`>\n{onClose && (\n<Button isDisabled={isPending} onPress={onClose}>\n{formatMessage(labels.cancel)}\n</Button>\n)}\n<FormSubmitButton data-test=`button-submit` isDisabled={false}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</Row>\n</Form>\n);\n}"
"export function LinkDeleteButton({\nlinkId,\nname,\nonSave,\n}: {\nlinkId: string;\nwebsiteId: string;\nname: string;\nonSave?: () => void;\n}) {\nconst { formatMessage, labels, getErrorMessage, FormattedMessage } = useMessages();\nconst { mutateAsync, isPending, error, touch } = useDeleteQuery(`/links/${linkId}`);\nconst handleConfirm = async (close: () => void) => {\nawait mutateAsync(null, {\nonSuccess: () => {\ntouch('links');\nonSave?.();\nclose();\n},\n});\n};\nreturn (\n<DialogButton\nicon={<Trash />}\ntitle={formatMessage(labels.confirm)}\nvariant=`quiet`\nwidth=`400px`\n>\n{({ close }) => (\n<ConfirmationForm\nmessage={\n<FormattedMessage\n{...messages.confirmRemove}\nvalues={{\ntarget: <b>{name}</b>,\n}}\n/>\n}\nisLoading={isPending}\nerror={getErrorMessage(error)}\nonConfirm={handleConfirm.bind(null, close)}\nonClose={close}\nbuttonLabel={formatMessage(labels.delete)}\nbuttonVariant=`danger`\n/>\n)}\n</DialogButton>\n);\n}"
"export function PixelDeleteButton({\npixelId,\nname,\nonSave,\n}: {\npixelId: string;\nname: string;\nonSave?: () => void;\n}) {\nconst { formatMessage, labels, getErrorMessage, FormattedMessage } = useMessages();\nconst { mutateAsync, isPending, error } = useDeleteQuery(`/pixels/${pixelId}`);\nconst { touch } = useModified();\nconst handleConfirm = async (close: () => void) => {\nawait mutateAsync(null, {\nonSuccess: () => {\ntouch('pixels');\nonSave?.();\nclose();\n},\n});\n};\nreturn (\n<DialogButton\nicon={<Trash />}\nvariant=`quiet`\ntitle={formatMessage(labels.confirm)}\nwidth=`400px`\n>\n{({ close }) => (\n<ConfirmationForm\nmessage={\n<FormattedMessage\n{...messages.confirmRemove}\nvalues={{\ntarget: <b>{name}</b>,\n}}\n/>\n}\nisLoading={isPending}\nerror={getErrorMessage(error)}\nonConfirm={handleConfirm.bind(null, close)}\nonClose={close}\nbuttonLabel={formatMessage(labels.delete)}\nbuttonVariant=`danger`\n/>\n)}\n</DialogButton>\n);\n}"
"export function SettingsNav({ onItemClick }: { onItemClick?: () => void }) {\nconst { formatMessage, labels } = useMessages();\nconst { renderUrl, pathname } = useNavigation();\nconst items = [\n{\nlabel: formatMessage(labels.application),\nitems: [\n{\nid: 'preferences',\nlabel: formatMessage(labels.preferences),\npath: renderUrl('/settings/preferences'),\nicon: <Settings2 />,\n},\n],\n},\n{\nlabel: formatMessage(labels.account),\nitems: [\n{\nid: 'profile',\nlabel: formatMessage(labels.profile),\npath: renderUrl('/settings/profile'),\nicon: <UserCircle />,\n},\n{\nid: 'teams',\nlabel: formatMessage(labels.teams),\npath: renderUrl('/settings/teams'),\nicon: <Users />,\n},\n],\n},\n];\nconst selectedKey = items\n.flatMap(e => e.items)\n.find(({ path }) => path && pathname.includes(path.split('?')[0]))?.id;\nreturn (\n<SideMenu\nitems={items}\ntitle={formatMessage(labels.settings)}\nselectedKey={selectedKey}\nallowMinimize={false}\nonItemClick={onItemClick}\n/>\n);\n}"
"export function TeamLeaveForm({\nteamId,\nuserId,\nteamName,\nonSave,\nonClose,\n}: {\nteamId: string;\nuserId: string;\nteamName: string;\nonSave: () => void;\nonClose: () => void;\n}) {\nconst { formatMessage, labels, messages, getErrorMessage, FormattedMessage } = useMessages();\nconst { mutateAsync, error, isPending } = useDeleteQuery(`/teams/${teamId}/users/${userId}`);\nconst { touch } = useModified();\nconst handleConfirm = async () => {\nawait mutateAsync(null, {\nonSuccess: async () => {\ntouch('teams:members');\nonSave();\nonClose();\n},\n});\n};\nreturn (\n<ConfirmationForm\nbuttonLabel={formatMessage(labels.leave)}\nmessage={\n<FormattedMessage\n{...messages.confirmLeave}\nvalues={{\ntarget: <b>{teamName}</b>,\n}}\n/>\n}\nonConfirm={handleConfirm}\nonClose={onClose}\nisLoading={isPending}\nerror={getErrorMessage(error)}\n/>\n);\n}"
"export function WebsiteAddForm({\nteamId,\nonSave,\nonClose,\n}: {\nteamId?: string;\nonSave?: () => void;\nonClose?: () => void;\n}) {\nconst { formatMessage, labels, messages } = useMessages();\nconst { mutateAsync, error, isPending } = useUpdateQuery('/websites', { teamId });\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\nonSave?.();\nonClose?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={error?.message}>\n<FormField\nlabel={formatMessage(labels.name)}\ndata-test=`input-name`\nname=`name`\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField autoComplete=`off` />\n</FormField>\n<FormField\nlabel={formatMessage(labels.domain)}\ndata-test=`input-domain`\nname=`domain`\nrules={{\nrequired: formatMessage(labels.required),\npattern: { value: DOMAIN_REGEX, message: formatMessage(messages.invalidDomain) },\n}}\n>\n<TextField autoComplete=`off` />\n</FormField>\n<Row justifyContent=`flex-end` paddingTop=`3` gap=`3`>\n{onClose && (\n<Button isDisabled={isPending} onPress={onClose}>\n{formatMessage(labels.cancel)}\n</Button>\n)}\n<FormSubmitButton data-test=`button-submit` isDisabled={false}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</Row>\n</Form>\n);\n}"
"export async function POST(request: Request) {\nconst schema = z.object({\nname: z.string().max(100),\ndomain: z.string().max(500),\nshareId: z.string().max(50).nullable().optional(),\nteamId: z.uuid().nullable().optional(),\nid: z.uuid().nullable().optional(),\n});\nconst { auth, body, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { id, name, domain, shareId, teamId } = body;\nif (process.env.CLOUD_MODE && !teamId) {\nconst account = await redis.client.get(`account:${auth.user.id}`);\nif (!account?.hasSubscription) {\nconst count = await getWebsiteCount(auth.user.id);\nif (count >= CLOUD_WEBSITE_LIMIT) {\nreturn unauthorized({ message: 'Website limit reached.' });\n}\n}\n}\nif ((teamId && !(await canCreateTeamWebsite(auth, teamId))) || !(await canCreateWebsite(auth))) {\nreturn unauthorized();\n}\nconst data: any = {\nid: id ?? uuid(),\ncreatedBy: auth.user.id,\nname,\ndomain,\nshareId,\nteamId,\n};\nif (!teamId) {\ndata.userId = auth.user.id;\n}\nconst website = await createWebsite(data);\nreturn json(website);\n}"
"export function useWebsiteValuesQuery({\nwebsiteId,\ntype,\nstartDate,\nendDate,\nsearch,\n}: {\nwebsiteId: string;\ntype: string;\nstartDate: Date;\nendDate: Date;\nsearch?: string;\n}) {\nconst { get, useQuery } = useApi();\nconst { locale } = useLocale();\nconst { countryNames } = useCountryNames(locale);\nconst { regionNames } = useRegionNames(locale);\nconst names = {\ncountry: countryNames,\nregion: regionNames,\n};\nconst getSearch = (type: string, value: string) => {\nif (value) {\nconst values = names[type];\nif (values) {\nreturn (\nObject.keys(values)\n.reduce((arr: string[], key: string) => {\nif (values[key].toLowerCase().includes(value.toLowerCase())) {\nreturn arr.concat(key);\n}\nreturn arr;\n}, [])\n.slice(0, 5)\n.join(',') || value\n);\n}\nreturn value;\n}\n};\nreturn useQuery({\nqueryKey: ['websites:values', { websiteId, type, startDate, endDate, search }],\nqueryFn: () =>\nget(`/websites/${websiteId}/values`, {\ntype,\nstartAt: +startDate,\nendAt: +endDate,\nsearch: getSearch(type, search),\n}),\nenabled: !!(websiteId && type && startDate && endDate),\n});\n}"
"async function relationalQuery(websiteId: string, filters: QueryFilters) {\nconst { rawQuery, parseFilters } = prisma;\nconst { event } = filters;\nconst { queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nif (event) {\nreturn rawQuery(\n`\nselect\nwebsite_event.event_name as `eventName`,\nevent_data.data_key as `propertyName`,\nevent_data.data_type as `dataType`,\nevent_data.string_value as `propertyValue`,\ncount(*) as `total`\nfrom event_data\ninner join website_event\non website_event.event_id = event_data.website_event_id\nwhere event_data.website_id = {{websiteId::uuid}}\nand event_data.created_at between {{startDate}} and {{endDate}}\nand website_event.event_name = {{event}}\ngroup by website_event.event_name, event_data.data_key, event_data.data_type, event_data.string_value\norder by 1 asc, 2 asc, 3 asc, 5 desc\n`,\nqueryParams,\nFUNCTION_NAME,\n);\n}\nreturn rawQuery(\n`\nselect\nwebsite_event.event_name as `eventName`,\nevent_data.data_key as `propertyName`,\nevent_data.data_type as `dataType`,\ncount(*) as `total`\nfrom event_data\ninner join website_event\non website_event.event_id = event_data.website_event_id\nwhere event_data.website_id = {{websiteId::uuid}}\nand event_data.created_at between {{startDate}} and {{endDate}}\nlimit 500\n`,\nqueryParams,\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<{ eventName: string; propertyName: string; dataType: number; total: number }[]> {\nconst { rawQuery, parseFilters } = clickhouse;\nconst { event } = filters;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nif (event) {\nreturn rawQuery(\n`\nselect\nevent_name as eventName,\ndata_key as propertyName,\ndata_type as dataType,\nstring_value as propertyValue,\ncount(*) as total\nfrom event_data\njoin website_event\non website_event.event_id = event_data.event_id\nand website_event.website_id = event_data.website_id\nand website_event.website_id = {websiteId:UUID}\nand website_event.created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${cohortQuery}\nwhere event_data.website_id = {websiteId:UUID}\nand event_data.created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_data.event_name = {event:String}\n${filterQuery}\ngroup by data_key, data_type, string_value, event_name\norder by 1 asc, 2 asc, 3 asc, 5 desc\nlimit 500\n`,\nqueryParams,\nFUNCTION_NAME,\n);\n}\nreturn rawQuery(\n`\nselect\nevent_name as eventName,\ndata_key as propertyName,\ndata_type as dataType,\ncount(*) as total\nfrom event_data\njoin website_event\non website_event.event_id = event_data.event_id\nand website_event.website_id = event_data.website_id\nand website_event.website_id = {websiteId:UUID}\nand website_event.created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${cohortQuery}\nwhere event_data.website_id = {websiteId:UUID}\nand event_data.created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\ngroup by data_key, data_type, event_name\norder by 1 asc, 2 asc\nlimit 500\n`,\nqueryParams,\nFUNCTION_NAME,\n);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: EventExpandedMetricParameters,\nfilters: QueryFilters,\n) {\nconst { type, limit = 500, offset = 0 } = parameters;\nconst column = FILTER_COLUMNS[type] || type;\nconst { rawQuery, parseFilters, getTimestampDiffSQL } = prisma;\nconst { filterQuery, cohortQuery, joinSessionQuery, queryParams } = parseFilters(\n{\n...filters,\nwebsiteId,\neventType: EVENT_TYPE.customEvent,\n},\n{ joinSession: SESSION_COLUMNS.includes(type) },\n);\nreturn rawQuery(\n`\nselect\nname,\nsum(t.c) as `pageviews`,\ncount(distinct t.session_id) as `visitors`,\ncount(distinct t.visit_id) as `visits`,\nsum(case when t.c = 1 then 1 else 0 end) as `bounces`,\nsum(${getTimestampDiffSQL('t.min_time', 't.max_time')}) as `totaltime`\nfrom (\nselect\n${column} name,\nwebsite_event.session_id,\nwebsite_event.visit_id,\ncount(*) as `c`,\nmin(website_event.created_at) as `min_time`,\nmax(website_event.created_at) as `max_time`\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\n${filterQuery}\ngroup by name, website_event.session_id, website_event.visit_id\n) as t\ngroup by name\norder by visitors desc, visits desc\nlimit ${limit}\noffset ${offset}\n`,\nqueryParams,\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nparameters: EventExpandedMetricParameters,\nfilters: QueryFilters,\n): Promise<EventExpandedMetricData[]> {\nconst { type, limit = 500, offset = 0 } = parameters;\nconst column = FILTER_COLUMNS[type] || type;\nconst { rawQuery, parseFilters } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\neventType: EVENT_TYPE.customEvent,\n});\nreturn rawQuery(\n`\nselect\nname,\nsum(t.c) as `pageviews`,\nuniq(t.session_id) as `visitors`,\nuniq(t.visit_id) as `visits`,\nsum(if(t.c = 1, 1, 0)) as `bounces`,\nsum(max_time-min_time) as `totaltime`\nfrom (\nselect\n${column} name,\nsession_id,\nvisit_id,\ncount(*) c,\nmin(created_at) min_time,\nmax(created_at) max_time\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand name != ''\n${filterQuery}\ngroup by name, session_id, visit_id\n) as t\ngroup by name\norder by visitors desc, visits desc\nlimit ${limit}\noffset ${offset}\n`,\n{ ...queryParams, ...parameters },\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<{ x: string; t: string; y: number }[]> {\nconst { timezone = 'UTC', unit = 'day' } = filters;\nconst { rawQuery, getDateSQL, parseFilters } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\neventType: EVENT_TYPE.customEvent,\n});\nlet sql = '';\nif (filterQuery || cohortQuery) {\nsql = `\nselect\nevent_name x,\n${getDateSQL('created_at', unit, timezone)} t,\ncount(*) y\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\ngroup by x, t\norder by t\n`;\n} else {\nsql = `\nselect\nevent_name x,\n${getDateSQL('created_at', unit, timezone)} t,\ncount(*) y\nfrom (\nselect arrayJoin(event_name) as event_name,\ncreated_at\nfrom website_event_stats_hourly website_event\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type = {eventType:UInt32}\n) as g\ngroup by x, t\norder by t\n`;\n}\nreturn rawQuery(sql, queryParams, FUNCTION_NAME);\n}"
"async function relationalQuery(websiteId: string, filters: QueryFilters) {\nconst { pagedRawQuery, parseFilters } = prisma;\nconst { search } = filters;\nconst { filterQuery, dateQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nconst searchQuery = search\n? `and ((event_name ilike {{search}} and event_type = 2)\nor (url_path ilike {{search}} and event_type = 1))`\n: '';\nreturn pagedRawQuery(\n`\nselect\nwebsite_event.event_id as `id`,\nwebsite_event.website_id as `websiteId`,\nwebsite_event.session_id as `sessionId`,\nwebsite_event.created_at as `createdAt`,\nwebsite_event.hostname,\nwebsite_event.url_path as `urlPath`,\nwebsite_event.url_query as `urlQuery`,\nwebsite_event.referrer_path as `referrerPath`,\nwebsite_event.referrer_query as `referrerQuery`,\nwebsite_event.referrer_domain as `referrerDomain`,\nsession.country as country,\ncity as city,\ndevice as  device,\nos as os,\nbrowser as browser,\npage_title as `pageTitle`,\nwebsite_event.event_type as `eventType`,\nwebsite_event.event_name as `eventName`,\nevent_id IN (select website_event_id\nfrom event_data\nwhere website_id = {{websiteId::uuid}}\nand created_at between {{startDate}} and {{endDate}}) AS `hasData`\nfrom website_event\n${cohortQuery}\njoin session on session.session_id = website_event.session_id\nand session.website_id = website_event.website_id\nwhere website_event.website_id = {{websiteId::uuid}}\n${dateQuery}\n${filterQuery}\n${searchQuery}\norder by website_event.created_at desc\n`,\nqueryParams,\nfilters,\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(websiteId: string, filters: QueryFilters) {\nconst { pagedRawQuery, parseFilters } = clickhouse;\nconst { search } = filters;\nconst { queryParams, dateQuery, cohortQuery, filterQuery } = parseFilters({\n...filters,\nwebsiteId,\n});\nconst searchQuery = search\n? `and ((positionCaseInsensitive(event_name, {search:String}) > 0 and event_type = 2)\nor (positionCaseInsensitive(url_path, {search:String}) > 0 and event_type = 1))`\n: '';\nreturn pagedRawQuery(\n`\nselect\nevent_id as id,\nwebsite_id as websiteId,\nsession_id as sessionId,\ncreated_at as createdAt,\nhostname,\nurl_path as urlPath,\nurl_query as urlQuery,\nreferrer_path as referrerPath,\nreferrer_query as referrerQuery,\nreferrer_domain as referrerDomain,\ncountry as country,\ncity as city,\ndevice as device,\nos as os,\nbrowser as browser,\npage_title as pageTitle,\nevent_type as eventType,\nevent_name as eventName,\nevent_id IN (select event_id\nfrom event_data\nwhere website_id = {websiteId:UUID}\n${dateQuery}) as hasData\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\n${dateQuery}\n${filterQuery}\n${searchQuery}\norder by created_at desc\n`,\nqueryParams,\nfilters,\nFUNCTION_NAME,\n);\n}"
"async function relationalQuery({\nwebsiteId,\nsessionId,\nvisitId,\neventType,\ncreatedAt,\npageTitle,\nhostname,\nurlPath,\nurlQuery,\nreferrerPath,\nreferrerQuery,\nreferrerDomain,\neventName,\neventData,\ntag,\nutmSource,\nutmMedium,\nutmCampaign,\nutmContent,\nutmTerm,\ngclid,\nfbclid,\nmsclkid,\nttclid,\nlifatid,\ntwclid,\n}: SaveEventArgs) {\nconst websiteEventId = uuid();\nawait prisma.client.websiteEvent.create({\ndata: {\nid: websiteEventId,\nwebsiteId,\nsessionId,\nvisitId,\nurlPath: urlPath?.substring(0, URL_LENGTH),\nurlQuery: urlQuery?.substring(0, URL_LENGTH),\nutmSource,\nutmMedium,\nutmCampaign,\nutmContent,\nutmTerm,\nreferrerPath: referrerPath?.substring(0, URL_LENGTH),\nreferrerQuery: referrerQuery?.substring(0, URL_LENGTH),\nreferrerDomain: referrerDomain?.substring(0, URL_LENGTH),\npageTitle: pageTitle?.substring(0, PAGE_TITLE_LENGTH),\ngclid,\nfbclid,\nmsclkid,\nttclid,\nlifatid,\ntwclid,\neventType,\neventName: eventName ? eventName?.substring(0, EVENT_NAME_LENGTH) : null,\ntag,\nhostname,\ncreatedAt,\n},\n});\nif (eventData) {\nawait saveEventData({\nwebsiteId,\nsessionId,\neventId: websiteEventId,\nurlPath: urlPath?.substring(0, URL_LENGTH),\neventName: eventName?.substring(0, EVENT_NAME_LENGTH),\neventData,\ncreatedAt,\n});\nconst { revenue, currency } = eventData;\nif (revenue > 0 && currency) {\nawait saveRevenue({\nwebsiteId,\nsessionId,\neventId: websiteEventId,\neventName: eventName?.substring(0, EVENT_NAME_LENGTH),\ncurrency,\nrevenue,\ncreatedAt,\n});\n}\n}\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: PageviewMetricsParameters,\nfilters: QueryFilters,\n): Promise<PageviewMetricsData[]> {\nconst { type, limit = 500, offset = 0 } = parameters;\nlet column = FILTER_COLUMNS[type] || type;\nconst { rawQuery, parseFilters } = prisma;\nconst { filterQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters(\n{\n...filters,\nwebsiteId,\n},\n{ joinSession: SESSION_COLUMNS.includes(type) },\n);\nlet entryExitQuery = '';\nlet excludeDomain = '';\nif (column === 'referrer_domain') {\nexcludeDomain = `and website_event.referrer_domain != website_event.hostname\nand website_event.referrer_domain != ''`;\n}\nif (type === 'entry' || type === 'exit') {\nconst order = type === 'entry' ? 'asc' : 'desc';\ncolumn = `x.${column}`;\nentryExitQuery = `\njoin (\nselect distinct on (visit_id)\nvisit_id,\nurl_path\nfrom website_event\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\nand website_event.event_type != 2\norder by visit_id, created_at ${order}\n) x\non x.visit_id = website_event.visit_id\n`;\n}\nreturn rawQuery(\n`\nselect ${column} x,\ncount(distinct website_event.session_id) as y\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\n${entryExitQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\nand website_event.event_type != 2\n${excludeDomain}\n${filterQuery}\ngroup by 1\norder by 2 desc\nlimit ${limit}\noffset ${offset}\n`,\n{ ...queryParams, ...parameters },\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<{ x: string; y: number }[]> {\nconst { timezone = 'UTC', unit = 'day' } = filters;\nconst { parseFilters, rawQuery, getDateSQL } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nlet sql = '';\nif (EVENT_COLUMNS.some(item => Object.keys(filters).includes(item)) || unit === 'minute') {\nsql = `\nselect\ng.t as x,\ng.y as y\nfrom (\nselect\n${getDateSQL('website_event.created_at', unit, timezone)} as t,\ncount(*) as y\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by t\n) as g\norder by t\n`;\n} else {\nsql = `\nselect\ng.t as x,\ng.y as y\nfrom (\nselect\n${getDateSQL('website_event.created_at', unit, timezone)} as t,\nsum(views) as y\nfrom website_event_stats_hourly as website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by t\n) as g\norder by t\n`;\n}\nreturn rawQuery(sql, queryParams, FUNCTION_NAME);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: BreakdownParameters,\nfilters: QueryFilters,\n): Promise<BreakdownData[]> {\nconst { getTimestampDiffSQL, parseFilters, rawQuery } = prisma;\nconst { startDate, endDate, fields } = parameters;\nconst { filterQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters(\n{\n...filters,\nwebsiteId,\nstartDate,\nendDate,\neventType: EVENT_TYPE.pageView,\n},\n{\njoinSession: !!fields.find((name: string) => SESSION_COLUMNS.includes(name)),\n},\n);\nreturn rawQuery(\n`\nselect\nsum(t.c) as `views`,\ncount(distinct t.session_id) as `visitors`,\ncount(distinct t.visit_id) as `visits`,\nsum(case when t.c = 1 then 1 else 0 end) as `bounces`,\nsum(${getTimestampDiffSQL('t.min_time', 't.max_time')}) as `totaltime`,\n${parseFieldsByName(fields)}\nfrom (\nselect\n${parseFields(fields)},\nwebsite_event.session_id,\nwebsite_event.visit_id,\ncount(*) as `c`,\nmin(website_event.created_at) as `min_time`,\nmax(website_event.created_at) as `max_time`\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\n${filterQuery}\ngroup by ${parseFieldsByName(fields)},\nwebsite_event.session_id, website_event.visit_id\n) as t\ngroup by ${parseFieldsByName(fields)}\norder by 1 desc, 2 desc\nlimit 500\n`,\nqueryParams,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nparameters: BreakdownParameters,\nfilters: QueryFilters,\n): Promise<BreakdownData[]> {\nconst { parseFilters, rawQuery } = clickhouse;\nconst { startDate, endDate, fields } = parameters;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\nstartDate,\nendDate,\neventType: EVENT_TYPE.pageView,\n});\nreturn rawQuery(\n`\nselect\nsum(t.c) as `views`,\ncount(distinct t.session_id) as `visitors`,\ncount(distinct t.visit_id) as `visits`,\nsum(if(t.c = 1, 1, 0)) as `bounces`,\nsum(max_time-min_time) as `totaltime`,\n${parseFieldsByName(fields)}\nfrom (\nselect\n${parseFields(fields)},\nsession_id,\nvisit_id,\ncount(*) c,\nmin(created_at) min_time,\nmax(created_at) max_time\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\ngroup by ${parseFieldsByName(fields)},\nsession_id, visit_id\n) as t\ngroup by ${parseFieldsByName(fields)}\norder by 1 desc, 2 desc\nlimit 500\n`,\nqueryParams,\n);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: GoalParameters,\nfilters: QueryFilters,\n) {\nconst { startDate, endDate, type, value } = parameters;\nconst { rawQuery, parseFilters } = prisma;\nconst eventType = type === 'path' ? EVENT_TYPE.pageView : EVENT_TYPE.customEvent;\nconst column = type === 'path' ? 'url_path' : 'event_name';\nconst { filterQuery, dateQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\nvalue,\nstartDate,\nendDate,\neventType,\n});\nreturn rawQuery(\n`\nselect count(distinct website_event.session_id) as num,\n(\nselect count(distinct website_event.session_id)\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\n${dateQuery}\n${filterQuery}\n) as total\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand ${column} = {{value}}\n${dateQuery}\n${filterQuery}\n`,\nqueryParams,\n).then(results => results?.[0]);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: RetentionParameters,\nfilters: QueryFilters,\n): Promise<RetentionResult[]> {\nconst { startDate, endDate, timezone } = parameters;\nconst { getDateSQL, getDayDiffQuery, getCastColumnQuery, rawQuery, parseFilters } = prisma;\nconst unit = 'day';\nconst { filterQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\nstartDate,\nendDate,\ntimezone,\n});\nreturn rawQuery(\n`\nWITH cohort_items AS (\nselect\nmin(${getDateSQL('website_event.created_at', unit, timezone)}) as cohort_date,\nwebsite_event.session_id\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\n${filterQuery}\ngroup by website_event.session_id\n),\nuser_activities AS (\nselect distinct\nwebsite_event.session_id,\n${getDayDiffQuery(getDateSQL('created_at', unit, timezone), 'cohort_items.cohort_date')} as day_number\nfrom website_event\njoin cohort_items\non website_event.session_id = cohort_items.session_id\nwhere website_id = {{websiteId::uuid}}\nand created_at between {{startDate}} and {{endDate}}\n),\ncohort_size as (\nselect cohort_date,\ncount(*) as visitors\nfrom cohort_items\ngroup by 1\norder by 1\n),\ncohort_date as (\nselect\nc.cohort_date,\na.day_number,\ncount(*) as visitors\nfrom user_activities a\njoin cohort_items c\non a.session_id = c.session_id\ngroup by 1, 2\n)\nselect\nc.cohort_date as date,\nc.day_number as day,\ns.visitors,\nc.visitors as `returnVisitors`,\n${getCastColumnQuery('c.visitors', 'float')} * 100 / s.visitors  as percentage\nfrom cohort_date c\njoin cohort_size s\non c.cohort_date = s.cohort_date\nwhere c.day_number <= 31\norder by 1, 2`,\nqueryParams,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nparameters: RetentionParameters,\nfilters: QueryFilters,\n): Promise<RetentionResult[]> {\nconst { startDate, endDate, timezone } = parameters;\nconst { getDateSQL, rawQuery, parseFilters } = clickhouse;\nconst unit = 'day';\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\nstartDate,\nendDate,\ntimezone,\n});\nreturn rawQuery(\n`\nWITH cohort_items AS (\nselect\nmin(${getDateSQL('created_at', unit, timezone)}) as cohort_date,\nsession_id\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\ngroup by session_id\n),\nuser_activities AS (\nselect distinct\nwebsite_event.session_id,\ntoInt32((${getDateSQL('created_at', unit, timezone)} - cohort_items.cohort_date) / 86400) as day_number\nfrom website_event\njoin cohort_items\non website_event.session_id = cohort_items.session_id\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n),\ncohort_size as (\nselect cohort_date,\ncount(*) as visitors\nfrom cohort_items\ngroup by 1\norder by 1\n),\ncohort_date as (\nselect\nc.cohort_date,\na.day_number,\ncount(*) as visitors\nfrom user_activities a\njoin cohort_items c\non a.session_id = c.session_id\ngroup by 1, 2\n)\nselect\nc.cohort_date as date,\nc.day_number as day,\ns.visitors as visitors,\nc.visitors returnVisitors,\nc.visitors * 100 / s.visitors as percentage\nfrom cohort_date c\njoin cohort_size s\non c.cohort_date = s.cohort_date\nwhere c.day_number <= 31\norder by 1, 2`,\nqueryParams,\n);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: SessionExpandedMetricsParameters,\nfilters: QueryFilters,\n): Promise<SessionExpandedMetricsData[]> {\nconst { type, limit = 500, offset = 0 } = parameters;\nlet column = FILTER_COLUMNS[type] || type;\nconst { parseFilters, rawQuery, getTimestampDiffSQL } = prisma;\nconst { filterQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters(\n{\n...filters,\nwebsiteId,\n},\n{\njoinSession: SESSION_COLUMNS.includes(type),\n},\n);\nconst includeCountry = column === 'city' || column === 'region';\nif (type === 'language') {\ncolumn = `lower(left(${type}, 2))`;\n}\nreturn rawQuery(\n`\nselect\nname,\n${includeCountry ? 'country,' : ''}\nsum(t.c) as `pageviews`,\ncount(distinct t.session_id) as `visitors`,\ncount(distinct t.visit_id) as `visits`,\nsum(case when t.c = 1 then 1 else 0 end) as `bounces`,\nsum(${getTimestampDiffSQL('t.min_time', 't.max_time')}) as `totaltime`\nfrom (\nselect\n${column} name,\n${includeCountry ? 'country,' : ''}\nwebsite_event.session_id,\nwebsite_event.visit_id,\ncount(*) as `c`,\nmin(website_event.created_at) as `min_time`,\nmax(website_event.created_at) as `max_time`\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\nand website_event.event_type != 2\n${filterQuery}\ngroup by name, website_event.session_id, website_event.visit_id\n${includeCountry ? ', country' : ''}\n) as t\ngroup by name\n${includeCountry ? ', country' : ''}\norder by visitors desc, visits desc\nlimit ${limit}\noffset ${offset}\n`,\n{ ...queryParams, ...parameters },\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nparameters: SessionExpandedMetricsParameters,\nfilters: QueryFilters,\n): Promise<SessionExpandedMetricsData[]> {\nconst { type, limit = 500, offset = 0 } = parameters;\nlet column = FILTER_COLUMNS[type] || type;\nconst { parseFilters, rawQuery } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nconst includeCountry = column === 'city' || column === 'region';\nif (type === 'language') {\ncolumn = `lower(left(${type}, 2))`;\n}\nreturn rawQuery(\n`\nselect\nname,\n${includeCountry ? 'country,' : ''}\nsum(t.c) as `pageviews`,\nuniq(t.session_id) as `visitors`,\nuniq(t.visit_id) as `visits`,\nsum(if(t.c = 1, 1, 0)) as `bounces`,\nsum(max_time-min_time) as `totaltime`\nfrom (\nselect\n${column} name,\n${includeCountry ? 'country,' : ''}\nsession_id,\nvisit_id,\ncount(*) c,\nmin(created_at) min_time,\nmax(created_at) max_time\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\nand name != ''\n${filterQuery}\ngroup by name, session_id, visit_id\n${includeCountry ? ', country' : ''}\n) as t\ngroup by name\n${includeCountry ? ', country' : ''}\norder by visitors desc, visits desc\nlimit ${limit}\noffset ${offset}\n`,\n{ ...queryParams, ...parameters },\nFUNCTION_NAME,\n);\n}"
"async function relationalQuery(\nwebsiteId: string,\nparameters: SessionMetricsParameters,\nfilters: QueryFilters,\n) {\nconst { type, limit = 500, offset = 0 } = parameters;\nlet column = FILTER_COLUMNS[type] || type;\nconst { parseFilters, rawQuery } = prisma;\nconst { filterQuery, joinSessionQuery, cohortQuery, queryParams } = parseFilters(\n{\n...filters,\nwebsiteId,\n},\n{\njoinSession: SESSION_COLUMNS.includes(type),\n},\n);\nconst includeCountry = column === 'city' || column === 'region';\nif (type === 'language') {\ncolumn = `lower(left(${type}, 2))`;\n}\nreturn rawQuery(\n`\nselect\n${column} x,\ncount(distinct website_event.session_id) y\n${includeCountry ? ', country' : ''}\nfrom website_event\n${cohortQuery}\n${joinSessionQuery}\nwhere website_event.website_id = {{websiteId::uuid}}\nand website_event.created_at between {{startDate}} and {{endDate}}\nand website_event.event_type != 2\n${filterQuery}\ngroup by 1\n${includeCountry ? ', 3' : ''}\norder by 2 desc\nlimit ${limit}\noffset ${offset}\n`,\n{ ...queryParams, ...parameters },\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nparameters: SessionMetricsParameters,\nfilters: QueryFilters,\n): Promise<{ x: string; y: number }[]> {\nconst { type, limit = 500, offset = 0 } = parameters;\nlet column = FILTER_COLUMNS[type] || type;\nconst { parseFilters, rawQuery } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nconst includeCountry = column === 'city' || column === 'region';\nif (type === 'language') {\ncolumn = `lower(left(${type}, 2))`;\n}\nlet sql = '';\nif (EVENT_COLUMNS.some(item => Object.keys(filters).includes(item))) {\nsql = `\nselect\n${column} x,\ncount(distinct session_id) y\n${includeCountry ? ', country' : ''}\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by x\n${includeCountry ? ', country' : ''}\norder by y desc\nlimit ${limit}\noffset ${offset}\n`;\n} else {\nsql = `\nselect\n${column} x,\nuniq(session_id) y\n${includeCountry ? ', country' : ''}\nfrom website_event_stats_hourly as website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by x\n${includeCountry ? ', country' : ''}\norder by y desc\nlimit ${limit}\noffset ${offset}\n`;\n}\nreturn rawQuery(sql, { ...queryParams, ...parameters }, FUNCTION_NAME);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<{ x: string; y: number }[]> {\nconst { timezone = 'UTC', unit = 'day' } = filters;\nconst { parseFilters, rawQuery, getDateSQL } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\n});\nlet sql = '';\nif (EVENT_COLUMNS.some(item => Object.keys(filters).includes(item)) || unit === 'minute') {\nsql = `\nselect\ng.t as x,\ng.y as y\nfrom (\nselect\n${getDateSQL('website_event.created_at', unit, timezone)} as t,\ncount(distinct session_id) as y\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by t\n) as g\norder by t\n`;\n} else {\nsql = `\nselect\ng.t as x,\ng.y as y\nfrom (\nselect\n${getDateSQL('website_event.created_at', unit, timezone)} as t,\nuniq(session_id) as y\nfrom website_event_stats_hourly as website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\nand event_type != 2\n${filterQuery}\ngroup by t\n) as g\norder by t\n`;\n}\nreturn rawQuery(sql, queryParams, FUNCTION_NAME);\n}"
"async function relationalQuery(websiteId: string, sessionId: string) {\nconst { rawQuery, getTimestampDiffSQL } = prisma;\nreturn rawQuery(\n`\nselect id,\ndistinct_id as `distinctId`,\nwebsite_id as `websiteId`,\nbrowser,\nos,\ndevice,\nscreen,\nlanguage,\ncountry,\nregion,\ncity,\nmin(min_time) as `firstAt`,\nmax(max_time) as `lastAt`,\ncount(distinct visit_id) as visits,\nsum(views) as views,\nsum(events) as events,\nsum(${getTimestampDiffSQL('min_time', 'max_time')}) as `totaltime`\nfrom (select\nsession.session_id as id,\nsession.distinct_id,\nwebsite_event.visit_id,\nsession.website_id,\nsession.browser,\nsession.os,\nsession.device,\nsession.screen,\nsession.language,\nsession.country,\nsession.region,\nsession.city,\nmin(website_event.created_at) as min_time,\nmax(website_event.created_at) as max_time,\nsum(case when website_event.event_type = 1 then 1 else 0 end) as views,\nsum(case when website_event.event_type = 2 then 1 else 0 end) as events\nfrom session\njoin website_event on website_event.session_id = session.session_id\nwhere session.website_id = {{websiteId::uuid}}\nand session.session_id = {{sessionId::uuid}}\ngroup by session.session_id, session.distinct_id, visit_id, session.website_id, session.browser, session.os, session.device, session.screen, session.language, session.country, session.region, session.city) t\ngroup by id, distinct_id, website_id, browser, os, device, screen, language, country, region, city;\n`,\n{ websiteId, sessionId },\nFUNCTION_NAME,\n).then(result => result?.[0]);\n}"
"async function clickhouseQuery(websiteId: string, sessionId: string) {\nconst { rawQuery, getDateStringSQL } = clickhouse;\nreturn rawQuery(\n`\nselect id,\nwebsiteId,\ndistinctId,\nbrowser,\nos,\ndevice,\nscreen,\nlanguage,\ncountry,\nregion,\ncity,\n${getDateStringSQL('min(min_time)')} as firstAt,\n${getDateStringSQL('max(max_time)')} as lastAt,\nuniq(visit_id) visits,\nsum(views) as views,\nsum(events) as events,\nsum(max_time-min_time) as totaltime\nfrom (select\nsession_id as id,\ndistinct_id as distinctId,\nvisit_id,\nwebsite_id as websiteId,\nbrowser,\nos,\ndevice,\nscreen,\nlanguage,\ncountry,\nregion,\ncity,\nmin(min_time) as min_time,\nmax(max_time) as max_time,\nsum(views) as views,\nlength(groupArrayArray(event_name)) as events\nfrom website_event_stats_hourly\nwhere website_id = {websiteId:UUID}\nand session_id = {sessionId:UUID}\ngroup by session_id, distinct_id, visit_id, website_id, browser, os, device, screen, language, country, region, city) t\ngroup by id, websiteId, distinctId, browser, os, device, screen, language, country, region, city;\n`,\n{ websiteId, sessionId },\nFUNCTION_NAME,\n).then(result => result?.[0]);\n}"
"async function relationalQuery(websiteId: string, filters: QueryFilters) {\nconst { pagedRawQuery, parseFilters } = prisma;\nconst { search } = filters;\nconst { filterQuery, dateQuery, cohortQuery, queryParams } = parseFilters({\n...filters,\nwebsiteId,\nsearch: search ? `%${search}%` : undefined,\n});\nconst searchQuery = search\n? `and (distinct_id ilike {{search}}\nor city ilike {{search}}\nor browser ilike {{search}}\nor os ilike {{search}}\nor device ilike {{search}})`\n: '';\nreturn pagedRawQuery(\n`\nselect\nsession.session_id as `id`,\nsession.website_id as `websiteId`,\nwebsite_event.hostname,\nsession.browser,\nsession.os,\nsession.device,\nsession.screen,\nsession.language,\nsession.country,\nsession.region,\nsession.city,\nmin(website_event.created_at) as `firstAt`,\nmax(website_event.created_at) as `lastAt`,\ncount(distinct website_event.visit_id) as `visits`,\nsum(case when website_event.event_type = 1 then 1 else 0 end) as `views`,\nmax(website_event.created_at) as `createdAt`\nfrom website_event\n${cohortQuery}\njoin session on session.session_id = website_event.session_id\nand session.website_id = website_event.website_id\nwhere website_event.website_id = {{websiteId::uuid}}\n${dateQuery}\n${filterQuery}\n${searchQuery}\ngroup by session.session_id,\nsession.website_id,\nwebsite_event.hostname,\nsession.browser,\nsession.os,\nsession.device,\nsession.screen,\nsession.language,\nsession.country,\nsession.region,\nsession.city\norder by max(website_event.created_at) desc\n`,\nqueryParams,\nfilters,\nFUNCTION_NAME,\n);\n}"
"async function clickhouseQuery(\nwebsiteId: string,\nfilters: QueryFilters,\n): Promise<WebsiteSessionStatsData[]> {\nconst { rawQuery, parseFilters } = clickhouse;\nconst { filterQuery, cohortQuery, queryParams } = parseFilters({ ...filters, websiteId });\nlet sql = '';\nif (EVENT_COLUMNS.some(item => Object.keys(filters).includes(item))) {\nsql = `\nselect\nsumIf(1, event_type = 1) as `pageviews`,\nuniq(session_id) as `visitors`,\nuniq(visit_id) as `visits`,\nuniq(country) as `countries`,\nsum(length(event_name)) as `events`\nfrom website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\n`;\n} else {\nsql = `\nselect\nsum(views) as `pageviews`,\nuniq(session_id) as `visitors`,\nuniq(visit_id) as `visits`,\nuniq(country) as `countries`,\nsum(length(event_name)) as `events`\nfrom website_event_stats_hourly website_event\n${cohortQuery}\nwhere website_id = {websiteId:UUID}\nand created_at between {startDate:DateTime64} and {endDate:DateTime64}\n${filterQuery}\n`;\n}\nreturn rawQuery(sql, queryParams, FUNCTION_NAME);\n}"
"export async function relationalQuery({\nwebsiteId,\nsessionId,\nsessionData,\ndistinctId,\ncreatedAt,\n}: SaveSessionDataArgs) {\nconst { client } = prisma;\nconst jsonKeys = flattenJSON(sessionData);\nconst flattenedData = jsonKeys.map(a => ({\nid: uuid(),\nwebsiteId,\nsessionId,\ndataKey: a.key,\nstringValue: getStringValue(a.value, a.dataType),\nnumberValue: a.dataType === DATA_TYPE.number ? a.value : null,\ndateValue: a.dataType === DATA_TYPE.date ? new Date(a.value) : null,\ndataType: a.dataType,\ndistinctId,\ncreatedAt,\n}));\nconst existing = await client.sessionData.findMany({\nwhere: {\nsessionId,\n},\nselect: {\nid: true,\nsessionId: true,\ndataKey: true,\n},\n});\nfor (const data of flattenedData) {\nconst { sessionId, dataKey, ...props } = data;\nconst record = existing.find(e => e.sessionId === sessionId && e.dataKey === dataKey);\nif (record) {\nawait client.sessionData.update({\nwhere: {\nid: record.id,\n},\ndata: {\n...props,\n},\n});\n} else {\nawait client.sessionData.create({\ndata,\n});\n}\n}\n}"
"export async function GET(request: Request, { params }: { params: Promise<{ slug: string }> }) {\nconst { slug } = await params;\nlet pixel: Pixel;\nif (redis.enabled) {\npixel = await redis.client.fetch(\n`pixel:${slug}`,\nasync () => {\nreturn findPixel({\nwhere: {\nslug,\n},\n});\n},\n86400,\n);\nif (!pixel) {\nreturn notFound();\n}\n} else {\npixel = await findPixel({\nwhere: {\nslug,\n},\n});\nif (!pixel) {\nreturn notFound();\n}\n}\nconst payload = {\ntype: 'event',\npayload: {\npixel: pixel.id,\nurl: request.url,\nreferrer: request.headers.get('referer'),\n},\n};\nconst req = new Request(request.url, {\nmethod: 'POST',\nheaders: request.headers,\nbody: JSON.stringify(payload),\n});\nawait POST(req);\nreturn new NextResponse(image, {\nheaders: {\n'Content-Type': 'image/gif',\n'Content-Length': image.length.toString(),\n},\n});\n}"
"export async function GET(request: Request, { params }: { params: Promise<{ slug: string }> }) {\nconst { slug } = await params;\nlet link: Link;\nif (redis.enabled) {\nlink = await redis.client.fetch(\n`link:${slug}`,\nasync () => {\nreturn findLink({\nwhere: {\nslug,\n},\n});\n},\n86400,\n);\nif (!link) {\nreturn notFound();\n}\n} else {\nlink = await findLink({\nwhere: {\nslug,\n},\n});\nif (!link) {\nreturn notFound();\n}\n}\nconst payload = {\ntype: 'event',\npayload: {\nlink: link.id,\nurl: request.url,\nreferrer: request.headers.get('referer'),\n},\n};\nconst req = new Request(request.url, {\nmethod: 'POST',\nheaders: request.headers,\nbody: JSON.stringify(payload),\n});\nawait POST(req);\nreturn NextResponse.redirect(link.url);\n}"
"export function UserAddForm({ onSave, onClose }) {\nconst { mutateAsync, error, isPending } = useUpdateQuery(`/users`);\nconst { formatMessage, labels, getErrorMessage } = useMessages();\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\nonSave(data);\nonClose();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)}>\n<FormField\nlabel={formatMessage(labels.username)}\nname=`username`\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField autoComplete=`new-username` data-test=`input-username` />\n</FormField>\n<FormField\nlabel={formatMessage(labels.password)}\nname=`password`\nrules={{ required: formatMessage(labels.required) }}\n>\n<PasswordField autoComplete=`new-password` data-test=`input-password` />\n</FormField>\n<FormField\nlabel={formatMessage(labels.role)}\nname=`role`\nrules={{ required: formatMessage(labels.required) }}\n>\n<Select>\n<ListItem id={ROLES.viewOnly} data-test=`dropdown-item-viewOnly`>\n{formatMessage(labels.viewOnly)}\n</ListItem>\n<ListItem id={ROLES.user} data-test=`dropdown-item-user`>\n{formatMessage(labels.user)}\n</ListItem>\n<ListItem id={ROLES.admin} data-test=`dropdown-item-admin`>\n{formatMessage(labels.admin)}\n</ListItem>\n</Select>\n</FormField>\n<FormButtons>\n<Button isDisabled={isPending} onPress={onClose}>\n{formatMessage(labels.cancel)}\n</Button>\n<FormSubmitButton variant=`primary` data-test=`button-submit` isDisabled={false}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function UsersTable({\ndata = [],\nshowActions = true,\n}: {\ndata: any[];\nshowActions?: boolean;\n}) {\nconst { formatMessage, labels } = useMessages();\nconst [deleteUser, setDeleteUser] = useState(null);\nreturn (\n<>\n<DataTable data={data}>\n<DataColumn id=`username` label={formatMessage(labels.username)} width=`2fr`>\n{(row: any) => <Link href={`/admin/users/${row.id}`}>{row.username}</Link>}\n</DataColumn>\n<DataColumn id=`role` label={formatMessage(labels.role)}>\n{(row: any) =>\nformatMessage(\nlabels[Object.keys(ROLES).find(key => ROLES[key] === row.role)] || labels.unknown,\n)\n}\n</DataColumn>\n<DataColumn id=`websites` label={formatMessage(labels.websites)}>\n{(row: any) => row._count.websites}\n</DataColumn>\n<DataColumn id=`created` label={formatMessage(labels.created)}>\n{(row: any) => <DateDistance date={new Date(row.createdAt)} />}\n</DataColumn>\n{showActions && (\n<DataColumn id=`action` align=`end` width=`100px`>\n{(row: any) => {\nconst { id } = row;\nreturn (\n<MenuButton>\n<MenuItem href={`/admin/users/${id}`} data-test=`link-button-edit`>\n<Row alignItems=`center` gap>\n<Icon>\n<Edit />\n</Icon>\n<Text>{formatMessage(labels.edit)}</Text>\n</Row>\n</MenuItem>\n<MenuItem\nid=`delete`\nonAction={() => setDeleteUser(row)}\ndata-test=`link-button-delete`\n>\n<Row alignItems=`center` gap>\n<Icon>\n<Trash />\n</Icon>\n<Text>{formatMessage(labels.delete)}</Text>\n</Row>\n</MenuItem>\n</MenuButton>\n);\n}}\n</DataColumn>\n)}\n</DataTable>\n<Modal isOpen={!!deleteUser}>\n<UserDeleteForm\nuserId={deleteUser?.id}\nusername={deleteUser?.username}\nonClose={() => {\nsetDeleteUser(null);\n}}\n/>\n</Modal>\n</>\n);\n}"
"export function LinkMetricsBar({\nlinkId,\n}: {\nlinkId: string;\nshowChange?: boolean;\ncompareMode?: boolean;\n}) {\nconst { isAllTime } = useDateRange();\nconst { formatMessage, labels } = useMessages();\nconst { data, isLoading, isFetching, error } = useWebsiteStatsQuery(linkId);\nconst { pageviews, visitors, visits, comparison } = data || {};\nconst metrics = data\n? [\n{\nvalue: visitors,\nlabel: formatMessage(labels.visitors),\nchange: visitors - comparison.visitors,\nformatValue: formatLongNumber,\n},\n{\nvalue: visits,\nlabel: formatMessage(labels.visits),\nchange: visits - comparison.visits,\nformatValue: formatLongNumber,\n},\n{\nvalue: pageviews,\nlabel: formatMessage(labels.views),\nchange: pageviews - comparison.pageviews,\nformatValue: formatLongNumber,\n},\n]\n: null;\nreturn (\n<LoadingPanel\ndata={metrics}\nisLoading={isLoading}\nisFetching={isFetching}\nerror={error}\nminHeight=`136px`\n>\n<MetricsBar>\n{metrics?.map(({ label, value, prev, change, formatValue, reverseColors }: any) => {\nreturn (\n<MetricCard\nkey={label}\nvalue={value}\npreviousValue={prev}\nlabel={label}\nchange={change}\nformatValue={formatValue}\nreverseColors={reverseColors}\nshowChange={!isAllTime}\n/>\n);\n})}\n</MetricsBar>\n</LoadingPanel>\n);\n}"
"export function PixelMetricsBar({\npixelId,\n}: {\npixelId: string;\nshowChange?: boolean;\ncompareMode?: boolean;\n}) {\nconst { isAllTime } = useDateRange();\nconst { formatMessage, labels } = useMessages();\nconst { data, isLoading, isFetching, error } = useWebsiteStatsQuery(pixelId);\nconst { pageviews, visitors, visits, comparison } = data || {};\nconst metrics = data\n? [\n{\nvalue: visitors,\nlabel: formatMessage(labels.visitors),\nchange: visitors - comparison.visitors,\nformatValue: formatLongNumber,\n},\n{\nvalue: visits,\nlabel: formatMessage(labels.visits),\nchange: visits - comparison.visits,\nformatValue: formatLongNumber,\n},\n{\nvalue: pageviews,\nlabel: formatMessage(labels.views),\nchange: pageviews - comparison.pageviews,\nformatValue: formatLongNumber,\n},\n]\n: null;\nreturn (\n<LoadingPanel\ndata={metrics}\nisLoading={isLoading}\nisFetching={isFetching}\nerror={error}\nminHeight=`136px`\n>\n<MetricsBar>\n{metrics?.map(({ label, value, prev, change, formatValue, reverseColors }: any) => {\nreturn (\n<MetricCard\nkey={label}\nvalue={value}\npreviousValue={prev}\nlabel={label}\nchange={change}\nformatValue={formatValue}\nreverseColors={reverseColors}\nshowChange={!isAllTime}\n/>\n);\n})}\n</MetricsBar>\n</LoadingPanel>\n);\n}"
"export function LanguageSetting() {\nconst [search, setSearch] = useState('');\nconst { formatMessage, labels } = useMessages();\nconst { locale, saveLocale } = useLocale();\nconst items = search\n? Object.keys(languages).filter(n => {\nreturn (\nn.toLowerCase().includes(search.toLowerCase()) ||\nlanguages[n].label.toLowerCase().includes(search.toLowerCase())\n);\n})\n: Object.keys(languages);\nconst handleReset = () => saveLocale(DEFAULT_LOCALE);\nconst handleOpen = (isOpen: boolean) => {\nif (isOpen) {\nsetSearch('');\n}\n};\nreturn (\n<Row gap>\n<Select\nvalue={locale}\nonChange={val => saveLocale(val as string)}\nallowSearch\nonSearch={setSearch}\nonOpenChange={handleOpen}\nlistProps={{ style: { maxHeight: 300 } }}\n>\n{items.map(item => (\n<ListItem key={item} id={item}>\n{languages[item].label}\n</ListItem>\n))}\n{!items.length && <ListItem></ListItem>}\n</Select>\n<Button onPress={handleReset}>{formatMessage(labels.reset)}</Button>\n</Row>\n);\n}"
"export function PasswordEditForm({ onSave, onClose }) {\nconst { formatMessage, labels, messages, getErrorMessage } = useMessages();\nconst { mutateAsync, error, isPending } = useUpdateQuery('/me/password');\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\nonSave();\nonClose();\n},\n});\n};\nconst samePassword = (value: string, values: Record<string, any>) => {\nif (value !== values.newPassword) {\nreturn formatMessage(messages.noMatchPassword);\n}\nreturn true;\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)}>\n<FormField\nlabel={formatMessage(labels.currentPassword)}\nname=`currentPassword`\nrules={{ required: 'Required' }}\n>\n<PasswordField autoComplete=`current-password` />\n</FormField>\n<FormField\nname=`newPassword`\nlabel={formatMessage(labels.newPassword)}\nrules={{\nrequired: 'Required',\nminLength: { value: 8, message: formatMessage(messages.minPasswordLength, { n: '8' }) },\n}}\n>\n<PasswordField autoComplete=`new-password` />\n</FormField>\n<FormField\nname=`confirmPassword`\nlabel={formatMessage(labels.confirmPassword)}\nrules={{\nrequired: formatMessage(labels.required),\nminLength: { value: 8, message: formatMessage(messages.minPasswordLength, { n: '8' }) },\nvalidate: samePassword,\n}}\n>\n<PasswordField autoComplete=`confirm-password` />\n</FormField>\n<FormButtons>\n<Button onPress={onClose}>{formatMessage(labels.cancel)}</Button>\n<FormSubmitButton isDisabled={isPending}>{formatMessage(labels.save)}</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function ProfileSettings() {\nconst { user } = useLoginQuery();\nconst { formatMessage, labels } = useMessages();\nconst { cloudMode } = useConfig();\nif (!user) {\nreturn null;\n}\nconst { username, role } = user;\nconst renderRole = (value: string) => {\nif (value === ROLES.user) {\nreturn formatMessage(labels.user);\n}\nif (value === ROLES.admin) {\nreturn formatMessage(labels.admin);\n}\nif (value === ROLES.viewOnly) {\nreturn formatMessage(labels.viewOnly);\n}\nreturn formatMessage(labels.unknown);\n};\nreturn (\n<Column width=`400px` gap=`6`>\n<Column>\n<Label>{formatMessage(labels.username)}</Label>\n{username}\n</Column>\n<Column>\n<Label>{formatMessage(labels.role)}</Label>\n{renderRole(role)}\n</Column>\n{!cloudMode && (\n<Column>\n<Label>{formatMessage(labels.password)}</Label>\n<Row>\n<PasswordChangeButton />\n</Row>\n</Column>\n)}\n</Column>\n);\n}"
"export function TeamEditForm({\nteamId,\nallowEdit,\nshowAccessCode,\nonSave,\n}: {\nteamId: string;\nallowEdit?: boolean;\nshowAccessCode?: boolean;\nonSave?: () => void;\n}) {\nconst team = useTeam();\nconst { formatMessage, labels, messages, getErrorMessage } = useMessages();\nconst { mutateAsync, error, isPending, touch, toast } = useUpdateQuery(`/teams/${teamId}`);\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\ntoast(formatMessage(messages.saved));\ntouch('teams');\ntouch(`teams:${teamId}`);\nonSave?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)} defaultValues={{ ...team }}>\n{({ setValue }) => {\nreturn (\n<>\n<FormField name=`id` label={formatMessage(labels.teamId)}>\n<TextField isReadOnly allowCopy />\n</FormField>\n<FormField\nname=`name`\nlabel={formatMessage(labels.name)}\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField isReadOnly={!allowEdit} />\n</FormField>\n{showAccessCode && (\n<Row alignItems=`flex-end` gap>\n<FormField\nname=`accessCode`\nlabel={formatMessage(labels.accessCode)}\nstyle={{ flex: 1 }}\n>\n<TextField isReadOnly allowCopy />\n</FormField>\n{allowEdit && (\n<Button\nonPress={() => setValue('accessCode', generateId(), { shouldDirty: true })}\n>\n<IconLabel icon={<RefreshCw />} label={formatMessage(labels.regenerate)} />\n</Button>\n)}\n</Row>\n)}\n{allowEdit && (\n<FormButtons justifyContent=`flex-end`>\n<FormSubmitButton variant=`primary` isPending={isPending}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n)}\n</>\n);\n}}\n</Form>\n);\n}"
"export function TeamMemberEditForm({\nteamId,\nuserId,\nrole,\nonSave,\nonClose,\n}: {\nteamId: string;\nuserId: string;\nrole: string;\nonSave?: () => void;\nonClose?: () => void;\n}) {\nconst { mutateAsync, error, isPending } = useUpdateQuery(`/teams/${teamId}/users/${userId}`);\nconst { formatMessage, labels, getErrorMessage } = useMessages();\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\nonSave();\nonClose();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)} defaultValues={{ role }}>\n<FormField\nname=`role`\nrules={{ required: formatMessage(labels.required) }}\nlabel={formatMessage(labels.role)}\n>\n<Select>\n<ListItem id={ROLES.teamManager}>{formatMessage(labels.manager)}</ListItem>\n<ListItem id={ROLES.teamMember}>{formatMessage(labels.member)}</ListItem>\n<ListItem id={ROLES.teamViewOnly}>{formatMessage(labels.viewOnly)}</ListItem>\n</Select>\n</FormField>\n<FormButtons>\n<Button isDisabled={isPending} onPress={onClose}>\n{formatMessage(labels.cancel)}\n</Button>\n<FormSubmitButton variant=`primary` isDisabled={false}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function TeamMemberRemoveButton({\nteamId,\nuserId,\nuserName,\nonSave,\n}: {\nteamId: string;\nuserId: string;\nuserName: string;\ndisabled?: boolean;\nonSave?: () => void;\n}) {\nconst { formatMessage, labels, FormattedMessage } = useMessages();\nconst { mutateAsync, isPending, error } = useDeleteQuery(`/teams/${teamId}/users/${userId}`);\nconst { touch } = useModified();\nconst handleConfirm = async (close: () => void) => {\nawait mutateAsync(null, {\nonSuccess: () => {\ntouch('teams:members');\nonSave?.();\nclose();\n},\n});\n};\nreturn (\n<DialogButton\nicon={<Trash />}\ntitle={formatMessage(labels.confirm)}\nvariant=`quiet`\nwidth=`400px`\n>\n{({ close }) => (\n<ConfirmationForm\nmessage={\n<FormattedMessage\n{...messages.confirmRemove}\nvalues={{\ntarget: <b>{userName}</b>,\n}}\n/>\n}\nisLoading={isPending}\nerror={error}\nonConfirm={handleConfirm.bind(null, close)}\nonClose={close}\nbuttonLabel={formatMessage(labels.remove)}\nbuttonVariant=`danger`\n/>\n)}\n</DialogButton>\n);\n}"
"export function TeamMembersTable({\ndata = [],\nteamId,\nallowEdit = false,\n}: {\ndata: any[];\nteamId: string;\nallowEdit: boolean;\n}) {\nconst { formatMessage, labels } = useMessages();\nconst roles = {\n[ROLES.teamOwner]: formatMessage(labels.teamOwner),\n[ROLES.teamManager]: formatMessage(labels.teamManager),\n[ROLES.teamMember]: formatMessage(labels.teamMember),\n[ROLES.teamViewOnly]: formatMessage(labels.viewOnly),\n};\nreturn (\n<DataTable data={data}>\n<DataColumn id=`username` label={formatMessage(labels.username)}>\n{(row: any) => row?.user?.username}\n</DataColumn>\n<DataColumn id=`role` label={formatMessage(labels.role)}>\n{(row: any) => roles[row?.role]}\n</DataColumn>\n{allowEdit && (\n<DataColumn id=`action` align=`end`>\n{(row: any) => {\nif (row?.role === ROLES.teamOwner) {\nreturn null;\n}\nreturn (\n<Row alignItems=`center` maxHeight=`20px`>\n<TeamMemberEditButton teamId={teamId} userId={row?.user?.id} role={row?.role} />\n<TeamMemberRemoveButton\nteamId={teamId}\nuserId={row?.user?.id}\nuserName={row?.user?.username}\n/>\n</Row>\n);\n}}\n</DataColumn>\n)}\n</DataTable>\n);\n}"
"export function TeamWebsitesTable({\nteamId,\ndata = [],\nallowEdit,\n}: {\nteamId: string;\ndata: any[];\nallowEdit: boolean;\n}) {\nconst { formatMessage, labels } = useMessages();\nreturn (\n<DataTable data={data}>\n<DataColumn id=`name` label={formatMessage(labels.name)}>\n{(row: any) => <Link href={`/teams/${teamId}/websites/${row.id}`}>{row.name}</Link>}\n</DataColumn>\n<DataColumn id=`domain` label={formatMessage(labels.domain)} />\n<DataColumn id=`createdBy` label={formatMessage(labels.createdBy)}>\n{(row: any) => row?.createUser?.username}\n</DataColumn>\n{allowEdit && (\n<DataColumn id=`action` align=`end`>\n{(row: any) => {\nif (row?.role === ROLES.teamOwner) {\nreturn null;\n}\nreturn (\n<Row alignItems=`center`>\n<TeamMemberEditButton teamId={teamId} userId={row?.user?.id} role={row?.role} />\n<TeamMemberRemoveButton\nteamId={teamId}\nuserId={row?.user?.id}\nuserName={row?.user?.username}\n/>\n</Row>\n);\n}}\n</DataColumn>\n)}\n</DataTable>\n);\n}"
"export function ExpandedViewModal({\nwebsiteId,\nexcludedIds,\n}: {\nwebsiteId: string;\nexcludedIds?: string[];\n}) {\nconst {\nrouter,\nquery: { view },\nupdateParams,\n} = useNavigation();\nconst { isMobile } = useMobile();\nconst handleClose = (close: () => void) => {\nrouter.push(updateParams({ view: undefined }));\nclose();\n};\nconst handleOpenChange = (isOpen: boolean) => {\nif (!isOpen) {\nrouter.push(updateParams({ view: undefined }));\n}\n};\nreturn (\n<Modal isOpen={!!view} onOpenChange={handleOpenChange} isDismissable>\n<Dialog\nstyle={{\nmaxWidth: 1320,\nwidth: '100vw',\nheight: isMobile ? '100dvh' : 'calc(100dvh - 40px)',\noverflow: 'hidden',\n}}\n>\n{({ close }) => {\nreturn (\n<WebsiteExpandedView\nwebsiteId={websiteId}\nexcludedIds={excludedIds}\nonClose={() => handleClose(close)}\n/>\n);\n}}\n</Dialog>\n</Modal>\n);\n}"
"export function WebsiteChart({\nwebsiteId,\ncompareMode,\n}: {\nwebsiteId: string;\ncompareMode?: boolean;\n}) {\nconst { timezone } = useTimezone();\nconst { dateRange, dateCompare } = useDateRange({ timezone: timezone });\nconst { startDate, endDate, unit, value } = dateRange;\nconst { data, isLoading, isFetching, error } = useWebsitePageviewsQuery({\nwebsiteId,\ncompare: compareMode ? dateCompare?.compare : undefined,\n});\nconst { pageviews, sessions, compare } = (data || {}) as any;\nconst chartData = useMemo(() => {\nif (data) {\nconst result = {\npageviews,\nsessions,\n};\nif (compare) {\nresult['compare'] = {\npageviews: result.pageviews.map(({ x }, i) => ({\nx,\ny: compare.pageviews[i]?.y,\nd: compare.pageviews[i]?.x,\n})),\nsessions: result.sessions.map(({ x }, i) => ({\nx,\ny: compare.sessions[i]?.y,\nd: compare.sessions[i]?.x,\n})),\n};\n}\nreturn result;\n}\nreturn { pageviews: [], sessions: [] };\n}, [data, startDate, endDate, unit]);\nreturn (\n<LoadingPanel data={data} isFetching={isFetching} isLoading={isLoading} error={error}>\n<PageviewsChart\nkey={value}\ndata={chartData}\nminDate={startDate}\nmaxDate={endDate}\nunit={unit}\n/>\n</LoadingPanel>\n);\n}"
"export function WebsiteExpandedView({\nwebsiteId,\nexcludedIds = [],\nonClose,\n}: {\nwebsiteId: string;\nexcludedIds?: string[];\nonClose?: () => void;\n}) {\nconst { formatMessage, labels } = useMessages();\nconst {\nquery: { view },\n} = useNavigation();\nreturn (\n<Column height=`100%` overflow=`hidden` gap>\n<Row id=`expanded-mobile-menu-button` display={{ xs: 'flex', md: 'none' }}>\n<MobileMenuButton>\n{({ close }) => {\nreturn (\n<Column padding=`3`>\n<WebsiteExpandedMenu excludedIds={excludedIds} onItemClick={close} />\n</Column>\n);\n}}\n</MobileMenuButton>\n</Row>\n<Grid columns={{ xs: '1fr', md: 'auto 1fr' }} gap=`6` overflow=`hidden`>\n<Column\nid=`metrics-expanded-menu`\ndisplay={{ xs: 'none', md: 'flex' }}\nwidth=`240px`\ngap=`6`\nborder=`right`\npaddingRight=`3`\noverflow=`auto`\n>\n<WebsiteExpandedMenu excludedIds={excludedIds} />\n</Column>\n<Column id=`metrics-expanded-table` overflow=`hidden`>\n<MetricsExpandedTable\ntitle={formatMessage(labels[view])}\ntype={view}\nwebsiteId={websiteId}\nonClose={onClose}\n/>\n</Column>\n</Grid>\n</Column>\n);\n}"
"export function WebsiteMenu({ websiteId }: { websiteId: string }) {\nconst { formatMessage, labels } = useMessages();\nconst { router, updateParams, renderUrl } = useNavigation();\nconst menuItems = [\n{ id: 'share', label: formatMessage(labels.share), icon: <Share /> },\n{ id: 'edit', label: formatMessage(labels.edit), icon: <Edit />, seperator: true },\n];\nconst handleAction = (id: any) => {\nif (id === 'compare') {\nrouter.push(updateParams({ compare: 'prev' }));\n} else if (id === 'edit') {\nrouter.push(renderUrl(`/websites/${websiteId}`));\n}\n};\nreturn (\n<MenuTrigger>\n<Button variant=`quiet`>\n<Icon>\n<More />\n</Icon>\n</Button>\n<Popover placement=`bottom`>\n<Menu onAction={handleAction}>\n{menuItems.map(({ id, label, icon, seperator }, index) => {\nreturn (\n<Fragment key={index}>\n{seperator && <MenuSeparator />}\n<MenuItem id={id}>\n<Icon>{icon}</Icon>\n<Text>{label}</Text>\n</MenuItem>\n</Fragment>\n);\n})}\n</Menu>\n</Popover>\n</MenuTrigger>\n);\n}"
"export function WebsiteTabs() {\nconst website = useWebsite();\nconst { pathname, renderUrl } = useNavigation();\nconst { formatMessage, labels } = useMessages();\nconst links = [\n{\nid: 'overview',\nlabel: formatMessage(labels.overview),\nicon: <Eye />,\npath: '',\n},\n{\nid: 'events',\nlabel: formatMessage(labels.events),\nicon: <Lightning />,\npath: '/events',\n},\n{\nid: 'sessions',\nlabel: formatMessage(labels.sessions),\nicon: <User />,\npath: '/sessions',\n},\n{\nid: 'realtime',\nlabel: formatMessage(labels.realtime),\nicon: <Clock />,\npath: '/realtime',\n},\n{\nid: 'reports',\nlabel: formatMessage(labels.reports),\nicon: <ChartPie />,\npath: '/reports',\n},\n];\nconst selectedKey = links.find(({ path }) => path && pathname.includes(path))?.id || 'overview';\nreturn (\n<Row marginBottom=`6`>\n<Tabs selectedKey={selectedKey}>\n<TabList>\n{links.map(({ id, label, icon, path }) => {\nreturn (\n<Tab key={id} id={id} href={renderUrl(`/websites/${website.id}${path}`)}>\n<Row alignItems=`center` gap>\n<Icon>{icon}</Icon>\n<Text>{label}</Text>\n</Row>\n</Tab>\n);\n})}\n</TabList>\n</Tabs>\n</Row>\n);\n}"
"export async function GET(request: Request) {\nconst schema = z.object({\n...pagingParams,\n...searchParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nif (!(await canViewAllTeams(auth))) {\nreturn unauthorized();\n}\nconst teams = await getTeams(\n{\ninclude: {\nmembers: {\ninclude: {\nuser: {\nselect: {\nid: true,\nusername: true,\n},\n},\n},\n},\n_count: {\nselect: {\nwebsites: {\nwhere: { deletedAt: null },\n},\nmembers: {\nwhere: {\nuser: { deletedAt: null },\n},\n},\n},\n},\n},\norderBy: {\ncreatedAt: 'desc',\n},\n},\nquery,\n);\nreturn json(teams);\n}"
"export async function GET(request: Request) {\nconst schema = z.object({\n...pagingParams,\n...searchParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nif (!(await canViewAllWebsites(auth))) {\nreturn unauthorized();\n}\nconst websites = await getWebsites(\n{\ninclude: {\nuser: {\nwhere: {\ndeletedAt: null,\n},\nselect: {\nusername: true,\nid: true,\n},\n},\nteam: {\nwhere: {\ndeletedAt: null,\n},\ninclude: {\nmembers: {\nwhere: {\nrole: ROLES.teamOwner,\n},\n},\n},\n},\n},\norderBy: {\ncreatedAt: 'desc',\n},\n},\nquery,\n);\nreturn json(websites);\n}"
"export async function POST(request: Request, { params }: { params: Promise<{ userId: string }> }) {\nconst schema = z.object({\nusername: z.string().max(255).optional(),\npassword: z.string().max(255).optional(),\nrole: userRoleParam.optional(),\n});\nconst { auth, body, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { userId } = await params;\nif (!(await canUpdateUser(auth, userId))) {\nreturn unauthorized();\n}\nconst { username, password, role } = body;\nconst user = await getUser(userId);\nconst data: any = {};\nif (password) {\ndata.password = hashPassword(password);\n}\nif (role && auth.user.isAdmin) {\ndata.role = role;\n}\nif (username && auth.user.isAdmin) {\ndata.username = username;\n}\nif (data.username && user.username !== data.username) {\nconst user = await getUserByUsername(username);\nif (user) {\nreturn badRequest({ message: 'User already exists' });\n}\n}\nconst updated = await updateUser(userId, data);\nreturn json(updated);\n}"
"export function UserEditForm({ userId, onSave }: { userId: string; onSave?: () => void }) {\nconst { formatMessage, labels, messages, getMessage } = useMessages();\nconst user = useUser();\nconst { user: login } = useLoginQuery();\nconst { mutateAsync, error, toast, touch } = useUpdateQuery(`/users/${userId}`);\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\ntoast(formatMessage(messages.saved));\ntouch('users');\ntouch(`user:${user.id}`);\nonSave?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getMessage(error?.['code'])} values={user}>\n<FormField name=`username` label={formatMessage(labels.username)}>\n<TextField data-test=`input-username` />\n</FormField>\n<FormField\nname=`password`\nlabel={formatMessage(labels.password)}\nrules={{\nminLength: { value: 8, message: formatMessage(messages.minPasswordLength, { n: '8' }) },\n}}\n>\n<PasswordField autoComplete=`new-password` data-test=`input-password` />\n</FormField>\n{user.id !== login.id && (\n<FormField\nname=`role`\nlabel={formatMessage(labels.role)}\nrules={{ required: formatMessage(labels.required) }}\n>\n<Select defaultSelectedKey={user.role}>\n<ListItem id={ROLES.viewOnly} data-test=`dropdown-item-viewOnly`>\n{formatMessage(labels.viewOnly)}\n</ListItem>\n<ListItem id={ROLES.user} data-test=`dropdown-item-user`>\n{formatMessage(labels.user)}\n</ListItem>\n<ListItem id={ROLES.admin} data-test=`dropdown-item-admin`>\n{formatMessage(labels.admin)}\n</ListItem>\n</Select>\n</FormField>\n)}\n<FormButtons>\n<FormSubmitButton data-test=`button-submit` variant=`primary`>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function CohortDeleteButton({\ncohortId,\nwebsiteId,\nname,\nonSave,\n}: {\ncohortId: string;\nwebsiteId: string;\nname: string;\nonSave?: () => void;\n}) {\nconst { formatMessage, labels, FormattedMessage } = useMessages();\nconst { mutateAsync, isPending, error, touch } = useDeleteQuery(\n`/websites/${websiteId}/segments/${cohortId}`,\n);\nconst handleConfirm = async (close: () => void) => {\nawait mutateAsync(null, {\nonSuccess: () => {\ntouch('cohorts');\nonSave?.();\nclose();\n},\n});\n};\nreturn (\n<DialogButton\nicon={<Trash />}\nvariant=`quiet`\ntitle={formatMessage(labels.confirm)}\nwidth=`400px`\n>\n{({ close }) => (\n<ConfirmationForm\nmessage={\n<FormattedMessage\n{...messages.confirmRemove}\nvalues={{\ntarget: <b>{name}</b>,\n}}\n/>\n}\nisLoading={isPending}\nerror={error}\nonConfirm={handleConfirm.bind(null, close)}\nonClose={close}\nbuttonLabel={formatMessage(labels.delete)}\nbuttonVariant=`danger`\n/>\n)}\n</DialogButton>\n);\n}"
"export function EventProperties({ websiteId }: { websiteId: string }) {\nconst [propertyName, setPropertyName] = useState('');\nconst [eventName, setEventName] = useState('');\nconst { formatMessage, labels } = useMessages();\nconst { data, isLoading, isFetching, error } = useEventDataPropertiesQuery(websiteId);\nconst events: string[] = data\n? data.reduce((arr: string | any[], e: { eventName: any }) => {\nreturn !arr.includes(e.eventName) ? arr.concat(e.eventName) : arr;\n}, [])\n: [];\nconst properties: string[] = eventName\n? data?.filter(e => e.eventName === eventName).map(e => e.propertyName)\n: [];\nreturn (\n<LoadingPanel\ndata={data}\nisLoading={isLoading}\nisFetching={isFetching}\nerror={error}\nminHeight=`300px`\n>\n<Column gap=`6`>\n{data && (\n<Grid columns=`repeat(auto-fill, minmax(300px, 1fr))` marginBottom=`3` gap>\n<Select\nlabel={formatMessage(labels.event)}\nvalue={eventName}\nonChange={setEventName}\nplaceholder=``\n>\n{events?.map(p => (\n<ListItem key={p} id={p}>\n{p}\n</ListItem>\n))}\n</Select>\n<Select\nlabel={formatMessage(labels.property)}\nvalue={propertyName}\nonChange={setPropertyName}\nisDisabled={!eventName}\nplaceholder=``\n>\n{properties?.map(p => (\n<ListItem key={p} id={p}>\n{p}\n</ListItem>\n))}\n</Select>\n</Grid>\n)}\n{eventName && propertyName && (\n<EventValues websiteId={websiteId} eventName={eventName} propertyName={propertyName} />\n)}\n</Column>\n</LoadingPanel>\n);\n}"
"export function EventsDataTable({\nwebsiteId,\n}: {\nwebsiteId?: string;\nteamId?: string;\nchildren?: ReactNode;\n}) {\nconst { formatMessage, labels } = useMessages();\nconst [view, setView] = useState('all');\nconst query = useWebsiteEventsQuery(websiteId, { view });\nconst buttons = [\n{\nid: 'all',\nlabel: formatMessage(labels.all),\n},\n{\nid: 'views',\nlabel: formatMessage(labels.views),\n},\n{\nid: 'events',\nlabel: formatMessage(labels.events),\n},\n];\nconst renderActions = () => {\nreturn <FilterButtons items={buttons} value={view} onChange={setView} />;\n};\nreturn (\n<DataGrid\nquery={query}\nallowSearch={true}\nautoFocus={false}\nallowPaging={true}\nrenderActions={renderActions}\n>\n{({ data }) => <EventsTable data={data} />}\n</DataGrid>\n);\n}"
"export function EventsPage({ websiteId }) {\nconst [tab, setTab] = useState(getItem(KEY_NAME) || 'chart');\nconst { formatMessage, labels } = useMessages();\nconst handleSelect = (value: Key) => {\nsetItem(KEY_NAME, value);\nsetTab(value);\n};\nreturn (\n<Column gap=`3`>\n<WebsiteControls websiteId={websiteId} />\n<Panel>\n<Tabs selectedKey={tab} onSelectionChange={key => handleSelect(key)}>\n<TabList>\n<Tab id=`chart`>{formatMessage(labels.chart)}</Tab>\n<Tab id=`activity`>{formatMessage(labels.activity)}</Tab>\n<Tab id=`properties`>{formatMessage(labels.properties)}</Tab>\n</TabList>\n<TabPanel id=`activity`>\n<EventsDataTable websiteId={websiteId} />\n</TabPanel>\n<TabPanel id=`chart`>\n<Column gap=`6`>\n<Column border=`bottom` paddingBottom=`6`>\n<EventsChart websiteId={websiteId} />\n</Column>\n<MetricsTable\nwebsiteId={websiteId}\ntype=`event`\ntitle={formatMessage(labels.event)}\nmetric={formatMessage(labels.count)}\n/>\n</Column>\n</TabPanel>\n<TabPanel id=`properties`>\n<EventProperties websiteId={websiteId} />\n</TabPanel>\n</Tabs>\n</Panel>\n<SessionModal websiteId={websiteId} />\n</Column>\n);\n}"
"export function RealtimePage({ websiteId }: { websiteId: string }) {\nconst { data, isLoading, error } = useRealtimeQuery(websiteId);\nconst { isMobile } = useMobile();\nif (isLoading || error) {\nreturn <PageBody isLoading={isLoading} error={error} />;\n}\nconst countries = percentFilter(\nObject.keys(data.countries)\n.map(key => ({ x: key, y: data.countries[key] }))\n.sort(firstBy('y', -1)),\n);\nreturn (\n<Grid gap=`3`>\n<RealtimeHeader data={data} />\n<Panel>\n<RealtimeChart data={data} unit=`minute` />\n</Panel>\n<Panel>\n<RealtimeLog data={data} />\n</Panel>\n<GridRow layout=`two`>\n<Panel>\n<RealtimePaths data={data} />\n</Panel>\n<Panel>\n<RealtimeReferrers data={data} />\n</Panel>\n</GridRow>\n<GridRow layout=`one-two`>\n<Panel>\n<RealtimeCountries data={countries} />\n</Panel>\n<Panel gridColumn={isMobile ? null : 'span 2'} padding=`0`>\n<WorldMap data={countries} />\n</Panel>\n</GridRow>\n</Grid>\n);\n}"
"export function SegmentDeleteButton({\nsegmentId,\nwebsiteId,\nname,\nonSave,\n}: {\nsegmentId: string;\nwebsiteId: string;\nname: string;\nonSave?: () => void;\n}) {\nconst { formatMessage, labels, FormattedMessage } = useMessages();\nconst { mutateAsync, isPending, error, touch } = useDeleteQuery(\n`/websites/${websiteId}/segments/${segmentId}`,\n);\nconst handleConfirm = async (close: () => void) => {\nawait mutateAsync(null, {\nonSuccess: () => {\ntouch('segments');\nonSave?.();\nclose();\n},\n});\n};\nreturn (\n<DialogButton\nicon={<Trash />}\ntitle={formatMessage(labels.confirm)}\nvariant=`quiet`\nwidth=`600px`\n>\n{({ close }) => (\n<ConfirmationForm\nmessage={\n<FormattedMessage\n{...messages.confirmRemove}\nvalues={{\ntarget: <b>{name}</b>,\n}}\n/>\n}\nisLoading={isPending}\nerror={error}\nonConfirm={handleConfirm.bind(null, close)}\nonClose={close}\nbuttonLabel={formatMessage(labels.delete)}\nbuttonVariant=`danger`\n/>\n)}\n</DialogButton>\n);\n}"
"export function SegmentEditForm({\nsegmentId,\nwebsiteId,\nfilters = [],\nshowFilters = true,\nonSave,\nonClose,\n}: {\nsegmentId?: string;\nwebsiteId: string;\nfilters?: any[];\nshowFilters?: boolean;\nonSave?: () => void;\nonClose?: () => void;\n}) {\nconst { data } = useWebsiteSegmentQuery(websiteId, segmentId);\nconst { formatMessage, labels, getErrorMessage } = useMessages();\nconst { mutateAsync, error, isPending, touch, toast } = useUpdateQuery(\n`/websites/${websiteId}/segments${segmentId ? `/${segmentId}` : ''}`,\n{\ntype: 'segment',\n},\n);\nconst handleSubmit = async (formData: any) => {\nawait mutateAsync(formData, {\nonSuccess: async () => {\ntoast(formatMessage(messages.saved));\ntouch('segments');\nonSave?.();\nonClose?.();\n},\n});\n};\nif (segmentId && !data) {\nreturn <Loading placement=`absolute` />;\n}\nreturn (\n<Form\nonSubmit={handleSubmit}\ndefaultValues={data || { parameters: { filters } }}\nerror={getErrorMessage(error)}\n>\n<FormField\nname=`name`\nlabel={formatMessage(labels.name)}\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField autoFocus={!segmentId} />\n</FormField>\n{showFilters && (\n<>\n<Label>{formatMessage(labels.filters)}</Label>\n<FormField name=`parameters.filters` rules={{ required: formatMessage(labels.required) }}>\n<FieldFilters websiteId={websiteId} />\n</FormField>\n</>\n)}\n<FormButtons>\n<Button isDisabled={isPending} onPress={onClose}>\n{formatMessage(labels.cancel)}\n</Button>\n<FormSubmitButton variant=`primary` data-test=`button-submit` isDisabled={isPending}>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function SessionActivity({\nwebsiteId,\nsessionId,\nstartDate,\nendDate,\n}: {\nwebsiteId: string;\nsessionId: string;\nstartDate: Date;\nendDate: Date;\n}) {\nconst { formatMessage, labels } = useMessages();\nconst { formatTimezoneDate } = useTimezone();\nconst { data, isLoading, error } = useSessionActivityQuery(\nwebsiteId,\nsessionId,\nstartDate,\nendDate,\n);\nconst { isMobile } = useMobile();\nlet lastDay = null;\nreturn (\n<LoadingPanel data={data} isLoading={isLoading} error={error}>\n<Column gap>\n{data?.map(({ eventId, createdAt, urlPath, eventName, visitId, hasData }) => {\nconst showHeader = !lastDay || !isSameDay(new Date(lastDay), new Date(createdAt));\nlastDay = createdAt;\nreturn (\n<Column key={eventId} gap>\n{showHeader && <Heading size=`1`>{formatTimezoneDate(createdAt, 'PPPP')}</Heading>}\n<Row alignItems=`center` gap=`6` height=`40px`>\n<StatusLight color={`#${visitId?.substring(0, 6)}`}>\n<Text wrap=`nowrap`>{formatTimezoneDate(createdAt, 'pp')}</Text>\n</StatusLight>\n<Row alignItems=`center` gap=`2`>\n<Icon>{eventName ? <Lightning /> : <Eye />}</Icon>\n<Text wrap=`nowrap`>\n{eventName\n? formatMessage(labels.triggeredEvent)\n: formatMessage(labels.viewedPage)}\n</Text>\n<Text weight=`bold` style={{ maxWidth: isMobile ? '400px' : null }} truncate>\n{eventName || urlPath}\n</Text>\n{hasData > 0 && <PropertiesButton websiteId={websiteId} eventId={eventId} />}\n</Row>\n</Row>\n</Column>\n);\n})}\n</Column>\n</LoadingPanel>\n);\n}"
"export function SessionInfo({ data }) {\nconst { locale } = useLocale();\nconst { formatMessage, labels } = useMessages();\nconst { formatValue } = useFormat();\nconst { getRegionName } = useRegionNames(locale);\nreturn (\n<Grid columns=`repeat(auto-fit, minmax(200px, 1fr)` gap>\n<Info label={formatMessage(labels.distinctId)} icon={<KeyRound />}>\n{data?.distinctId}\n</Info>\n<Info label={formatMessage(labels.lastSeen)} icon={<Calendar />}>\n<DateDistance date={new Date(data.lastAt)} />\n</Info>\n<Info label={formatMessage(labels.firstSeen)} icon={<Calendar />}>\n<DateDistance date={new Date(data.firstAt)} />\n</Info>\n<Info\nlabel={formatMessage(labels.country)}\nicon={<TypeIcon type=`country` value={data?.country} />}\n>\n{formatValue(data?.country, 'country')}\n</Info>\n<Info label={formatMessage(labels.region)} icon={<MapPin />}>\n{getRegionName(data?.region)}\n</Info>\n<Info label={formatMessage(labels.city)} icon={<Landmark />}>\n{data?.city}\n</Info>\n<Info\nlabel={formatMessage(labels.browser)}\nicon={<TypeIcon type=`browser` value={data?.browser} />}\n>\n{formatValue(data?.browser, 'browser')}\n</Info>\n<Info\nlabel={formatMessage(labels.os)}\nicon={<TypeIcon type=`os` value={data?.os?.toLowerCase()?.replaceAll(/\W/g, '-')} />}\n>\n{formatValue(data?.os, 'os')}\n</Info>\n<Info\nlabel={formatMessage(labels.device)}\nicon={<TypeIcon type=`device` value={data?.device} />}\n>\n{formatValue(data?.device, 'device')}\n</Info>\n</Grid>\n);\n}"
"export function SessionProfile({\nwebsiteId,\nsessionId,\nonClose,\n}: {\nwebsiteId: string;\nsessionId: string;\nonClose?: () => void;\n}) {\nconst { data, isLoading, error } = useWebsiteSessionQuery(websiteId, sessionId);\nconst { formatMessage, labels } = useMessages();\nreturn (\n<LoadingPanel\ndata={data}\nisLoading={isLoading}\nerror={error}\nloadingIcon=`spinner`\nloadingPlacement=`absolute`\n>\n{data && (\n<Column gap>\n{onClose && (\n<Row justifyContent=`flex-end`>\n<Button onPress={onClose} variant=`quiet`>\n<Icon>\n<X />\n</Icon>\n</Button>\n</Row>\n)}\n<Column gap=`6`>\n<Row justifyContent=`center` alignItems=`center` gap=`6`>\n<Avatar seed={data?.id} size={128} />\n<Column width=`360px`>\n<TextField label=`ID` value={data?.id} allowCopy />\n</Column>\n</Row>\n<SessionStats data={data} />\n<SessionInfo data={data} />\n<Tabs>\n<TabList>\n<Tab id=`activity`>{formatMessage(labels.activity)}</Tab>\n<Tab id=`properties`>{formatMessage(labels.properties)}</Tab>\n</TabList>\n<TabPanel id=`activity`>\n<SessionActivity\nwebsiteId={websiteId}\nsessionId={sessionId}\nstartDate={data?.firstAt}\nendDate={data?.lastAt}\n/>\n</TabPanel>\n<TabPanel id=`properties`>\n<SessionData sessionId={sessionId} websiteId={websiteId} />\n</TabPanel>\n</Tabs>\n</Column>\n</Column>\n)}\n</LoadingPanel>\n);\n}"
"export function SessionsTable(props: DataTableProps) {\nconst { formatMessage, labels } = useMessages();\nconst { formatValue } = useFormat();\nconst { updateParams } = useNavigation();\nreturn (\n<DataTable {...props}>\n<DataColumn id=`id` label={formatMessage(labels.session)} width=`100px`>\n{(row: any) => (\n<Link href={updateParams({ session: row.id })}>\n<Avatar seed={row.id} size={32} />\n</Link>\n)}\n</DataColumn>\n<DataColumn id=`visits` label={formatMessage(labels.visits)} width=`80px` />\n<DataColumn id=`views` label={formatMessage(labels.views)} width=`80px` />\n<DataColumn id=`country` label={formatMessage(labels.country)}>\n{(row: any) => (\n<TypeIcon type=`country` value={row.country}>\n{formatValue(row.country, 'country')}\n</TypeIcon>\n)}\n</DataColumn>\n<DataColumn id=`city` label={formatMessage(labels.city)} />\n<DataColumn id=`browser` label={formatMessage(labels.browser)}>\n{(row: any) => (\n<TypeIcon type=`browser` value={row.browser}>\n{formatValue(row.browser, 'browser')}\n</TypeIcon>\n)}\n</DataColumn>\n<DataColumn id=`os` label={formatMessage(labels.os)}>\n{(row: any) => (\n<TypeIcon type=`os` value={row.os}>\n{formatValue(row.os, 'os')}\n</TypeIcon>\n)}\n</DataColumn>\n<DataColumn id=`device` label={formatMessage(labels.device)}>\n{(row: any) => (\n<TypeIcon type=`device` value={row.device}>\n{formatValue(row.device, 'device')}\n</TypeIcon>\n)}\n</DataColumn>\n<DataColumn id=`lastAt` label={formatMessage(labels.lastSeen)}>\n{(row: any) => <DateDistance date={new Date(row.createdAt)} />}\n</DataColumn>\n</DataTable>\n);\n}"
"export function WebsiteEditForm({ websiteId, onSave }: { websiteId: string; onSave?: () => void }) {\nconst website = useWebsite();\nconst { formatMessage, labels, messages, getErrorMessage } = useMessages();\nconst { mutateAsync, error, touch, toast } = useUpdateQuery(`/websites/${websiteId}`);\nconst handleSubmit = async (data: any) => {\nawait mutateAsync(data, {\nonSuccess: async () => {\ntoast(formatMessage(messages.saved));\ntouch('websites');\ntouch(`website:${website.id}`);\nonSave?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSubmit} error={getErrorMessage(error)} values={website}>\n<FormField name=`id` label={formatMessage(labels.websiteId)}>\n<TextField data-test=`text-field-websiteId` value={website?.id} isReadOnly allowCopy />\n</FormField>\n<FormField\nlabel={formatMessage(labels.name)}\ndata-test=`input-name`\nname=`name`\nrules={{ required: formatMessage(labels.required) }}\n>\n<TextField />\n</FormField>\n<FormField\nlabel={formatMessage(labels.domain)}\ndata-test=`input-domain`\nname=`domain`\nrules={{\nrequired: formatMessage(labels.required),\npattern: {\nvalue: DOMAIN_REGEX,\nmessage: formatMessage(messages.invalidDomain),\n},\n}}\n>\n<TextField />\n</FormField>\n<FormButtons>\n<FormSubmitButton data-test=`button-submit` variant=`primary`>\n{formatMessage(labels.save)}\n</FormSubmitButton>\n</FormButtons>\n</Form>\n);\n}"
"export function WebsiteShareForm({ websiteId, shareId, onSave, onClose }: WebsiteShareFormProps) {\nconst { formatMessage, labels, messages, getErrorMessage } = useMessages();\nconst [currentId, setCurrentId] = useState(shareId);\nconst { mutateAsync, error, touch, toast } = useUpdateQuery(`/websites/${websiteId}`);\nconst { cloudMode } = useConfig();\nconst getUrl = (shareId: string) => {\nif (cloudMode) {\nreturn `${process.env.cloudUrl}/share/${shareId}`;\n}\nreturn `${window?.location.origin}${process.env.basePath || ''}/share/${shareId}`;\n};\nconst url = getUrl(currentId);\nconst handleGenerate = () => {\nsetCurrentId(generateId());\n};\nconst handleSwitch = () => {\nsetCurrentId(currentId ? null : generateId());\n};\nconst handleSave = async () => {\nconst data = {\nshareId: currentId,\n};\nawait mutateAsync(data, {\nonSuccess: async () => {\ntoast(formatMessage(messages.saved));\ntouch(`website:${websiteId}`);\nonSave?.();\nonClose?.();\n},\n});\n};\nreturn (\n<Form onSubmit={handleSave} error={getErrorMessage(error)} values={{ url }}>\n<Column gap>\n<Switch isSelected={!!currentId} onChange={handleSwitch}>\n{formatMessage(labels.enableShareUrl)}\n</Switch>\n{currentId && (\n<Row alignItems=`flex-end` gap>\n<Column flexGrow={1}>\n<Label>{formatMessage(labels.shareUrl)}</Label>\n<TextField value={url} isReadOnly allowCopy />\n</Column>\n<Column>\n<Button onPress={handleGenerate}>\n<IconLabel icon={<RefreshCcw />} label={formatMessage(labels.regenerate)} />\n</Button>\n</Column>\n</Row>\n)}\n<FormButtons justifyContent=`flex-end`>\n<Row alignItems=`center` gap>\n{onClose && <Button onPress={onClose}>{formatMessage(labels.cancel)}</Button>}\n<FormSubmitButton isDisabled={false}>{formatMessage(labels.save)}</FormSubmitButton>\n</Row>\n</FormButtons>\n</Column>\n</Form>\n);\n}"
"export async function GET(request: Request, { params }: { params: Promise<{ teamId: string }> }) {\nconst schema = z.object({\n...pagingParams,\n...searchParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { teamId } = await params;\nif (!(await canViewTeam(auth, teamId))) {\nreturn unauthorized({ message: 'You must be a member of this team.' });\n}\nconst filters = await getQueryFilters(query);\nconst users = await getTeamUsers(\n{\nwhere: {\nteamId,\nuser: {\ndeletedAt: null,\n},\n},\ninclude: {\nuser: {\nselect: {\nid: true,\nusername: true,\n},\n},\n},\norderBy: {\ncreatedAt: 'asc',\n},\n},\nfilters,\n);\nreturn json(users);\n}"
"export async function GET(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\n...dateRangeParams,\n...pagingParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nif (!(await canViewWebsite(auth, websiteId))) {\nreturn unauthorized();\n}\nconst filters = await getQueryFilters(query, websiteId);\nconst [events, pages, referrers, browsers, os, devices, countries] = await Promise.all([\ngetEventMetrics(websiteId, { type: 'event' }, filters),\ngetPageviewMetrics(websiteId, { type: 'path' }, filters),\ngetPageviewMetrics(websiteId, { type: 'referrer' }, filters),\ngetSessionMetrics(websiteId, { type: 'browser' }, filters),\ngetSessionMetrics(websiteId, { type: 'os' }, filters),\ngetSessionMetrics(websiteId, { type: 'device' }, filters),\ngetSessionMetrics(websiteId, { type: 'country' }, filters),\n]);\nconst zip = new JSZip();\nconst parse = (data: any) => {\nreturn Papa.unparse(data, {\nheader: true,\nskipEmptyLines: true,\n});\n};\nzip.file('events.csv', parse(events));\nzip.file('pages.csv', parse(pages));\nzip.file('referrers.csv', parse(referrers));\nzip.file('browsers.csv', parse(browsers));\nzip.file('os.csv', parse(os));\nzip.file('devices.csv', parse(devices));\nzip.file('countries.csv', parse(countries));\nconst content = await zip.generateAsync({ type: 'nodebuffer' });\nconst base64 = content.toString('base64');\nreturn json({ zip: base64 });\n}"
"export async function GET(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\ntype: z.string(),\nlimit: z.coerce.number().optional(),\noffset: z.coerce.number().optional(),\n...dateRangeParams,\n...searchParams,\n...filterParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nif (!(await canViewWebsite(auth, websiteId))) {\nreturn unauthorized();\n}\nconst { type, limit, offset, search } = query;\nconst filters = await getQueryFilters(query, websiteId);\nif (search) {\nfilters[type] = `c.${search}`;\n}\nif (SESSION_COLUMNS.includes(type)) {\nconst data = await getSessionMetrics(websiteId, { type, limit, offset }, filters);\nreturn json(data);\n}\nif (EVENT_COLUMNS.includes(type)) {\nif (type === 'event') {\nfilters.eventType = EVENT_TYPE.customEvent;\nreturn json(await getEventMetrics(websiteId, { type, limit, offset }, filters));\n} else {\nreturn json(await getPageviewMetrics(websiteId, { type, limit, offset }, filters));\n}\n}\nif (type === 'channel') {\nreturn json(await getChannelMetrics(websiteId, filters));\n}\nreturn badRequest();\n}"
"export async function GET(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\n...dateRangeParams,\n...filterParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nif (!(await canViewWebsite(auth, websiteId))) {\nreturn unauthorized();\n}\nconst filters = await getQueryFilters(query, websiteId);\nconst [pageviews, sessions] = await Promise.all([\ngetPageviewStats(websiteId, filters),\ngetSessionStats(websiteId, filters),\n]);\nif (filters.compare) {\nconst { startDate: compareStartDate, endDate: compareEndDate } = getCompareDate(\nfilters.compare,\nfilters.startDate,\nfilters.endDate,\n);\nconst [comparePageviews, compareSessions] = await Promise.all([\ngetPageviewStats(websiteId, {\n...filters,\nstartDate: compareStartDate,\nendDate: compareEndDate,\n}),\ngetSessionStats(websiteId, {\n...filters,\nstartDate: compareStartDate,\nendDate: compareEndDate,\n}),\n]);\nreturn json({\npageviews,\nsessions,\nstartDate: filters.startDate,\nendDate: filters.endDate,\ncompare: {\npageviews: comparePageviews,\nsessions: compareSessions,\nstartDate: compareStartDate,\nendDate: compareEndDate,\n},\n});\n}\nreturn json({ pageviews, sessions });\n}"
"export async function POST(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\nuserId: z.uuid().optional(),\nteamId: z.uuid().optional(),\n});\nconst { auth, body, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nconst { userId, teamId } = body;\nif (userId) {\nif (!(await canTransferWebsiteToUser(auth, websiteId, userId))) {\nreturn unauthorized();\n}\nconst website = await updateWebsite(websiteId, {\nuserId,\nteamId: null,\n});\nreturn json(website);\n} else if (teamId) {\nif (!(await canTransferWebsiteToTeam(auth, websiteId, teamId))) {\nreturn unauthorized();\n}\nconst website = await updateWebsite(websiteId, {\nuserId: null,\nteamId,\n});\nreturn json(website);\n}\nreturn badRequest();\n}"
"export async function GET(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\ntype: fieldsParam,\n...dateRangeParams,\n...searchParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nif (!(await canViewWebsite(auth, websiteId))) {\nreturn unauthorized();\n}\nconst { type } = query;\nif (!SESSION_COLUMNS.includes(type) && !EVENT_COLUMNS.includes(type) && !SEGMENT_TYPES[type]) {\nreturn badRequest();\n}\nlet values: any[];\nif (SEGMENT_TYPES[type]) {\nvalues = (await getWebsiteSegments(websiteId, type))?.data?.map(segment => ({\nvalue: segment.name,\n}));\n} else {\nconst filters = await getQueryFilters(query, websiteId);\nvalues = await getValues(websiteId, FILTER_COLUMNS[type], filters);\n}\nreturn json(values.filter(n => n).sort());\n}"
"export function AttributionPage({ websiteId }: { websiteId: string }) {\nconst [model, setModel] = useState('first-click');\nconst [type, setType] = useState('path');\nconst [step, setStep] = useState('/');\nconst { formatMessage, labels } = useMessages();\nconst {\ndateRange: { startDate, endDate },\n} = useDateRange();\nreturn (\n<Column gap=`6`>\n<WebsiteControls websiteId={websiteId} />\n<Grid columns={{ xs: '1fr', md: '1fr 1fr 1fr' }} gap>\n<Column>\n<Select\nlabel={formatMessage(labels.model)}\nvalue={model}\ndefaultValue={model}\nonChange={setModel}\n>\n<ListItem id=`first-click`>{formatMessage(labels.firstClick)}</ListItem>\n<ListItem id=`last-click`>{formatMessage(labels.lastClick)}</ListItem>\n</Select>\n</Column>\n<Column>\n<Select\nlabel={formatMessage(labels.type)}\nvalue={type}\ndefaultValue={type}\nonChange={setType}\n>\n<ListItem id=`path`>{formatMessage(labels.viewedPage)}</ListItem>\n<ListItem id=`event`>{formatMessage(labels.triggeredEvent)}</ListItem>\n</Select>\n</Column>\n<Column>\n<SearchField\nlabel={formatMessage(labels.conversionStep)}\nvalue={step}\ndefaultValue={step}\nonSearch={setStep}\ndelay={1000}\n/>\n</Column>\n</Grid>\n<Attribution\nwebsiteId={websiteId}\nstartDate={startDate}\nendDate={endDate}\nmodel={model}\ntype={type}\nstep={step}\n/>\n</Column>\n);\n}"
"export function FieldSelectForm({\nselectedFields = [],\nonChange,\nonClose,\n}: {\nselectedFields?: string[];\nonChange: (values: string[]) => void;\nonClose?: () => void;\n}) {\nconst [selected, setSelected] = useState(selectedFields);\nconst { formatMessage, labels } = useMessages();\nconst { fields } = useFields();\nconst handleChange = (value: string[]) => {\nsetSelected(value);\n};\nconst handleApply = () => {\nonChange?.(selected);\nonClose();\n};\nreturn (\n<Column gap=`6`>\n<List value={selected} onChange={handleChange} selectionMode=`multiple`>\n{fields.map(({ name, label }) => {\nreturn (\n<ListItem key={name} id={name}>\n{label}\n</ListItem>\n);\n})}\n</List>\n<Grid columns=`1fr 1fr` gap>\n<Button onPress={onClose}>{formatMessage(labels.cancel)}</Button>\n<Button onPress={handleApply} variant=`primary`>\n{formatMessage(labels.apply)}\n</Button>\n</Grid>\n</Column>\n);\n}"
"export function JourneysPage({ websiteId }: { websiteId: string }) {\nconst { formatMessage, labels } = useMessages();\nconst {\ndateRange: { startDate, endDate },\n} = useDateRange();\nconst [steps, setSteps] = useState(DEFAULT_STEP);\nconst [startStep, setStartStep] = useState('');\nconst [endStep, setEndStep] = useState('');\nreturn (\n<Column gap>\n<WebsiteControls websiteId={websiteId} />\n<Grid columns=`repeat(3, 1fr)` gap>\n<Select\nitems={JOURNEY_STEPS}\nlabel={formatMessage(labels.steps)}\nvalue={steps}\ndefaultValue={steps}\nonChange={setSteps}\n>\n{JOURNEY_STEPS.map(step => (\n<ListItem key={step} id={step}>\n{step}\n</ListItem>\n))}\n</Select>\n<Column>\n<SearchField\nlabel={formatMessage(labels.startStep)}\nvalue={startStep}\nonSearch={setStartStep}\ndelay={1000}\n/>\n</Column>\n<Column>\n<SearchField\nlabel={formatMessage(labels.endStep)}\nvalue={endStep}\nonSearch={setEndStep}\ndelay={1000}\n/>\n</Column>\n</Grid>\n<Panel height=`900px` allowFullscreen>\n<Journey\nwebsiteId={websiteId}\nstartDate={startDate}\nendDate={endDate}\nsteps={steps}\nstartStep={startStep}\nendStep={endStep}\n/>\n</Panel>\n</Column>\n);\n}"
"export function UTM({ websiteId, startDate, endDate }: UTMProps) {\nconst { formatMessage, labels } = useMessages();\nconst { data, error, isLoading } = useResultQuery<any>('utm', {\nwebsiteId,\nstartDate,\nendDate,\n});\nreturn (\n<LoadingPanel data={data} isLoading={isLoading} error={error} minHeight=`300px`>\n{data && (\n<Column gap>\n{UTM_PARAMS.map(param => {\nconst items = data?.[param];\nconst chartData = {\nlabels: items.map(({ utm }) => utm),\ndatasets: [\n{\ndata: items.map(({ views }) => views),\nbackgroundColor: CHART_COLORS,\nborderWidth: 0,\n},\n],\n};\nconst total = items.reduce((sum, { views }) => {\nreturn +sum + +views;\n}, 0);\nreturn (\n<Panel key={param}>\n<Grid columns={{ xs: '1fr', md: '1fr 1fr' }} gap=`6`>\n<Column>\n<Heading>\n<Text transform=`capitalize`>{param.replace(/^utm_/, '')}</Text>\n</Heading>\n<ListTable\nmetric={formatMessage(labels.views)}\ndata={items.map(({ utm, views }) => ({\nlabel: utm,\ncount: views,\npercent: (views / total) * 100,\n}))}\n/>\n</Column>\n<Column>\n<PieChart type=`doughnut` chartData={chartData} />\n</Column>\n</Grid>\n</Panel>\n);\n})}\n</Column>\n)}\n</LoadingPanel>\n);\n}"
"export async function GET(\nrequest: Request,\n{ params }: { params: Promise<{ websiteId: string }> },\n) {\nconst schema = z.object({\ntype: z.string(),\nlimit: z.coerce.number().optional(),\noffset: z.coerce.number().optional(),\n...dateRangeParams,\n...searchParams,\n...filterParams,\n});\nconst { auth, query, error } = await parseRequest(request, schema);\nif (error) {\nreturn error();\n}\nconst { websiteId } = await params;\nif (!(await canViewWebsite(auth, websiteId))) {\nreturn unauthorized();\n}\nconst { type, limit, offset, search } = query;\nconst filters = await getQueryFilters(query, websiteId);\nif (search) {\nfilters[type] = `c.${search}`;\n}\nif (SESSION_COLUMNS.includes(type)) {\nconst data = await getSessionExpandedMetrics(websiteId, { type, limit, offset }, filters);\nreturn json(data);\n}\nif (EVENT_COLUMNS.includes(type)) {\nif (type === 'event') {\nfilters.eventType = EVENT_TYPE.customEvent;\nreturn json(await getEventExpandedMetrics(websiteId, { type, limit, offset }, filters));\n} else {\nreturn json(await getPageviewExpandedMetrics(websiteId, { type, limit, offset }, filters));\n}\n}\nif (type === 'channel') {\nreturn json(await getChannelExpandedMetrics(websiteId, filters));\n}\nreturn badRequest();\n}"
"async start(name: string): Promise<SessionDTO> {\nthis.onlyDefault(name);\nif (this.session) {\nthrow new UnprocessableEntityException(\n`Session '${this.DEFAULT}' is already started.`,\n);\n}\nthis.log.info({ session: name }, `Starting session...`);\nconst logger = this.log.logger.child({ session: name });\nlogger.level = getPinoLogLevel(this.sessionConfig?.debug);\nconst loggerBuilder: LoggerBuilder = logger;\nconst storage = await this.mediaStorageFactory.build(\nname,\nloggerBuilder.child({ name: 'Storage' }),\n);\nawait storage.init();\nconst mediaManager = new MediaManager(\nstorage,\nthis.config.mimetypes,\nloggerBuilder.child({ name: 'MediaManager' }),\n);\nconst webhook = new WebhookConductor(loggerBuilder);\nconst proxyConfig = this.getProxyConfig();\nconst sessionConfig: SessionParams = {\nname,\nmediaManager,\nloggerBuilder,\nprintQR: this.engineConfigService.shouldPrintQR,\nsessionStore: this.store,\nproxyConfig: proxyConfig,\nsessionConfig: this.sessionConfig,\n};\nif (this.EngineClass === WhatsappSessionWebJSCore) {\nsessionConfig.engineConfig = this.webjsEngineConfigService.getConfig();\n} else if (this.EngineClass === WhatsappSessionGoWSCore) {\nsessionConfig.engineConfig = this.gowsConfigService.getConfig();\n}\nawait this.sessionAuthRepository.init(name);\nconst session = new this.EngineClass(sessionConfig);\nthis.session = session;\nthis.updateSession();\nconst webhooks = this.getWebhooks();\nwebhook.configure(session, webhooks);\nawait this.configureApps(session);\nawait session.start();\nlogger.info('Session has been started.');\nreturn {\nname: session.name,\nstatus: session.status,\nconfig: session.sessionConfig,\n};\n}"
"catch(exception: any | Error, host: ArgumentsHost): void {\nconst ctx = host.switchToHttp();\nconst response = ctx.getResponse<Response>();\nconst request = ctx.getRequest<Request>();\nif (exception.code === 'ENOENT') {\nresponse.status(HttpStatus.NOT_FOUND).json({\nerror: {\ncode: 404,\nkey: 'FILE_NOT_FOUND',\nmessage: 'File not found',\ndetails: 'File not found or no longer available',\n},\n});\nresponse.send();\nreturn;\n}\nif (exception instanceof HttpException) {\nresponse.status(exception.getStatus()).json(exception.getResponse());\nreturn;\n}\nconst httpStatus = HttpStatus.INTERNAL_SERVER_ERROR;\nresponse.status(httpStatus).json({\nstatusCode: httpStatus,\ntimestamp: new Date().toISOString(),\nexception: serializeError(exception),\nrequest: {\npath: request.url,\nmethod: request.method,\nbody: request.body,\nquery: request.query,\n},\nversion: VERSION,\n});\n}"
"async waitUntilStatus(\nsessionName: string,\nexpected: WAHASessionStatus[],\n): Promise<WhatsappSession> {\nif (!sessionName) {\nthrow new UnprocessableEntityException({\nerror: `Session name is required`,\nsession: sessionName,\n});\n}\nconst running = await waitUntil(\nasync () => this.isRunning(sessionName),\nthis.WAIT_SESSION_RUNNING_INTERVAL,\nthis.WAIT_SESSION_RUNNING_TIMEOUT,\n);\nif (!running) {\nconst exists = await this.exists(sessionName);\nif (!exists) {\nthrow new UnprocessableEntityException({\nerror: `Session `${sessionName}` does not exist`,\nsession: sessionName,\n});\n}\nconst msg = {\nerror:\n'Session status is not as expected. Try again later or restart the session',\nsession: sessionName,\nstatus: 'STOPPED',\nexpected: expected,\n};\nthrow new UnprocessableEntityException(msg);\n}\nconst session = this.getSession(sessionName);\nconst valid = await waitUntil(\nasync () => expected.includes(session.status),\nthis.WAIT_STATUS_INTERVAL,\nthis.WAIT_STATUS_TIMEOUT,\n);\nif (!valid) {\nconst msg = {\nerror:\n'Session status is not as expected. Try again later or restart the session',\nsession: sessionName,\nstatus: session.status,\nexpected: expected,\n};\nthrow new UnprocessableEntityException(msg);\n}\nreturn session;\n}"
"getBrowserArgsForPuppeteer() {\nreturn [\n'--disable-accelerated-2d-canvas',\n'--disable-application-cache',\n'--disable-client-side-phishing-detection',\n'--disable-component-update',\n'--disable-default-apps',\n'--disable-dev-shm-usage',\n'--disable-extensions',\n'--disable-gpu',\n'--disable-offer-store-unmasked-wallet-cards',\n'--disable-offline-load-stale-cache',\n'--disable-popup-blocking',\n'--disable-setuid-sandbox',\n'--disable-site-isolation-trials',\n'--disable-speech-api',\n'--disable-sync',\n'--disable-translate',\n'--disable-web-security',\n'--hide-scrollbars',\n'--ignore-certificate-errors',\n'--ignore-ssl-errors',\n'--metrics-recording-only',\n'--mute-audio',\n'--no-default-browser-check',\n'--no-first-run',\n'--no-pings',\n'--no-sandbox',\n'--no-zygote',\n'--password-store=basic',\n'--renderer-process-limit=2',\n'--safebrowsing-disable-auto-update',\n'--use-mock-keychain',\n'--window-size=1280,720',\n'--disk-cache-size=1073741824',\n];\n}"
"private async processMediaInternal<Message>(\nprocessor: IMediaEngineProcessor<Message>,\nmessage: Message,\nsession: string,\n): Promise<WAMedia | null> {\nconst messageId = processor.getMessageId(message);\nconst chatId = processor.getChatId(message);\nconst mimetype = processor.getMimetype(message);\nconst filename = processor.getFilename(message);\nif (!this.shouldProcessMimetype(mimetype)) {\nthis.log.info(\n`The message '${messageId}' has '${mimetype}' mimetype media, skip it.`,\n);\nreturn null;\n}\nconst extension = mime.extension(mimetype);\nconst mediaData: MediaData = {\nsession: session,\nmessage: {\nid: messageId,\nchatId: chatId,\n},\nfile: {\nextension: extension,\nfilename: filename,\n},\n};\nconst exists = await this.withRetry('Checking media', () =>\nthis.exists(mediaData),\n);\nif (!exists) {\nthis.log.info(`The message ${messageId} has media, downloading it...`);\nconst buffer = await this.withRetry('Fetching media', () =>\nthis.fetchMedia(message, processor),\n);\nawait this.withRetry('Saving media', () =>\nthis.saveMedia(buffer, mediaData),\n);\nthis.log.info(`The media from '${messageId}' has been saved.`);\n}\nconst data = await this.withRetry('Getting media URL', () =>\nthis.getStorageData(mediaData),\n);\nreturn data;\n}"
"@Post(':session/:id')\n@ApiOperation({\nsummary: 'Chatwoot Webhook',\ndescription: 'Chatwoot Webhook',\n})\nasync webhook(\n@Param('session') session: string,\n@Param('id') id: string,\n@Body() body: any,\n) {\nif (!body || !body?.event) {\nreturn { success: true };\n}\nif (body.private) {\nreturn { success: true };\n}\nif (body.message_type == MessageType.INCOMING) {\nreturn { success: true };\n}\nconst data: InboxData = {\nsession: session,\napp: id,\nbody: body,\n};\nconst sender = body?.conversation?.meta?.sender;\nconst chatId = GetChatID(sender);\nconst isCommandsChat = chatId === INBOX_CONTACT_CHAT_ID;\nif (body.content_attributes?.deleted && !isCommandsChat) {\nawait this.chatWootQueueService.addMessageDeletedJob(data);\nreturn { success: true };\n}\nswitch (body.event) {\ncase EventName.MESSAGE_CREATED:\nif (!isCommandsChat) {\nawait this.chatWootQueueService.addMessageCreatedJob(data);\n} else {\nawait this.chatWootQueueService.addCommandsJob(body.event, data);\n}\nreturn { success: true };\ncase EventName.MESSAGE_UPDATED:\nif (!isCommandsChat) {\nawait this.chatWootQueueService.addMessageUpdatedJob(data);\n} else {\nawait this.chatWootQueueService.addCommandsJob(body.event, data);\n}\nreturn { success: true };\ndefault:\nreturn { success: true };\n}\n}"
"async searchByAnyID(chatId: string): Promise<ContactResponse | null> {\nconst payload: any[] = [\n{\nattribute_key: AttributeKey.WA_CHAT_ID,\nfilter_operator: 'equal_to',\nvalues: [chatId],\nattribute_model: 'standard',\ncustom_attribute_type: '',\nquery_operator: 'OR',\n},\n{\nattribute_key: AttributeKey.WA_JID,\nfilter_operator: 'equal_to',\nvalues: [chatId],\nattribute_model: 'standard',\ncustom_attribute_type: '',\nquery_operator: 'OR',\n},\n{\nattribute_key: AttributeKey.WA_LID,\nfilter_operator: 'equal_to',\nvalues: [chatId],\nattribute_model: 'standard',\ncustom_attribute_type: '',\nquery_operator: 'OR',\n},\n{\nattribute_key: 'identifier',\nfilter_operator: 'equal_to',\nvalues: [chatId],\nattribute_model: 'standard',\ncustom_attribute_type: '',\n},\n];\nif (isJidCusFormat(chatId)) {\nlet phone_number = chatId.split('@')[0];\nphone_number = phone_number.replace('+', '');\npayload[payload.length - 1].query_operator = 'OR';\npayload.push({\nattribute_key: 'phone_number',\nfilter_operator: 'equal_to',\nvalues: [phone_number],\n});\n}\nconst response: any = await this.accountAPI.contacts.filter({\naccountId: this.config.accountId,\npayload: payload as any,\n});\nconst contacts = response.payload;\nif (contacts.length == 0) {\nreturn null;\n}\nconst contact = contacts[0];\nconst inboxes = lodash.filter(contact.contact_inboxes, {\ninbox: { id: this.config.inboxId },\n});\nif (inboxes.length == 0) {\nreturn null;\n}\nreturn {\ndata: contact,\nsourceId: inboxes[0].source_id,\n};\n}"
"private async upsertByContactInfo(\ncontactInfo: ContactInfo,\n): Promise<public_conversation> {\nconst chatId = contactInfo.ChatId();\nif (this.cache.has(chatId)) {\nreturn this.cache.get(chatId);\n}\nlet contact = await this.contactAPI.searchByAnyID(chatId);\nif (!contact) {\nconst request = await contactInfo.PublicContactCreate();\ncontact = await this.contactAPI.create(chatId, request);\n}\nconst attributes = await contactInfo.Attributes();\nthis.logger.info(\n`Updating contact custom attributes for chat.id: ${chatId}, contact.id: ${contact.data.id}`,\n);\nawait this.contactAPI.updateCustomAttributes(contact.data, attributes);\nif (!contact.data.thumbnail) {\nconst avatarUrl = await contactInfo.AvatarUrl();\nif (avatarUrl) {\nthis.contactAPI.updateAvatarUrlSafe(contact.data.id, avatarUrl);\n}\n}\nthis.logger.info(\n`Using contact for chat.id: ${chatId}, contact.id: ${contact.sourceId}`,\n);\nconst conversation = await this.conversationAPI.upsert(contact.sourceId);\nthis.logger.info(\n`Using conversation for chat.id: ${chatId}, conversation.id: ${conversation.id}, contact.id: ${contact.sourceId}`,\n);\nthis.cache.set(chatId, conversation);\nreturn conversation;\n}"
"async start() {\nthis.status = WAHASessionStatus.STARTING;\nthis.buildStreams();\nthis.subscribeEvents();\nthis.subscribeEngineEvents2();\nif (this.isDebugEnabled()) {\nthis.listenEngineEventsInDebugMode();\n}\nconst auth = await this.authFactory.buildAuth(this.sessionStore, this.name);\nconst level = messages.LogLevel[this.logger.level.toUpperCase()];\nconst request = new messages.StartSessionRequest({\nid: this.name,\nconfig: new messages.SessionConfig({\nstore: new messages.SessionStoreConfig({\naddress: auth.address(),\ndialect: auth.dialect(),\n}),\nlog: new messages.SessionLogConfig({\nlevel: level ?? messages.LogLevel.INFO,\n}),\nproxy: new messages.SessionProxyConfig({\nurl: this.getProxyUrl(this.proxyConfig),\n}),\n}),\n});\nthis.client = new MessageServiceClient(\nthis.engineConfig.connection,\ngrpc.credentials.createInsecure(),\ngRPCClientConfig,\n);\ntry {\nawait promisify(this.client.StartSession)(request);\n} catch (err) {\nthis.logger.error('Failed to start the client');\nthis.logger.error(err, err.stack);\nthis.status = WAHASessionStatus.FAILED;\nthrow err;\n}\n}"
"public async setPresence(presence: WAHAPresenceStatus, chatId?: string) {\nlet request: any;\nlet method: any;\nconst jid = chatId ? toJID(this.ensureSuffix(chatId)) : null;\nswitch (presence) {\ncase WAHAPresenceStatus.ONLINE:\nrequest = new messages.PresenceRequest({\nsession: this.session,\nstatus: messages.Presence.AVAILABLE,\n});\nmethod = this.client.SendPresence;\nbreak;\ncase WAHAPresenceStatus.OFFLINE:\nrequest = new messages.PresenceRequest({\nsession: this.session,\nstatus: messages.Presence.UNAVAILABLE,\n});\nmethod = this.client.SendPresence;\nbreak;\ncase WAHAPresenceStatus.TYPING:\nrequest = new messages.ChatPresenceRequest({\nsession: this.session,\njid: jid,\nstatus: messages.ChatPresence.TYPING,\n});\nmethod = this.client.SendChatPresence;\nbreak;\ncase WAHAPresenceStatus.RECORDING:\nrequest = new messages.ChatPresenceRequest({\nsession: this.session,\njid: jid,\nstatus: messages.ChatPresence.RECORDING,\n});\nmethod = this.client.SendChatPresence;\nbreak;\ncase WAHAPresenceStatus.PAUSED:\nrequest = new messages.ChatPresenceRequest({\nsession: this.session,\njid: jid,\nstatus: messages.ChatPresence.PAUSED,\n});\nmethod = this.client.SendChatPresence;\nbreak;\ndefault:\nthrow new Error('Invalid presence status');\n}\nawait promisify(method)(request);\n}"
"public async getChatMessages(\nchatId: string,\nquery: GetChatMessagesQuery,\nfilter: GetChatMessagesFilter,\n) {\nconst downloadMedia = query.downloadMedia;\nlet jid: messages.OptionalString;\nif (chatId === 'all') {\njid = null;\n} else {\njid = new messages.OptionalString({\nvalue: toJID(this.ensureSuffix(chatId)),\n});\n}\nconst status =\nfilter['filter.ack'] != null ? AckToStatus(filter['filter.ack']) : null;\nconst request = new messages.GetMessagesRequest({\nsession: this.session,\nfilters: new messages.MessageFilters({\njid: jid,\ntimestampGte: optional(\nfilter['filter.timestamp.gte'],\nmessages.OptionalUInt64,\n),\ntimestampLte: optional(\nfilter['filter.timestamp.lte'],\nmessages.OptionalUInt64,\n),\nfromMe: optional(filter['filter.fromMe'], messages.OptionalBool),\nstatus: optional(status, messages.OptionalUInt32),\n}),\npagination: new messages.Pagination({\nlimit: query.limit,\noffset: query.offset,\n}),\n});\nconst response = await promisify(this.client.GetMessages)(request);\nconst msgs = parseJsonList(response);\nconst promises = [];\nfor (const msg of msgs) {\npromises.push(this.processIncomingMessage(msg, downloadMedia));\n}\nlet result = await Promise.all(promises);\nresult = result.filter(Boolean);\nreturn result;\n}"
"receiptToMessageAck(receipt: any): WAMessageAckBody[] {\nconst fromToParticipant = getFromToParticipant(receipt);\nlet ack;\nswitch (receipt.Type) {\ncase '':\nack = WAMessageAck.DEVICE;\nbreak;\ncase 'server-error':\nack = WAMessageAck.ERROR;\nbreak;\ncase 'inactive':\nack = WAMessageAck.DEVICE;\nbreak;\ncase 'active':\nack = WAMessageAck.DEVICE;\nbreak;\ncase 'read':\nack = WAMessageAck.READ;\nbreak;\ncase 'played':\nack = WAMessageAck.PLAYED;\nbreak;\ndefault:\nreturn [];\n}\nconst acks = [];\nfor (const messageId of receipt.MessageIDs) {\nconst msg = {\n...receipt,\nID: messageId,\nIsFromMe: !receipt.IsFromMe,\nSender: receipt.MessageSender || this.me?.id,\n};\nconst id = buildMessageId(msg);\nconst body: WAMessageAckBody = {\nid: id,\nfrom: toCusFormat(fromToParticipant.from),\nto: toCusFormat(fromToParticipant.to),\nparticipant: toCusFormat(fromToParticipant.participant),\nfromMe: msg.IsFromMe,\nack: ack,\nackName: WAMessageAck[ack] || ACK_UNKNOWN,\n_data: receipt,\n};\nacks.push(body);\n}\nreturn acks;\n}"
"export function ToGroupV2Participants(\nupdate: GroupParticipantUpdate,\n): GroupV2ParticipantsEvent {\nlet role: GroupParticipantRole;\nlet type: GroupParticipantType;\nswitch (update.action) {\ncase 'add':\nrole = GroupParticipantRole.PARTICIPANT;\ntype = GroupParticipantType.JOIN;\nbreak;\ncase 'remove':\nrole = GroupParticipantRole.LEFT;\ntype = GroupParticipantType.LEAVE;\nbreak;\ncase 'promote':\nrole = GroupParticipantRole.ADMIN;\ntype = GroupParticipantType.PROMOTE;\nbreak;\ncase 'demote':\nrole = GroupParticipantRole.ADMIN;\ntype = GroupParticipantType.DEMOTE;\nbreak;\n}\nconst participants: GroupParticipant[] = update.participants.map((id) => {\nreturn {\nid: toCusFormat(id),\nrole: role,\n};\n});\nreturn {\ngroup: {\nid: toCusFormat(update.id),\n},\ntype: type,\ntimestamp: Date.now(),\nparticipants: participants,\n_data: update,\n};\n}"
"export async function sendButtonMessage(\nsock: any,\nchatId: string,\nbuttons: Button[],\nheader?: string,\nheaderImage?: any,\nbody?: string,\nfooter?: string,\n) {\nconst data = {\nviewOnceMessage: {\nmessage: {\nmessageContextInfo: {\ndeviceListMetadata: {},\ndeviceListMetadataVersion: 2,\n},\ninteractiveMessage: {\nbody: undefined,\nheader: undefined,\nfooter: undefined,\nnativeFlowMessage: {\nbuttons: buttons.map(buttonToJson),\nmessageParamsJson: JSON.stringify({\nfrom: 'api',\ntemplateId: randomId(),\n}),\n},\n},\n},\n},\n};\nif (header || headerImage) {\ndata.viewOnceMessage.message.interactiveMessage.header = {\ntitle: header,\nhasMediaAttachment: !!headerImage,\nimageMessage: headerImage,\n};\n}\nif (body) {\ndata.viewOnceMessage.message.interactiveMessage.body = {\ntext: body,\n};\n}\nif (footer) {\ndata.viewOnceMessage.message.interactiveMessage.footer = {\ntext: footer,\n};\n}\nconst msg = proto.Message.fromObject(data);\nconst fullMessage = generateWAMessageFromContent(chatId, msg, {\nuserJid: sock?.user?.id,\n});\nawait sock.relayMessage(chatId, fullMessage.message, {\nmessageId: fullMessage.key.id,\n});\nreturn fullMessage;\n}"
"protected listenConnectionEvents() {\nthis.logger.debug(`Start listening ${BaileysEvents.CONNECTION_UPDATE}...`);\nthis.sock.ev.on('connection.update', async (update) => {\nconst { connection, lastDisconnect, qr, isNewLogin } = update;\nif (isNewLogin) {\nthis.restartClient();\n} else if (connection === 'open') {\nthis.qr.save('');\nthis.status = WAHASessionStatus.WORKING;\nreturn;\n} else if (connection === 'close') {\nthis.qr.save('');\nconst error = lastDisconnect.error as any;\nconst statusCode = error?.output?.statusCode;\nconst restartRequired = statusCode === DisconnectReason.restartRequired;\nif (restartRequired) {\nthis.restartClient();\nreturn;\n}\nif (this.statusTracker.isStuckInStarting()) {\nthis.logger.error(\n'Session stuck in STARTING status, force stopping the session.',\n);\nawait this.failed();\nreturn;\n}\nif (this.status == WAHASessionStatus.SCAN_QR_CODE) {\nthis.logger.warn(\n'QR code has not been scanned yet, force stopping the session.',\n);\nawait this.failed();\nreturn;\n}\nconst shouldReconnect = statusCode !== DisconnectReason.loggedOut;\nif (shouldReconnect) {\nif (lastDisconnect.error) {\nthis.logger.info(\n`Connection closed due to '${lastDisconnect.error}', reconnecting...`,\n);\n}\nthis.restartClient();\nreturn;\n}\nthis.logger.error(\n`Connection closed due to '${lastDisconnect.error}', do not reconnect the session.`,\n);\nawait this.failed();\n}\nif (qr) {\nthis.qr.save(qr);\nthis.printQR(this.qr);\nthis.status = WAHASessionStatus.SCAN_QR_CODE;\n}\n});\n}"
"private issueMessageUpdateOnPoll() {\nthis.sock.ev.on('messages.upsert', async ({ messages }) => {\nconst meId = this.getSessionMeInfo().id;\nif (!meId) {\nreturn;\n}\nfor (const message of messages) {\nconst content = normalizeMessageContent(message.message);\nif (!content?.pollUpdateMessage) {\ncontinue;\n}\nconst creationMsgKey = content.pollUpdateMessage.pollCreationMessageKey;\nconst pollMsg = await this.getMessage(creationMsgKey);\nif (!pollMsg) {\nthis.logger.warn(\n{ creationMsgKey },\n'poll creation message not found, cannot decrypt update',\n);\ncontinue;\n}\nconst meIdNormalised = jidNormalizedUser(meId);\nconst pollCreatorJid = getKeyAuthor(creationMsgKey, meIdNormalised);\nconst voterJid = getKeyAuthor(message.key, meIdNormalised);\nconst pollEncKey = pollMsg.messageContextInfo?.messageSecret;\ntry {\nconst voteMsg = decryptPollVote(content.pollUpdateMessage.vote, {\npollEncKey,\npollCreatorJid,\npollMsgId: creationMsgKey.id,\nvoterJid,\n});\nthis.sock.ev.emit('messages.update', [\n{\nkey: creationMsgKey,\nupdate: {\npollUpdates: [\n{\npollUpdateMessageKey: message.key,\nvote: voteMsg,\nsenderTimestampMs: (\ncontent.pollUpdateMessage.senderTimestampMs as Long\n).toNumber(),\n},\n],\n},\n},\n]);\n} catch (err) {\nthis.logger.warn(\n{ err, creationMsgKey },\n'failed to decrypt poll vote',\n);\n}\n}\n});\n}"
"protected async processIncomingMessage(message, downloadMedia = true) {\nif (!message) return;\nif (!message.message) return;\nif (message.message.reactionMessage) return;\nif (message.message.pollUpdateMessage) return;\nif (message.message.call?.callKey) return;\nif (\nmessage.message?.protocolMessage?.type ===\nproto.Message.ProtocolMessage.Type.REVOKE\n)\nreturn;\nif (\nmessage.message?.protocolMessage?.type ===\nproto.Message.ProtocolMessage.Type.MESSAGE_EDIT\n)\nreturn;\nif (\nmessage.message?.protocolMessage?.type ===\nproto.Message.ProtocolMessage.Type.EPHEMERAL_SYNC_RESPONSE\n)\nreturn;\nconst normalizedContent = normalizeMessageContent(message.message);\nconst hasSomeContent = !!getContentType(normalizedContent);\nif (!hasSomeContent) {\nif (message?.message?.senderKeyDistributionMessage) return;\n}\nif (downloadMedia) {\ntry {\nmessage = await this.downloadMedia(message);\n} catch (e) {\nthis.logger.error('Failed when tried to download media for a message');\nthis.logger.error(e, e.stack);\n}\n}\ntry {\nreturn await this.toWAMessage(message);\n} catch (error) {\nthis.logger.error('Failed to process incoming message');\nthis.logger.error(error);\nconsole.trace(error);\nreturn null;\n}\n}"
"export function TagReceiptNodeToReceiptEvent(\nnode: BinaryNode,\nme: Me,\n): ReceiptEvent[] {\nconst { attrs, content } = node;\nconst status = getStatusFromReceiptType(attrs.type);\nif (status == null) {\nreturn null;\n}\nconst from = jidNormalizedUser(jid(attrs.from));\nconst participant = jidNormalizedUser(jid(attrs.participant));\nconst recipient = jidNormalizedUser(jid(attrs.recipient));\nconst isLid = from.includes('lid');\nconst isNodeFromMe = areJidsSameUser(\nparticipant || from,\nisLid ? me?.lid : me?.id,\n);\nconst remoteJid = !isNodeFromMe || isJidGroup(from) ? from : recipient;\nconst fromMe = !recipient || (attrs.type === 'retry' && isNodeFromMe);\nif (status < proto.WebMessageInfo.Status.SERVER_ACK && isNodeFromMe) {\nreturn [];\n}\nconst key: proto.IMessageKey = {\nremoteJid: remoteJid,\nid: '',\nfromMe: fromMe,\n};\nconst ids = [attrs.id];\nif (Array.isArray(content)) {\nconst items = getBinaryNodeChildren(content[0], 'item');\nids.push(...items.map((i) => i.attrs.id));\n}\nif (isJidGroup(remoteJid) || isJidStatusBroadcast(remoteJid)) {\nif (participant) {\nkey.participant = fromMe ? (isLid ? me.lid : me.id) : recipient;\nconst eventParticipant = fromMe ? participant : isLid ? me.lid : me.id;\nreturn [\n{\nkey: key,\nmessageIds: ids,\nstatus: status as any,\nparticipant: eventParticipant,\n_node: node,\n},\n];\n} else {\nreturn handleGroupedReceipts(node, key, status, fromMe, isLid, me);\n}\n}\nreturn [\n{\nkey: key,\nmessageIds: ids,\nstatus: status as any,\n_node: node,\n},\n];\n}"
"function handleGroupedReceipts(\nnode: BinaryNode,\nkey: proto.IMessageKey,\nstatus: number,\nfromMe: boolean,\nisLid: boolean,\nme: Me,\n): ReceiptEvent[] | null {\nconst { content } = node;\nif (!Array.isArray(content)) {\nreturn [];\n}\nconst participantsTags = content.filter((c) => c.tag === 'participants');\nif (participantsTags.length === 0) {\nreturn null;\n}\nconst receiptEvents: ReceiptEvent[] = [];\nfor (const participants of participantsTags) {\nconst participantKey = participants.attrs?.key;\nif (!participantKey) continue;\nconst users = getBinaryNodeChildren(participants, 'user');\nfor (const user of users) {\nconst userAttrs = user.attrs;\nif (!userAttrs) continue;\nconst userJid = jidNormalizedUser(jid(userAttrs.jid));\nif (!userJid) continue;\nkey.participant = fromMe ? (isLid ? me.lid : me.id) : userJid;\nconst eventParticipant = fromMe ? userJid : isLid ? me.lid : me.id;\nconst receiptEvent: ReceiptEvent = {\nkey: {\n...key,\nid: participantKey,\n},\nmessageIds: [participantKey],\nstatus: status as any,\nparticipant: eventParticipant,\n_node: node,\n};\nreceiptEvents.push(receiptEvent);\n}\n}\nreturn receiptEvents;\n}"
"export function ToGroupV2ParticipantsEvent(\nnotification: GroupNotification,\n): GroupV2ParticipantsEvent | null {\nlet type: GroupParticipantType;\nlet role: GroupParticipantRole;\nif (['add', 'invite', 'linked_group_join'].includes(notification.type)) {\ntype = GroupParticipantType.JOIN;\nrole = GroupParticipantRole.PARTICIPANT;\n} else if (['remove', 'leave'].includes(notification.type)) {\ntype = GroupParticipantType.LEAVE;\nrole = GroupParticipantRole.LEFT;\n} else if (['promote'].includes(notification.type)) {\ntype = GroupParticipantType.PROMOTE;\nrole = GroupParticipantRole.ADMIN;\n} else if (['demote'].includes(notification.type)) {\ntype = GroupParticipantType.DEMOTE;\nrole = GroupParticipantRole.PARTICIPANT;\n} else {\nreturn null;\n}\nconst participants: GroupParticipant[] = notification.recipientIds.map(\n(id) => {\nreturn {\nid: id,\nrole: role,\n};\n},\n);\nconst group: GroupId = {\nid: notification.id.remote,\n};\nreturn {\ngroup: group,\ntype: type,\ntimestamp: notification.timestamp,\nparticipants: participants,\n_data: notification,\n};\n}"
"protected async init() {\nthis.shouldRestart = true;\nthis.whatsapp = await this.buildClient();\nthis.whatsapp\n.initialize()\n.then(() => {\nthis.whatsapp.pupBrowser.on('disconnected', () => {\nif (this.shouldRestart) {\nthis.logger.error('The browser has been disconnected');\n} else {\nthis.logger.info('The browser has been disconnected');\n}\nthis.failed();\n});\nthis.whatsapp.pupPage.on('close', () => {\nthis.logger.error('The WhatsApp Web page has been closed');\nthis.failed();\n});\nthis.whatsapp.events.on(\nPAGE_CALL_ERROR_EVENT,\n(event: CallErrorEvent) => {\nif (event.error instanceof ProtocolError) {\nthis.logger.error(\n`ProtocolError when calling page method: ${String(\nevent.method,\n)}, restarting client...`,\n);\nthis.logger.error(event.error);\nthis.failed();\n}\n},\n);\nif (this.isDebugEnabled()) {\nthis.logger.debug(`Logging 'console' event for web page`);\nthis.whatsapp.pupPage.on('console', (msg) =>\nthis.logger.debug(`WEBJS page log: ${msg.text()}`),\n);\nthis.whatsapp.pupPage.evaluate(() =>\nconsole.log(`url is ${location.href}`),\n);\n}\n})\n.catch((error) => {\nthis.logger.error(error);\nthis.failed();\nreturn;\n});\nif (this.isDebugEnabled()) {\nthis.listenEngineEventsInDebugMode();\n}\nthis.listenConnectionEvents();\nthis.subscribeEngineEvents2();\n}"
"private async end() {\nthis.engineStateCheckDelayedJob.cancel();\nthis.whatsapp?.removeAllListeners();\nthis.whatsapp?.pupBrowser?.removeAllListeners();\nthis.whatsapp?.pupPage?.removeAllListeners();\ntry {\nawait waitUntil(\nasync () => {\nconst result = !!this.whatsapp.pupBrowser;\nthis.logger.debug(`Browser is ready to be closed: ${result}`);\nreturn result;\n},\n1_000,\n10_000,\n);\nthis.logger.debug(\n'Successfully waited for browser to be ready for closing',\n);\n} catch (error) {\nthis.logger.error(\nerror,\n'Failed while waiting for browser to be ready for closing',\n);\n}\ntry {\nawait this.whatsapp?.destroy();\nthis.logger.debug('Successfully destroyed whatsapp client');\n} catch (error) {\nthis.logger.error(error, 'Failed to destroy whatsapp client');\n}\ntry {\nconst strategy: AuthStrategy = this.whatsapp?.authStrategy;\nawait strategy?.destroy();\nthis.logger.debug('Successfully destroyed auth strategy');\n} catch (error) {\nthis.logger.error(error, 'Failed to destroy auth strategy');\n}\n}"
"async getMessages(\nchatId: string,\nfilter: GetChatMessagesFilter,\npagination: PaginationParams,\n) {\nconst messages = await this.pupPage.evaluate(\nasync (chatId, filter, pagination) => {\npagination.limit ||= Infinity;\npagination.offset ||= 0;\nconst msgFilter = (m) => {\nif (m.isNotification) {\nreturn false;\n}\nif (\nfilter['filter.fromMe'] != null &&\nm.id.fromMe !== filter['filter.fromMe']\n) {\nreturn false;\n}\nif (\nfilter['filter.timestamp.gte'] != null &&\nm.t < filter['filter.timestamp.gte']\n) {\nreturn false;\n}\nif (\nfilter['filter.timestamp.lte'] != null &&\nm.t > filter['filter.timestamp.lte']\n) {\nreturn false;\n}\nif (filter['filter.ack'] != null && m.ack !== filter['filter.ack']) {\nreturn false;\n}\nreturn true;\n};\nconst chat = await window.WWebJS.getChat(chatId, { getAsModel: false });\nlet msgs = chat.msgs.getModelsArray().filter(msgFilter);\nwhile (msgs.length < pagination.limit + pagination.offset) {\nconst loadedMessages =\nawait window.Store.ConversationMsgs.loadEarlierMsgs(chat);\nif (!loadedMessages || loadedMessages.length == 0) break;\nmsgs = [...loadedMessages.filter(msgFilter), ...msgs];\nmsgs = msgs.sort((a, b) => b.t - a.t);\nconst earliest = msgs[msgs.length - 1];\nif (earliest.t < (filter['filter.timestamp.gte'] || Infinity)) {\nbreak;\n}\n}\nif (msgs.length > pagination.limit + pagination.offset) {\nmsgs = msgs.sort((a, b) => b.t - a.t);\nmsgs = msgs.slice(\npagination.offset,\npagination.limit + pagination.offset,\n);\n}\nreturn msgs.map((m) => window.WWebJS.getMessageModel(m));\n},\nchatId,\nfilter,\npagination,\n);\nreturn messages.map((m) => new Message(this, m));\n}"
"send(json: any) {\nconst body = JSON.stringify(json);\nconst headers = {\n'content-type': 'application/json',\n};\nObject.assign(headers, this.getWebhookHeader(json));\nObject.assign(headers, this.getHMACHeaders(body));\nconst ctx = {\nid: headers['X-Webhook-Request-Id'],\n['event.id']: json.id,\nurl: this.url,\n};\nthis.logger.info(ctx, `Sending POST...`);\nthis.logger.debug(ctx, `POST DATA`);\nthis.axios\n.post(this.url, body, { headers: headers })\n.then((response) => {\nthis.logger.info(\nctx,\n`POST request was sent with status code: ${response.status}`,\n);\nthis.logger.debug(\n{\n...ctx,\nbody: response.data,\n},\n`Response`,\n);\n})\n.catch((error) => {\nthis.logger.error(\n{\n...ctx,\nerror: error.message,\ndata: error.response?.data,\n},\n`POST request failed: ${error.message}`,\n);\n});\n}"
"async handle(body: any) {\nconst chatId = await LookupAndCheckChatId(this.session, body);\nconst message = body;\nif (message.content_type != 'text') {\nthis.logger.info(\n`Message content type not supported. Content type: ${message.content_type}`,\n);\nreturn;\n}\nconst content = MarkdownToWhatsApp(message.content);\nconst attachments = message.attachments || [];\nconst results = [];\nconst multipleAttachments = attachments.length > 1;\nlet part = 1;\nconst replyTo = await this.getReplyTo(message).catch((err) => {\nthis.logger.error(`Error getting reply to message ID: ${err}`);\nreturn undefined;\n});\nif (attachments.length == 0 || multipleAttachments) {\nconst msg = await this.sendTextMessage(chatId, content, replyTo);\nresults.push(msg);\npart = await this.saveMapping(message, msg, part);\nthis.logger.info(`Text message sent: ${msg.id}`);\n}\nconst fileMessageContent = multipleAttachments ? '' : content;\nfor (const file of attachments) {\nconst msg = await this.sendFile(\nchatId,\nfileMessageContent,\nfile,\nreplyTo,\n);\nthis.logger.info(\n`File message sent: ${msg.id} - ${file.data_url} - ${file.file_type}`,\n);\nresults.push(msg);\npart = await this.saveMapping(message, msg, part);\n}\nreturn results;\n}"
"private async sendFile(\nchatId: string,\ncontent: string,\nfile: MessageAttachment,\nreplyTo: string,\n) {\nconst url = file.data_url;\nlet filename = url.split('/').pop();\nif (filename) {\nfilename = decodeURIComponent(filename);\n}\nconst mimetype = mime.lookup(filename);\nconst session = this.session;\nswitch (file.file_type) {\ncase 'image':\nif (mimetype != 'image/jpeg' && mimetype != 'image/png') {\nbreak;\n}\nconst imageRequest: MessageImageRequest = {\nsession: '',\ncaption: content,\nchatId: chatId,\nreply_to: replyTo,\nfile: {\nurl: url,\nmimetype: mimetype,\n},\n};\nreturn session.sendImage(imageRequest);\ncase 'video':\nif (mimetype != 'video/mp4') {\nbreak;\n}\nconst videoRequest: MessageVideoRequest = {\nsession: '',\ncaption: content,\nchatId: chatId,\nreply_to: replyTo,\nfile: {\nurl: url,\nmimetype: mimetype,\nfilename: filename,\n},\nconvert: true,\n};\nreturn session.sendVideo(videoRequest);\ncase 'audio':\nconst voiceRequest: MessageVoiceRequest = {\nsession: '',\nchatId: chatId,\nfile: {\nurl: url,\nmimetype: mimetype,\nfilename: filename,\n},\nconvert: true,\n};\nreturn session.sendVoice(voiceRequest);\n}\nconst fileRequest: MessageFileRequest = {\nsession: '',\ncaption: content,\nchatId: chatId,\nreply_to: replyTo,\nfile: {\nfilename: filename,\nurl: url,\nmimetype: mimetype,\n},\n};\nreturn session.sendFile(fileRequest);\n}"
"private async buildChatWootMessage(\npayload: Payload,\n): Promise<conversation_message_create> {\nlet content: string = this.getContent(payload);\nif (payload.fromMe && payload.source === MessageSource.APP) {\nconst key = TKey.MESSAGE_FROM_WHATSAPP;\ncontent = this.l.key(key).render({ text: content });\n} else if (payload.fromMe && payload.source === MessageSource.API) {\nconst key = TKey.MESSAGE_FROM_API;\ncontent = this.l.key(key).render({ text: content });\n}\nconst chatId = payload.from;\nconst manyParticipants = isJidGroup(chatId) || isJidStatusBroadcast(chatId);\nif (!payload.fromMe && manyParticipants) {\nconst key = parseMessageIdSerialized(payload.id, true);\nlet participant = toCusFormat(key.participant);\nconst contact: any = await this.session.getContact(key.participant);\nconst name = contact?.name || contact?.pushName || contact?.pushname;\nif (name) {\nparticipant = `${name} (${participant})`;\n}\ncontent = this.l.key(TKey.WHATSAPP_GROUP_MESSAGE).render({\ntext: content,\nparticipant: participant,\n});\n}\nconst attachments: SendAttachment[] = await this.getAttachments(payload);\nif (!content && attachments.length > 0) {\ncontent = ' ';\n}\nconst replyTo = await this.getReplyToChatWootMessageID(payload).catch(\n(err) => {\nthis.logger.error(`Error getting reply to message ID: ${err}`);\nreturn undefined;\n},\n);\nconst type = payload.fromMe ? MessageType.OUTGOING : MessageType.INCOMING;\nreturn {\ncontent: content,\nmessage_type: type,\nprivate: payload.fromMe,\nattachments: attachments as any,\ncontent_attributes: {\nin_reply_to: replyTo,\n},\n};\n}"
"async handle(data: WAHAWebhookSessionStatus) {\nconst conversation = await this.repo.InboxNotifications();\nconst emoji = SessionStatusEmoji(data.payload.status);\nconst activity = this.l.key(TKey.APP_SESSION_STATUS_CHANGE).r({\nemoji: emoji,\nsession: data.session,\nstatus: data.payload.status,\n});\nawait conversation.activity(activity);\nconst payload = data.payload;\nlet text = '';\nswitch (payload.status) {\ncase WAHASessionStatus.STARTING:\nbreak;\ncase WAHASessionStatus.WORKING:\ntext = this.l.key(TKey.APP_SESSION_STATUS_WORKING).r({\nname: data.me?.pushName || 'Unknown',\nid: data.me?.id || 'No phone number',\n});\nbreak;\ncase WAHASessionStatus.STOPPED:\ncase WAHASessionStatus.FAILED:\ntext = this.l.key(TKey.APP_SESSION_STATUS_ERROR).r();\ntext += '\n\n';\ntext += this.l.key(TKey.APP_HELP_REMINDER).r();\ntext += '\n\n';\nbreak;\ncase WAHASessionStatus.SCAN_QR_CODE:\ntext = this.l.key(TKey.APP_SESSION_SCAN_QR_CODE).r();\n}\nif (text) {\nconst message: conversation_message_create = {\ncontent: text,\nmessage_type: MessageType.INCOMING as any,\n};\nawait conversation.send(message);\n}\nif (payload.status === WAHASessionStatus.SCAN_QR_CODE) {\nconst buffer = await this.waha.qr(data.session);\nconst message = AttachmentFromBuffer(buffer, 'qr.jpg');\nmessage.message_type = MessageType.INCOMING;\nreturn await conversation.send(message);\n}\n}"
static fromObject(data: {\nsession?: ReturnType<typeof Session.prototype.toObject>;\njid?: string;\ntext?: string;\nmedia?: ReturnType<typeof Media.prototype.toObject>;\nbackgroundColor?: ReturnType<typeof OptionalString.prototype.toObject>;\nfont?: ReturnType<typeof OptionalUInt32.prototype.toObject>;\nlinkPreview?: boolean;\nlinkPreviewHighQuality?: boolean;\nreplyTo?: string;\nid?: string;\nparticipants?: string[];\npreview?: ReturnType<typeof LinkPreview.prototype.toObject>;\ncontacts?: ReturnType<typeof vCardContact.prototype.toObject>[];\nevent?: ReturnType<typeof EventMessage.prototype.toObject>;\npoll?: ReturnType<typeof PollMessage.prototype.toObject>;\n}): MessageRequest {\nconst message = new MessageRequest({});\nif (data.session != null) {\nmessage.session = Session.fromObject(data.session);\n}\nif (data.jid != null) {\nmessage.jid = data.jid;\n}\nif (data.text != null) {\nmessage.text = data.text;\n}\nif (data.media != null) {\nmessage.media = Media.fromObject(data.media);\n}\nif (data.backgroundColor != null) {\nmessage.backgroundColor = OptionalString.fromObject(data.backgroundColor);\n}\nif (data.font != null) {\nmessage.font = OptionalUInt32.fromObject(data.font);\n}\nif (data.linkPreview != null) {\nmessage.linkPreview = data.linkPreview;\n}\nif (data.linkPreviewHighQuality != null) {\nmessage.linkPreviewHighQuality = data.linkPreviewHighQuality;\n}\nif (data.replyTo != null) {\nmessage.replyTo = data.replyTo;\n}\nif (data.id != null) {\nmessage.id = data.id;\n}\nif (data.participants != null) {\nmessage.participants = data.participants;\n}\nif (data.preview != null) {\nmessage.preview = LinkPreview.fromObject(data.preview);\n}\nif (data.contacts != null) {\nmessage.contacts = data.contacts.map(item => vCardContact.fromObject(item));\n}\nif (data.event != null) {\nmessage.event = EventMessage.fromObject(data.event);\n}\nif (data.poll != null) {\nmessage.poll = PollMessage.fromObject(data.poll);\n}\nreturn message;\n}
toObject() {\nconst data: {\nsession?: ReturnType<typeof Session.prototype.toObject>;\njid?: string;\ntext?: string;\nmedia?: ReturnType<typeof Media.prototype.toObject>;\nbackgroundColor?: ReturnType<typeof OptionalString.prototype.toObject>;\nfont?: ReturnType<typeof OptionalUInt32.prototype.toObject>;\nlinkPreview?: boolean;\nlinkPreviewHighQuality?: boolean;\nreplyTo?: string;\nid?: string;\nparticipants?: string[];\npreview?: ReturnType<typeof LinkPreview.prototype.toObject>;\ncontacts?: ReturnType<typeof vCardContact.prototype.toObject>[];\nevent?: ReturnType<typeof EventMessage.prototype.toObject>;\npoll?: ReturnType<typeof PollMessage.prototype.toObject>;\n} = {};\nif (this.session != null) {\ndata.session = this.session.toObject();\n}\nif (this.jid != null) {\ndata.jid = this.jid;\n}\nif (this.text != null) {\ndata.text = this.text;\n}\nif (this.media != null) {\ndata.media = this.media.toObject();\n}\nif (this.backgroundColor != null) {\ndata.backgroundColor = this.backgroundColor.toObject();\n}\nif (this.font != null) {\ndata.font = this.font.toObject();\n}\nif (this.linkPreview != null) {\ndata.linkPreview = this.linkPreview;\n}\nif (this.linkPreviewHighQuality != null) {\ndata.linkPreviewHighQuality = this.linkPreviewHighQuality;\n}\nif (this.replyTo != null) {\ndata.replyTo = this.replyTo;\n}\nif (this.id != null) {\ndata.id = this.id;\n}\nif (this.participants != null) {\ndata.participants = this.participants;\n}\nif (this.preview != null) {\ndata.preview = this.preview.toObject();\n}\nif (this.contacts != null) {\ndata.contacts = this.contacts.map((item: vCardContact) => item.toObject());\n}\nif (this.event != null) {\ndata.event = this.event.toObject();\n}\nif (this.poll != null) {\ndata.poll = this.poll.toObject();\n}\nreturn data;\n}
"static deserialize(bytes: Uint8Array | pb_1.BinaryReader): MessageRequest {\nconst reader = bytes instanceof pb_1.BinaryReader ? bytes : new pb_1.BinaryReader(bytes), message = new MessageRequest();\nwhile (reader.nextField()) {\nif (reader.isEndGroup())\nbreak;\nswitch (reader.getFieldNumber()) {\ncase 1:\nreader.readMessage(message.session, () => message.session = Session.deserialize(reader));\nbreak;\ncase 2:\nmessage.jid = reader.readString();\nbreak;\ncase 3:\nmessage.text = reader.readString();\nbreak;\ncase 4:\nreader.readMessage(message.media, () => message.media = Media.deserialize(reader));\nbreak;\ncase 5:\nreader.readMessage(message.backgroundColor, () => message.backgroundColor = OptionalString.deserialize(reader));\nbreak;\ncase 6:\nreader.readMessage(message.font, () => message.font = OptionalUInt32.deserialize(reader));\nbreak;\ncase 7:\nmessage.linkPreview = reader.readBool();\nbreak;\ncase 8:\nmessage.linkPreviewHighQuality = reader.readBool();\nbreak;\ncase 9:\nmessage.replyTo = reader.readString();\nbreak;\ncase 10:\nmessage.id = reader.readString();\nbreak;\ncase 11:\npb_1.Message.addToRepeatedField(message, 11, reader.readString());\nbreak;\ncase 12:\nreader.readMessage(message.preview, () => message.preview = LinkPreview.deserialize(reader));\nbreak;\ncase 13:\nreader.readMessage(message.contacts, () => pb_1.Message.addToRepeatedWrapperField(message, 13, vCardContact.deserialize(reader), vCardContact));\nbreak;\ncase 14:\nreader.readMessage(message.event, () => message.event = EventMessage.deserialize(reader));\nbreak;\ncase 15:\nreader.readMessage(message.poll, () => message.poll = PollMessage.deserialize(reader));\nbreak;\ndefault: reader.skipField();\n}\n}\nreturn message;\n}"
static fromObject(data: {\nid?: string;\nname?: string;\ndescription?: string;\ninvite?: string;\npreview?: string;\npicture?: string;\nverified?: boolean;\nrole?: string;\nsubscriberCount?: number;\n}): Newsletter {\nconst message = new Newsletter({});\nif (data.id != null) {\nmessage.id = data.id;\n}\nif (data.name != null) {\nmessage.name = data.name;\n}\nif (data.description != null) {\nmessage.description = data.description;\n}\nif (data.invite != null) {\nmessage.invite = data.invite;\n}\nif (data.preview != null) {\nmessage.preview = data.preview;\n}\nif (data.picture != null) {\nmessage.picture = data.picture;\n}\nif (data.verified != null) {\nmessage.verified = data.verified;\n}\nif (data.role != null) {\nmessage.role = data.role;\n}\nif (data.subscriberCount != null) {\nmessage.subscriberCount = data.subscriberCount;\n}\nreturn message;\n}
toObject() {\nconst data: {\nid?: string;\nname?: string;\ndescription?: string;\ninvite?: string;\npreview?: string;\npicture?: string;\nverified?: boolean;\nrole?: string;\nsubscriberCount?: number;\n} = {};\nif (this.id != null) {\ndata.id = this.id;\n}\nif (this.name != null) {\ndata.name = this.name;\n}\nif (this.description != null) {\ndata.description = this.description;\n}\nif (this.invite != null) {\ndata.invite = this.invite;\n}\nif (this.preview != null) {\ndata.preview = this.preview;\n}\nif (this.picture != null) {\ndata.picture = this.picture;\n}\nif (this.verified != null) {\ndata.verified = this.verified;\n}\nif (this.role != null) {\ndata.role = this.role;\n}\nif (this.subscriberCount != null) {\ndata.subscriberCount = this.subscriberCount;\n}\nreturn data;\n}
"private async onMessageUpdate(updates) {\nfor (const update of updates) {\nconst jid = jidNormalizedUser(update.key.remoteJid!);\nif (!update.key.id) {\ncontinue;\n}\nif (!jid) {\nthis.logger.warn(\n`got message update for unknown jid. update: '${JSON.stringify(\nupdate,\n)}'`,\n);\ncontinue;\n}\nconst message = await this.messagesRepo.getByJidById(jid, update.key.id);\nif (!message) {\nthis.logger.warn(\n`got update for non-existent message. update: '${JSON.stringify(\nupdate,\n)}'`,\n);\ncontinue;\n}\nconst fields = { ...update.update };\nconst onlyStatusField =\nObject.keys(fields).length === 1 &&\n'status' in fields &&\nfields.status !== null;\nif (onlyStatusField) {\nif (message.status >= fields.status) {\ncontinue;\n}\n}\ndelete fields['key'];\nObject.assign(message, fields);\nconst isYetRealMessage =\nisRealMessage(message, this.socket?.authState?.creds?.me?.id) || false;\nif (isYetRealMessage) {\nawait this.messagesRepo.upsertOne(message);\n} else {\nawait this.messagesRepo.deleteByJidByIds(jid, [update.key.id]);\n}\n}\n}"
"export function BackgroundVideo({ src }: BackgroundVideoProps) {\nconst isDesktop = useMediaQuery('(min-width: 1280px)');\nconst [isVideoLoaded, setIsVideoLoaded] = useState(false);\nconst baseName = src.replace(/\.[^/.]+$/, '');\nif (!isDesktop) {\nreturn (\n<div className=`fixed inset-0`>\n<Image\nsrc={`${baseName}-placeholder.jpg`}\nalt=`Background placeholder`\nfill\npriority\nclassName=`object-cover opacity-30 blur-md`\nsizes=`100vw`\n/>\n</div>\n);\n}\nreturn (\n<div className=`fixed inset-0`>\n{}\n<Image\nsrc={`${baseName}-placeholder.jpg`}\nalt=`Background placeholder`\nfill\npriority\nsizes=`100vw`\nclassName={`object-cover transition-opacity duration-500 ${\nisVideoLoaded ? 'opacity-0' : 'opacity-30'\n} blur-md`}\n/>\n{}\n<video\nautoPlay\nloop\nmuted\nplaysInline\nonLoadedData={() => setIsVideoLoaded(true)}\nclassName={`w-full h-full object-cover transition-opacity duration-500 ${\nisVideoLoaded ? 'opacity-30' : 'opacity-0'\n} blur-md`}\n>\n<source src={src} type=`video/mp4` />\n</video>\n</div>\n);\n}"
"export async function POST(req: Request) {\nconst body: SettleRequest = await req.json();\nconst network = body.paymentRequirements.network;\nconst privateKey = SupportedEVMNetworks.includes(network)\n? process.env.PRIVATE_KEY\n: SupportedSVMNetworks.includes(network)\n? process.env.SOLANA_PRIVATE_KEY\n: undefined;\nif (!privateKey) {\nreturn Response.json(\n{\nsuccess: false,\nerrorReason: `invalid_network`,\n} as SettleResponse,\n{ status: 400 },\n);\n}\nconst wallet = await createSigner(network, privateKey);\nlet paymentPayload: PaymentPayload;\ntry {\npaymentPayload = PaymentPayloadSchema.parse(body.paymentPayload);\n} catch (error) {\nconsole.error(`Invalid payment payload:`, error);\nreturn Response.json(\n{\nsuccess: false,\nerrorReason: `invalid_payload`,\ntransaction: ``,\nnetwork: body.paymentPayload?.network || ``,\n} as SettleResponse,\n{ status: 400 },\n);\n}\nlet paymentRequirements: PaymentRequirements;\ntry {\npaymentRequirements = PaymentRequirementsSchema.parse(body.paymentRequirements);\n} catch (error) {\nconsole.error(`Invalid payment requirements:`, error);\nreturn Response.json(\n{\nsuccess: false,\nerrorReason: `invalid_payment_requirements`,\ntransaction: ``,\nnetwork: paymentPayload.network,\n} as SettleResponse,\n{ status: 400 },\n);\n}\ntry {\nconst response = await settle(wallet, paymentPayload, paymentRequirements);\nreturn Response.json(response);\n} catch (error) {\nconsole.error(`Error settling payment:`, error);\nreturn Response.json(\n{\nsuccess: false,\nerrorReason: `unexpected_settle_error`,\ntransaction: ``,\nnetwork: paymentPayload.network,\n} as SettleResponse,\n{ status: 500 },\n);\n}\n}"
"export async function POST(req: Request) {\nconst body: VerifyRequest = await req.json();\nconst network = body.paymentRequirements.network;\nconst client = SupportedEVMNetworks.includes(network)\n? createConnectedClient(body.paymentRequirements.network)\n: SupportedSVMNetworks.includes(network)\n? await createSigner(network, process.env.SOLANA_PRIVATE_KEY)\n: undefined;\nif (!client) {\nreturn Response.json(\n{\nisValid: false,\ninvalidReason: `invalid_network`,\n} as VerifyResponse,\n{ status: 400 },\n);\n}\nlet paymentPayload: PaymentPayload;\ntry {\npaymentPayload = PaymentPayloadSchema.parse(body.paymentPayload);\n} catch (error) {\nconsole.error(`Invalid payment payload:`, error);\nreturn Response.json(\n{\nisValid: false,\ninvalidReason: `invalid_payload`,\npayer:\nbody.paymentPayload?.payload && `authorization` in body.paymentPayload.payload\n? body.paymentPayload.payload.authorization.from\n: ``,\n} as VerifyResponse,\n{ status: 400 },\n);\n}\nlet paymentRequirements: PaymentRequirements;\ntry {\npaymentRequirements = PaymentRequirementsSchema.parse(body.paymentRequirements);\n} catch (error) {\nconsole.error(`Invalid payment requirements:`, error);\nreturn Response.json(\n{\nisValid: false,\ninvalidReason: `invalid_payment_requirements`,\npayer:\n`authorization` in paymentPayload.payload\n? paymentPayload.payload.authorization.from\n: ``,\n} as VerifyResponse,\n{ status: 400 },\n);\n}\ntry {\nconst valid = await verify(client, paymentPayload, paymentRequirements);\nreturn Response.json(valid);\n} catch (error) {\nconsole.error(`Error verifying payment:`, error);\nreturn Response.json(\n{\nisValid: false,\ninvalidReason: `unexpected_verify_error`,\npayer:\n`authorization` in paymentPayload.payload\n? paymentPayload.payload.authorization.from\n: ``,\n} as VerifyResponse,\n{ status: 500 },\n);\n}\n}"
"export function createCdpAuthHeaders(apiKeyId?: string, apiKeySecret?: string): CreateHeaders {\nconst requestHost = COINBASE_FACILITATOR_BASE_URL.replace(`https:\nreturn async () => {\napiKeyId = apiKeyId ?? process.env.CDP_API_KEY_ID;\napiKeySecret = apiKeySecret ?? process.env.CDP_API_KEY_SECRET;\nconst headers = {\nverify: {\n`Correlation-Context`: createCorrelationHeader(),\n} as Record<string, string>,\nsettle: {\n`Correlation-Context`: createCorrelationHeader(),\n} as Record<string, string>,\nsupported: {\n`Correlation-Context`: createCorrelationHeader(),\n} as Record<string, string>,\nlist: {\n`Correlation-Context`: createCorrelationHeader(),\n},\n};\nif (apiKeyId && apiKeySecret) {\nheaders.verify.Authorization = await createAuthHeader(\napiKeyId,\napiKeySecret,\n`POST`,\nrequestHost,\n`${COINBASE_FACILITATOR_V2_ROUTE}/verify`,\n);\nheaders.settle.Authorization = await createAuthHeader(\napiKeyId,\napiKeySecret,\n`POST`,\nrequestHost,\n`${COINBASE_FACILITATOR_V2_ROUTE}/settle`,\n);\nheaders.supported.Authorization = await createAuthHeader(\napiKeyId,\napiKeySecret,\n`GET`,\nrequestHost,\n`${COINBASE_FACILITATOR_V2_ROUTE}/supported`,\n);\n}\nreturn headers;\n};\n}"
"async function build() {\ntry {\nif (!fs.existsSync(DIST_DIR)) {\nfs.mkdirSync(DIST_DIR, { recursive: true });\n}\nconst genDir = path.dirname(OUTPUT_TS);\nif (!fs.existsSync(genDir)) {\nfs.mkdirSync(genDir, { recursive: true });\n}\nawait esbuild.build(options);\nconsole.log(`Build completed successfully!`);\nif (fs.existsSync(OUTPUT_HTML)) {\nconst html = fs.readFileSync(OUTPUT_HTML, `utf8`);\nconst tsContent = `\nexport const PAYWALL_TEMPLATE = ${JSON.stringify(html)};\n`;\nconst pyContent = `PAYWALL_TEMPLATE = ${JSON.stringify(html)}`;\nfs.writeFileSync(OUTPUT_TS, tsContent);\nconsole.log(`Generated template.ts with bundled HTML (${html.length} bytes)`);\nfs.writeFileSync(OUTPUT_PY, pyContent);\nconsole.log(`Generated template.py with bundled HTML (${html.length} bytes)`);\n} else {\nthrow new Error(`Bundled HTML file not found at ${OUTPUT_HTML}`);\n}\n} catch (error) {\nconsole.error(`Build failed:`, error);\nprocess.exit(1);\n}\n}"
"export function findMatchingRoute(\nroutePatterns: RoutePattern[],\npath: string,\nmethod: string,\n): RoutePattern | undefined {\nlet normalizedPath: string;\ntry {\nconst pathWithoutQuery = path.split(/[?#]/)[0];\nconst decodedPath = decodeURIComponent(pathWithoutQuery);\nnormalizedPath = decodedPath\n.replace(/\\/g, `/`)\n.replace(/\/+/g, `/`)\n.replace(/(.+?)\/+$/, `$1`);\n} catch {\nreturn undefined;\n}\nconst matchingRoutes = routePatterns.filter(({ pattern, verb }) => {\nconst matchesPath = pattern.test(normalizedPath);\nconst upperMethod = method.toUpperCase();\nconst matchesVerb = verb === `*` || upperMethod === verb;\nconst result = matchesPath && matchesVerb;\nreturn result;\n});\nif (matchingRoutes.length === 0) {\nreturn undefined;\n}\nconst matchingRoute = matchingRoutes.reduce((a, b) =>\nb.pattern.source.length > a.pattern.source.length ? b : a,\n);\nreturn matchingRoute;\n}"
"export async function settle<transport extends Transport, chain extends Chain>(\nwallet: SignerWallet<chain, transport>,\npaymentPayload: PaymentPayload,\npaymentRequirements: PaymentRequirements,\n): Promise<SettleResponse> {\nconst payload = paymentPayload.payload as ExactEvmPayload;\nconst valid = await verify(wallet, paymentPayload, paymentRequirements);\nif (!valid.isValid) {\nreturn {\nsuccess: false,\nnetwork: paymentPayload.network,\ntransaction: ``,\nerrorReason: valid.invalidReason ?? `invalid_scheme`,\npayer: payload.authorization.from,\n};\n}\nconst { signature } = parseErc6492Signature(payload.signature as Hex);\nconst tx = await wallet.writeContract({\naddress: paymentRequirements.asset as Address,\nabi,\nfunctionName: `transferWithAuthorization` as const,\nargs: [\npayload.authorization.from as Address,\npayload.authorization.to as Address,\nBigInt(payload.authorization.value),\nBigInt(payload.authorization.validAfter),\nBigInt(payload.authorization.validBefore),\npayload.authorization.nonce as Hex,\nsignature,\n],\nchain: wallet.chain as Chain,\n});\nconst receipt = await wallet.waitForTransactionReceipt({ hash: tx });\nif (receipt.status !== `success`) {\nreturn {\nsuccess: false,\nerrorReason: `invalid_transaction_state`,\ntransaction: tx,\nnetwork: paymentPayload.network,\npayer: payload.authorization.from,\n};\n}\nreturn {\nsuccess: true,\ntransaction: tx,\nnetwork: paymentPayload.network,\npayer: payload.authorization.from,\n};\n}"
"export async function signAuthorization<transport extends Transport, chain extends Chain>(\nwalletClient: SignerWallet<chain, transport> | LocalAccount,\n{ from, to, value, validAfter, validBefore, nonce }: ExactEvmPayloadAuthorization,\n{ asset, network, extra }: PaymentRequirements,\n): Promise<{ signature: Hex }> {\nconst chainId = getNetworkId(network);\nconst name = extra?.name;\nconst version = extra?.version;\nconst data = {\ntypes: authorizationTypes,\ndomain: {\nname,\nversion,\nchainId,\nverifyingContract: getAddress(asset),\n},\nprimaryType: `TransferWithAuthorization` as const,\nmessage: {\nfrom: getAddress(from),\nto: getAddress(to),\nvalue,\nvalidAfter,\nvalidBefore,\nnonce: nonce,\n},\n};\nif (isSignerWallet(walletClient)) {\nconst signature = await walletClient.signTypedData(data);\nreturn {\nsignature,\n};\n} else if (isAccount(walletClient) && walletClient.signTypedData) {\nconst signature = await walletClient.signTypedData(data);\nreturn {\nsignature,\n};\n} else {\nthrow new Error(`Invalid wallet client provided does not support signTypedData`);\n}\n}"
"async function createTransferTransactionMessage(\nclient: KeyPairSigner,\npaymentRequirements: PaymentRequirements,\nconfig?: X402Config,\n) {\nconst rpc = getRpcClient(paymentRequirements.network, config?.svmConfig?.rpcUrl);\nconst transferInstructions = await createAtaAndTransferInstructions(\nclient,\npaymentRequirements,\nconfig,\n);\nconst feePayer = paymentRequirements.extra?.feePayer as Address;\nconst txToSimulate = pipe(\ncreateTransactionMessage({ version: 0 }),\ntx => setTransactionMessageComputeUnitPrice(1, tx),\ntx => setTransactionMessageFeePayer(feePayer, tx),\ntx => appendTransactionMessageInstructions(transferInstructions, tx),\n);\nconst estimateComputeUnitLimit = estimateComputeUnitLimitFactory({ rpc });\nconst estimatedUnits = await estimateComputeUnitLimit(txToSimulate);\nconst { value: latestBlockhash } = await rpc.getLatestBlockhash().send();\nconst tx = pipe(\ntxToSimulate,\ntx =>\nprependTransactionMessageInstruction(\ngetSetComputeUnitLimitInstruction({ units: estimatedUnits }),\ntx,\n),\ntx => setTransactionMessageLifetimeUsingBlockhash(latestBlockhash, tx),\n);\nreturn tx;\n}"
"async function createAtaAndTransferInstructions(\nclient: KeyPairSigner,\npaymentRequirements: PaymentRequirements,\nconfig?: X402Config,\n): Promise<Instruction[]> {\nconst { asset } = paymentRequirements;\nconst rpc = getRpcClient(paymentRequirements.network, config?.svmConfig?.rpcUrl);\nconst tokenMint = await fetchMint(rpc, asset as Address);\nconst tokenProgramAddress = tokenMint.programAddress;\nif (\ntokenProgramAddress.toString() !== TOKEN_PROGRAM_ADDRESS.toString() &&\ntokenProgramAddress.toString() !== TOKEN_2022_PROGRAM_ADDRESS.toString()\n) {\nthrow new Error(`Asset was not created by a known token program`);\n}\nconst instructions: Instruction[] = [];\nconst createAtaIx = await createAtaInstructionOrUndefined(\npaymentRequirements,\ntokenProgramAddress,\nconfig,\n);\nif (createAtaIx) {\ninstructions.push(createAtaIx);\n}\nconst transferIx = await createTransferInstruction(\nclient,\npaymentRequirements,\ntokenMint.data.decimals,\ntokenProgramAddress,\n);\ninstructions.push(transferIx);\nreturn instructions;\n}"
"async function createAtaInstructionOrUndefined(\npaymentRequirements: PaymentRequirements,\ntokenProgramAddress: Address,\nconfig?: X402Config,\n): Promise<Instruction | undefined> {\nconst { asset, payTo, extra } = paymentRequirements;\nconst feePayer = extra?.feePayer as Address;\nif (!feePayer) {\nthrow new Error(\n`feePayer is required in paymentRequirements.extra in order to set the ` +\n`facilitator as the fee payer for the create associated token account instruction`,\n);\n}\nconst [destinationATAAddress] = await findAssociatedTokenPda({\nmint: asset as Address,\nowner: payTo as Address,\ntokenProgram: tokenProgramAddress,\n});\nconst rpc = getRpcClient(paymentRequirements.network, config?.svmConfig?.rpcUrl);\nconst maybeAccount = await fetchEncodedAccount(rpc, destinationATAAddress);\nif (!maybeAccount.exists) {\nreturn getCreateAssociatedTokenInstruction({\npayer: paymentRequirements.extra?.feePayer as TransactionSigner<string>,\nata: destinationATAAddress,\nowner: payTo as Address,\nmint: asset as Address,\ntokenProgram: tokenProgramAddress,\n});\n}\nreturn undefined;\n}"
"export async function settle(\nsigner: KeyPairSigner,\npayload: PaymentPayload,\npaymentRequirements: PaymentRequirements,\nconfig?: X402Config,\n): Promise<SettleResponse> {\nconst verifyResponse = await verify(signer, payload, paymentRequirements, config);\nif (!verifyResponse.isValid) {\nreturn {\nsuccess: false,\nerrorReason: verifyResponse.invalidReason,\nnetwork: payload.network,\ntransaction: ``,\n};\n}\nconst svmPayload = payload.payload as ExactSvmPayload;\nconst decodedTransaction = decodeTransactionFromPayload(svmPayload);\nconst signedTransaction = await signTransaction([signer.keyPair], decodedTransaction);\nconst payer = signer.address.toString();\nconst rpc = getRpcClient(paymentRequirements.network, config?.svmConfig?.rpcUrl);\nconst rpcSubscriptions = getRpcSubscriptions(\npaymentRequirements.network,\nconfig?.svmConfig?.rpcUrl,\n);\ntry {\nconst { success, errorReason, signature } = await sendAndConfirmSignedTransaction(\nsignedTransaction,\nrpc,\nrpcSubscriptions,\n);\nreturn {\nsuccess,\nerrorReason,\npayer,\ntransaction: signature,\nnetwork: payload.network,\n};\n} catch (error) {\nconsole.error(`Unexpected error during transaction settlement:`, error);\nreturn {\nsuccess: false,\nerrorReason: `unexpected_settle_error`,\nnetwork: payload.network,\ntransaction: getSignatureFromTransaction(signedTransaction),\n};\n}\n}"
"export async function verify(\nsigner: KeyPairSigner,\npayload: PaymentPayload,\npaymentRequirements: PaymentRequirements,\nconfig?: X402Config,\n): Promise<VerifyResponse> {\ntry {\nverifySchemesAndNetworks(payload, paymentRequirements);\nconst svmPayload = payload.payload as ExactSvmPayload;\nconst decodedTransaction = decodeTransactionFromPayload(svmPayload);\nconst rpc = getRpcClient(paymentRequirements.network, config?.svmConfig?.rpcUrl);\nawait transactionIntrospection(svmPayload, paymentRequirements, config);\nconst simulateResult = await signAndSimulateTransaction(signer, decodedTransaction, rpc);\nif (simulateResult.value?.err) {\nthrow new Error(`invalid_exact_svm_payload_transaction_simulation_failed`);\n}\nreturn {\nisValid: true,\ninvalidReason: undefined,\n};\n} catch (error) {\nif (error instanceof Error) {\nif (ErrorReasons.includes(error.message as (typeof ErrorReasons)[number])) {\nreturn {\nisValid: false,\ninvalidReason: error.message as (typeof ErrorReasons)[number],\n};\n}\n}\nconsole.error(error);\nreturn {\nisValid: false,\ninvalidReason: `unexpected_verify_error`,\n};\n}\n}"
"export async function verifyTransactionInstructions(\ntransactionMessage: CompilableTransactionMessage,\npaymentRequirements: PaymentRequirements,\nrpc: RpcDevnet<SolanaRpcApiDevnet> | RpcMainnet<SolanaRpcApiMainnet>,\n) {\nif (\ntransactionMessage.instructions.length !== 3 &&\ntransactionMessage.instructions.length !== 4\n) {\nthrow new Error(`invalid_exact_svm_payload_transaction_instructions_length`);\n}\nverifyComputeLimitInstruction(transactionMessage.instructions[0]);\nverifyComputePriceInstruction(transactionMessage.instructions[1]);\nif (transactionMessage.instructions.length === 3) {\nawait verifyTransferInstruction(\ntransactionMessage.instructions[2],\npaymentRequirements,\n{\ntxHasCreateDestATAInstruction: false,\n},\nrpc,\n);\n}\nelse {\nverifyCreateATAInstruction(transactionMessage.instructions[2], paymentRequirements);\nawait verifyTransferInstruction(\ntransactionMessage.instructions[3],\npaymentRequirements,\n{\ntxHasCreateDestATAInstruction: true,\n},\nrpc,\n);\n}\n}"
"export async function verifyTransferCheckedInstruction(\nparsedInstruction: ReturnType<typeof parseTransferCheckedInstruction2022>,\npaymentRequirements: PaymentRequirements,\n{ txHasCreateDestATAInstruction }: { txHasCreateDestATAInstruction: boolean },\nrpc: RpcDevnet<SolanaRpcApiDevnet> | RpcMainnet<SolanaRpcApiMainnet>,\n) {\nconst tokenProgramAddress =\nparsedInstruction.programAddress.toString() === TOKEN_PROGRAM_ADDRESS.toString()\n? TOKEN_PROGRAM_ADDRESS\n: TOKEN_2022_PROGRAM_ADDRESS;\nconst payToATA = await findAssociatedTokenPda({\nmint: paymentRequirements.asset as Address,\nowner: paymentRequirements.payTo as Address,\ntokenProgram: tokenProgramAddress,\n});\nif (parsedInstruction.accounts.destination.address !== payToATA[0]) {\nthrow new Error(`invalid_exact_svm_payload_transaction_transfer_to_incorrect_ata`);\n}\nconst addresses = [parsedInstruction.accounts.source.address, payToATA[0]];\nconst maybeAccounts = await fetchEncodedAccounts(rpc, addresses);\nconst missingAccounts = maybeAccounts.filter(a => !a.exists);\nfor (const missingAccount of missingAccounts) {\nif (missingAccount.address === parsedInstruction.accounts.source.address) {\nthrow new Error(`invalid_exact_svm_payload_transaction_sender_ata_not_found`);\n}\nif (missingAccount.address === payToATA[0] && !txHasCreateDestATAInstruction) {\nthrow new Error(`invalid_exact_svm_payload_transaction_receiver_ata_not_found`);\n}\n}\nconst instructionAmount = parsedInstruction.data.amount;\nconst paymentRequirementsAmount = BigInt(paymentRequirements.maxAmountRequired);\nif (instructionAmount !== paymentRequirementsAmount) {\nthrow new Error(`invalid_exact_svm_payload_transaction_amount_mismatch`);\n}\n}"
"export function getValidatedTransferCheckedInstruction(\ninstruction: Instruction<\nstring,\nreadonly (AccountLookupMeta<string, string> | AccountMeta<string>)[]\n>,\n) {\ntry {\nassertIsInstructionWithData(instruction);\nassertIsInstructionWithAccounts(instruction);\n} catch (error) {\nconsole.error(error);\nthrow new Error(`invalid_exact_svm_payload_transaction_instructions`);\n}\nlet tokenInstruction;\nif (instruction.programAddress.toString() === TOKEN_PROGRAM_ADDRESS.toString()) {\nconst identifiedInstruction = identifyTokenInstruction(instruction);\nif (identifiedInstruction !== TokenInstruction.TransferChecked) {\nthrow new Error(\n`invalid_exact_svm_payload_transaction_instruction_not_spl_token_transfer_checked`,\n);\n}\ntokenInstruction = parseTransferCheckedInstructionToken({\n...instruction,\ndata: new Uint8Array(instruction.data),\n});\n}\nelse if (instruction.programAddress.toString() === TOKEN_2022_PROGRAM_ADDRESS.toString()) {\nconst identifiedInstruction = identifyToken2022Instruction(instruction);\nif (identifiedInstruction !== Token2022Instruction.TransferChecked) {\nthrow new Error(\n`invalid_exact_svm_payload_transaction_instruction_not_token_2022_transfer_checked`,\n);\n}\ntokenInstruction = parseTransferCheckedInstruction2022({\n...instruction,\ndata: new Uint8Array(instruction.data),\n});\n}\nelse {\nthrow new Error(`invalid_exact_svm_payload_transaction_not_a_transfer_instruction`);\n}\nreturn tokenInstruction;\n}"
"export function withPaymentInterceptor(\naxiosClient: AxiosInstance,\nwalletClient: Signer | MultiNetworkSigner,\npaymentRequirementsSelector: PaymentRequirementsSelector = selectPaymentRequirements,\nconfig?: X402Config,\n) {\naxiosClient.interceptors.response.use(\nresponse => response,\nasync (error: AxiosError) => {\nif (!error.response || error.response.status !== 402) {\nreturn Promise.reject(error);\n}\ntry {\nconst originalConfig = error.config;\nif (!originalConfig || !originalConfig.headers) {\nreturn Promise.reject(new Error(`Missing axios request configuration`));\n}\nif ((originalConfig as { __is402Retry?: boolean }).__is402Retry) {\nreturn Promise.reject(error);\n}\nconst { x402Version, accepts } = error.response.data as {\nx402Version: number;\naccepts: PaymentRequirements[];\n};\nconst parsed = accepts.map(x => PaymentRequirementsSchema.parse(x));\nconst network = isMultiNetworkSigner(walletClient)\n? undefined\n: evm.isSignerWallet(walletClient as typeof evm.EvmSigner)\n? ChainIdToNetwork[(walletClient as typeof evm.EvmSigner).chain?.id]\n: isSvmSignerWallet(walletClient as Signer)\n? ([`solana`, `solana-devnet`] as Network[])\n: undefined;\nconst selectedPaymentRequirements = paymentRequirementsSelector(parsed, network, `exact`);\nconst paymentHeader = await createPaymentHeader(\nwalletClient,\nx402Version,\nselectedPaymentRequirements,\nconfig,\n);\n(originalConfig as { __is402Retry?: boolean }).__is402Retry = true;\noriginalConfig.headers[`X-PAYMENT`] = paymentHeader;\noriginalConfig.headers[`Access-Control-Expose-Headers`] = `X-PAYMENT-RESPONSE`;\nconst secondResponse = await axiosClient.request(originalConfig);\nreturn secondResponse;\n} catch (paymentError) {\nreturn Promise.reject(paymentError);\n}\n},\n);\nreturn axiosClient;\n}"
"export async function POST(req: Request, res: Response) {\ntry {\nconst apiKeyId = process.env.CDP_API_KEY_ID;\nconst apiKeySecret = process.env.CDP_API_KEY_SECRET;\nif (!apiKeyId || !apiKeySecret) {\nconsole.error(`Missing CDP API credentials`);\nreturn res.status(500).json({\nerror: `Server configuration error: Missing CDP API credentials`,\n});\n}\nconst body = req.body as {\naddresses?: Array<{ address: string; blockchains?: string[] }>;\nassets?: string[];\n};\nconst { addresses, assets } = body;\nif (!addresses || !Array.isArray(addresses) || addresses.length === 0) {\nreturn res.status(400).json({\nerror: `addresses is required and must be a non-empty array`,\n});\n}\nconst jwt = await generateJwt({\napiKeyId,\napiKeySecret,\nrequestMethod: `POST`,\nrequestHost: `api.developer.coinbase.com`,\nrequestPath: `/onramp/v1/token`,\n});\nconst tokenRequestPayload = {\naddresses: addresses.map((addr: { address: string; blockchains?: string[] }) => ({\naddress: addr.address,\nblockchains: addr.blockchains || [`base`],\n})),\n...(assets && { assets }),\n};\nconst response = await fetch(`https:\nmethod: `POST`,\nheaders: {\nAuthorization: `Bearer ${jwt}`,\n`Content-Type`: `application/json`,\n},\nbody: JSON.stringify(tokenRequestPayload),\n});\nif (!response.ok) {\nconst errorText = await response.text();\nconsole.error(`Failed to generate session token:`, response.status, errorText);\nreturn res.status(response.status).json({\nerror: `Failed to generate session token`,\n});\n}\nconst data = await response.json();\nreturn res.json(data);\n} catch (error) {\nconsole.error(`Error generating session token:`, error);\nreturn res.status(500).json({ error: `Internal server error` });\n}\n}"
"export function wrapFetchWithPayment(\nfetch: typeof globalThis.fetch,\nwalletClient: Signer | MultiNetworkSigner,\nmaxValue: bigint = BigInt(0.1 * 10 ** 6),\npaymentRequirementsSelector: PaymentRequirementsSelector = selectPaymentRequirements,\nconfig?: X402Config,\n) {\nreturn async (input: RequestInfo, init?: RequestInit) => {\nconst response = await fetch(input, init);\nif (response.status !== 402) {\nreturn response;\n}\nconst { x402Version, accepts } = (await response.json()) as {\nx402Version: number;\naccepts: unknown[];\n};\nconst parsedPaymentRequirements = accepts.map(x => PaymentRequirementsSchema.parse(x));\nconst network = isMultiNetworkSigner(walletClient)\n? undefined\n: evm.isSignerWallet(walletClient as typeof evm.EvmSigner)\n? ChainIdToNetwork[(walletClient as typeof evm.EvmSigner).chain?.id]\n: isSvmSignerWallet(walletClient)\n? ([`solana`, `solana-devnet`] as Network[])\n: undefined;\nconst selectedPaymentRequirements = paymentRequirementsSelector(\nparsedPaymentRequirements,\nnetwork,\n`exact`,\n);\nif (BigInt(selectedPaymentRequirements.maxAmountRequired) > maxValue) {\nthrow new Error(`Payment amount exceeds maximum allowed`);\n}\nconst paymentHeader = await createPaymentHeader(\nwalletClient,\nx402Version,\nselectedPaymentRequirements,\nconfig,\n);\nif (!init) {\nthrow new Error(`Missing fetch request configuration`);\n}\nif ((init as { __is402Retry?: boolean }).__is402Retry) {\nthrow new Error(`Payment already attempted`);\n}\nconst newInit = {\n...init,\nheaders: {\n...(init.headers || {}),\n`X-PAYMENT`: paymentHeader,\n`Access-Control-Expose-Headers`: `X-PAYMENT-RESPONSE`,\n},\n__is402Retry: true,\n};\nconst secondResponse = await fetch(input, newInit);\nreturn secondResponse;\n};\n}"
"export async function POST(c: Context) {\ntry {\nconst apiKeyId = process.env.CDP_API_KEY_ID;\nconst apiKeySecret = process.env.CDP_API_KEY_SECRET;\nif (!apiKeyId || !apiKeySecret) {\nconsole.error(`Missing CDP API credentials`);\nreturn c.json(\n{ error: `Server configuration error: Missing CDP API credentials` },\n{ status: 500 },\n);\n}\nconst body = (await c.req.json()) as {\naddresses?: Array<{ address: string; blockchains?: string[] }>;\nassets?: string[];\n};\nconst { addresses, assets } = body;\nif (!addresses || !Array.isArray(addresses) || addresses.length === 0) {\nreturn c.json(\n{ error: `addresses is required and must be a non-empty array` },\n{ status: 400 },\n);\n}\nconst jwt = await generateJwt({\napiKeyId,\napiKeySecret,\nrequestMethod: `POST`,\nrequestHost: `api.developer.coinbase.com`,\nrequestPath: `/onramp/v1/token`,\n});\nconst tokenRequestPayload = {\naddresses: addresses.map((addr: { address: string; blockchains?: string[] }) => ({\naddress: addr.address,\nblockchains: addr.blockchains || [`base`],\n})),\n...(assets && { assets }),\n};\nconst response = await fetch(`https:\nmethod: `POST`,\nheaders: {\nAuthorization: `Bearer ${jwt}`,\n`Content-Type`: `application/json`,\n},\nbody: JSON.stringify(tokenRequestPayload),\n});\nif (!response.ok) {\nconst errorText = await response.text();\nconsole.error(`Failed to generate session token:`, response.status, errorText);\nreturn c.json(\n{ error: `Failed to generate session token` },\n{ status: response.status as 400 | 401 | 500 },\n);\n}\nconst data = (await response.json()) as Record<string, unknown>;\nreturn c.json(data);\n} catch (error) {\nconsole.error(`Error generating session token:`, error);\nreturn c.json({ error: `Internal server error` }, { status: 500 });\n}\n}"
"export async function POST(request: NextRequest) {\ntry {\nconst apiKeyId = process.env.CDP_API_KEY_ID;\nconst apiKeySecret = process.env.CDP_API_KEY_SECRET;\nif (!apiKeyId || !apiKeySecret) {\nconsole.error(`Missing CDP API credentials`);\nreturn NextResponse.json(\n{ error: `Server configuration error: Missing CDP API credentials` },\n{ status: 500 },\n);\n}\nconst body = (await request.json()) as {\naddresses?: Array<{ address: string; blockchains?: string[] }>;\nassets?: string[];\n};\nconst { addresses, assets } = body;\nif (!addresses || !Array.isArray(addresses) || addresses.length === 0) {\nreturn NextResponse.json(\n{ error: `addresses is required and must be a non-empty array` },\n{ status: 400 },\n);\n}\nconst jwt = await generateJwt({\napiKeyId,\napiKeySecret,\nrequestMethod: `POST`,\nrequestHost: `api.developer.coinbase.com`,\nrequestPath: `/onramp/v1/token`,\n});\nconst tokenRequestPayload = {\naddresses: addresses.map((addr: { address: string; blockchains?: string[] }) => ({\naddress: addr.address,\nblockchains: addr.blockchains || [`base`],\n})),\n...(assets && { assets }),\n};\nconst response = await fetch(`https:\nmethod: `POST`,\nheaders: {\nAuthorization: `Bearer ${jwt}`,\n`Content-Type`: `application/json`,\n},\nbody: JSON.stringify(tokenRequestPayload),\n});\nif (!response.ok) {\nconst errorText = await response.text();\nconsole.error(`Failed to generate session token:`, response.status, errorText);\nreturn NextResponse.json(\n{ error: `Failed to generate session token` },\n{ status: response.status },\n);\n}\nconst data = await response.json();\nreturn NextResponse.json(data);\n} catch (error) {\nconsole.error(`Error generating session token:`, error);\nreturn NextResponse.json({ error: `Internal server error` }, { status: 500 });\n}\n}"
"export function BinaryFileEditor({\ncontentType,\nbody,\nonChange,\nonChangeContentType,\nrequestId,\n}: Props) {\nconst ignoreContentType = useKeyValue<boolean>({\nnamespace: 'global',\nkey: ['ignore_content_type', requestId],\nfallback: false,\n});\nconst handleChange = async ({ filePath }: { filePath: string | null }) => {\nawait ignoreContentType.set(false);\nonChange({ filePath: filePath ?? undefined });\n};\nconst filePath = typeof body.filePath === 'string' ? body.filePath : null;\nconst mimeType = mime.getType(filePath ?? '') ?? 'application/octet-stream';\nreturn (\n<VStack space={2}>\n<SelectFile onChange={handleChange} filePath={filePath} />\n{filePath != null && mimeType !== contentType && !ignoreContentType.value && (\n<Banner className=`mt-3 !py-5`>\n<div className=`mb-4 text-center`>\n<div>Set Content-Type header</div>\n<InlineCode>{mimeType}</InlineCode> for current request?\n</div>\n<HStack space={1.5} justifyContent=`center`>\n<Button size=`sm` variant=`border` onClick={() => ignoreContentType.set(true)}>\nIgnore\n</Button>\n<Button\nvariant=`solid`\ncolor=`primary`\nsize=`sm`\nonClick={() => onChangeContentType(mimeType)}\n>\nSet Header\n</Button>\n</HStack>\n</Banner>\n)}\n</VStack>\n);\n}"
"export function ConfirmLargeRequestBody({ children, request }: Props) {\nconst [showLargeResponse, toggleShowLargeResponse] = useToggle();\nif (request.body?.text == null) {\nreturn children;\n}\nconst contentLength = request.body.text.length ?? 0;\nconst tooLargeBytes = LARGE_TEXT_BYTES;\nconst isLarge = contentLength > tooLargeBytes;\nif (!showLargeResponse && isLarge) {\nreturn (\n<Banner color=`primary` className=`flex flex-col gap-3`>\n<p>\nRendering content over{' '}\n<InlineCode>\n<SizeTag contentLength={tooLargeBytes} />\n</InlineCode>{' '}\nmay impact performance.\n</p>\n<p>\nSee{' '}\n<Link href=`https:\nWorking With Large Values\n</Link>{' '}\nfor tips.\n</p>\n<HStack wrap space={2}>\n<Button color=`primary` size=`xs` onClick={toggleShowLargeResponse}>\nReveal Body\n</Button>\n<Button\ncolor=`danger`\nsize=`xs`\nvariant=`border`\nonClick={async () => {\nconst confirm = await showConfirm({\nid: `delete-body-${request.id}`,\nconfirmText: 'Delete Body',\ntitle: 'Delete Body Text',\ndescription: 'Are you sure you want to delete the request body text?',\ncolor: 'danger',\n});\nif (confirm) {\nawait patchModel(request, { body: { ...request.body, text: '' } });\n}\n}}\n>\nDelete Body\n</Button>\n</HStack>\n</Banner>\n);\n}\nreturn <>{children}</>;\n}"
"export function ConfirmLargeResponse({ children, response }: Props) {\nconst { mutate: saveResponse } = useSaveResponse(response);\nconst [showLargeResponse, toggleShowLargeResponse] = useToggle();\nconst isProbablyText = useMemo(() => {\nconst contentType = getContentTypeFromHeaders(response.headers);\nreturn isProbablyTextContentType(contentType);\n}, [response.headers]);\nconst contentLength = response.contentLength ?? 0;\nconst isLarge = contentLength > LARGE_BYTES;\nif (!showLargeResponse && isLarge) {\nreturn (\n<Banner color=`primary` className=`flex flex-col gap-3`>\n<p>\nShowing responses over{' '}\n<InlineCode>\n<SizeTag contentLength={LARGE_BYTES} />\n</InlineCode>{' '}\nmay impact performance\n</p>\n<HStack wrap space={2}>\n<Button color=`primary` size=`xs` onClick={toggleShowLargeResponse}>\nReveal Response\n</Button>\n<Button color=`secondary` variant=`border` size=`xs` onClick={() => saveResponse()}>\nSave to File\n</Button>\n{isProbablyText && (\n<CopyButton\ncolor=`secondary`\nvariant=`border`\nsize=`xs`\ntext={() => getResponseBodyText({ response, filter: null })}\n/>\n)}\n</HStack>\n</Banner>\n);\n}\nreturn <>{children}</>;\n}"
"export function CreateEnvironmentDialog({ workspaceId, hide, onCreate }: Props) {\nconst [name, setName] = useState<string>('');\nconst [color, setColor] = useState<string | null>(null);\nconst [sharable, toggleSharable] = useToggle(false);\nreturn (\n<form\nclassName=`pb-3 flex flex-col gap-3`\nonSubmit={async (e) => {\ne.preventDefault();\nconst id = await createWorkspaceModel({\nmodel: 'environment',\nname,\ncolor,\nvariables: [],\npublic: sharable,\nworkspaceId,\nparentModel: 'environment',\n});\nhide();\nonCreate(id);\n}}\n>\n<PlainInput\nlabel=`Name`\nrequired\ndefaultValue={name}\nonChange={setName}\nplaceholder=`Production`\n/>\n<Checkbox\nchecked={sharable}\ntitle=`Share this environment`\nhelp=`Sharable environments are included in data export and directory sync.`\nonChange={toggleSharable}\n/>\n<div>\n<Label\nhtmlFor=`color`\nclassName=`mb-1.5`\nhelp=`Select a color to be displayed when this environment is active, to help identify it.`\n>\nColor\n</Label>\n<ColorPickerWithThemeColors onChange={setColor} color={color} />\n</div>\n<Button type=`submit` color=`secondary` className=`mt-3`>\n{color != null && <ColorIndicator color={color} />}\nCreate Environment\n</Button>\n</form>\n);\n}"
"export function CreateWorkspaceDialog({ hide }: Props) {\nconst [name, setName] = useState<string>('');\nconst [syncConfig, setSyncConfig] = useState<{\nfilePath: string | null;\ninitGit?: boolean;\n}>({ filePath: null, initGit: false });\nconst [setupEncryption, setSetupEncryption] = useState<boolean>(false);\nreturn (\n<VStack\nas=`form`\nspace={3}\nalignItems=`start`\nclassName=`pb-3`\nonSubmit={async (e) => {\ne.preventDefault();\nconst workspaceId = await createGlobalModel({ model: 'workspace', name });\nif (workspaceId == null) return;\nconst workspaceMeta = await invokeCmd<WorkspaceMeta>('cmd_get_workspace_meta', {\nworkspaceId,\n});\nawait updateModel({\n...workspaceMeta,\nsettingSyncDir: syncConfig.filePath,\n});\nif (syncConfig.initGit && syncConfig.filePath) {\ngitMutations(syncConfig.filePath, gitCallbacks(syncConfig.filePath))\n.init.mutateAsync()\n.catch((err) => {\nshowErrorToast('git-init-error', String(err));\n});\n}\nawait router.navigate({\nto: '/workspaces/$workspaceId',\nparams: { workspaceId },\n});\nhide();\nif (setupEncryption) {\nsetupOrConfigureEncryption();\n}\n}}\n>\n<PlainInput required label=`Name` defaultValue={name} onChange={setName} />\n<SyncToFilesystemSetting\nonChange={setSyncConfig}\nonCreateNewWorkspace={hide}\nvalue={syncConfig}\n/>\n<div>\n<Label htmlFor={null} help={<EncryptionHelp />}>\nWorkspace encryption\n</Label>\n<Checkbox\nchecked={setupEncryption}\nonChange={setSetupEncryption}\ntitle=`Enable Encryption`\n/>\n</div>\n<Button type=`submit` color=`primary` className=`w-full mt-3`>\nCreate Workspace\n</Button>\n</VStack>\n);\n}"
"export function EnvironmentEditDialog({ initialEnvironmentId, setRef }: Props) {\nconst { allEnvironments, baseEnvironment, baseEnvironments } = useEnvironmentsBreakdown();\nconst [selectedEnvironmentId, setSelectedEnvironmentId] = useState<string | null>(\ninitialEnvironmentId ?? null,\n);\nconst selectedEnvironment =\nselectedEnvironmentId != null\n? allEnvironments.find((e) => e.id === selectedEnvironmentId)\n: baseEnvironment;\nreturn (\n<SplitLayout\nname=`env_editor`\ndefaultRatio={0.75}\nlayout=`horizontal`\nclassName=`gap-0`\nresizeHandleClassName=`-translate-x-[1px]`\nfirstSlot={() => (\n<EnvironmentEditDialogSidebar\nselectedEnvironmentId={selectedEnvironment?.id ?? null}\nsetSelectedEnvironmentId={setSelectedEnvironmentId}\n/>\n)}\nsecondSlot={() => (\n<div className=`grid grid-rows-[auto_minmax(0,1fr)]`>\n{baseEnvironments.length > 1 ? (\n<div className=`p-3`>\n<Banner color=`notice`>\nThere are multiple base environments for this workspace. Please delete the\nenvironments you no longer need.\n</Banner>\n</div>\n) : (\n<span />\n)}\n{selectedEnvironment == null ? (\n<div className=`p-3 mt-10`>\n<Banner color=`danger`>\nFailed to find selected environment <InlineCode>{selectedEnvironmentId}</InlineCode>\n</Banner>\n</div>\n) : (\n<EnvironmentEditor\nkey={selectedEnvironment.id}\nsetRef={setRef}\nclassName=`pl-4 pt-3`\nenvironment={selectedEnvironment}\n/>\n)}\n</div>\n)}\n/>\n);\n}"
"function ChildCard({ child }: { child: Folder | HttpRequest | GrpcRequest | WebsocketRequest }) {\nlet card: ReactNode;\nif (child.model === 'folder') {\ncard = <FolderCard folder={child} />;\n} else if (child.model === 'http_request') {\ncard = <HttpRequestCard request={child} />;\n} else if (child.model === 'grpc_request') {\ncard = <RequestCard request={child} />;\n} else if (child.model === 'websocket_request') {\ncard = <RequestCard request={child} />;\n} else {\ncard = <div>Unknown model</div>;\n}\nconst navigate = useCallback(async () => {\nawait router.navigate({\nto: '/workspaces/$workspaceId',\nparams: { workspaceId: child.workspaceId },\nsearch: (prev) => ({ ...prev, request_id: child.id }),\n});\n}, [child.id, child.workspaceId]);\nreturn (\n<div\nclassName={classNames(\n'rounded-lg bg-surface-highlight p-3 pt-1 border border-border',\n'flex flex-col gap-3',\n)}\n>\n<HStack space={2}>\n{child.model === 'folder' && <Icon icon=`folder` size=`lg` />}\n<Heading className=`truncate` level={2}>\n{resolvedModelName(child)}\n</Heading>\n<HStack space={0.5} className=`ml-auto -mr-1.5`>\n<IconButton\ncolor=`custom`\ntitle=`Send Request`\nsize=`sm`\nicon=`external_link`\nclassName=`opacity-70 hover:opacity-100`\nonClick={navigate}\n/>\n<IconButton\ncolor=`custom`\ntitle=`Send Request`\nsize=`sm`\nicon=`send_horizontal`\nclassName=`opacity-70 hover:opacity-100`\nonClick={() => {\nsendAnyHttpRequest.mutate(child.id);\n}}\n/>\n</HStack>\n</HStack>\n<div className=`text-text-subtle`>{card}</div>\n</div>\n);\n}"
"function HttpRequestCard({ request }: { request: HttpRequest }) {\nconst latestResponse = useLatestHttpResponse(request.id);\nreturn (\n<div className=`grid grid-rows-2 grid-cols-[minmax(0,1fr)] gap-2 overflow-hidden`>\n<code className=`font-mono text-editor text-info border border-info rounded px-2.5 py-0.5 truncate w-full min-w-0`>\n{request.method} {request.url}\n</code>\n{latestResponse ? (\n<button\nclassName=`block mr-auto`\ntype=`button`\ntabIndex={-1}\nonClick={(e) => {\ne.stopPropagation();\nshowDialog({\nid: 'response-preview',\ntitle: 'Response Preview',\nsize: 'md',\nclassName: 'h-full',\nrender: () => {\nreturn <HttpResponsePane activeRequestId={request.id} />;\n},\n});\n}}\n>\n<HStack\nspace={2}\nalignItems=`center`\nclassName={classNames(\n'cursor-default select-none',\n'whitespace-nowrap w-full pl-3 overflow-x-auto font-mono text-sm hide-scrollbars',\n'font-mono text-editor border rounded px-1.5 py-0.5 truncate w-full',\n)}\n>\n{latestResponse.state !== 'closed' && <LoadingIcon size=`sm` />}\n<HttpStatusTag showReason response={latestResponse} />\n<span>&bull;</span>\n<HttpResponseDurationTag response={latestResponse} />\n<span>&bull;</span>\n<SizeTag contentLength={latestResponse.contentLength ?? 0} />\n</HStack>\n</button>\n) : (\n<div>No Responses</div>\n)}\n</div>\n);\n}"
"export function FormMultipartEditor({ request, forceUpdateKey, onChange }: Props) {\nconst pairs = useMemo<Pair[]>(\n() =>\n(Array.isArray(request.body.form) ? request.body.form : []).map((p) => ({\nenabled: p.enabled,\nname: p.name,\nvalue: p.file ?? p.value,\ncontentType: p.contentType,\nisFile: !!p.file,\nid: p.id,\n})),\n[request.body.form],\n);\nconst handleChange = useCallback<PairEditorProps['onChange']>(\n(pairs) =>\nonChange({\nform: pairs.map((p) => ({\nenabled: p.enabled,\nname: p.name,\ncontentType: p.contentType,\nfile: p.isFile ? p.value : undefined,\nvalue: p.isFile ? undefined : p.value,\nid: p.id,\n})),\n}),\n[onChange],\n);\nreturn (\n<PairEditor\nvalueAutocompleteFunctions\nvalueAutocompleteVariables\nnameAutocompleteVariables\nnameAutocompleteFunctions\nallowFileValues\nallowMultilineValues\npairs={pairs}\nonChange={handleChange}\nforceUpdateKey={forceUpdateKey}\nstateKey={`multipart.${request.id}`}\n/>\n);\n}"
"function EventRow({\nonClick,\nisActive,\nevent,\n}: {\nonClick?: () => void;\nisActive?: boolean;\nevent: GrpcEvent;\n}) {\nconst { eventType, status, createdAt, content, error } = event;\nconst ref = useRef<HTMLDivElement>(null);\nreturn (\n<div className=`px-1` ref={ref}>\n<button\ntype=`button`\nonClick={onClick}\nclassName={classNames(\n'w-full grid grid-cols-[auto_minmax(0,3fr)_auto] gap-2 items-center text-left',\n'px-1.5 h-xs font-mono cursor-default group focus:outline-none focus:text-text rounded',\nisActive && '!bg-surface-active !text-text',\n'text-text-subtle hover:text',\n)}\n>\n<Icon\ncolor={\neventType === 'server_message'\n? 'info'\n: eventType === 'client_message'\n? 'primary'\n: eventType === 'error' || (status != null && status > 0)\n? 'danger'\n: eventType === 'connection_end'\n? 'success'\n: undefined\n}\ntitle={\neventType === 'server_message'\n? 'Server message'\n: eventType === 'client_message'\n? 'Client message'\n: eventType === 'error' || (status != null && status > 0)\n? 'Error'\n: eventType === 'connection_end'\n? 'Connection response'\n: undefined\n}\nicon={\neventType === 'server_message'\n? 'arrow_big_down_dash'\n: eventType === 'client_message'\n? 'arrow_big_up_dash'\n: eventType === 'error' || (status != null && status > 0)\n? 'alert_triangle'\n: eventType === 'connection_end'\n? 'check'\n: 'info'\n}\n/>\n<div className={classNames('w-full truncate text-xs')}>\n{content.slice(0, 1000)}\n{error && <span className=`text-warning`> ({error})</span>}\n</div>\n<div className={classNames('opacity-50 text-xs')}>\n{format(`${createdAt}Z`, 'HH:mm:ss.SSS')}\n</div>\n</button>\n</div>\n);\n}"
"export function HeadersEditor({\nstateKey,\nheaders,\ninheritedHeaders,\nonChange,\nforceUpdateKey,\n}: Props) {\nconst validInheritedHeaders =\ninheritedHeaders?.filter((pair) => pair.enabled && (pair.name || pair.value)) ?? [];\nreturn (\n<div className=`@container w-full h-full grid grid-rows-[auto_minmax(0,1fr)]`>\n{validInheritedHeaders.length > 0 ? (\n<DetailsBanner\ncolor=`secondary`\nclassName=`text-sm mb-1.5`\nsummary={\n<HStack>\nInherited <CountBadge count={validInheritedHeaders.length} />\n</HStack>\n}\n>\n<div className=`pb-2`>\n{validInheritedHeaders?.map((pair, i) => (\n<PairEditorRow\nkey={`${pair.id}.${i}`}\nindex={i}\ndisabled\ndisableDrag\nclassName=`py-1`\npair={ensurePairId(pair)}\nstateKey={null}\nnameAutocompleteFunctions\nnameAutocompleteVariables\nvalueAutocompleteFunctions\nvalueAutocompleteVariables\n/>\n))}\n</div>\n</DetailsBanner>\n) : (\n<span />\n)}\n<PairOrBulkEditor\nforceUpdateKey={forceUpdateKey}\nnameAutocomplete={nameAutocomplete}\nnameAutocompleteFunctions\nnameAutocompleteVariables\nnamePlaceholder=`Header-Name`\nnameValidate={validateHttpHeader}\nonChange={onChange}\npairs={headers}\npreferenceName=`headers`\nstateKey={stateKey}\nvalueType={valueType}\nvalueAutocomplete={valueAutocomplete}\nvalueAutocompleteFunctions\nvalueAutocompleteVariables\n/>\n</div>\n);\n}"
"export function HeaderSize({\nclassName,\nstyle,\nsize,\nignoreControlsSpacing,\nonlyXWindowControl,\nchildren,\nhideControls,\n}: HeaderSizeProps) {\nconst settings = useAtomValue(settingsAtom);\nconst isFullscreen = useIsFullscreen();\nconst finalStyle = useMemo<CSSProperties>(() => {\nconst s = { ...style };\nif (size === 'md') s.minHeight = HEADER_SIZE_MD;\nif (size === 'lg') s.minHeight = HEADER_SIZE_LG;\nif (type() === 'macos') {\nif (!isFullscreen) {\ns.paddingLeft = 72 / settings.interfaceScale;\n}\n} else if (!ignoreControlsSpacing && !settings.hideWindowControls) {\ns.paddingRight = WINDOW_CONTROLS_WIDTH;\n}\nreturn s;\n}, [\nignoreControlsSpacing,\nisFullscreen,\nsettings.hideWindowControls,\nsettings.interfaceScale,\nsize,\nstyle,\n]);\nreturn (\n<div\ndata-tauri-drag-region\nstyle={finalStyle}\nclassName={classNames(\nclassName,\n'pt-[1px]',\n'select-none relative',\n'w-full border-b border-border-subtle min-w-0',\n)}\n>\n{}\n<div\nclassName={classNames(\n'pointer-events-none h-full w-full overflow-x-auto hide-scrollbars grid',\n'px-1',\n)}\n>\n{children}\n</div>\n{!hideControls && <WindowControls onlyX={onlyXWindowControl} />}\n</div>\n);\n}"
"export function HttpRequestLayout({ activeRequest, style }: Props) {\nconst showGraphQLDocExplorer = useAtomValue(showGraphQLDocExplorerAtom);\nconst graphQLSchema = useCurrentGraphQLSchema(activeRequest);\nconst workspaceLayout = useAtomValue(workspaceLayoutAtom);\nconst requestResponseSplit = ({ style }: Pick<SlotProps, 'style'>) => (\n<SplitLayout\nname=`http_layout`\nclassName=`p-3 gap-1.5`\nstyle={style}\nlayout={workspaceLayout}\nfirstSlot={({ orientation, style }) => (\n<HttpRequestPane\nstyle={style}\nactiveRequest={activeRequest}\nfullHeight={orientation === 'horizontal'}\n/>\n)}\nsecondSlot={({ style }) => (\n<HttpResponsePane activeRequestId={activeRequest.id} style={style} />\n)}\n/>\n);\nif (\nactiveRequest.bodyType === 'graphql' &&\nshowGraphQLDocExplorer[activeRequest.id] !== undefined &&\ngraphQLSchema != null\n) {\nreturn (\n<SplitLayout\nname=`graphql_layout`\ndefaultRatio={1 / 3}\nfirstSlot={requestResponseSplit}\nsecondSlot={({ style, orientation }) => (\n<GraphQLDocsExplorer\nrequestId={activeRequest.id}\nschema={graphQLSchema}\nclassName={classNames(orientation === 'horizontal' && '!ml-0')}\nstyle={style}\n/>\n)}\n/>\n);\n}\nreturn requestResponseSplit({ style });\n}"
"export function ImportCurlButton() {\nconst focused = useWindowFocus();\nconst [clipboardText, setClipboardText] = useState('');\nconst importCurl = useImportCurl();\nconst [isLoading, setIsLoading] = useState(false);\nuseEffect(() => {\nreadText().then(setClipboardText);\n}, [focused]);\nif (!clipboardText?.trim().startsWith('curl ')) {\nreturn null;\n}\nreturn (\n<m.div\ninitial={{ opacity: 0, scale: 0 }}\nanimate={{ opacity: 1, scale: 1 }}\ntransition={{ delay: 0.5 }}\n>\n<Button\nsize=`2xs`\nvariant=`border`\ncolor=`success`\nclassName=`rounded-full`\nrightSlot={<Icon icon=`import` size=`sm` />}\nisLoading={isLoading}\ntitle=`Import Curl command from clipboard`\nonClick={async () => {\nsetIsLoading(true);\ntry {\nawait importCurl.mutateAsync({ command: clipboardText });\nawait clear();\nsetClipboardText('');\n} catch (e) {\nconsole.log('Failed to import curl', e);\n} finally {\nsetIsLoading(false);\n}\n}}\n>\nImport Curl\n</Button>\n</m.div>\n);\n}"
"export function ImportDataDialog({ importData }: Props) {\nconst [isLoading, setIsLoading] = useState<boolean>(false);\nconst [filePath, setFilePath] = useLocalStorage<string | null>('importFilePath', null);\nreturn (\n<VStack space={5} className=`pb-4`>\n<VStack space={1}>\n<ul className=`list-disc pl-5`>\n<li>OpenAPI 3.0, 3.1</li>\n<li>Postman Collection v2, v2.1</li>\n<li>Insomnia v4+</li>\n<li>Swagger 2.0</li>\n<li>\nCurl commands <em className=`text-text-subtle`>(or paste into URL)</em>\n</li>\n</ul>\n</VStack>\n<VStack space={2}>\n<SelectFile\nfilePath={filePath ?? null}\nonChange={({ filePath }) => setFilePath(filePath)}\n/>\n{filePath && (\n<Button\ncolor=`primary`\ndisabled={!filePath || isLoading}\nisLoading={isLoading}\nsize=`sm`\nonClick={async () => {\nsetIsLoading(true);\ntry {\nawait importData(filePath);\n} finally {\nsetIsLoading(false);\n}\n}}\n>\n{isLoading ? 'Importing' : 'Import'}\n</Button>\n)}\n</VStack>\n</VStack>\n);\n}"
"export function MarkdownEditor({\nclassName,\neditorClassName,\ndefaultValue,\nonChange,\nname,\nforceUpdateKey,\n...editorProps\n}: Props) {\nconst [viewMode, setViewMode] = useState<ViewMode>(defaultValue ? 'preview' : 'edit');\nconst containerRef = useRef<HTMLDivElement>(null);\nconst editor = (\n<Editor\nhideGutter\nwrapLines\nclassName={classNames(editorClassName, '[&_.cm-line]:!max-w-lg max-h-full')}\nlanguage=`markdown`\ndefaultValue={defaultValue}\nonChange={onChange}\nforceUpdateKey={forceUpdateKey}\n{...editorProps}\n/>\n);\nconst preview =\ndefaultValue.length === 0 ? (\n<p className=`text-text-subtlest`>No description</p>\n) : (\n<div className=`pr-1.5 overflow-y-auto max-h-full [&_*]:cursor-auto [&_*]:select-auto`>\n<Markdown className=`max-w-lg select-auto cursor-auto`>{defaultValue}</Markdown>\n</div>\n);\nconst contents = viewMode === 'preview' ? preview : editor;\nreturn (\n<div\nref={containerRef}\nclassName={classNames(\n'group/markdown',\n'relative w-full h-full pt-1.5 rounded-md gap-x-1.5',\n'min-w-0',\nclassName,\n)}\n>\n<div className=`h-full w-full`>{contents}</div>\n<div className=`absolute top-0 right-0 pt-1.5 pr-1.5`>\n<SegmentedControl\nname={name}\nonChange={setViewMode}\nvalue={viewMode}\noptions={[\n{ icon: 'eye', label: 'Preview mode', value: 'preview' },\n{ icon: 'pencil', label: 'Edit mode', value: 'edit' },\n]}\n/>\n</div>\n</div>\n);\n}"
"export function MoveToWorkspaceDialog({ onDone, request, activeWorkspaceId }: Props) {\nconst workspaces = useAtomValue(workspacesAtom);\nconst [selectedWorkspaceId, setSelectedWorkspaceId] = useState<string>(activeWorkspaceId);\nreturn (\n<VStack space={4} className=`mb-4`>\n<Select\nlabel=`New Workspace`\nname=`workspace`\nvalue={selectedWorkspaceId}\nonChange={setSelectedWorkspaceId}\noptions={workspaces.map((w) => ({\nlabel: w.id === activeWorkspaceId ? `${w.name} (current)` : w.name,\nvalue: w.id,\n}))}\n/>\n<Button\ncolor=`primary`\ndisabled={selectedWorkspaceId === activeWorkspaceId}\nonClick={async () => {\nconst patch = {\nworkspaceId: selectedWorkspaceId,\nfolderId: null,\n};\nawait patchModel(request, patch);\nsetTimeout(onDone, 100);\nshowToast({\nid: 'workspace-moved',\nmessage: (\n<>\n<InlineCode>{resolvedModelName(request)}</InlineCode> moved to{' '}\n<InlineCode>\n{workspaces.find((w) => w.id === selectedWorkspaceId)?.name ?? 'unknown'}\n</InlineCode>\n</>\n),\naction: ({ hide }) => (\n<Button\nsize=`xs`\ncolor=`secondary`\nclassName=`mr-auto min-w-[5rem]`\nonClick={async () => {\nawait router.navigate({\nto: '/workspaces/$workspaceId',\nparams: { workspaceId: selectedWorkspaceId },\n});\nhide();\n}}\n>\nSwitch to Workspace\n</Button>\n),\n});\n}}\n>\nMove\n</Button>\n</VStack>\n);\n}"
"export function Overlay({\nvariant = 'default',\nzIndex = 30,\nopen,\nonClose,\nportalName,\nnoBackdrop,\nchildren,\n}: Props) {\nconst containerRef = useRef<HTMLDivElement>(null);\nif (noBackdrop) {\nreturn (\n<Portal name={portalName}>\n{open && (\n<FocusTrap focusTrapOptions={{ clickOutsideDeactivates: true }}>\n{}\n<div>{children}</div>\n</FocusTrap>\n)}\n</Portal>\n);\n}\nreturn (\n<Portal name={portalName}>\n{open && (\n<FocusTrap\nfocusTrapOptions={{\nallowOutsideClick: true,\ndelayInitialFocus: true,\ncheckCanFocusTrap: async () => {\n},\n}}\n>\n<m.div\nref={containerRef}\nclassName={classNames('fixed inset-0', zIndexes[zIndex])}\ninitial={{ opacity: 0 }}\nanimate={{ opacity: 1 }}\n>\n<div\naria-hidden\nonClick={onClose}\nclassName={classNames(\n'absolute inset-0',\nvariant === 'default' && 'bg-backdrop backdrop-blur-sm',\n)}\n/>\n{}\n{}\n{variant === 'default' && (\n<div data-tauri-drag-region className=`absolute top-0 left-0 h-md right-0` />\n)}\n{children}\n</m.div>\n</FocusTrap>\n)}\n</Portal>\n);\n}"
"export function RecentGrpcConnectionsDropdown({\nactiveConnection,\nconnections,\nonPinnedConnectionId,\n}: Props) {\nconst deleteAllConnections = useDeleteGrpcConnections(activeConnection?.requestId);\nconst latestConnectionId = connections[0]?.id ?? 'n/a';\nreturn (\n<Dropdown\nitems={[\n{\nlabel: 'Clear Connection',\nonSelect: () => deleteModel(activeConnection),\ndisabled: connections.length === 0,\n},\n{\nlabel: `Clear ${pluralizeCount('Connection', connections.length)}`,\nonSelect: deleteAllConnections.mutate,\nhidden: connections.length <= 1,\ndisabled: connections.length === 0,\n},\n{ type: 'separator', label: 'History' },\n...connections.map((c) => ({\nlabel: (\n<HStack space={2}>\n{formatDistanceToNowStrict(`${c.createdAt}Z`)} ago &bull;{' '}\n<span className=`font-mono text-sm`>{c.elapsed}ms</span>\n</HStack>\n),\nleftSlot: activeConnection?.id === c.id ? <Icon icon=`check` /> : <Icon icon=`empty` />,\nonSelect: () => onPinnedConnectionId(c.id),\n})),\n]}\n>\n<IconButton\ntitle=`Show connection history`\nicon={activeConnection?.id === latestConnectionId ? 'history' : 'pin'}\nclassName=`m-0.5 text-text-subtle`\nsize=`sm`\niconSize=`md`\n/>\n</Dropdown>\n);\n}"
"private handleList(event: Electron.IpcMainEvent, eventData: Action) {\nconst { identifier, destinationFolder } = eventData;\nif (destinationFolder) {\nPluginManager.list(destinationFolder, progress => {\nevent.sender.send(\n'plugin-manager',\nJSON.stringify({ identifier: identifier, ...progress })\n);\n});\nreturn;\n}\ntry {\nconst allPlugins: any[] = [];\nconst shippedDir = path.join(__dirname, '.plugins');\ntry {\nconst shippedPlugins = PluginManager.list(shippedDir);\nif (shippedPlugins) {\nallPlugins.push(...shippedPlugins);\n}\n} catch (error: any) {\nif (error?.code !== 'ENOENT') {\nconsole.error('Error listing shipped plugins:', error);\n}\n}\nconst userDir = defaultUserPluginsDir();\ntry {\nconst userPlugins = PluginManager.list(userDir);\nif (userPlugins) {\nallPlugins.push(...userPlugins);\n}\n} catch (error: any) {\nif (error?.code !== 'ENOENT') {\nconsole.error('Error listing user plugins:', error);\n}\n}\nconst devDir = defaultPluginsDir();\ntry {\nconst devPlugins = PluginManager.list(devDir);\nif (devPlugins) {\nallPlugins.push(...devPlugins);\n}\n} catch (error: any) {\nif (error?.code !== 'ENOENT') {\nconsole.error('Error listing development plugins:', error);\n}\n}\nevent.sender.send(\n'plugin-manager',\nJSON.stringify({\nidentifier: identifier,\ntype: 'success',\nmessage: 'Plugins Listed',\ndata: allPlugins,\n})\n);\n} catch (error) {\nevent.sender.send(\n'plugin-manager',\nJSON.stringify({\nidentifier: identifier,\ntype: 'error',\nmessage: error instanceof Error ? error.message : String(error),\n})\n);\n}\n}"
"export function getExtraFiles(\nannotations: Record<string, string>\n): ArtifactHubHeadlampPkg['extraFiles'] | undefined {\nconst converted = convertAnnotations(annotations);\nconst extraFiles: ArtifactHubHeadlampPkg['extraFiles'] =\nconverted?.headlamp?.plugin?.['extra-files'];\nif (!extraFiles) {\nreturn undefined;\n}\nfor (const file of Object.values(extraFiles)) {\nfor (const value of Object.values(file.output)) {\nif (\nvalue.output.startsWith('..') ||\nvalue.output.startsWith('/') ||\nvalue.output.startsWith('\\')\n) {\nthrow new Error(`Invalid extra file output path, ${value.output}`);\n}\nif (\nvalue.input.startsWith('..') ||\nvalue.input.startsWith('/') ||\nvalue.input.startsWith('\\')\n) {\nthrow new Error(`Invalid extra file input path, ${value.input}`);\n}\n}\n}\nfor (const file of Object.values(extraFiles)) {\nconst underTest = process.env.NODE_ENV === 'test' && file.url.includes('localhost');\nconst validURL =\nfile.url &&\n(file.url.startsWith('https:\nfile.url.startsWith('https:\nif (!underTest && !validURL) {\nthrow new Error(`Invalid URL, ${file.url}`);\n}\n}\nreturn converted.headlamp.plugin['extra-files'];\n}"
"static list(folder = defaultPluginsDir(), progressCallback: null | ProgressCallback = null) {\ntry {\nconst pluginsData: PluginData[] = [];\nconst entries = fs.readdirSync(folder, { withFileTypes: true });\nconst pluginFolders = entries.filter(entry => entry.isDirectory());\nfor (const pluginFolder of pluginFolders) {\nconst pluginDir = path.join(folder, pluginFolder.name);\nif (checkValidPluginFolder(pluginDir)) {\nconst packageJsonPath = path.join(pluginDir, 'package.json');\nconst packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf8'));\nconst pluginName = packageJson.name || pluginFolder.name;\nconst pluginTitle = packageJson.artifacthub.title;\nconst pluginVersion = packageJson.version || null;\nconst artifacthubURL = packageJson.artifacthub ? packageJson.artifacthub.url : null;\nconst repoName = packageJson.artifacthub ? packageJson.artifacthub.repoName : null;\nconst author = packageJson.artifacthub ? packageJson.artifacthub.author : null;\nconst artifacthubVersion = packageJson.artifacthub\n? packageJson.artifacthub.version\n: null;\npluginsData.push({\npluginName,\npluginTitle,\npluginVersion,\nfolderName: pluginFolder.name,\nartifacthubURL: artifacthubURL,\nrepoName: repoName,\nauthor: author,\nartifacthubVersion: artifacthubVersion,\n});\n}\n}\nif (progressCallback) {\nprogressCallback({ type: 'success', message: 'Plugins Listed', data: pluginsData });\n} else {\nreturn pluginsData;\n}\n} catch (e) {\nif (progressCallback) {\nprogressCallback({ type: 'error', message: e instanceof Error ? e.message : String(e) });\n} else {\nthrow e;\n}\n}\n}"
"function aggregateTypeInfo(value: any, node: TypeInfoNode, parentObjectCount: number): void {\nnode.presenceCount++;\nnode.parentObjectCount = parentObjectCount;\nconst type = typeof value;\nif (value === null) {\nnode.primitiveTypes.add('null');\n} else if (type === 'string') {\nnode.hasStringType = true;\nnode.primitiveTypes.add('string');\nif (node.stringLiterals.size < MAX_STRING_LITERALS) {\nif (value.length < MAX_STRING_LITERAL_LENGTH) {\nnode.stringLiterals.add(value);\n}\n} else {\nnode.stringLiterals.clear();\n}\n} else if (type === 'number') {\nnode.primitiveTypes.add('number');\n} else if (type === 'boolean') {\nnode.primitiveTypes.add('boolean');\n} else if (Array.isArray(value)) {\nnode.isArray = true;\nif (!node.arrayElementInfo) {\nnode.arrayElementInfo = createTypeInfoNode();\n}\nconst arrayPresenceCount = node.presenceCount;\nvalue.forEach(element => {\naggregateTypeInfo(element, node.arrayElementInfo!, arrayPresenceCount);\n});\nif (node.arrayElementInfo) node.arrayElementInfo.parentObjectCount = arrayPresenceCount;\n} else if (type === 'object') {\nnode.isObject = true;\nconst numObjectOccurrences = node.presenceCount;\nconst currentKeys = new Set<string>();\nfor (const key in value) {\nif (Object.prototype.hasOwnProperty.call(value, key)) {\ncurrentKeys.add(key);\nif (!node.objectProperties.has(key)) {\nnode.objectProperties.set(key, createTypeInfoNode());\n}\nconst propertyNode = node.objectProperties.get(key)!;\naggregateTypeInfo(value[key], propertyNode, numObjectOccurrences);\n}\n}\nnode.objectProperties.forEach((propNode, key) => {\nif (!currentKeys.has(key)) {\npropNode.parentObjectCount = numObjectOccurrences;\n}\n});\n}\n}"
"export function generateGlobalVarDeclarations(\nobjects: Record<string, any>[],\nmaxKeysPerObject?: number\n): string {\nif (!Array.isArray(objects)) {\nthrow new TypeError('Input must be an array.');\n}\nif (objects.length === 0) {\nreturn '';\n}\nconst topLevelPropertyNodes = new Map<string, TypeInfoNode>();\nlet validObjectCount = 0;\nfor (const obj of objects) {\nif (typeof obj === 'object' && obj !== null && !Array.isArray(obj)) {\nvalidObjectCount++;\nfor (const key in obj) {\nif (Object.prototype.hasOwnProperty.call(obj, key)) {\nif (!topLevelPropertyNodes.has(key)) {\ntopLevelPropertyNodes.set(key, createTypeInfoNode());\n}\nconst propertyRootNode = topLevelPropertyNodes.get(key)!;\naggregateTypeInfo(obj[key], propertyRootNode, 1);\n}\n}\n}\n}\nif (validObjectCount === 0) {\nreturn '';\n}\nconst declarations: string[] = [];\nconst sortedKeys = Array.from(topLevelPropertyNodes.keys()).sort();\nfor (const key of sortedKeys) {\nif (validIdentifierRegex.test(key)) {\nconst propertyNode = topLevelPropertyNodes.get(key)!;\npropertyNode.parentObjectCount = propertyNode.presenceCount;\nconst typeString = generateTypeString(propertyNode, undefined, maxKeysPerObject);\nif (typeString !== 'any' || propertyNode.presenceCount > 0) {\ndeclarations.push(`declare var ${key}: ${typeString};`);\n}\n}\n}\nreturn declarations.join('\n\n');\n}"
"function getContainerDisplayStatus(container: KubeContainerStatus) {\nconst state = container.state || {};\nlet color = 'grey';\nlet label = '';\nconst tooltipLines: string[] = [`Name: ${container.name}`];\nif (state.waiting) {\ncolor = 'orange';\nlabel = 'Waiting';\nif (state.waiting.reason) {\ntooltipLines.push(`Reason: ${state.waiting.reason}`);\n}\n} else if (state.terminated) {\ncolor = 'green';\nlabel = 'Terminated';\nif (state.terminated.reason === 'Error') {\ncolor = 'red';\n}\nif (state.terminated.reason) {\ntooltipLines.push(`Reason: ${state.terminated.reason}`);\n}\nif (state.terminated.exitCode !== undefined) {\ntooltipLines.push(`Exit Code: ${state.terminated.exitCode}`);\n}\nif (state.terminated.startedAt) {\ntooltipLines.push(`Started: ${new Date(state.terminated.startedAt).toLocaleString()}`);\n}\nif (state.terminated.finishedAt) {\ntooltipLines.push(`Finished: ${new Date(state.terminated.finishedAt).toLocaleString()}`);\n}\nif (container.restartCount > 0) {\ntooltipLines.push(`Restarts: ${container.restartCount}`);\n}\n} else if (state.running) {\ncolor = 'green';\nlabel = 'Running';\nif (state.running.startedAt) {\ntooltipLines.push(`Started: ${new Date(state.running.startedAt).toLocaleString()}`);\n}\nif (container.restartCount > 0) {\ntooltipLines.push(`Restarts: ${container.restartCount}`);\n}\n}\ntooltipLines.splice(1, 0, `Status: ${label}`);\nreturn {\ncolor,\nlabel,\ntooltip: <span style={{ whiteSpace: 'pre-line' }}>{tooltipLines.join('\n')}</span>,\n};\n}"
"export function getPluginBinDirectories(pluginsDir: string): string[] {\nif (!fs.existsSync(pluginsDir)) {\nreturn [];\n}\nconst binDirs: string[] = [];\ntry {\nconst entries = fs.readdirSync(pluginsDir, { withFileTypes: true });\nconst pluginFolders = entries.filter(entry => entry.isDirectory());\nfor (const pluginFolder of pluginFolders) {\nif (!validPluginBinFolder(pluginFolder.name)) {\ncontinue;\n}\nconst binDir = path.join(pluginsDir, pluginFolder.name, 'bin');\nif (fs.existsSync(binDir)) {\nif (process.platform !== 'win32') {\ntry {\nconst files = fs.readdirSync(binDir);\nfor (const file of files) {\nconst filePath = path.join(binDir, file);\nif (fs.statSync(filePath).isDirectory()) {\ncontinue;\n}\nfs.chmodSync(filePath, 0o755);\n}\n} catch (err) {\nconsole.error(`Error setting executable permissions in ${binDir}:`, err);\n}\n}\nbinDirs.push(binDir);\n}\n}\n} catch (err) {\nconsole.error(`Error scanning plugin directories in ${pluginsDir}:`, err);\n}\nreturn binDirs;\n}"
"function replaceUseId(node: any) {\nconst attributesToReplace = ['id', 'for', 'aria-describedby', 'aria-labelledby', 'aria-controls'];\nif (node.nodeType === Node.ELEMENT_NODE) {\nfor (const attr of node.attributes) {\nif (attributesToReplace.includes(attr.name)) {\nif (attr.value.includes(':')) {\nnode.setAttribute(attr.name, ':mock-test-id:');\n} else if (attr.name === 'id' && attr.value.includes('recharts')) {\nnode.setAttribute(attr.name, 'recharts-id');\n}\n}\n}\nif (node.className && typeof node.className === 'string') {\nnode.className = node.className.replace(\n/xterm-dom-renderer-owner-\d+/g,\n'xterm-dom-renderer-owner'\n);\n}\n}\nfor (const child of node.childNodes) {\nreplaceUseId(child);\n}\n}"
"handleWebSocketMessage(event: MessageEvent): void {\ntry {\nconst data = JSON.parse(event.data);\nif (!data.clusterId || !data.path) {\nreturn;\n}\nconst key = this.createKey(data.clusterId, data.path, data.query || '');\nif (data.type === 'COMPLETE') {\nthis.completedPaths.add(key);\nreturn;\n}\nlet update;\ntry {\nupdate = data.data ? JSON.parse(data.data) : data;\n} catch (err) {\nconsole.error('Failed to parse update data:', err);\nreturn;\n}\nif (update && typeof update === 'object') {\nconst listeners = this.listeners.get(key);\nif (listeners) {\nfor (const listener of listeners) {\ntry {\nlistener(update);\n} catch (err) {\nconsole.error('Failed to process WebSocket message:', err);\n}\n}\n}\n}\n} catch (err) {\nconsole.error('Failed to process WebSocket message:', err);\n}\n},"
"export function LinkStringFormat({ url, item, urlPath }: LinkStringFormatProps) {\nlet urlProtocol;\nlet formatURL;\nif ((url === '*' || !url) && !urlPath) {\nreturn <Typography>{url || ''}</Typography>;\n}\nif ((url === '*' || !url) && urlPath) {\nreturn <Typography>{urlPath}</Typography>;\n} else {\nif (!item.jsonData.spec?.tls) {\nurlProtocol = 'http:\n} else {\nisHttpsUsed(item, url) ? (urlProtocol = 'https:\n}\nconst rules: any[] | undefined = item.spec.rules;\nlet currentPathType;\nif (rules) {\nfor (let i = 0; i < rules.length; i++) {\nfor (let j = 0; j < rules[i].http.paths.length; j++) {\nif (rules[i].http.paths[j].path === urlPath) {\ncurrentPathType = rules[i].http.paths[j].pathType;\n}\n}\n}\n}\nfunction isValidURL(url: string): boolean {\ntry {\nnew URL(url);\n} catch (e) {\nreturn false;\n}\nreturn true;\n}\nif (!isValidURL(urlProtocol + url)) {\nconsole.debug(`Ingress' host ${url} is not a valid URL; displaying it without a link.`);\nreturn <Typography>{url}</Typography>;\n}\nformatURL = new URL(urlProtocol + url);\nif (formatURL && urlPath) {\nreturn (\n<Box style={{ display: 'flex', marginBottom: '5px' }}>\n<MuiLink\nhref={`${formatURL.protocol}\nstyle={{ marginRight: '5px' }}\n>\n{urlPath}\n</MuiLink>\n{`(${currentPathType})`}\n</Box>\n);\n}\nreturn <MuiLink href={formatURL.toString()}>{`${formatURL.toString()}`}</MuiLink>;\n}\n}"
"export const findNearestUnoccupiedTilesForGroup = (\nitems: { id: string; targetTile: Coords }[],\nscene: ReturnType<typeof useScene>,\nexcludeIds: string[] = []\n): Coords[] | null => {\nconst result: Coords[] = [];\nconst occupiedTiles = new Set<string>();\nscene.items.forEach(item => {\nif (!excludeIds.includes(item.id)) {\noccupiedTiles.add(`${item.tile.x},${item.tile.y}`);\n}\n});\nfor (const item of items) {\nlet foundTile: Coords | null = null;\nconst targetKey = `${item.targetTile.x},${item.targetTile.y}`;\nif (!occupiedTiles.has(targetKey)) {\nfoundTile = item.targetTile;\n} else {\nfor (let distance = 1; distance <= 10; distance++) {\nfor (let dx = -distance; dx <= distance; dx++) {\nfor (let dy = -distance; dy <= distance; dy++) {\nif (Math.abs(dx) === distance || Math.abs(dy) === distance) {\nconst checkTile = {\nx: item.targetTile.x + dx,\ny: item.targetTile.y + dy\n};\nconst checkKey = `${checkTile.x},${checkTile.y}`;\nif (!occupiedTiles.has(checkKey)) {\nconst itemAtTile = getItemAtTile({ tile: checkTile, scene });\nif (!itemAtTile || itemAtTile.type !== 'ITEM' || excludeIds.includes(itemAtTile.id)) {\nfoundTile = checkTile;\nbreak;\n}\n}\n}\n}\nif (foundTile) break;\n}\nif (foundTile) break;\n}\n}\nif (!foundTile) {\nreturn null;\n}\nresult.push(foundTile);\noccupiedTiles.add(`${foundTile.x},${foundTile.y}`);\n}\nreturn result;\n};"
"export const getConnectorDirectionIcon = (connectorTiles: Coords[]) => {\nif (connectorTiles.length < 2) return null;\nconst iconTile = connectorTiles[connectorTiles.length - 2];\nconst lastTile = connectorTiles[connectorTiles.length - 1];\nlet rotation;\nif (lastTile.x > iconTile.x) {\nif (lastTile.y > iconTile.y) {\nrotation = 135;\n} else if (lastTile.y < iconTile.y) {\nrotation = 45;\n} else {\nrotation = 90;\n}\n}\nif (lastTile.x < iconTile.x) {\nif (lastTile.y > iconTile.y) {\nrotation = -135;\n} else if (lastTile.y < iconTile.y) {\nrotation = -45;\n} else {\nrotation = -90;\n}\n}\nif (lastTile.x === iconTile.x) {\nif (lastTile.y > iconTile.y) {\nrotation = 180;\n} else if (lastTile.y < iconTile.y) {\nrotation = 0;\n} else {\nrotation = -90;\n}\n}\nreturn {\nx: iconTile.x * UNPROJECTED_TILE_SIZE + UNPROJECTED_TILE_SIZE / 2,\ny: iconTile.y * UNPROJECTED_TILE_SIZE + UNPROJECTED_TILE_SIZE / 2,\nrotation\n};\n};"
"public handleKeyPress(key: KeyEvent | string): boolean {\nconst keyName = typeof key === `string` ? key : key.name\nconst keySequence = typeof key === `string` ? key : key.sequence\nconst keyCtrl = typeof key === `string` ? false : key.ctrl\nconst keyShift = typeof key === `string` ? false : key.shift\nconst keyMeta = typeof key === `string` ? false : key.meta\nconst keySuper = typeof key === `string` ? false : key.super\nconst keyHyper = typeof key === `string` ? false : key.hyper\nconst bindingKey = getKeyBindingKey({\nname: keyName,\nctrl: keyCtrl,\nshift: keyShift,\nmeta: keyMeta,\nsuper: keySuper,\naction: `move-left` as TextareaAction,\n})\nconst action = this._keyBindingsMap.get(bindingKey)\nif (action) {\nconst handler = this._actionHandlers.get(action)\nif (handler) {\nreturn handler()\n}\n}\nif (keySequence && !keyCtrl && !keyMeta && !keySuper && !keyHyper) {\nconst firstCharCode = keySequence.charCodeAt(0)\nif (firstCharCode < 32) {\nreturn false\n}\nif (firstCharCode === 127) {\nreturn false\n}\nthis.insertText(keySequence)\nreturn true\n}\nreturn false\n}"
"private buildErrorView(): void {\nthis.flexDirection = `column`\nif (this.leftSide && this.leftSideAdded) {\nsuper.remove(this.leftSide.id)\nthis.leftSideAdded = false\n}\nif (this.rightSide && this.rightSideAdded) {\nsuper.remove(this.rightSide.id)\nthis.rightSideAdded = false\n}\nconst errorMessage = `Error parsing diff: ${this._parseError?.message || `Unknown error`}\n`\nif (!this.errorTextRenderable) {\nthis.errorTextRenderable = new TextRenderable(this.ctx, {\nid: this.id ? `${this.id}-error-text` : undefined,\ncontent: errorMessage,\nfg: `#ef4444`,\nwidth: `100%`,\nflexShrink: 0,\n})\nsuper.add(this.errorTextRenderable)\n} else {\nthis.errorTextRenderable.content = errorMessage\nconst errorTextIndex = this.getChildren().indexOf(this.errorTextRenderable)\nif (errorTextIndex === -1) {\nsuper.add(this.errorTextRenderable)\n}\n}\nif (!this.errorCodeRenderable) {\nthis.errorCodeRenderable = new CodeRenderable(this.ctx, {\nid: this.id ? `${this.id}-error-code` : undefined,\ncontent: this._diff,\nfiletype: `diff`,\nsyntaxStyle: this._syntaxStyle ?? SyntaxStyle.create(),\nwrapMode: this._wrapMode,\nconceal: this._conceal,\nwidth: `100%`,\nflexGrow: 1,\nflexShrink: 1,\n...(this._treeSitterClient !== undefined && { treeSitterClient: this._treeSitterClient }),\n})\nsuper.add(this.errorCodeRenderable)\n} else {\nthis.errorCodeRenderable.content = this._diff\nthis.errorCodeRenderable.wrapMode = this._wrapMode ?? `none`\nif (this._syntaxStyle) {\nthis.errorCodeRenderable.syntaxStyle = this._syntaxStyle\n}\nconst errorCodeIndex = this.getChildren().indexOf(this.errorCodeRenderable)\nif (errorCodeIndex === -1) {\nsuper.add(this.errorCodeRenderable)\n}\n}\n}"
"private createOrUpdateCodeRenderable(\nside: `left` | `right`,\ncontent: string,\nwrapMode: `word` | `char` | `none` | undefined,\ndrawUnstyledText?: boolean,\n): CodeRenderable {\nconst existingRenderable = side === `left` ? this.leftCodeRenderable : this.rightCodeRenderable\nif (!existingRenderable) {\nconst codeOptions: CodeOptions = {\nid: this.id ? `${this.id}-${side}-code` : undefined,\ncontent,\nfiletype: this._filetype,\nwrapMode,\nconceal: this._conceal,\nsyntaxStyle: this._syntaxStyle ?? SyntaxStyle.create(),\nwidth: `100%`,\nheight: `100%`,\n...(drawUnstyledText !== undefined && { drawUnstyledText }),\n...(this._selectionBg !== undefined && { selectionBg: this._selectionBg }),\n...(this._selectionFg !== undefined && { selectionFg: this._selectionFg }),\n...(this._treeSitterClient !== undefined && { treeSitterClient: this._treeSitterClient }),\n}\nconst newRenderable = new CodeRenderable(this.ctx, codeOptions)\nif (side === `left`) {\nthis.leftCodeRenderable = newRenderable\n} else {\nthis.rightCodeRenderable = newRenderable\n}\nreturn newRenderable\n} else {\nexistingRenderable.content = content\nexistingRenderable.wrapMode = wrapMode ?? `none`\nexistingRenderable.conceal = this._conceal\nif (drawUnstyledText !== undefined) {\nexistingRenderable.drawUnstyledText = drawUnstyledText\n}\nif (this._filetype !== undefined) {\nexistingRenderable.filetype = this._filetype\n}\nif (this._syntaxStyle !== undefined) {\nexistingRenderable.syntaxStyle = this._syntaxStyle\n}\nif (this._selectionBg !== undefined) {\nexistingRenderable.selectionBg = this._selectionBg\n}\nif (this._selectionFg !== undefined) {\nexistingRenderable.selectionFg = this._selectionFg\n}\nreturn existingRenderable\n}\n}"
"protected updateSelectionForMovement(shiftPressed: boolean, isBeforeMovement: boolean): void {\nif (!this.selectable) return\nif (!shiftPressed) {\nthis._ctx.clearSelection()\nthis._selectionAnchorState = null\nreturn\n}\nconst visualCursor = this.editorView.getVisualCursor()\nconst viewport = this.editorView.getViewport()\nconst cursorX = this.x + visualCursor.visualCol\nconst cursorY = this.y + visualCursor.visualRow\nif (isBeforeMovement) {\nif (!this._ctx.hasSelection) {\nthis._ctx.startSelection(this, cursorX, cursorY)\nthis._selectionAnchorState = {\nscreenX: cursorX,\nscreenY: cursorY,\nviewportX: viewport.offsetX,\nviewportY: viewport.offsetY,\n}\n} else if (!this._selectionAnchorState) {\nconst selection = this._ctx.getSelection()\nif (selection && selection.isActive) {\nthis._selectionAnchorState = {\nscreenX: selection.anchor.x,\nscreenY: selection.anchor.y,\nviewportX: viewport.offsetX,\nviewportY: viewport.offsetY,\n}\n}\n}\n} else {\nif (this._selectionAnchorState) {\nconst deltaY = viewport.offsetY - this._selectionAnchorState.viewportY\nconst deltaX = viewport.offsetX - this._selectionAnchorState.viewportX\nif (deltaY !== 0 || deltaX !== 0) {\nconst newAnchorX = this._selectionAnchorState.screenX - deltaX\nconst newAnchorY = this._selectionAnchorState.screenY - deltaY\nthis._ctx.startSelection(this, newAnchorX, newAnchorY)\nthis._ctx.updateSelection(this, cursorX, cursorY)\n} else {\nthis._ctx.updateSelection(this, cursorX, cursorY)\n}\n} else {\nthis._ctx.updateSelection(this, cursorX, cursorY)\n}\n}\n}"
"protected onMouseEvent(event: MouseEvent): void {\nif (event.type === `scroll`) {\nlet dir = event.scroll?.direction\nif (event.modifiers.shift)\ndir = dir === `up` ? `left` : dir === `down` ? `right` : dir === `right` ? `down` : `up`\nconst baseDelta = event.scroll?.delta ?? 0\nconst now = Date.now()\nconst multiplier = this.scrollAccel.tick(now)\nconst scrollAmount = baseDelta * multiplier\nif (dir === `up`) {\nthis.scrollAccumulatorY -= scrollAmount\nconst integerScroll = Math.trunc(this.scrollAccumulatorY)\nif (integerScroll !== 0) {\nthis.scrollTop += integerScroll\nthis.scrollAccumulatorY -= integerScroll\n}\n} else if (dir === `down`) {\nthis.scrollAccumulatorY += scrollAmount\nconst integerScroll = Math.trunc(this.scrollAccumulatorY)\nif (integerScroll !== 0) {\nthis.scrollTop += integerScroll\nthis.scrollAccumulatorY -= integerScroll\n}\n} else if (dir === `left`) {\nthis.scrollAccumulatorX -= scrollAmount\nconst integerScroll = Math.trunc(this.scrollAccumulatorX)\nif (integerScroll !== 0) {\nthis.scrollLeft += integerScroll\nthis.scrollAccumulatorX -= integerScroll\n}\n} else if (dir === `right`) {\nthis.scrollAccumulatorX += scrollAmount\nconst integerScroll = Math.trunc(this.scrollAccumulatorX)\nif (integerScroll !== 0) {\nthis.scrollLeft += integerScroll\nthis.scrollAccumulatorX -= integerScroll\n}\n}\nconst maxScrollTop = Math.max(0, this.scrollHeight - this.viewport.height)\nconst maxScrollLeft = Math.max(0, this.scrollWidth - this.viewport.width)\nif (maxScrollTop > 1 || maxScrollLeft > 1) {\nthis._hasManualScroll = true\n}\n}\nif (event.type === `drag` && event.isSelecting) {\nthis.updateAutoScroll(event.x, event.y)\n} else if (event.type === `up`) {\nthis.stopAutoScroll()\n}\n}"
"private offsetExcludingNewlines(offset: number): number {\nconst text = this.editBuffer.getText()\nlet displayWidthSoFar = 0\nlet newlineCount = 0\nlet i = 0\nwhile (i < text.length && displayWidthSoFar < offset) {\nif (text[i] === `\n`) {\ndisplayWidthSoFar++\nnewlineCount++\ni++\n} else {\nlet j = i\nwhile (j < text.length && text[j] !== `\n`) {\nj++\n}\nconst chunk = text.substring(i, j)\nconst chunkWidth = Bun.stringWidth(chunk)\nif (displayWidthSoFar + chunkWidth < offset) {\ndisplayWidthSoFar += chunkWidth\ni = j\n} else {\nfor (let k = i; k < j && displayWidthSoFar < offset; k++) {\nconst charWidth = Bun.stringWidth(text[k])\ndisplayWidthSoFar += charWidth\n}\nbreak\n}\n}\n}\nreturn offset - newlineCount\n}"
"private ensureVisibleTextBeforeHighlight(): void {\nconst content = this._content\nif (!this._filetype) {\nif (this.isDestroyed) return\nthis.textBuffer.setText(content)\nthis._shouldRenderTextBuffer = true\nthis.updateTextInfo()\nreturn\n}\nconst isInitialContent = this._streaming && !this._hadInitialContent\nconst shouldDrawUnstyledNow = this._streaming ? isInitialContent && this._drawUnstyledText : this._drawUnstyledText\nif (this._streaming && !isInitialContent) {\nif (this._lastHighlights.length > 0) {\nconst chunks = treeSitterToTextChunks(content, this._lastHighlights, this._syntaxStyle, {\nenabled: this._conceal,\n})\nconst partialStyledText = new StyledText(chunks)\nif (this.isDestroyed) return\nthis.textBuffer.setStyledText(partialStyledText)\nthis._shouldRenderTextBuffer = true\nthis.updateTextInfo()\n} else {\nif (this.isDestroyed) return\nthis.textBuffer.setText(content)\nthis._shouldRenderTextBuffer = true\nthis.updateTextInfo()\n}\n} else if (shouldDrawUnstyledNow) {\nif (this.isDestroyed) return\nthis.textBuffer.setText(content)\nthis._shouldRenderTextBuffer = true\nthis.updateTextInfo()\n} else {\nif (this.isDestroyed) return\nthis._shouldRenderTextBuffer = false\nthis.updateTextInfo()\n}\n}"
"private renderPalette(): void {\nif (this.isDestroyed) return\nconst buffer = this.frameBuffer\nbuffer.clear(RGBA.fromInts(30, 41, 59, 255))\nconst size = this._colors.length\nfor (let i = 0; i < size; i++) {\nconst color = this._colors[i]\nif (!color) continue\nconst row = Math.floor(i / this._colorsPerRow)\nconst col = i % this._colorsPerRow\nconst x = col * this._blockWidth\nconst y = row * this._blockHeight\nconst hex = color.replace(`#`, ``)\nconst r = parseInt(hex.substring(0, 2), 16)\nconst g = parseInt(hex.substring(2, 4), 16)\nconst b = parseInt(hex.substring(4, 6), 16)\nconst rgba = RGBA.fromInts(r, g, b)\nfor (let dy = 0; dy < this._blockHeight; dy++) {\nfor (let dx = 0; dx < this._blockWidth; dx++) {\nbuffer.setCell(x + dx, y + dy, ` `, RGBA.fromInts(255, 255, 255), rgba)\n}\n}\nif (this._blockWidth >= 3 && this._blockHeight >= 1) {\nconst indexStr = i.toString()\nconst textX = x + Math.floor((this._blockWidth - indexStr.length) / 2)\nconst textY = y + Math.floor(this._blockHeight / 2)\nconst brightness = (r * 299 + g * 587 + b * 114) / 1000\nconst textColor = brightness > 128 ? RGBA.fromInts(0, 0, 0) : RGBA.fromInts(255, 255, 255)\nif (indexStr.length <= this._blockWidth) {\nfor (let ci = 0; ci < indexStr.length; ci++) {\nbuffer.drawText(indexStr[ci], textX + ci, textY, textColor, rgba, TextAttributes.NONE)\n}\n}\n}\n}\n}"
"function isCompleteCsiSequence(data: string): `complete` | `incomplete` {\nif (!data.startsWith(ESC + `[`)) {\nreturn `complete`\n}\nif (data.length < 3) {\nreturn `incomplete`\n}\nconst payload = data.slice(2)\nconst lastChar = payload[payload.length - 1]\nconst lastCharCode = lastChar.charCodeAt(0)\nif (lastCharCode >= 0x40 && lastCharCode <= 0x7e) {\nif (payload.startsWith(`<`)) {\nconst mouseMatch = /^<\d+;\d+;\d+[Mm]$/.test(payload)\nif (mouseMatch) {\nreturn `complete`\n}\nif (lastChar === `M` || lastChar === `m`) {\nconst parts = payload.slice(1, -1).split(`;`)\nif (parts.length === 3 && parts.every((p) => /^\d+$/.test(p))) {\nreturn `complete`\n}\n}\nreturn `incomplete`\n}\nreturn `complete`\n}\nreturn `incomplete`\n}"
"function extractCompleteSequences(buffer: string): { sequences: string[]; remainder: string } {\nconst sequences: string[] = []\nlet pos = 0\nwhile (pos < buffer.length) {\nconst remaining = buffer.slice(pos)\nif (remaining.startsWith(ESC)) {\nlet seqEnd = 1\nwhile (seqEnd <= remaining.length) {\nconst candidate = remaining.slice(0, seqEnd)\nconst status = isCompleteSequence(candidate)\nif (status === `complete`) {\nsequences.push(candidate)\npos += seqEnd\nbreak\n} else if (status === `incomplete`) {\nseqEnd++\n} else {\nsequences.push(candidate)\npos += seqEnd\nbreak\n}\n}\nif (seqEnd > remaining.length) {\nreturn { sequences, remainder: remaining }\n}\n} else {\nsequences.push(remaining[0])\npos++\n}\n}\nreturn { sequences, remainder: `` }\n}"
"async function downloadAndCombineQueries(\nfiletype: string,\nqueryUrls: string[],\nassetsDir: string,\noutputPath: string,\nqueryType: `highlights` | `injections`,\nconfigPath: string,\n): Promise<string> {\nconst queriesDir = path.join(assetsDir, filetype)\nconst queryPath = path.join(queriesDir, `${queryType}.scm`)\nconst queryContents: string[] = []\nfor (let i = 0; i < queryUrls.length; i++) {\nconst queryUrl = queryUrls[i]\nif (queryUrl.startsWith(`./`)) {\nconsole.log(`    Using local query ${i + 1}/${queryUrls.length}: ${queryUrl}`)\ntry {\nconst localPath = path.resolve(path.dirname(configPath), queryUrl)\nconst content = await readFile(localPath, `utf-8`)\nif (content.trim()) {\nqueryContents.push(content)\nconsole.log(`    ✓ Loaded ${content.split(`\n`).length} lines from local file`)\n}\n} catch (error) {\nconsole.warn(`Failed to read local query from ${queryUrl}: ${error}`)\ncontinue\n}\n} else {\nconsole.log(`    Downloading query ${i + 1}/${queryUrls.length}: ${queryUrl}`)\ntry {\nconst response = await fetch(queryUrl)\nif (!response.ok) {\nconsole.warn(`Failed to download query from ${queryUrl}: ${response.statusText}`)\ncontinue\n}\nconst content = await response.text()\nif (content.trim()) {\nqueryContents.push(`; Query from: ${queryUrl}\n${content}`)\nconsole.log(`    ✓ Downloaded ${content.split(`\n`).length} lines`)\n}\n} catch (error) {\nconsole.warn(`Failed to download query from ${queryUrl}: ${error}`)\ncontinue\n}\n}\n}\nconst combinedContent = queryContents.join(`\n\n`)\nawait writeFile(queryPath, combinedContent, `utf-8`)\nconsole.log(`  Combined ${queryContents.length} queries into ${queryPath}`)\nreturn `./` + path.relative(path.dirname(outputPath), queryPath)\n}"
"private getSimpleHighlights(\nmatches: QueryCapture[],\ninjectionRanges: Map<string, Array<{ start: number; end: number }>>,\n): SimpleHighlight[] {\nconst highlights: SimpleHighlight[] = []\nconst flatInjectionRanges: Array<{ start: number; end: number; lang: string }> = []\nfor (const [lang, ranges] of injectionRanges.entries()) {\nfor (const range of ranges) {\nflatInjectionRanges.push({ ...range, lang })\n}\n}\nfor (const match of matches) {\nconst node = match.node\nlet isInjection = false\nlet injectionLang: string | undefined\nlet containsInjection = false\nfor (const injRange of flatInjectionRanges) {\nif (node.startIndex >= injRange.start && node.endIndex <= injRange.end) {\nisInjection = true\ninjectionLang = injRange.lang\nbreak\n} else if (node.startIndex <= injRange.start && node.endIndex >= injRange.end) {\ncontainsInjection = true\nbreak\n}\n}\nconst matchQuery = (match as any)._injectedQuery\nconst patternProperties = matchQuery?.setProperties?.[match.patternIndex]\nconst concealValue = patternProperties?.conceal ?? match.setProperties?.conceal\nconst concealLines = patternProperties?.conceal_lines ?? match.setProperties?.conceal_lines\nconst meta: any = {}\nif (isInjection && injectionLang) {\nmeta.isInjection = true\nmeta.injectionLang = injectionLang\n}\nif (containsInjection) {\nmeta.containsInjection = true\n}\nif (concealValue !== undefined) {\nmeta.conceal = concealValue\n}\nif (concealLines !== undefined) {\nmeta.concealLines = concealLines\n}\nif (Object.keys(meta).length > 0) {\nhighlights.push([node.startIndex, node.endIndex, match.name, meta])\n} else {\nhighlights.push([node.startIndex, node.endIndex, match.name])\n}\n}\nhighlights.sort((a, b) => a[0] - b[0])\nreturn highlights\n}"
"public updateSelection(currentRenderable: Renderable | undefined, x: number, y: number): void {\nif (this.currentSelection) {\nthis.currentSelection.focus = { x, y }\nif (this.selectionContainers.length > 0) {\nconst currentContainer = this.selectionContainers[this.selectionContainers.length - 1]\nif (!currentRenderable || !this.isWithinContainer(currentRenderable, currentContainer)) {\nconst parentContainer = currentContainer.parent || this.root\nthis.selectionContainers.push(parentContainer)\n} else if (currentRenderable && this.selectionContainers.length > 1) {\nlet containerIndex = this.selectionContainers.indexOf(currentRenderable)\nif (containerIndex === -1) {\nconst immediateParent = currentRenderable.parent || this.root\ncontainerIndex = this.selectionContainers.indexOf(immediateParent)\n}\nif (containerIndex !== -1 && containerIndex < this.selectionContainers.length - 1) {\nthis.selectionContainers = this.selectionContainers.slice(0, containerIndex + 1)\n}\n}\n}\nthis.notifySelectablesOfSelectionChange()\n}\n}"
"public mergeStyles(...styleNames: string[]): MergedStyle {\nthis.guard()\nconst cacheKey = styleNames.join(`:`)\nconst cached = this.mergedCache.get(cacheKey)\nif (cached) return cached\nconst styleDefinition: StyleDefinition = {}\nfor (const name of styleNames) {\nconst style = this.getStyle(name)\nif (!style) continue\nif (style.fg) styleDefinition.fg = style.fg\nif (style.bg) styleDefinition.bg = style.bg\nif (style.bold !== undefined) styleDefinition.bold = style.bold\nif (style.italic !== undefined) styleDefinition.italic = style.italic\nif (style.underline !== undefined) styleDefinition.underline = style.underline\nif (style.dim !== undefined) styleDefinition.dim = style.dim\n}\nconst attributes = createTextAttributes({\nbold: styleDefinition.bold,\nitalic: styleDefinition.italic,\nunderline: styleDefinition.underline,\ndim: styleDefinition.dim,\n})\nconst merged: MergedStyle = {\nfg: styleDefinition.fg,\nbg: styleDefinition.bg,\nattributes,\n}\nthis.mergedCache.set(cacheKey, merged)\nreturn merged\n}"
"insertBefore(obj: Renderable | VNode<any, any[]> | unknown, anchor?: Renderable | unknown): number {\nif (!anchor) {\nreturn this.add(obj)\n}\nif (!obj) {\nreturn -1\n}\nconst renderable = maybeMakeRenderable(this._ctx, obj)\nif (!renderable) {\nreturn -1\n}\nif (renderable.isDestroyed) {\nif (process.env.NODE_ENV !== `production`) {\nconsole.warn(`Renderable with id ${renderable.id} was already destroyed, skipping insertBefore`)\n}\nreturn -1\n}\nif (!isRenderable(anchor)) {\nthrow new Error(`Anchor must be a Renderable`)\n}\nif (anchor.isDestroyed) {\nif (process.env.NODE_ENV !== `production`) {\nconsole.warn(`Anchor with id ${anchor.id} was already destroyed, skipping insertBefore`)\n}\nreturn -1\n}\nif (!this.renderableMapById.has(anchor.id)) {\nthrow new Error(`Anchor does not exist`)\n}\nif (renderable.parent === this) {\nthis.yogaNode.removeChild(renderable.getLayoutNode())\nthis._childrenInLayoutOrder.splice(this._childrenInLayoutOrder.indexOf(renderable), 1)\n} else {\nthis.replaceParent(renderable)\nthis.needsZIndexSort = true\nthis.renderableMapById.set(renderable.id, renderable)\nthis._childrenInZIndexOrder.push(renderable)\nif (typeof renderable.onLifecyclePass === `function`) {\nthis._ctx.registerLifecyclePass(renderable)\n}\nif (renderable._liveCount > 0) {\nthis.propagateLiveCount(renderable._liveCount)\n}\n}\nthis.childrenPrimarySortDirty = true\nconst anchorIndex = this._childrenInLayoutOrder.indexOf(anchor)\nconst insertedIndex = Math.max(0, Math.min(anchorIndex, this._childrenInLayoutOrder.length))\nthis._childrenInLayoutOrder.splice(insertedIndex, 0, renderable)\nthis.yogaNode.insertChild(renderable.getLayoutNode(), insertedIndex)\nthis._shouldUpdateBefore.add(renderable)\nthis.requestRender()\nreturn insertedIndex\n}"
"static async downloadOrLoad(\nsource: string,\ncacheDir: string,\ncacheSubdir: string,\nfileExtension: string,\nuseHashForCache: boolean = true,\nfiletype?: string,\n): Promise<DownloadResult> {\nconst isUrl = source.startsWith(`http:\nif (isUrl) {\nlet cacheFileName: string\nif (useHashForCache) {\nconst hash = this.hashUrl(source)\ncacheFileName = filetype ? `${filetype}-${hash}${fileExtension}` : `${hash}${fileExtension}`\n} else {\ncacheFileName = path.basename(source)\n}\nconst cacheFile = path.join(cacheDir, cacheSubdir, cacheFileName)\nawait mkdir(path.dirname(cacheFile), { recursive: true })\ntry {\nconst cachedContent = await Bun.file(cacheFile).arrayBuffer()\nif (cachedContent.byteLength > 0) {\nconsole.log(`Loaded from cache: ${cacheFile} (${source})`)\nreturn { content: cachedContent, filePath: cacheFile }\n}\n} catch (error) {\n}\ntry {\nconsole.log(`Downloading from URL: ${source}`)\nconst response = await fetch(source)\nif (!response.ok) {\nreturn { error: `Failed to fetch from ${source}: ${response.statusText}` }\n}\nconst content = await response.arrayBuffer()\ntry {\nawait writeFile(cacheFile, Buffer.from(content))\nconsole.log(`Cached: ${source}`)\n} catch (cacheError) {\nconsole.warn(`Failed to cache: ${cacheError}`)\n}\nreturn { content, filePath: cacheFile }\n} catch (error) {\nreturn { error: `Error downloading from ${source}: ${error}` }\n}\n} else {\ntry {\nconsole.log(`Loading from local path: ${source}`)\nconst content = await Bun.file(source).arrayBuffer()\nreturn { content, filePath: source }\n} catch (error) {\nreturn { error: `Error loading from local path ${source}: ${error}` }\n}\n}\n}"
"function getResizeDirection(\nmouseX: number,\nmouseY: number,\nboxLeft: number,\nboxTop: number,\nboxWidth: number,\nboxHeight: number,\n): `nw` | `ne` | `sw` | `se` | `n` | `s` | `w` | `e` | null {\nconst onLeftBorder = mouseX === boxLeft\nconst onRightBorder = mouseX === boxLeft + boxWidth - 1\nconst onTopBorder = mouseY === boxTop\nconst onBottomBorder = mouseY === boxTop + boxHeight - 1\nconst withinHorizontalBounds = mouseX >= boxLeft && mouseX <= boxLeft + boxWidth - 1\nconst withinVerticalBounds = mouseY >= boxTop && mouseY <= boxTop + boxHeight - 1\nconst left = onLeftBorder && withinVerticalBounds\nconst right = onRightBorder && withinVerticalBounds\nconst top = onTopBorder && withinHorizontalBounds\nconst bottom = onBottomBorder && withinHorizontalBounds\nif (top && left) return `nw`\nif (top && right) return `ne`\nif (bottom && left) return `sw`\nif (bottom && right) return `se`\nif (top) return `n`\nif (bottom) return `s`\nif (left) return `w`\nif (right) return `e`\nreturn null\n}"
"function setProperty(instance: Instance, type: Type, propKey: string, propValue: any, oldPropValue?: any) {\nswitch (propKey) {\ncase `onChange`:\nif (instance instanceof InputRenderable) {\ninitEventListeners(instance, InputRenderableEvents.CHANGE, propValue, oldPropValue)\n} else if (instance instanceof SelectRenderable) {\ninitEventListeners(instance, SelectRenderableEvents.SELECTION_CHANGED, propValue, oldPropValue)\n} else if (instance instanceof TabSelectRenderable) {\ninitEventListeners(instance, TabSelectRenderableEvents.SELECTION_CHANGED, propValue, oldPropValue)\n}\nbreak\ncase `onInput`:\nif (instance instanceof InputRenderable) {\ninitEventListeners(instance, InputRenderableEvents.INPUT, propValue, oldPropValue)\n}\nbreak\ncase `onSubmit`:\nif (instance instanceof InputRenderable) {\ninitEventListeners(instance, InputRenderableEvents.ENTER, propValue, oldPropValue)\n}\nbreak\ncase `onSelect`:\nif (instance instanceof SelectRenderable) {\ninitEventListeners(instance, SelectRenderableEvents.ITEM_SELECTED, propValue, oldPropValue)\n} else if (instance instanceof TabSelectRenderable) {\ninitEventListeners(instance, TabSelectRenderableEvents.ITEM_SELECTED, propValue, oldPropValue)\n}\nbreak\ncase `focused`:\nif (isRenderable(instance)) {\nif (!!propValue) {\ninstance.focus()\n} else {\ninstance.blur()\n}\n}\nbreak\ncase `style`:\nsetStyle(instance, propValue, oldPropValue)\nbreak\ncase `children`:\nbreak\ndefault:\ninstance[propKey] = propValue\n}\n}"
"onLocalSelectionChanged(localSelection: LocalSelectionBounds | null, width: number, height: number): boolean {\nconst previousSelection = this.localSelection\nif (!localSelection?.isActive) {\nthis.localSelection = null\nreturn previousSelection !== null\n}\nconst text = this.getText()\nconst font = this.getFont()\nconst selStart = { x: localSelection.anchorX, y: localSelection.anchorY }\nconst selEnd = { x: localSelection.focusX, y: localSelection.focusY }\nif (height - 1 < selStart.y || 0 > selEnd.y) {\nthis.localSelection = null\nreturn previousSelection !== null\n}\nlet startCharIndex = 0\nlet endCharIndex = text.length\nif (selStart.y > height - 1) {\nthis.localSelection = null\nreturn previousSelection !== null\n} else if (selStart.y >= 0 && selStart.y <= height - 1) {\nif (selStart.x > 0) {\nstartCharIndex = coordinateToCharacterIndex(selStart.x, text, font)\n}\n}\nif (selEnd.y < 0) {\nthis.localSelection = null\nreturn previousSelection !== null\n} else if (selEnd.y >= 0 && selEnd.y <= height - 1) {\nif (selEnd.x >= 0) {\nendCharIndex = coordinateToCharacterIndex(selEnd.x, text, font)\n} else {\nendCharIndex = 0\n}\n}\nif (startCharIndex < endCharIndex && startCharIndex >= 0 && endCharIndex <= text.length) {\nthis.localSelection = { start: startCharIndex, end: endCharIndex }\n} else {\nthis.localSelection = null\n}\nreturn (\npreviousSelection?.start !== this.localSelection?.start || previousSelection?.end !== this.localSelection?.end\n)\n}"
"export function instantiate<NodeType extends VNode | Renderable>(\nctx: RenderContext,\nnode: NodeType,\n): InstantiateFn<NodeType> {\nif (isRenderable(node)) return node\nif (!node || typeof node !== `object`) {\nthrow new TypeError(`mount() received an invalid vnode`)\n}\nconst vnode = node as VNode\nconst { type, props } = vnode\nconst children = flattenChildren(vnode.children || [])\nconst delegateMap = (vnode as any).__delegateMap as Record<string, string> | undefined\nif (isRenderableConstructor(type)) {\nconst instance = new type(ctx, (props || {}) as any)\nfor (const child of children) {\nif (isRenderable(child)) {\ninstance.add(child)\n} else {\nconst mounted = instantiate(ctx, child as NodeType)\ninstance.add(mounted)\n}\n}\nconst delegatedInstance = wrapWithDelegates(instance, delegateMap)\nconst pendingCalls = (vnode as any).__pendingCalls as PendingCall[] | undefined\nif (pendingCalls) {\nfor (const call of pendingCalls) {\nif (call.isProperty) {\n;(delegatedInstance as any)[call.method] = call.args[0]\n} else {\n;(delegatedInstance as any)[call.method].apply(delegatedInstance, call.args)\n}\n}\n}\nreturn delegatedInstance\n}\nconst resolved = (type as FunctionalConstruct)(props || ({} as any), children)\nconst inst = instantiate(ctx, resolved)\nreturn wrapWithDelegates(inst, delegateMap) as InstantiateFn<NodeType>\n}"
"function setStyle(instance: Instance, styles: any, oldStyles: any) {\nif (styles && typeof styles === `object`) {\nif (oldStyles != null) {\nfor (const styleName in styles) {\nconst value = styles[styleName]\nif (styles.hasOwnProperty(styleName) && oldStyles[styleName] !== value) {\ninstance[styleName] = value\n}\n}\n} else {\nfor (const styleName in styles) {\nif (styles.hasOwnProperty(styleName)) {\nconst value = styles[styleName]\ninstance[styleName] = value\n}\n}\n}\n}\n}"
"private updateYogaPosition(position: Position): void {\nconst node = this.yogaNode\nconst { top, right, bottom, left } = position\nif (isPositionType(top)) {\nif (top === `auto`) {\nnode.setPositionAuto(Edge.Top)\n} else {\nnode.setPosition(Edge.Top, top)\n}\n}\nif (isPositionType(right)) {\nif (right === `auto`) {\nnode.setPositionAuto(Edge.Right)\n} else {\nnode.setPosition(Edge.Right, right)\n}\n}\nif (isPositionType(bottom)) {\nif (bottom === `auto`) {\nnode.setPositionAuto(Edge.Bottom)\n} else {\nnode.setPosition(Edge.Bottom, bottom)\n}\n}\nif (isPositionType(left)) {\nif (left === `auto`) {\nnode.setPositionAuto(Edge.Left)\n} else {\nnode.setPosition(Edge.Left, left)\n}\n}\nthis.requestRender()\n}"
"export function getCharacterPositions(text: string, font: keyof typeof fonts = `tiny`): number[] {\nconst fontDef = getParsedFont(font)\nif (!fontDef) {\nreturn [0]\n}\nconst positions: number[] = [0]\nlet currentX = 0\nfor (let i = 0; i < text.length; i++) {\nconst char = text[i].toUpperCase()\nconst charDef = fontDef.chars[char]\nlet charWidth = 0\nif (!charDef) {\nconst spaceChar = fontDef.chars[` `]\nif (spaceChar && spaceChar[0]) {\nfor (const segment of spaceChar[0]) {\ncharWidth += segment.text.length\n}\n} else {\ncharWidth = 1\n}\n} else if (charDef[0]) {\nfor (const segment of charDef[0]) {\ncharWidth += segment.text.length\n}\n}\ncurrentX += charWidth\nif (i < text.length - 1) {\ncurrentX += fontDef.letterspace_size\n}\npositions.push(currentX)\n}\nreturn positions\n}"
"private _processLogEntry(logEntry: [Date, LogLevel, any[], CallerInfo | null]): DisplayLine[] {\nconst [date, level, args, callerInfo] = logEntry\nconst displayLines: DisplayLine[] = []\nconst timestamp = this.formatTimestamp(date)\nconst callerSource = callerInfo ? `${callerInfo.fileName}:${callerInfo.lineNumber}` : `unknown`\nconst prefix = `[${timestamp}] [${level}]` + (this._debugModeEnabled ? ` [${callerSource}]` : ``) + ` `\nconst formattedArgs = this.formatArguments(args)\nconst initialLines = formattedArgs.split(`\n`)\nfor (let i = 0; i < initialLines.length; i++) {\nconst lineText = initialLines[i]\nconst isFirstLineOfEntry = i === 0\nconst availableWidth = this.consoleWidth - 1 - (isFirstLineOfEntry ? 0 : INDENT_WIDTH)\nconst linePrefix = isFirstLineOfEntry ? prefix : ` `.repeat(INDENT_WIDTH)\nconst textToWrap = isFirstLineOfEntry ? linePrefix + lineText : lineText\nlet currentPos = 0\nwhile (currentPos < textToWrap.length || (isFirstLineOfEntry && currentPos === 0 && textToWrap.length === 0)) {\nconst segment = textToWrap.substring(currentPos, currentPos + availableWidth)\nconst isFirstSegmentOfLine = currentPos === 0\ndisplayLines.push({\ntext: isFirstSegmentOfLine && !isFirstLineOfEntry ? linePrefix + segment : segment,\nlevel: level,\nindent: !isFirstLineOfEntry || !isFirstSegmentOfLine,\n})\ncurrentPos += availableWidth\nif (isFirstLineOfEntry && currentPos === 0 && textToWrap.length === 0) break\n}\n}\nreturn displayLines\n}"
"export function measureText({ text, font = `tiny` }: { text: string; font?: keyof typeof fonts }): {\nwidth: number\nheight: number\n} {\nconst fontDef = getParsedFont(font)\nif (!fontDef) {\nconsole.warn(`Font '${font}' not found`)\nreturn { width: 0, height: 0 }\n}\nlet currentX = 0\nfor (let i = 0; i < text.length; i++) {\nconst char = text[i].toUpperCase()\nconst charDef = fontDef.chars[char]\nif (!charDef) {\nconst spaceChar = fontDef.chars[` `]\nif (spaceChar && spaceChar[0]) {\nlet spaceWidth = 0\nfor (const segment of spaceChar[0]) {\nspaceWidth += segment.text.length\n}\ncurrentX += spaceWidth\n} else {\ncurrentX += 1\n}\ncontinue\n}\nlet charWidth = 0\nif (charDef[0]) {\nfor (const segment of charDef[0]) {\ncharWidth += segment.text.length\n}\n}\ncurrentX += charWidth\nif (i < text.length - 1) {\ncurrentX += fontDef.letterspace_size\n}\n}\nreturn {\nwidth: currentX,\nheight: fontDef.lines,\n}\n}"
"function parseNoticeExtras(extras: NoticeExtra[]): ParsedNoticeExtras {\nlet params: Record<string, unknown> | undefined;\nlet raw: unknown;\nlet duration: number | undefined;\nfor (const extra of extras) {\nif (extra === undefined) continue;\nif (typeof extra === `number` && duration === undefined) {\nduration = extra;\ncontinue;\n}\nif (isPlainRecord(extra)) {\nif (!params) {\nparams = extra;\ncontinue;\n}\nif (!raw) {\nraw = extra;\ncontinue;\n}\n}\nif (!raw) {\nraw = extra;\ncontinue;\n}\nif (!params && isPlainRecord(extra)) {\nparams = extra;\ncontinue;\n}\nif (duration === undefined && typeof extra === `number`) {\nduration = extra;\n}\n}\nreturn { params, raw, duration };\n}"
"const compareVersionParts = (a: VersionParts, b: VersionParts): number => {\nconst length = Math.max(a.main.length, b.main.length);\nfor (let i = 0; i < length; i += 1) {\nconst diff = (a.main[i] ?? 0) - (b.main[i] ?? 0);\nif (diff !== 0) return diff > 0 ? 1 : -1;\n}\nif (a.pre.length === 0 && b.pre.length === 0) return 0;\nif (a.pre.length === 0) return 1;\nif (b.pre.length === 0) return -1;\nconst preLen = Math.max(a.pre.length, b.pre.length);\nfor (let i = 0; i < preLen; i += 1) {\nconst aToken = a.pre[i];\nconst bToken = b.pre[i];\nif (aToken === undefined) return -1;\nif (bToken === undefined) return 1;\nif (typeof aToken === `number` && typeof bToken === `number`) {\nif (aToken > bToken) return 1;\nif (aToken < bToken) return -1;\ncontinue;\n}\nif (typeof aToken === `number`) return -1;\nif (typeof bToken === `number`) return 1;\nif (aToken > bToken) return 1;\nif (aToken < bToken) return -1;\n}\nreturn 0;\n};"
"const LogItem = ({ value, searchState }: Props) => {\nconst renderHighlightText = (text: string) => {\nif (!searchState?.text.trim()) return text;\ntry {\nconst searchText = searchState.text;\nlet pattern: string;\nif (searchState.useRegularExpression) {\ntry {\nnew RegExp(searchText);\npattern = searchText;\n} catch {\npattern = searchText.replace(/[.*+?^${}()|[\]\\]/g, `\\$&`);\n}\n} else {\nconst escaped = searchText.replace(/[.*+?^${}()|[\]\\]/g, `\\$&`);\npattern = searchState.matchWholeWord ? `\\b${escaped}\\b` : escaped;\n}\nconst flags = searchState.matchCase ? `g` : `gi`;\nconst regex = new RegExp(pattern, flags);\nconst elements: ReactNode[] = [];\nlet lastIndex = 0;\nlet match: RegExpExecArray | null;\nwhile ((match = regex.exec(text)) !== null) {\nconst start = match.index;\nconst matchText = match[0];\nif (matchText === ``) {\nregex.lastIndex += 1;\ncontinue;\n}\nif (start > lastIndex) {\nelements.push(text.slice(lastIndex, start));\n}\nelements.push(\n<span key={`highlight-${start}`} className=`highlight`>\n{matchText}\n</span>,\n);\nlastIndex = start + matchText.length;\n}\nif (lastIndex < text.length) {\nelements.push(text.slice(lastIndex));\n}\nreturn elements.length ? elements : text;\n} catch {\nreturn text;\n}\n};\nreturn (\n<Item>\n<div>\n<span className=`time`>{renderHighlightText(value.time || ``)}</span>\n<span className=`type` data-type={value.type.toLowerCase()}>\n{renderHighlightText(value.type)}\n</span>\n</div>\n<div>\n<span className=`data`>{renderHighlightText(value.payload)}</span>\n</div>\n</Item>\n);\n};"
"export const getIpInfo = async (): Promise<IpInfo> => {\nconst maxRetries = 3;\nconst serviceTimeout = 5000;\nconst overallTimeout = 20000;\nconst overallTimeoutController = new AbortController();\nconst overallTimeoutId = setTimeout(() => {\noverallTimeoutController.abort();\n}, overallTimeout);\ntry {\nconst shuffledServices = shuffleServices();\nlet lastError: Error | null = null;\nfor (const service of shuffledServices) {\ndebugLog(`尝试IP检测服务: ${service.url}`);\nfor (let attempt = 0; attempt < maxRetries; attempt++) {\nlet timeoutId: ReturnType<typeof setTimeout> | null = null;\ntry {\nconst timeoutController = new AbortController();\ntimeoutId = setTimeout(() => {\ntimeoutController.abort();\n}, service.timeout || serviceTimeout);\nconsole.debug(`Fetching IP information...`);\nconst response = await fetch(service.url, {\nmethod: `GET`,\nsignal: timeoutController.signal,\nconnectTimeout: service.timeout || serviceTimeout,\n});\nconst data = await response.json();\nif (timeoutId) clearTimeout(timeoutId);\nif (data && data.ip) {\ndebugLog(`IP检测成功，使用服务: ${service.url}`);\nreturn service.mapping(data);\n} else {\nthrow new Error(`无效的响应格式 from ${service.url}`);\n}\n} catch (error: any) {\nif (timeoutId) clearTimeout(timeoutId);\nlastError = error;\nconsole.warn(\n`尝试 ${attempt + 1}/${maxRetries} 失败 (${service.url}):`,\nerror,\n);\nif (error.name === `AbortError`) {\nthrow error;\n}\nif (attempt < maxRetries - 1) {\nawait new Promise((resolve) => setTimeout(resolve, 1000));\n}\n}\n}\n}\nif (lastError) {\nthrow new Error(`所有IP检测服务都失败: ${lastError.message}`);\n} else {\nthrow new Error(`没有可用的IP检测服务`);\n}\n} finally {\nclearTimeout(overallTimeoutId);\n}\n};"
"function findCodeBlocks(docText: string): CodeBlockInfo[] {\nconst lines = docText.split(/\r?\n/)\nconst codeBlocks: CodeBlockInfo[] = []\nfor (let i = 0; i < lines.length; i++) {\nconst line = lines[i]\nconst trimmedLine = line.trimStart()\nif (trimmedLine.startsWith('```')) {\nconst indent = line.slice(0, line.length - trimmedLine.length)\nconst codeBlockLevel = line.match(/^\s*`+/)![0]\nconst backtickCount = codeBlockLevel.trim().length\nconst startLine = i\nif (backtickCount !== 3) {\ncontinue\n}\nlet endLine = i\nfor (let j = i + 1; j < lines.length; j++) {\nif (lines[j].startsWith(codeBlockLevel)) {\nendLine = j\nbreak\n}\n}\nif (endLine > startLine) {\ncodeBlocks.push({\nstartLine: startLine + 1,\nendLine,\nindent,\n})\n}\ni = endLine\n}\n}\nreturn codeBlocks\n}"
"function findRegion(lines: Array<string>, regionName: string) {\nlet chosen: { re: (typeof markers)[number], start: number } | null = null\nfor (let i = 0; i < lines.length; i++) {\nfor (const re of markers) {\nif (re.start.exec(lines[i])?.[1] === regionName) {\nchosen = { re, start: i + 1 }\nbreak\n}\n}\nif (chosen)\nbreak\n}\nif (!chosen)\nreturn null\nlet counter = 1\nfor (let i = chosen.start; i < lines.length; i++) {\nif (chosen.re.start.exec(lines[i])?.[1] === regionName) {\ncounter++\ncontinue\n}\nconst endRegion = chosen.re.end.exec(lines[i])?.[1]\nif (endRegion === regionName || endRegion === '') {\nif (--counter === 0) {\nreturn {\n...chosen,\nend: i,\n}\n}\n}\n}\nreturn null\n}"
"export function parseSync(\nmarkdown: string,\nfilepath: string,\noptions: SlidevParserOptions = {},\n): SlidevMarkdown {\nconst lines = markdown.split(options.preserveCR ? '\n' : /\r?\n/g)\nconst slides: SourceSlideInfo[] = []\nlet start = 0\nlet contentStart = 0\nfunction slice(end: number) {\nif (start === end)\nreturn\nconst raw = lines.slice(start, end).join('\n')\nconst slide: SourceSlideInfo = {\n...parseSlide(raw, options),\nfilepath,\nindex: slides.length,\nstart,\ncontentStart,\nend,\n}\nslides.push(slide)\nstart = end + 1\ncontentStart = end + 1\n}\nfor (let i = 0; i < lines.length; i++) {\nconst line = lines[i].trimEnd()\nif (line.startsWith('---')) {\nslice(i)\nconst next = lines[i + 1]\nif (line[3] !== '-' && next?.trim()) {\nstart = i\nfor (i += 1; i < lines.length; i++) {\nif (lines[i].trimEnd() === '---')\nbreak\n}\ncontentStart = i + 1\n}\n}\nelse if (line.trimStart().startsWith('```')) {\nconst codeBlockLevel = line.match(/^\s*`+/)![0]\nlet j = i + 1\nfor (; j < lines.length; j++) {\nif (lines[j].startsWith(codeBlockLevel))\nbreak\n}\nif (j !== lines.length)\ni = j\n}\n}\nif (start <= lines.length - 1)\nslice(lines.length)\nreturn {\nfilepath,\nraw: markdown,\nslides,\n}\n}"
"transform(data) {\nconst derivesMap: Record<string, string[]> = {}\nfor (const md of data) {\nconst name = basename(md.url, '.md')\nif (name === 'index' || name === 'features')\ncontinue\nfor (const depend of md.frontmatter.depends ?? []) {\nconst dependName = depend.match(/\/([\w-]+)($|#)/)?.[1]\nif (dependName) {\nderivesMap[dependName] ??= []\nderivesMap[dependName].push(`features/${name}`)\n}\n}\n}\nconst result: Record<string, Feature> = {}\nfor (const md of data) {\nconst name = basename(md.url, '.md')\nif (name === 'index' || name === 'features')\ncontinue\nconst title = md.src?.match(/^# (.*)$/m)?.[1]?.trim() ?? name\nconst derives = md.frontmatter.derives ?? []\nfor (const d of derivesMap[name] ?? []) {\nif (!derives.includes(d)) {\nderives.push(d)\n}\n}\nresult[name] = {\nname,\ntitle,\nlink: `/features/${name}.html`,\ndescription: md.frontmatter.description ?? '',\ndepends: md.frontmatter.depends ?? [],\nrelates: md.frontmatter.relates ?? [],\nderives,\ntags: md.frontmatter.tags ?? [],\nsince: md.frontmatter.since,\n}\n}\nreturn result\n},"
"export function useEmbeddedControl() {\nconst nav = useNav()\nconst clientId = `${Date.now()}`\nwindow.addEventListener('message', ({ data }) => {\nif (data && data.target === 'slidev') {\nif (data.type === 'navigate') {\nif (data.no || data.clicks) {\nnav.go(+data.no, +data.clicks || 0)\n}\nelse if (typeof data.operation === 'string') {\nconst fn = nav[data.operation as keyof typeof nav]\nif (typeof fn === 'function')\n(fn as any)(...(data.args ?? []))\n}\n}\nelse if (data.type === 'css-vars') {\nconst root = document.documentElement\nfor (const [key, value] of Object.entries(data.vars || {}))\nroot.style.setProperty(key, value as any)\n}\nelse if (data.type === 'color-schema') {\nisDark.value = data.color === 'dark'\n}\n}\n})\nif (nav.isEmbedded.value) {\nthrottledWatch(\n[nav.currentSlideNo, nav.clicks, nav.hasNext, nav.hasPrev],\n([no, clicks, hasNext, hasPrev]) => {\nwindow.parent.postMessage(\n{\ntarget: 'slidev',\nclientId,\nnavState: {\nno,\nclicks,\nhasNext,\nhasPrev,\n},\n},\n'*',\n)\n},\n{\nthrottle: 300,\nimmediate: true,\n},\n)\n}\n}"
"function transformImports(context: ts.TransformationContext): ts.Transformer<ts.SourceFile> {\nconst { factory } = context\nconst { isImportDeclaration, isNamedImports, NodeFlags } = tsModule!\nreturn (sourceFile: ts.SourceFile) => {\nconst statements = [...sourceFile.statements]\nfor (let i = 0; i < statements.length; i++) {\nconst statement = statements[i]\nif (!isImportDeclaration(statement))\ncontinue\nlet bindingPattern: ts.ObjectBindingPattern | ts.Identifier\nconst namedBindings = statement.importClause?.namedBindings\nconst bindings: ts.BindingElement[] = []\nif (statement.importClause?.name)\nbindings.push(factory.createBindingElement(undefined, factory.createIdentifier('default'), statement.importClause.name))\nif (namedBindings) {\nif (isNamedImports(namedBindings)) {\nfor (const specifier of namedBindings.elements)\nbindings.push(factory.createBindingElement(undefined, specifier.propertyName, specifier.name))\nbindingPattern = factory.createObjectBindingPattern(bindings)\n}\nelse {\nbindingPattern = factory.createIdentifier(namedBindings.name.text)\n}\n}\nelse {\nbindingPattern = factory.createObjectBindingPattern(bindings)\n}\nconst newStatement = factory.createVariableStatement(\nundefined,\nfactory.createVariableDeclarationList(\n[\nfactory.createVariableDeclaration(\nbindingPattern,\nundefined,\nundefined,\nfactory.createAwaitExpression(\nfactory.createCallExpression(\nfactory.createIdentifier('import'),\nundefined,\n[statement.moduleSpecifier],\n),\n),\n),\n],\nNodeFlags.Const,\n),\n)\nstatements[i] = newStatement\n}\nreturn factory.updateSourceFile(sourceFile, statements)\n}\n}"
"function math_inline(state: any, silent: boolean) {\nlet match, token, res, pos\nif (state.src[state.pos] !== '$')\nreturn false\nres = isValidDelim(state, state.pos)\nif (!res.can_open) {\nif (!silent)\nstate.pending += '$'\nstate.pos += 1\nreturn true\n}\nconst start = state.pos + 1\nmatch = start\nwhile ((match = state.src.indexOf('$', match)) !== -1) {\npos = match - 1\nwhile (state.src[pos] === '\\') pos -= 1\nif (((match - pos) % 2) === 1)\nbreak\nmatch += 1\n}\nif (match === -1) {\nif (!silent)\nstate.pending += '$'\nstate.pos = start\nreturn true\n}\nif (match - start === 0) {\nif (!silent)\nstate.pending += '$$'\nstate.pos = start + 1\nreturn true\n}\nres = isValidDelim(state, match)\nif (!res.can_close) {\nif (!silent)\nstate.pending += '$'\nstate.pos = start\nreturn true\n}\nif (!silent) {\ntoken = state.push('math_inline', 'math', 0)\ntoken.markup = '$'\ntoken.content = state.src.slice(start, match)\n}\nstate.pos = match + 1\nreturn true\n}"
"function math_block(state: any, start: number, end: number, silent: boolean) {\nlet firstLine\nlet lastLine\nlet next\nlet lastPos\nlet found = false\nlet pos = state.bMarks[start] + state.tShift[start]\nlet max = state.eMarks[start]\nif (pos + 2 > max)\nreturn false\nif (state.src.slice(pos, pos + 2) !== '$$')\nreturn false\npos += 2\nfirstLine = state.src.slice(pos, max)\nif (silent)\nreturn true\nif (firstLine.trim().slice(-2) === '$$') {\nfirstLine = firstLine.trim().slice(0, -2)\nfound = true\n}\nfor (next = start; !found;) {\nnext++\nif (next >= end)\nbreak\npos = state.bMarks[next] + state.tShift[next]\nmax = state.eMarks[next]\nif (pos < max && state.tShift[next] < state.blkIndent) {\nbreak\n}\nif (state.src.slice(pos, max).trim().slice(-2) === '$$') {\nlastPos = state.src.slice(0, max).lastIndexOf('$$')\nlastLine = state.src.slice(pos, lastPos)\nfound = true\n}\n}\nstate.line = next + 1\nconst token = state.push('math_block', 'math', 0)\ntoken.block = true\ntoken.content = (firstLine && firstLine.trim() ? `${firstLine}\n` : '')\n+ state.getLines(start + 1, next, state.tShift[start], true)\n+ (lastLine && lastLine.trim() ? lastLine : '')\ntoken.map = [start, state.line]\ntoken.markup = '$$'\nreturn true\n}"
